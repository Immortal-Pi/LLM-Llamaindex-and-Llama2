{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0706130c-07d3-432a-bfd8-e51ca29d1e7f",
   "metadata": {},
   "source": [
    "# Retrieval augmented generation\n",
    "\n",
    "## Objective\n",
    "- RAG system\n",
    "- load PDF documents\n",
    "- index those PDF documents\n",
    "- query PDF using llama2 index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fab5e44-0dfe-46c1-a61b-3b171df7e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @thomasmuller1521\n",
    "# 6 months ago\n",
    "# The libraries changed:\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "# from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "# import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0c0774a-7f0f-4b2b-a77a-9251924742a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b70b700-c0b2-4e9f-9bb5-bc36f1e7b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ace92a3-ccb2-4252-b8c5-ba63f3888877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='8fef814b-6ac0-4557-b5f9-6de4843f5951', embedding=None, metadata={'page_label': 'Cover', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='334fb4a8-40f3-4c95-a542-8896d4c5e1c3', embedding=None, metadata={'page_label': 'i', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='DATABASE SYSTEMS\\nCarlos Coronel  |  Steven MorrisDesign, Implementation,  \\nand Management\\nAustralia • Brazil • Mexico • Singapore • United Kingdom • United States12e\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='41e836f8-d270-4d39-b025-df0e54835ec7', embedding=None, metadata={'page_label': 'Statement', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='This is an electronic version of the print textbook. Due to electronic rights restrictions, some third party content may be suppressed. Editorial \\nreview has deemed that any suppressed content does not materially affect the overall learning experience. The publisher reserves the right to \\nremove content from this title at any time if subsequent rights restrictions require it. For valuable information on pricing, previous\\neditions, changes to current editions, and alternate formats, please visit www.cengage.com/highered to search by\\nISBN#, author, title, or keyword for materials in your areas of interest.\\nImportant Notice: Media content referenced within the product description or the product text may not be available in the eBook version.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba1b6b6e-4760-4575-a863-3806244adf71', embedding=None, metadata={'page_label': 'ii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='© 2017, 2015 Cengage Learning®\\nALL RIGHTS RESERVED. No part of this work covered by the copyright \\nherein may be reproduced or distributed in any form or by any means, \\nexcept as permitted by U.S. copyright law, without the prior written \\npermission of the copyright owner.\\nScreenshots for this book were created using Microsoft Access® and  \\nVisio® and were used with permission from Microsoft. Microsoft and the \\nOffice logo are either registered trademarks or trademarks of Microsoft \\nCorporation in the United States and/or other countries.\\nOracle is a registered trademark, and Oracle12  c and MySQL are trade-\\nmarks of Oracle Corporation.\\niPhone, iPad, and iPod are registered trademarks of Apple Inc.\\nLibrary of Congress Control Number: 2015955694\\nStudent Edition ISBN:  978-1-305-62748-2\\nLoose Leaf Edition ISBN:  978-1-305-86679-9\\nCengage Learning\\n20 Channel Center Street\\nBoston, MA 02210\\nUSA\\nCengage Learning is a leading provider of customized learning solutions \\nwith employees residing in nearly 40 different countries and sales in \\nmore than 125 countries around the world. Find your local representative \\nat www.cengage.com.\\nCengage Learning products are represented in Canada by \\nNelson Education, Ltd.\\nTo learn more about Cengage Learning Solutions,  \\nvisit www.cengage.com\\nPurchase any of our products at your local college store or  \\nat our preferred online store www.cengagebrain.comDatabase Systems: Design,  \\nImplementation, and Management,  \\n12th Edition\\nCarlos Coronel and Steven Morris\\nVice President, General Manager:  \\n Science, Math & Quantitative Business:  \\n Balraj S. Kalsi\\nProduct Director: Mike Schenk\\nSr. Product Team Manager: Joe Sabatino\\nContent Development Manager: Jennifer  \\n King\\nContent Developer: Ted Knight\\nProduct Assistant: Adele Scholtz\\nMarketing Director: Michele McTighe\\nContent Project Manager: Nadia Saloom\\nMedia Developer: Chris Valentine\\nManufacturing Planner: Ron Montgomery\\nMarketing Communications Manager:  \\n Dan Murphy\\nProduction Service: Cenveo Publisher \\n Services\\nSenior Art Director: Michelle Kunkler\\nCover and Internal Designer: Tippy  \\n McIntosh\\nCover Art Credit: agsandrew/iStock/ \\n Getty Images Plus/Getty Images\\nInternal Design Image: silver tiger/ \\n Shutterstock\\nIntellectual Property\\n Analyst: Christina Ciaramella\\n Project Manager: Kathryn KucharekFor product information and technology assistance, contact us at \\nCengage Learning Customer & Sales Support, 1-800-354-9706\\nFor permission to use material from this text or product, \\nsubmit all requests online at www.cengage.com/permissions  \\nFurther permissions questions can be emailed to \\npermissionrequest@cengage.com\\nPrinted in the United States of America\\nPrint Number: 01          Print Y ear:  2016\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.WCN: 02-200-203', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8c8b4a1b-10e1-4718-a044-ab3a561a9fe3', embedding=None, metadata={'page_label': 'iii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Dedication\\nTo the treasures in my life: To Victoria, for 26 wonderful years. Thank you for your un-\\nending support, for being my angel, my sweetie, and most importantly, my best friend. To Carlos Anthony, who is an awesome older brother to all. Thank you for your words of wisdom, hard-working attitude, and for giving us reasons to be happy. Y ou are still young; your best times are still to come. To Gabriela Victoria, who is the image of bril-liance, beauty, and faithfulness. Thank you for being the sunshine in my cloudy days. Y our future is bright and endless. To Christian Javier, who is smarter than of all of us. Thank you for being the youthful reminder of life’s simple beauties. Keep challenging yourself to new highs. To my parents, Sarah and Carlos, thank you for your sacrifice and example. To all of you, you are all my inspiration. “TQTATA. ”\\nCarlos Coronel\\nTo Pamela, from high school sweetheart through 26 years of marriage, you are the beau-tiful love of my life who has supported, encouraged, and inspired me. More than anyone else, you are responsible for whatever successes I have achieved. To my son, Alexander Logan, your depth of character is without measure. Y ou are my pride and joy. To my daughter, Lauren Elizabeth, your beauty and intensity take my breath away. Y ou are my heart and soul. Thank you all for the sacrifices you have made that enabled me to pur -\\nsue this dream. I love you so much more than I can express. To my mother, Florence \\n Maryann, and to the memory of my father, Alton Lamar, together they instilled in me the desire to learn and the passion to achieve. To my mother-in-law, Connie Duke, and to the memory of my father-in-law, Wayne Duke, they taught me to find joy in all things. To all of you, with all my love, I dedicate this book.\\nSteven Morris\\nFor Peter\\nTo longtime colleague and friend, Peter Rob: Y our drive and dedication to your students \\nstarted this book. Y our depth of knowledge, attention to detail, and pursuit of excellence made it succeed. Y our patience and guidance continue to light our path. It is our sincere hope that, as we move forward, we can continue to live up to your standard. Enjoy your retirement, my friend; you have surely earned it.\\nCarlos Coronel and Steven Morris\\nDedication    iii\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f81cb306-2bc4-4678-befe-3d1303deac94', embedding=None, metadata={'page_label': 'iv', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface, xiv\\nText Features, xixAdditional Features, xxiAcknowledgments, xxiii\\nPart 1: Database Concepts  1\\n1. Database Systems, 2\\n2. Data Models, 35\\nPart 2: Design Concepts  71\\n3. The Relational Database Model, 72\\n4. Entity Relationship (ER) Modeling, 117\\n5. Advanced Data Modeling, 169\\n6. Normalization of Database Tables, 201\\nPart 3: Advanced Design and Implementation  245\\n7. Introduction to Structured Query Language (SQL), 246\\n8. Advanced SQL , 340\\n9. Database Design, 439\\nPart 4: Advanced Database Concepts  481\\n10. Transaction Management and Concurrency Control, 482\\n11. Database Performance Tuning and Query Optimization, 515\\n12. Distributed Database Management Systems, 553\\n13. Business Intelligence and Data Warehouses, 589\\n14. Big Data Analytics and NoSQL, 648\\nPart 5: Databases and the Internet  679\\n15. Database Connectivity and Web Technologies, 680\\nPart 6: Database Administration  721\\n16. Database Administration and Security, 722\\nGlossary, 769Index, 783\\nBrief Contents\\niv  Brief Contents\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e026d67b-8086-4790-8baa-a11790c545c9', embedding=None, metadata={'page_label': 'v', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The following appendixes are included on the Instructor and Student Companion Sites at www.cengagebrain.com.\\nAppendix A1:  Designing Databases with Visio Professional 2010: A Tutorial \\nAppendix A2:  Designing Databases with Visio 2013: A Tutorial  \\nAppendix B:  The University Lab: Conceptual Design \\nAppendix C:  The University Lab: Conceptual Design Verification, Logical Design, and Implementation  \\nAppendix D:  Converting an ER Model into a Database Structure \\nAppendix E:  Comparison of ER Model Notations \\nAppendix F:  Client/Server Systems  \\nAppendix G:  Object-Oriented Databases \\nAppendix H:  Unified Modeling Language (UML) \\nAppendix I:  Databases in Electronic Commerce \\nAppendix J:  Web Database Development with ColdFusion \\nAppendix K:  The Hierarchical Database Model \\nAppendix L:  The Network Database Model \\nAppendix M:  MS Access Tutorial \\nAppendix N:  Creating a New Database Using Oracle 12c \\nAppendix O:  Data Warehouse Implementation Factors\\nBrief Contents    v\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94850e76-961b-4c25-bdc2-a3fe637268ea', embedding=None, metadata={'page_label': 'vi', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='vi  ContentsPart 1: Database Concepts  1\\nChapter 1:  Database Systems   2\\n1-1  Why Databases?   3\\n1-2  Data versus Information  4\\n1-3  Introducing the Database  6\\n1-3a  Role and Advantages of the DBMS  6\\n1-3b  Types of Databases  8\\n1-4  Why Database Design is Important   11\\n1-5  Evolution of File System Data Processing   14\\n1-5a  Manual File Systems  14\\n1-5b  Computerized File Systems  15\\n1-5c  File System Redux: Modern End-User  Productivity Tools  17\\n1-6  Problems with File System Data Processing  18\\n1-6a  Structural and Data Dependence  19\\n1-6b  Data Redundancy  20\\n1-6c  Data Anomalies  21\\n1-7  Database Systems  21\\n1-7a  The Database System Environment  22\\n1-7b  DBMS Functions  24\\n1-7c  Managing the Database System: A Shift in Focus  28\\n1-8  Preparing for Your Database Professional  Career  28\\nSummary 30  • Key Terms 31  • Review Questions 32  • Problems 32\\nChapter 2: Data Models   35\\n2-1  Data Modeling and Data Models   36\\n2-2  The Importance of Data Models   37\\n2-3  Data Model Basic Building Blocks   37\\n2-4  Business Rules   39\\n2-4a  Discovering Business Rules  39\\n2-4b  Translating Business Rules into Data Model Components  40\\n2-4c  Naming Conventions  41\\n2-5  The Evolution of Data Models  41\\n2-5a  Hierarchical and Network Models  41\\n2-5b  The Relational Model  43\\n2-5c  The Entity Relationship Model  45\\n2-5d  The Object-Oriented (OO) Model  48\\n2-5e  Object/Relational and XML  49\\n2-5f  Emerging Data Models: Big Data and NoSQL  50\\n2-5g  Data Models: A Summary  56\\n2-6 Degrees of Data Abstraction  57\\n2-6a  The External Model  60\\n2-6b  The Conceptual Model  61\\n2-6c  The Internal Model  62\\n2-6d  The Physical Model  63\\nSummary 64  • Key Terms 65  • Review Questions 65  • Problems 66\\nPart 2: Design Concepts  71\\nChapter 3: The Relational Database Model   72\\n3-1 A Logical View of Data  73\\n3-1a  Tables and Their Characteristics  73\\nContents\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5f9feb0c-2ac4-414d-8595-b9bfb0254e93', embedding=None, metadata={'page_label': 'vii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents   vii3-2 Keys  76\\n3-2a  Dependencies  76\\n3-2b  Types of Keys  77\\n3-3 Integrity Rules  80\\n3-4 Relational Algebra  82\\n3-4a  Formal Definitions and Terminology  82\\n3-4b  Relational Set Operators  83\\n3-5 The Data Dictionary and the System Catalog  91\\n3-6 Relationships within the Relational Database  93\\n3-6a  The 1:M Relationship  93\\n3-6b  The 1:1 Relationship  95\\n3-6c  The M:N Relationship  97\\n3-7 Data Redundancy Revisited  101\\n3-8 Indexes  103\\n3-9 Codd’s Relational Database Rules  104\\nSummary 106  • Key Terms 107  • Review Questions 107  • Problems 110\\nChapter 4: Entity Relationship (ER) Modeling   117\\n4-1 The Entity Relationship Model (ERM)  118\\n4-1a  Entities  118\\n4-1b  Attributes  118\\n4-1c  Relationships  124\\n4-1d  Connectivity and Cardinality  125\\n4-1e  Existence Dependence  126\\n4-1f  Relationship Strength  126\\n4-1g  Weak Entities  129\\n4-1h  Relationship Participation  131\\n4-1i  Relationship Degree  134\\n4-1j  Recursive Relationships  136\\n4-1k  Associative (Composite) Entities  138\\n4-2 Developing an ER Diagram  140\\n4-3 Database Design Challenges: Conflicting Goals  147\\nSummary 152  • Key Terms 153  • Review Questions 153  • Problems 156  • Cases 161\\nChapter 5: Advanced Data Modeling   169\\n5-1 The Extended Entity Relationship Model  170\\n5-1a  Entity Supertypes and Subtypes  170\\n5-1b  Specialization Hierarchy  171\\n5-1c  Inheritance  172\\n5-1d  Subtype Discriminator  174\\n5-1e  Disjoint and Overlapping Constraints  174\\n5-1f  Completeness Constraint  175\\n5-1g  Specialization and Generalization  176\\n5-2 Entity Clustering  176\\n5-3 Entity Integrity: Selecting Primary Keys  177\\n5-3a  Natural Keys and Primary Keys  178\\n5-3b  Primary Key Guidelines  178\\n5-3c  When To Use Composite Primary Keys  178\\n5-3d  When To Use Surrogate Primary Keys  180\\n5-4  Design Cases: Learning Flexible Database Design  182\\n5-4a  Design Case 1: Implementing 1:1 Relationships  182\\n5-4b  Design Case 2: Maintaining History of Time-Variant Data  183\\n5-4c  Design Case 3: Fan Traps  186\\n5-4d  Design Case 4: Redundant Relationships  187\\nSummary 188  • Key Terms 189  • Review Questions 189  • Problems 190  • Cases 192\\nChapter 6: Normalization of Database Tables   201\\n6-1 Database Tables and Normalization  202\\n6-2 The Need For Normalization  202\\n6-3 The Normalization Process  206\\n6-3a  Conversion To First Normal Form  208\\n6-3b  Conversion To Second Normal Form  211\\n6-3c  Conversion To Third Normal Form  213\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e3d483c8-7202-4b2f-aa2b-3f18e3d59424', embedding=None, metadata={'page_label': 'viii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='viii  Contents6-4 Improving the Design  215\\n6-5 Surrogate Key Considerations  219\\n6-6 Higher-Level Normal Forms  220\\n6-6a  The Boyce-Codd Normal Form  221\\n6-6b  Fourth Normal Form (4NF)  224\\n6-7 Normalization and Database Design  226\\n6-8 Denormalization  229\\n6-9 Data-Modeling Checklist  232\\nSummary 234  • Key Terms 235  • Review Questions 235  • Problems 237\\nPart 3: Advanced Design and Implementation  245\\nChapter 7: Introduction to Structured Query Language (SQL)   246\\n7-1 Introduction to SQL  247\\n7-2 Data Definition Commands  249\\n7-2a  The Database Model  249\\n7-2b  Creating The Database  251\\n7-2c  The Database Schema  251\\n7-2d  Data Types  252\\n7-2e  Creating Table Structures  255\\n7-2f  SQL Constraints  259\\n7-2g  SQL Indexes  263\\n7-3 Data Manipulation Commands  264\\n7-3a  Adding Table Rows  264\\n7-3b  Saving Table Changes  266\\n7-3c  Listing Table Rows  266\\n7-3d  Updating Table Rows  268\\n7-3e  Restoring Table Contents  269\\n7-3f  Deleting Table Rows  269\\n7-3g  Inserting Table Rows with a Select Subquery  270\\n7.4 SELECT  Queries  271\\n7-4a  Selecting Rows with Conditional Restrictions  271\\n7-4b  Arithmetic Operators: The Rule of Precedence  276\\n7-4c  Logical Operators: AND, OR, and NOT  277\\n7-4d  Special Operators  279\\n7-5 Additional Data Definition Commands  283\\n7-5a  Changing a Column’s Data Type  284\\n7-5b  Changing a Column’s Data Characteristics  284\\n7-5c  Adding a Column  284\\n7-5d  Dropping a Column  285\\n7-5e  Advanced Data Updates  285\\n7-5f  Copying Parts of Tables  287\\n7-5g  Adding Primary and Foreign Key Designations  289\\n7-5h  Deleting a Table from the Database  290\\n7-6 Additional SELECT  Query Keywords  290\\n7-6a  Ordering a Listing  290\\n7-6b  Listing Unique Values  292\\n7-6c  Aggregate Functions  292\\n7-6d  Grouping Data  297\\n7-7 Joining Database Tables  300\\n7-7a  Joining Tables with an Alias  303\\n7-7b  Recursive Joins  303\\nSummary 305  • Key Terms 306  • Review Questions 306  • Problems 307  • Cases 331\\nChapter 8: Advanced SQL   340\\n8-1 SQL Join Operators  341\\n8-1a  Cross Join  342\\n8-1b  Natural Join  343\\n8-1c  JOIN USING  Clause  344\\n8-1d  JOIN ON  Clause  345\\n8-1e  Outer Joins  347\\n8-2 Subqueries and Correlated Queries  349\\n8-2a  WHERE  Subqueries  351\\n8-2b  IN Subqueries  352\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8eb6d243-692e-4114-bc01-c07a361ae50d', embedding=None, metadata={'page_label': 'ix', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents   ix8-2c  HAVING  Subqueries  353\\n8-2d  Multirow Subquery Operators: ANY  and ALL  353\\n8-2e  FROM  Subqueries  355\\n8-2f  Attribute List Subqueries  356\\n8-2g  Correlated Subqueries  358\\n8-3 SQL Functions  361\\n8-3a  Date and Time Functions  361\\n8-3b  Numeric Functions  366\\n8-3c  String Functions  366\\n8-3d  Conversion Functions  368\\n8-4 Relational Set Operators  371\\n8-4a  UNION  371\\n8-4b  UNION ALL  373\\n8-4c  INTERSECT  373\\n8-4d  EXCEPT (MINUS)  375\\n8-4e  Syntax Alternatives  377\\n8-5 Virtual Tables: Creating a View  377\\n8-5a  Updatable Views  379\\n8-6 Sequences  382\\n8-7 Procedural SQL  387\\n8-7a  Triggers  392\\n8-7b  Stored Procedures  401\\n8-7c  PL/SQL Processing with Cursors  407\\n8-7d  PL/SQL Stored Functions  409\\n8-8 Embedded SQL  410\\nSummary 415  • Key Terms 416  • Review Questions 417  • Problems 418  • Cases 435\\nChapter 9: Database Design   439\\n9-1 The Information System  440\\n9-2 The Systems Development Life Cycle  442\\n9-2a  Planning  442\\n9-2b  Analysis  443\\n9-2c  Detailed Systems Design  444\\n9-2d  Implementation  444\\n9-2e  Maintenance  445\\n9-3 The Database Life Cycle  445\\n9-3a  The Database Initial Study  445\\n9-3b  Database Design  450\\n9-3c  Implementation and Loading  451\\n9-3d  Testing and Evaluation  454\\n9-3e  Operation  456\\n9-3f  Maintenance and Evolution  457\\n9-4 Conceptual Design  457\\n9-4a  Data Analysis and Requirements  459\\n9-4b  Entity Relationship Modeling and Normalization  461\\n9-4c  Data Model Verification  464\\n9-4d  Distributed Database Design  467\\n9-5 DBMS Software Selection  467\\n9-6 Logical Design  468\\n9-6a  Map the Conceptual Model to the Logical Model  468\\n9-6b  Validate the Logical Model Using Normalization  470\\n9-6c  Validate Logical Model Integrity Constraints  470\\n9-6d  Validate the Logical Model Against User Requirements  471\\n9-7 Physical Design  471\\n9-7a  Define Data Storage Organization  472\\n9-7b  Define Integrity and Security Measures  472\\n9-7c  Determine Performance Measures  473\\n9-8 Database Design Strategies  473\\n9-9 Centralized Versus Decentralized Design  474\\nSummary 477  • Key Terms 477  • Review Questions  477  • Problems 478\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='481929c1-f908-4275-8122-28022c771599', embedding=None, metadata={'page_label': 'x', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='x  ContentsPart 4: Advanced Database Concepts  481\\nChapter 10: Transaction Management and Concurrency Control   482\\n10-1  What Is a Transaction?  483\\n10-1a  Evaluating Transaction Results  484\\n10-1b  Transaction Properties  487\\n10-1c  Transaction Management with SQL  488\\n10-1d  The Transaction Log  489\\n10-2  Concurrency Control  490\\n10-2a  Lost Updates  490\\n10-2b  Uncommitted Data  491\\n10-2c  Inconsistent Retrievals  492\\n10-2d  The Scheduler  493\\n10-3   Concurrency Control with Locking Methods  495\\n10-3a  Lock Granularity  496\\n10-3b  Lock Types  498\\n10-3c  Two-Phase Locking to Ensure Serializability  500\\n10-3d  Deadlocks  500\\n10-4  Concurrency Control with Time Stamping Methods  502\\n10-4a  Wait/Die and Wound/Wait Schemes  502\\n10-5  Concurrency Control with Optimistic Methods  503\\n10-6  ANSI Levels of Transaction Isolation  504\\n10-7  Database Recovery Management  506\\n10-7a  Transaction Recovery  506\\nSummary 510  • Key Terms 511  • Review Questions 511  • Problems 512\\nChapter 11: Database Performance Tuning  \\nand Query Optimization   515\\n11-1  Database Performance-Tuning Concepts  516\\n11-1a  Performance Tuning: Client and Server  517\\n11-1b  DBMS Architecture  518\\n11-1c  Database Query Optimization Modes  520\\n11-1d  Database Statistics  521\\n11-2  Query Processing  522\\n11-2a  SQL Parsing Phase  523\\n11-2b  SQL Execution Phase  524\\n11-2c  SQL Fetching Phase  525\\n11-2d  Query Processing Bottlenecks  525\\n11-3  Indexes and Query Optimization  526\\n11-4  Optimizer Choices  528\\n11-4a  Using Hints to Affect Optimizer Choices  530\\n11-5  SQL Performance Tuning  531\\n11-5a  Index Selectivity  531\\n11-5b  Conditional Expressions  533\\n11-6  Query Formulation  534\\n11-7  DBMS Performance Tuning  536\\n11-8  Query Optimization Example  538\\nSummary 546  • Key Terms 547  • Review Questions 547  • Problems 548\\nChapter 12: Distributed Database Management Systems   553\\n12-1  The Evolution of Distributed Database Management Systems  554\\n12-2  DDBMS Advantages and Disadvantages  556\\n12-3  Distributed Processing and Distributed Databases  556\\n12-4  Characteristics of Distributed Database Management Systems  559\\n12-5  DDBMS Components  560\\n12-6  Levels of Data and Process Distribution  561\\n12-6a  Single-Site Processing, Single-Site Data  561\\n12-6b  Multiple-Site Processing, Single-Site Data  562\\n12-6c  Multiple-Site Processing, Multiple-Site Data  563\\n12-7  Distributed Database Transparency Features  564\\n12-8  Distribution Transparency  565\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c30b8ac0-948d-4fb2-baec-a715c0379db3', embedding=None, metadata={'page_label': 'xi', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents   xi12-9  Transaction Transparency  568\\n12-9a  Distributed Requests and Distributed Transactions  568\\n12-9b  Distributed Concurrency Control  571\\n12-9c  Two-Phase Commit Protocol  571\\n12-10  Performance and Failure Transparency  573\\n12-11  Distributed Database Design  575\\n12-11a  Data Fragmentation  575\\n12-11b  Data Replication  578\\n12-11c  Data Allocation  580\\n12-12  The CAP Theorem  581\\n12-13  C. J. Date’s 12 Commandments for Distributed Databases  583\\nSummary 584  • Key Terms 585  • Review Questions 585  • Problems 586\\nChapter 13: Business Intelligence and Data Warehouses   589\\n13-1  The Need for Data Analysis  590\\n13-2  Business Intelligence  590\\n13-2a  Business Intelligence Architecture  592\\n13-2b  Business Intelligence Benefits  598\\n13-2c  Business Intelligence Evolution  598\\n13-2d  Business Intelligence Technology Trends  601\\n13-3  Decision Support Data  602\\n13-3a  Operational Data Versus Decision Support Data  602\\n13-3b  Decision Support Database Requirements  605\\n13-4  The Data Warehouse  607\\n13-4a  Data Marts  610\\n13-4b  Twelve Rules That Define a Data Warehouse  610\\n13-5  Star Schemas  610\\n13-5a  Facts  611\\n13-5b  Dimensions  611\\n13-5c  Attributes  612\\n13-5d  Attribute Hierarchies  614\\n13-5e  Star Schema Representation  616\\n13-5f  Performance-Improving Techniques for the Star Schema  617\\n13-6  Online Analytical Processing  621\\n13-6a  Multidimensional Data Analysis Techniques  621\\n13-6b  Advanced Database Support  623\\n13-6c  Easy-to-Use End-User Interfaces  623\\n13-6d  OLAP Architecture  623\\n13-6e  Relational OLAP  626\\n13-6f  Multidimensional OLAP  628\\n13-6g  Relational versus Multidimensional OLAP  628\\n13-7  SQL Extensions for OLAP  629\\n13-7a  The ROLLUP Extension  630\\n13-7b  The CUBE Extension  631\\n13-7c  Materialized Views  633\\nSummary 636  • Key Terms 637  • Review Questions 637  • Problems 639\\nChapter 14: Big Data Analytics and NoSQL   648\\n14-1  Big Data  649\\n14-1a  Volume  651\\n14-1b  Velocity  652\\n14-1c  Variety  653\\n14-1d  Other Characteristics  654\\n14-2  Hadoop  655\\n14-2a  HDFS  655\\n14-2b  MapReduce  658\\n14-2c  Hadoop Ecosystem  660\\n14-3  NoSQL  662\\n14-3a  Key-Value Databases  663\\n14-3b  Document Databases  664\\n14-3c  Column-Oriented Databases  665\\n14-3d  Graph Databases  668\\n14-3e  NewSQL Databases  669\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc3d7b05-5081-4caf-a60e-120e225d2b47', embedding=None, metadata={'page_label': 'xii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xii  Contents14-4  Data Analytics  670\\n14-4a  Data Mining  671\\n14-4b  Predictive Analytics  673\\nSummary 675  • Key Terms 676  • Review Questions 677\\nPart 5: Databases and the Internet  679\\nChapter 15: Database Connectivity and Web Technologies   680\\n15-1  Database Connectivity  681\\n15-1a  Native SQL Connectivity  682\\n15-1b  ODBC, DAO, and RDO  683\\n15-1c  OLE-DB  685\\n15-1d  ADO.NET  687\\n15-1e  Java Database Connectivity (JDBC)  691\\n15-2  Database Internet Connectivity  692\\n15-2a  Web-to-Database Middleware: Server-Side Extensions  693\\n15-2b  Web Server Interfaces  695\\n15-2c  The Web Browser  696\\n15-2d  Client-Side Extensions  697\\n15-2e  Web Application Servers  698\\n15-2f  Web Database Development  699\\n15-3  Extensible Markup Language (XML)  702\\n15-3a  Document Type Definitions (DTD) and XML Schemas  704\\n15-3b  XML Presentation  706\\n15-3c  XML Applications  708\\n15-4  Cloud Computing Services  709\\n15-4a  Cloud Implementation Types  712\\n15-4b  Characteristics of Cloud Services  712\\n15-4c  Types of Cloud Services  713\\n15-4d  Cloud Services: Advantages and Disadvantages  714\\n15-4e  SQL Data Services  716\\nSummary 717  • Key Terms 718  • Review Questions 718  • Problems 719\\nPart 6: Database Administration  721\\nChapter 16: Database Administration and Security  722\\n16-1  Data as a Corporate Asset  723\\n16-2   The Need for a Database and its Role in an Organization  724\\n16-3   Introduction of a Database: Special Considerations  726\\n16-4  The Evolution of Database Administration  727\\n16-5   The Database Environment’s Human Component  731\\n16-5a  The DBA’s Managerial Role  733\\n16-5b  The DBA’s Technical Role  738\\n16-6  Security  745\\n16-6a  Security Policies  746\\n16-6b  Security Vulnerabilities  746\\n16-6c  Database Security  748\\n16-7  Database Administration Tools  749\\n16-7a  The Data Dictionary  750\\n16-7b  Case Tools  752\\n16-8  Developing a Data Administration Strategy  755\\n16-9  The DBA’s Role in the Cloud  756\\n16-10   The DBA at Work: Using Oracle for Database Administration  757\\n16-10a  Oracle Database Administration Tools  758\\n16-10b  Ensuring that the RDBMS Starts Automatically  758\\n16-10c  Creating Tablespaces and Datafiles  760\\n16-10d  Managing Users and Establishing Security  762\\n16-10e   Customizing the Database Initialization Parameters  763\\nSummary  765 • Key Terms 766  • Review Questions 767\\nGlossary  769\\nIndex  783\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='24edad7b-1742-4ef9-93d5-41673a2865d9', embedding=None, metadata={'page_label': 'xiii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents   xiiiThe following appendixes are included on the Instructor and Student Companion Sites at www.cengagebrain.com.\\nAppendix A1:  Designing Databases with Visio Professional 2010: A Tutorial \\nAppendix A2:  Designing Databases with Visio 2013: A Tutorial  \\nAppendix B:  The University Lab: Conceptual Design \\nAppendix C:   The University Lab: Conceptual Design Verification, Logical Design, and Implementation\\nAppendix D:  Converting an ER Model into a Database Structure \\nAppendix E:  Comparison of ER Model Notations \\nAppendix F:  Client/Server Systems  \\nAppendix G:  Object-Oriented Databases \\nAppendix H:  Unified Modeling Language (UML) \\nAppendix I:  Databases in Electronic Commerce \\nAppendix J:  Web Database Development with ColdFusion \\nAppendix K:  The Hierarchical Database Model \\nAppendix L:  The Network Database Model \\nAppendix M:  MS Access Tutorial \\nAppendix N:  Creating a New Database Using Oracle 12c \\nAppendix O:  Data Warehouse Implementation Factors\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5477d14-d57b-4739-9bd4-d16c8c4699be', embedding=None, metadata={'page_label': 'xiv', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xiv  PrefaceIt is our great pleasure to present the twelfth edition of Database Systems. We are grateful and \\nhumbled that so many of our colleagues around the world have chosen this text to support their \\nclasses. We wrote the first edition of this book because we wanted to explain the complexity of database systems in a language that was easy for students to understand. Over the years, we have maintained this emphasis on reaching out to students to explain complex concepts in a practical, approachable manner.\\n  This book has been successful through eleven editions because the au-\\nthors, editors, and the publisher paid attention to the impact of technology and to adopter ques-tions and suggestions. We believe that this twelfth edition successfully reflects the same attention to such factors.\\nIn many respects, rewriting a book is more difficult than writing it the first time. If the book is \\nsuccessful, as this one is, a major concern is that the updates, inserts, and deletions will adversely affect writing style and continuity of coverage. The combination of superb reviewers and editors, plus a wealth of feedback from adopters and students of the previous editions, helped make this new edition the best yet.\\nChanges to The Twelfth Edition\\nIn this twelfth edition, we added some new features and reorganized some coverage to provide a better flow of material. Aside from enhancing the already strong coverage of database design, we made other improvements in the topical coverage. In particular, the continued growth of Big Data and NoSQL technologies have challenged the status quo in the database industry. Therefore, we created an entire new chapter, Big Data Analytics and NoSQL, to help students grasp the key aspects of these complex new technologies and challenges. The twelfth edition also presents a ma-jor step forward in the integration of digital content with the text through online, automatically graded exercises to improve student outcomes. Here are a few of the highlights of changes in the twelfth edition:\\n• New coverage of Big Data challenges beyond the traditional 3Vs\\n• Expanded coverage of Hadoop, the Hadoop Distributed File System (HDFS), and MapReduce\\n• Updated coverage of cloud data services and their impact on DBAs\\n• Expanded coverage of NoSQL databases, including key-value databases, document databases, column-oriented database, and graph databases\\n• New coverage of the emerging NewSQL technologies\\n• Improved coverage of data visualization\\n• Added coverage of new sequence and identity capabilities in Oracle and SQL Server\\n• Complete redesign of the look and feel of the text and layout to improve readability and visual appeal\\n• Embedded key term definitions within the text\\nThis twelfth edition continues to provide a solid and practical foundation for the design, im-\\nplementation, and management of database systems. This foundation is built on the notion that, while databases are very practical, their successful creation depends on understanding the im-portant concepts that define them. It’s not easy to come up with the proper mix of theory and practice, but the previously mentioned feedback suggests that we largely succeeded in our quest to maintain the proper balance.\\nPreface\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3739ee9-ebde-4a7f-a768-fe84467a53ae', embedding=None, metadata={'page_label': 'xv', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface   xv\\nThe Approach: A Continued Emphasis  \\nOn Design\\nAs the title suggests, Database Systems: Design, Implementation, and Management covers three broad aspects of database systems. However, for several important reasons, special attention is given to database design.\\n• The availability of excellent database software enables people with little experience to cre-ate databases and database applications. Unfortunately, the “create without design” approach usually paves the road to a number of database disasters. In our experience, many database system failures are traceable to poor design and cannot be solved with the help of even the best programmers and managers. Nor is better DBMS software likely to overcome problems created or magnified by poor design. Even the best bricklayers and carpenters can’t create a good building from a bad blueprint.\\n• Most vexing problems of database system management seem to be triggered by poorly de-signed databases. It hardly seems worthwhile to use scarce resources to develop excellent da-tabase management skills merely to use them on crises induced by poorly designed databases.\\n• Design provides an excellent means of communication. Clients are more likely to get what they need when database system design is approached carefully and thoughtfully. In fact, clients may discover how their organizations really function once a good database design is completed.\\n• Familiarity with database design techniques promotes understanding of current database technologies. For example, because data warehouses derive much of their data from opera-tional databases, data warehouse concepts, structures, and procedures make more sense when the operational database’s structure and implementation are understood.\\nBecause the practical aspects of database design are stressed, we have covered design concepts \\nand procedures in detail, making sure that the numerous end-of-chapter problems and cases are sufficiently challenging so students can develop real and useful design skills. We also make sure that students understand the potential and actual conflicts between database design elegance, information requirements, and transaction processing speed. For example, it makes little sense to design databases that meet design elegance standards while they fail to meet end-user informa-tion requirements. Therefore, we explore the use of carefully defined trade-offs to ensure that the databases meet end-user requirements while conforming to high design standards.\\nTopical Coverage\\nThe Systems View\\nThe book’s title begins with Database Systems . There-\\nfore, we examine the database and design concepts covered in Chapters 1–6 as part of a larger whole by placing them within the systems analysis framework of Chapter 9. Database designers who fail to understand that the database is part of a larger system are likely to overlook important design requirements. In fact, Chapter 9, Database Design, provides the map for the advanced database design developed in Appendixes B and C. Within the larger systems framework, we can also explore issues such as transaction management and concurrency control (Chapter 10), distributed da-tabase management systems (Chapter 12), business in-telligence and data warehouses (Chapter 13), database connectivity and web technologies (Chapter 15), and database administration and security (Chapter 16).\\nPART 1\\nDatabase Concepts\\n1Database Systems\\n2 Data Models\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp01.indd   1 19/12/15   2:03 PM\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c11bfeb-97d1-4b12-9a06-ee4e6dcc11b5', embedding=None, metadata={'page_label': 'xvi', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xvi  Preface\\nDatabase Design\\nThe first item in the book’s subtitle is Design , and our \\nexamination of database design is comprehensive. For \\nexample, Chapters 1 and 2 examine the development and future of databases and data models, and illustrate the need for design. Chapter 3 examines the details of the relational database model; Chapter 4 provides ex-tensive, in-depth, and practical database design cover -\\nage; and Chapter 5 explores advanced database design topics. Chapter 6 is devoted to critical normalization issues that affect database efficiency and effectiveness. Chapter 9 examines database design within the systems framework and maps the activities required to success-fully design and implement the complex, real-world database developed in Appendixes B and C. Appendix A, Designing Databases with Visio Professional: A Tu-torial, provides a good introductory tutorial for the use of a database design tool.\\nBecause database design is affected by real-world \\ntransactions, the way data is distributed, and ever-in-creasing information requirements, we examine major database features that must be supported in current-gen-eration databases and models. For example, Chapter 10, Transaction Management and Concurrency Control, focuses on the characteristics of database transactions and how they affect database integrity and consistency. Chapter 11, Database Performance Tuning and Query \\nOptimization, illustrates the need for query efficiency in a world that routinely generates and uses tera-byte-size databases and tables with millions of records. Chapter 12, Distributed Database Management Systems, focuses on data distribution, replication, and allocation. In Chapter 13, Business Intelligence and Data Warehouses, we explore the characteristics of databases that are used in decision support and online analytical processing. Chapter 14, Big Data Analytics and NoSQL, explores the challenges of designing nonrelational databases to use vast global stores of unstructured data. Chapter 15, Database Connectivity and Web Technologies, covers the basic database connectivity issues in a web-based data world, development of web-based database front ends, and emerging cloud-based services.\\nImplementation\\nThe second portion of the subtitle is Implementation . \\nWe use Structured Query Language (SQL) in Chap-ters 7 and 8 to show how relational databases are implemented and managed. Appendix M, Microsoft  Access Tutorial, provides a quick but comprehensive guide to implementing an MS Access database. Ap-pendixes B and C demonstrate the design of a da-tabase that was fully implemented; these appendix-es \\n illustrate a wide range of implementation issues. \\nWe had to deal with conflicting design goals: design elegance, information requirements, and operation-al speed. Therefore, we carefully audited the initial design in Appendix B to check its ability to meet end-user needs and establish appropriate implemen-tation protocols. The result of this audit yielded the fi-nal design developed in Appendix C. While relational databases are still the appropriate database technolo-gy to use in the vast majority of situations, Big Data issues have created an environment in which special \\nChapter 9\\nDatabase Design\\nIn this chapter, you will learn:\\n• That a sound database design is the foundation for a successful information system, and that the \\ndatabase design must reflect the information system of which the database is a part\\n• That successful information systems are developed within a framework known as the Systems \\nDevelopment Life Cycle (SDLC)\\n• That within the information system, the most successful databases are subject to frequent \\nevaluation and revision within a framework known as the Database Life Cycle (DBLC)\\n• How to conduct evaluation and revision within the SDLC and DBLC frameworks\\n• About database design strategies: top-down versus bottom-up design and centralized versus \\ndecentralized design\\nPreviewDatabases are a part of a larger picture called an information system. Database designs that fail to recognize this fact are not likely to be successful. Database designers must rec-ognize that the database is a critical means to an end rather than an end in itself. Managers want the database to serve their management needs, but too many databases seem to force managers to alter their routines to fit the database requirements.\\nInformation systems don’t just happen; they are the product of a carefully staged devel-\\nopment process. Systems analysis is used to determine the need for an information system and to establish its limits. Within systems analysis, the actual information system is cre-ated through a process known as systems development.\\nThe creation and evolution of information systems follows an iterative pattern called \\nthe Systems Development Life Cycle (SDLC), which is a continuous process of creation, maintenance, enhancement, and replacement of the information system. A similar cycle applies to databases: the database is created, maintained, enhanced, and eventually replaced. The Database Life Cycle (DBLC) is carefully traced in this chapter, and is shown in the context of the larger Systems Development Life Cycle.\\nAt the end of the chapter, you will be introduced to some classical approaches to data-\\nbase design: top-down versus bottom-up and centralized versus decentralized.\\nBecause it is purely conceptual, this chapter does not reference any data files.NoteData Files Available on cengagebrain.com\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp09.indd   439 19/12/15   11:54 AM\\nPART 3\\nAdvanced Design and Implementation\\n7Introduction to Structured Query Language (SQL)\\n8\\n9Advanced SQL\\nDatabase Design\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp07.indd   245 19/12/15   3:22 PM\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d8aa9e7e-f94c-4824-947f-7891661ea5f5', embedding=None, metadata={'page_label': 'xvii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface   xvii\\nrequirements can call for the use of new, nonrela-\\ntional technologies. Chapter 14, Big Data Analyt-ics and NoSQL, describes the types of data that are appropriate for these new technologies and the ar -\\nray of options available in these special cases. The special issues encountered in an Internet database environment are addressed in Chapter 15, Database Connectivity and Web Technologies, and in Appen-dix J, Web Database Development with ColdFusion.\\nManagement\\nThe final portion of the subtitle is Management . We \\ndeal with database management issues in Chapter 10, Transaction Management and Concurrency Control; Chapter 12, Distributed Database Man-agement Systems; and Chapter 16, Database Ad-ministration and Security. Chapter 11, Database Performance Tuning and Query Optimization, is a valuable resource that illustrates how a DBMS man-ages data retrieval. In addition, Appendix N, Cre-ating a New Database Using Oracle 12c, walks you through the process of setting up a new database.\\nTeaching Database: A Matter of  Focus\\nGiven the wealth of detailed coverage, instructors can “mix and match” chapters to produce the desired coverage. Depending on where database courses fit into the curriculum, instructors may choose to emphasize database design or database management. (See Figure 1.)\\nThe hands-on nature of database design lends itself particularly well to class projects in which \\nstudents use instructor-selected software to prototype a system that they design for the end user. Several end-of-chapter problems are sufficiently complex to serve as projects, or an instructor may work with local businesses to give students hands-on experience. Note that some elements of the database design track are also found in the database management track, because it is difficult to manage database technologies that are not well understood.\\nThe options shown in Figure 1 serve only as a starting point. Naturally, instructors will tailor \\ntheir coverage based on their specific course requirements. For example, an instructor may decide to make Appendix I an outside reading assignment and make Appendix A a self-taught tutori-al, and then use that time to cover client/server systems or object-oriented databases. The latter choice would serve as a gateway to UML coverage.\\nPART 6\\nDatabase Administration\\n16 Database Administration and Security\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp16.indd   721 19/12/15   12:04 PM\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5346a53-61b0-4ad6-8576-e2958854ec9f', embedding=None, metadata={'page_label': 'xviii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xviii   PrefaceFIGURE  1 \\n(1) Database Systems\\n(2) Data Models\\n(3) The Relational Database Model\\n(4) Entity Relationship (ER) Modeling\\n(6) Normalization of Database Tables\\n(7) Introduction to Structured Query Language (SQL)\\n(10) Transaction Management and Concurrency Control\\n(11) Database Performance Tuning and Query Optimization\\n(12) Distributed Database Management Systems\\n(13) Business Intelligence and Data Warehouses\\n(15) Database Connectivity and Web Technologies\\n(16) Database Administration and Security\\n(F) Client/Server Systems\\n(G) Object Oriented Databases\\n (9) Database Design\\n(M) Microsoft Access Tutorial\\n(N) Creating a New Database Using Oracle 12c\\n(O) Data Warehouse Implementation Factors\\n(I) Databases in Electronic Commerce\\n(J) Web Database Development with ColdFusion(5) Advanced Data Modeling\\n(8) Advanced SQL\\n(9) Database Design\\n(A) Designing Databases with Visio Professional\\n(D) Converting an ER Model into a Database Structure\\n(E) Comparison of ER Model Notations\\n(H) Uniﬁed Modeling Language (UML)\\n(14) Big Data Analytics and NoSQL\\n(15) Database Connectivity and Web Technologies\\n(B) The University Lab: Conceptual Design\\n(C) The University Lab: Conceptual Design Veriﬁcation,\\nLogical Design, and Implementation\\n(M) Microsoft Access Tutorial\\n(J) Web Database Development with ColdFusion\\n(K) The Hierarchical Database Model\\n(L) The Network Database ModelCore Coverage\\nDatabase Design and Implementation Focus Database Management Focus\\nSupplementary Reading Supplementary Reading\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c23d4bc8-b745-474f-9804-7a81056c24c2', embedding=None, metadata={'page_label': 'xix', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Text Features   xix\\nText Features\\nOnline Content boxes \\ndraw attention to material at www.cengagebrain.com for this text and provide ideas for incorporating this content into the course. Chapter 3    The Relational Database Model    75\\nUsing the STUDENT table shown in Figure 3.1, you can draw the following conclu-\\nsions corresponding to the points in Table 3.1:\\n1. The STUDENT table is perceived to be a two-dimensional structure composed of 8 rows (tuples) and 12 columns (attributes).\\n2. Each row in the STUDENT table describes a single entity occurrence within the entity set. (The entity set is represented by the STUDENT table.) For example, row 4 in Figure 3.1 describes a student named Walter H. Oblonski. Given the table con -\\ntents, the STUDENT entity set includes eight distinct entities (rows), or students.\\n3. Each column represents an attribute, and each column has a distinct name.\\n4. All of the values in a column match the attribute’s characteristics. For example, \\nthe grade point average (STU_GPA) column contains only STU_GPA entries for each of the table rows. Data must be classified according to its format and func-tion. Although various DBMSs can support different data types, most support at least the following:\\na. Numeric . Y ou can use numeric data to perform meaningful arithmetic procedures. \\nFor example, in Figure 3.1, STU_HRS and STU_GPA are numeric attributes.\\nb. Character . Character data, also known as text data or string data, can contain any \\ncharacter or symbol not intended for mathematical manipulation. In Figure 3.1, \\nSTU_CLASS and STU_PHONE are examples of character attributes.\\nc. Date . Date attributes contain calendar dates stored in a special format known as \\nthe Julian date format. In Figure 3.1, STU_DOB is a date attribute.\\nd. Logical . Logical data can only have true or false (yes or no) values. In Figure 3.1, \\nthe STU_TRANSFER attribute uses a logical data format.\\n5. The column’s range of permissible values is known as its domain. Because the STU_GPA values are limited to the range 0–4, inclusive, the domain is [0,4].\\n6. The order of rows and columns is immaterial to the user.FIGURE 3.1  STUDENT TABLE ATTRIBUTE VALUES  \\nDatabase name: Ch03_Ti nyCollege\\nSTU_NUM  = Student number\\nSTU_LNAME  = Student last nameSTU_FNAME  = Student ﬁrst nameSTU_INIT  = Student middle initialSTU_DOB  = Student date of birthSTU_HRS  = Credit hours earnedSTU_CLASS  = Student classiﬁcationSTU_GPA  = Grade point ave rage\\nSTU_TRANSFER = Student transferred from another institutionDEPT_CODE  = Department codeSTU_PHONE  = 4-digit campus phone extension\\nPROF_NUM  = Number of the professor who is the student’s advisorTable name: STUDENT\\nAll of the databases used to illustrate the material in this chapter (see the Data Files list at the beginning of the chapter) are available at www.cengagebrain.\\ncom . The database \\nnames match the data-base names shown in the figures.Online \\nContent\\ntuple\\nIn the relational model,  \\na table row.\\ndomain\\nIn data modeling, the construct used to organize and describe an attribute’s set of possible values.\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp03.indd   75 19/12/15   11:40 AMNotes  highlights \\n important facts about \\nthe\\xa0concepts introduced  in the chapter.78   Part 2    Design Concepts\\nOne specific type of superkey is called a candidate key. A candidate key is a minimal \\nsuperkey—that is, a superkey without any unnecessary attributes. A candidate key is based on a full functional dependency. For example, STU_NUM would be a candidate key, as would (STU_LNAME, STU_FNAME, STU_INIT, STU_PHONE). On the other hand, (STU_NUM, STU_LNAME) is a superkey, but it is not a candidate key because STU_LNAME could be removed and the key would still be a superkey. A table can have many different candidate keys. If the STUDENT table also included the students’ Social Security numbers as STU_SSN, then it would appear to be a candidate key. Candidate keys are called candidates  because they are the eligible options from which the designer \\nwill choose when selecting the primary key. The primary key is the candidate key chosen to be the primary means by which the rows of the table are uniquely identified.\\nEntity integrity is the condition in which each row (entity instance) in the table has \\nits own unique identity. To ensure entity integrity, the primary key has two requirements: (1) all of the values in the primary key must be unique, and (2) no key attribute in the primary key can contain a null.\\nNull values are problematic in the relational model. A null is the absence of any \\ndata value, and it is never allowed in any part of the primary key. From a theoretical perspective, it can be argued that a table that contains a null is not properly a relational table at all. From a practical perspective, however, some nulls cannot be reasonably avoided. For example, not all students have a middle initial. As a general rule, nulls should be avoided as much as reasonably possible. In fact, an abundance of nulls is often a sign of a poor design. Also, nulls should be avoided in the database because their meaning is not always identifiable. For example, a null could represent any of the following:\\n• An unknown attribute value\\n• A known, but missing, attribute value\\n• A “not applicable” condition\\nDepending on the sophistication of the application development software, nulls can \\ncreate problems when functions such as COUNT, AVERAGE, and SUM are used. In \\naddition, nulls can create logical problems when relational tables are linked.\\nIn addition to its role in providing a unique identity to each row in the table, the \\nprimary key may play an additional role in the controlled redundancy that allows the TABLE 3.2\\nSTUDENT CLASSIFICATION\\nHOURS COMPLETED CLASSIFICATION\\nLess than 30 Fr\\n30–59 So\\n60–89 Jr\\n90 or more Sr\\nA null is no value at all. It does not mean a zero or a space. A null is created when you press \\nthe Enter key or the Tab key to move to the next entry without making an entry of any kind. Pressing the Spacebar creates a blank (or a space).Note\\ncandidate key\\nA minimal superkey; that is, a key that does not contain a subset of attributes that is itself a superkey. See key .\\nentity integrity\\nThe property of a relational table that guarantees each entity has a unique value in a primary key and that the key has no null values.\\nnull\\nThe absence of an attribute value. Note that a null is not a blank.\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp03.indd   78 19/12/15   11:40 AM Chapter 1    Database Systems    25\\nFIGURE 1.11  ILLUSTRATING METADATA WITH MICROSOFT SQL SERVER EXPRESS\\naccess the data in the database work through the DBMS. The DBMS uses the data  dictionary to look up the required data component structures and relationships, \\nthus relieving you from having to code such complex relationships in each pro-gram. Additionally, any changes made in a database structure are automatically recorded in the data dictionary, thereby freeing you from having to modify all of the  programs that access the changed structure. In other words, the DBMS provides \\ndata abstraction, and it removes structural and data dependence from the system. \\nFor example,  Figure\\xa0 1.11 shows how Microsoft SQL Server Express presents the \\ndata definition for the  CUSTOMER table.\\n• Data storage management. The DBMS creates and manages the complex structures required for data storage, thus relieving you from the difficult task of defining and programming the physical data characteristics. A modern DBMS provides storage not only for the data but for related data-entry forms or screen definitions, report definitions, data validation rules, procedural code, structures to handle video and picture formats, and so on. Data storage management is also important for database performance tuning. Performance tuning relates to the activities that make the database perform more efficiently in terms of storage and access speed. Although the user sees the database as a single data storage unit, the DBMS actu-ally stores the database in multiple physical data files. (See Figure\\xa01.12.) Such data files may even be stored on different storage media. Therefore, the DBMS doesn’t have to wait for one disk request to finish before the next one starts. In other words, the DBMS can fulfill database requests  concurrently. Data storage man-\\nagement and performance tuning issues are  addressed in Chapter 11,  Database \\nPerformance Tuning and Query Optimization.\\ndata dictionary\\nA DBMS component that stores metadata—data about data. The data dictionary contains data definitions as well as data characteristics and relationships. May also include data that is external to the DBMS. \\nperformance tuning\\nActivities that make a database perform more efficiently in terms of storage and access speed.\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp01.indd   25 19/12/15   2:03 PMA variety of four-color figures, including  ER models and  implementations,  tables, and illustra- tions, clearly illustrate difficult concepts.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='75c1fb78-04f5-4497-b987-3b08fcc6ca12', embedding=None, metadata={'page_label': 'xx', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xx  Text FeaturesA robust Summary at \\nthe end of each chapter ties together the major concepts and serves as a quick review for students. Chapter 9    Database Design    477\\n• An information system is designed to help transform data into information and to manage both data and information. Thus, the database is a very important part of the information system. Systems analysis is the process that establishes the need for an information system and its extent. Systems development is the process of \\ncreating an information system.\\n• The Systems Development Life Cycle (SDLC) traces the history of an application within the information system. The SDLC can be divided into five phases: planning, analysis, detailed systems design, implementation, and maintenance. The SDLC is an iterative process rather than a sequential process.\\n• The Database Life Cycle (DBLC) describes the history of the database within the infor -\\nmation system. The DBLC is composed of six phases: database initial study, database design, implementation and loading, testing and evaluation, operation, and main-tenance and evolution. Like the SDLC, the DBLC is iterative rather than sequential.\\n• The conceptual portion of the design may be subject to several variations based on two basic design philosophies: bottom-up versus top-down and centralized versus decentralized.Summary\\nbottom-up design\\nboundariescentralized designclustered tablescohesivitycomputer-aided software \\nengineering (CASE)\\nconceptual designdatabase developmentdatabase fragmentDatabase Life Cycle (DBLC)database roledecentralized designdescription of operationsdifferential backupfull backupinformation systemlogical designminimal data rulemodulemodule couplingphysical designscopesystems analysissystems developmentSystems Development  \\nLife Cycle (SDLC)\\ntop-down designtransaction log backupvirtualization\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. What is an information system? What is its purpose?\\n2. How do systems analysis and systems development fit into a discussion about infor -\\nmation systems?\\n3. What does the acronym SDLC mean, and what does an SDLC portray?4. What does the acronym DBLC mean, and what does a DBLC portray?5. Discuss the distinction between centralized and decentralized conceptual database \\ndesign.Review Questions\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp09.indd   477 19/12/15   11:55 AM Chapter 9    Database Design    477\\n• An information system is designed to help transform data into information and to manage both data and information. Thus, the database is a very important part of the information system. Systems analysis is the process that establishes the need for an information system and its extent. Systems development is the process of creating an information system.\\n• The Systems Development Life Cycle (SDLC) traces the history of an application within the information system. The SDLC can be divided into five phases: planning, analysis, detailed systems design, implementation, and maintenance. The SDLC is an iterative process rather than a sequential process.\\n• The Database Life Cycle (DBLC) describes the history of the database within the infor -\\nmation system. The DBLC is composed of six phases: database initial study, database design, implementation and loading, testing and evaluation, operation, and main-tenance and evolution. Like the SDLC, the DBLC is iterative rather than sequential.\\n• The conceptual portion of the design may be subject to several variations based on two basic design philosophies: bottom-up versus top-down and centralized versus decentralized.Summary\\nbottom-up design\\nboundariescentralized designclustered tablescohesivitycomputer-aided software \\nengineering (CASE)\\nconceptual designdatabase developmentdatabase fragmentDatabase Life Cycle (DBLC)database roledecentralized designdescription of operationsdifferential backupfull backupinformation systemlogical designminimal data rulemodulemodule couplingphysical designscopesystems analysissystems developmentSystems Development  \\nLife Cycle (SDLC)\\ntop-down designtransaction log backupvirtualization\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. What is an information system? What is its purpose?\\n2. How do systems analysis and systems development fit into a discussion about infor -\\nmation systems?\\n3. What does the acronym SDLC mean, and what does an SDLC portray?4. What does the acronym DBLC mean, and what does a DBLC portray?5. \\nDiscuss the distinction between centralized and decentralized conceptual database \\ndesign.Review Questions\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp09.indd   477 19/12/15   11:55 AMReview Questions \\n challenge students to \\napply the skills learned in each chapter. Chapter 9    Database Design    477\\n• An information system is designed to help transform data into information and to manage both data and information. Thus, the database is a very important part of the information system. Systems analysis is the process that establishes the need for an information system and its extent. Systems development is the process of creating an information system.\\n• The Systems Development Life Cycle (SDLC) traces the history of an application within the information system. The SDLC can be divided into five phases: planning, analysis, detailed systems design, implementation, and maintenance. The SDLC is an iterative process rather than a sequential process.\\n• The Database Life Cycle (DBLC) describes the history of the database within the infor -\\nmation system. The DBLC is composed of six phases: database initial study, database design, implementation and loading, testing and evaluation, operation, and main-tenance and evolution. Like the SDLC, the DBLC is iterative rather than sequential.\\n• The conceptual portion of the design may be subject to several variations based on two basic design philosophies: bottom-up versus top-down and centralized versus decentralized.Summary\\nbottom-up design\\nboundariescentralized designclustered tablescohesivitycomputer-aided software \\nengineering (CASE)\\nconceptual designdatabase developmentdatabase fragmentDatabase Life Cycle (DBLC)database roledecentralized designdescription of operationsdifferential backupfull backupinformation systemlogical designminimal data rulemodulemodule couplingphysical designscopesystems analysissystems developmentSystems Development  \\nLife Cycle (SDLC)\\ntop-down designtransaction log backupvirtualization\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. What is an information system? What is its purpose?\\n2. How do systems analysis and systems development fit into a discussion about infor -\\nmation systems?\\n3. What does the acronym SDLC mean, and what does an SDLC portray?4. What does the acronym DBLC mean, and what does a DBLC portray?5. Discuss the distinction between centralized and decentralized conceptual database \\ndesign.Review Questions\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp09.indd   477 19/12/15   11:55 AMAn alphabetic list of \\nKey Terms summarizes important terms.\\n Chapter 15    Database Connectivity and Web Technologies    719\\n14. What is a web application server, and how does it work from a database  \\nperspective?\\n15. What are scripts, and what is their function? (Think in terms of database  \\napplication development.)\\n16. What is XML, and why is it important?\\n17. What are document type definition (DTD) documents, and what do they do?18. What are XML schema definition (XSD) documents, and what do they do?19. What is JDBC, and what is it used for?20. What is cloud computing, and why is it a “game changer”?21. Name and contrast the types of cloud computing implementation.22. Name and describe the most prevalent characteristics of cloud computing services.23. Using the Internet, search for providers of cloud services. Then, classify the types of \\nservices they provide (SaaS, PaaS, and IaaS).\\n24. Summarize the main advantages and disadvantages of cloud computing services.25. Define SQL data services and list their advantages.The Ch02 databases used in \\nthe Problems for this chap -\\nter are available at www.  \\ncengagebrain.com.Online \\nContent\\nIn the following exercises, you will set up database connectivity using MS Excel.\\n1. Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, \\nand retrieve all of the AGENTs.\\n2. Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, and retrieve all of the CUSTOMERs.\\n3. Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, and retrieve the customers whose AGENT_CODE is equal to 503.\\n4. Create a System DSN ODBC connection called Ch02_SaleCo using the Administra-tive Tools section of the Windows Control Panel.\\n5. Use MS Excel to list all of the invoice lines for Invoice 103 using the Ch02_SaleCo System DSN.\\n6. Create a System DSN ODBC connection called Ch02_Tinycollege using the Admin-istrative Tools section of the Windows Control Panel.\\n7. Use MS Excel to list all classes taught in room KLR200 using the Ch02_TinyCollege System DSN.\\nTo answer Problems 8−11, use Section 15-3a as your guide.\\n8. Create a sample XML document and DTD for the exchange of customer data.\\n9. Create a sample XML document and DTD for the exchange of product and pricing \\ndata.\\n10. Create a sample XML document and DTD for the exchange of order data.\\n11. Create a sample XML document and DTD for the exchange of student transcript \\ndata. Use your college transcript as a sample.Problems\\nBK-CHE-CORONEL_MORRIS_12E-150049-Chp15.indd   719 20/12/15   2:32 AMProblems  become \\n progressively more \\n complex as students draw on the lessons learned from the \\n completion of preceding problems.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='df15426e-abc5-4a04-9800-51846a0fba05', embedding=None, metadata={'page_label': 'xxi', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Additional Features   xxiMindTap® for Database Systems 12e\\nMindTap ® combines learning tools—such as readings, multimedia, activities, and assessments—\\ninto a singular learning path that guides students through the course. Y ou’ll find a full ebook as \\nwell as a robust set of auto-gradable homework problems. Multiple-choice homework questions developed from the end-of-chapter review questions confirm students’ understanding of core concepts and key terms. Higher-level assignments enable students to practice database design concepts in an automated environment, and chapter quizzes help prepare students for exams. Students will also benefit from the chapter-opening videos created by the authors, as well as study tools such as crossword puzzles and key-term flashcards.\\nMindTap\\n® is designed to be fully integrated with any Learning Management System and can be \\nused as a stand-alone product or in conjunction with a print textbook.\\nAppendixes\\nFifteen online appendixes provide additional material on a variety of important areas, such as using Microsoft\\n® Visio® and Microsoft ® Access ®, ER model notations, UML, object-oriented da-\\ntabases, databases and electronic commerce, and Adobe ® ColdFusion ®.\\nDatabase, SQL Script, and ColdFusion Files\\nThe online materials for this book include all of the database structures and table contents used in the text. For students using Oracle®, MySQL, and Microsoft SQL Server ™, SQL scripts are included  \\nto help students create and load all tables used in the SQL chapters (7 and 8). In addition, all Cold-Fusion scripts used to develop the web interfaces in Appendix\\xa0J are included.\\nInstructor Resources\\nDatabase Systems: Design, Implementation, and Management, Twelfth Edition, includes teaching tools to support instructors in the classroom. The ancillary material that accompanies the text-book is listed below. They are available on the web at www.cengagebrain.com.\\nInstructor’s Manual\\nThe authors have created this manual to help instructors make their classes informative and inter -\\nesting. Because the authors tackle so many problems in depth, instructors will find the Instructor’s Manual especially useful. The details of the design solution process are shown in the Instructor’s \\nManual , as well as notes about alternative approaches that may be used to solve a particular problem.\\nSQL Script Files for Instructors\\nThe authors have provided teacher’s SQL script files to allow instructors to cut and paste the SQL code into the SQL windows. (Scripts are provided for Oracle, MySQL, and MS SQL Server.) The SQL scripts, which have all been tested by Cengage Learning, are a major convenience for instructors. Y ou won’t have to type in the SQL commands, and the use of the scripts eliminates typographical errors that are sometimes difficult to trace.\\nColdFusion Files for Instructors\\nThe ColdFusion web development solutions are provided. Instructors have access to a menu- driven system that allows teachers to show the code as well as its execution.\\nAdditional Features\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6be80355-2470-4f10-b2bd-e37176e18d31', embedding=None, metadata={'page_label': 'xxii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xxii  Additional FeaturesDatabases\\nFor many chapters, Microsoft ® Access ® instructor databases are available that include features \\nnot found in the student databases. For example, the databases that accompany Chapters 7 and 8 \\ninclude many of the queries that produce the problem solutions. Other Access databases, such as the ones that accompany Chapters 3, 4, 5, and 6, include implementations of the design problem solutions to allow instructors to illustrate the effect of design decisions. In addition, instructors have access to all the script files for Oracle, MySQL, and MS SQL Server so that all the databases and their tables can be converted easily and precisely.\\nCengage Learning Testing Powered by Cognero \\nA flexible, online system that allows you to:\\n• Author, edit, and manage test bank content from multiple Cengage Learning solutions\\n• Create multiple test versions in an instant\\n• Deliver tests from your LMS, your classroom, or wherever you want\\nStart right away!Cengage Learning Testing Powered by Cognero works on any operating system or browser.\\n• No special installs or downloads needed\\n• Create tests from school, home, the coffee shop—anywhere with Internet access\\nWhat will you find?\\n• Simplicity at every step. A desktop-inspired interface features drop-down menus and familiar, intuitive tools that take you through content creation and management with ease.\\n• Full-featured test generator. Create ideal assessments with your choice of 15 question types (including true/false, multiple-choice, opinion scale/Likert, and essay). Multi-language sup-port, an equation editor, and unlimited metadata help ensure your tests are complete and compliant.\\n• Cross-compatible capability. Import and export content into other systems.\\nPowerPoint® Presentations\\nMicrosoft PowerPoint slides are included for each chapter. Instructors can use the slides in a vari-ety of ways—for example, as teaching aids during classroom presentations or as printed handouts for classroom distribution. Instructors can modify these slides or include slides of their own for additional topics introduced to the class.\\nFigure Files\\nFigure files for solutions are presented in the Instructor’s Manual  to allow instructors to create \\ntheir own presentations. Instructors can also manipulate these files to meet their particular needs.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d872e8e2-8676-4d5d-9fab-154b8c63ad9a', embedding=None, metadata={'page_label': 'xxiii', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Acknowledgments   xxiiiRegardless of how many editions of this book are published, they will always rest on the solid \\nfoundation created by the first edition. We remain convinced that our work has become successful because that first edition was guided by Frank Ruggirello, a former Wadsworth senior editor and publisher. Aside from guiding the book’s development, Frank also managed to solicit the great Peter Keen’s evaluation (thankfully favorable) and subsequently convinced Peter Keen to write the foreword for the first edition. Although we sometimes found Frank to be an especially demanding taskmaster, we also found him to be a superb professional and a fine friend. We suspect Frank will still see his fingerprints all over our current work. Many thanks.\\nA difficult task in rewriting a book is deciding what new approaches, topical coverage, and \\nchanges to depth of coverage are appropriate for a product that has successfully weathered the test of the marketplace. The comments and suggestions made by the book’s adopters, students, and reviewers play a major role in deciding what coverage is desirable and how that coverage is to be treated.\\nSome adopters became extraordinary reviewers, providing incredibly detailed and well-rea-\\nsoned critiques even as they praised the book’s coverage and style. Dr. David Hatherly, a superb database professional who is a senior lecturer in the School of Information Technology, Charles Sturt University–Mitchell, Bathhurst, Australia, made sure that we knew precisely what issues led to his critiques. Even better for us, he provided the suggestions that made it much easier for us to improve the topical coverage in earlier editions. All of his help was given freely and without prompting on our part. His efforts are much appreciated, and our thanks are heartfelt.\\nWe also owe a debt of gratitude to Professor Emil T. Cipolla, who teaches at St. Mary College. \\nProfessor Cipolla’s wealth of IBM experience turned out to be a valuable resource when we tack-led the embedded SQL coverage in Chapter 8.\\nEvery technical book receives careful scrutiny by several groups of reviewers selected by the \\npublisher. We were fortunate to face the scrutiny of reviewers who were superbly qualified to of-fer their critiques, comments, and suggestions—many of which strengthened this edition. While holding them blameless for any remaining shortcomings, we owe these reviewers many thanks for their contributions:\\nAcknowledgments\\nMubarak Banisaklher, Bethune  \\nCookman University\\nDavid Bell, Pacific Union CollegeYurii Boreisha, Minnesota State  \\nUniversity, Moorhead\\nLaurie Crawford, Franklin  \\nUniversity\\nMel Goetting, Shawnee State  \\nUniversity\\nJeff Guan, University of LouisvilleWilliam Hochstettler, Franklin  \\nUniversityLaurene Hutchinson, Louisiana State \\nUniversity, Baton\\xa0Rouge\\nNitin Kale, University of Southern \\nCalifornia, Los AngelesGerald Karush, Southern  New Hampshire University\\nMichael Kelly, Community College  \\nof Rhode Island\\nTimothy Koets, Grand Rapids  \\nCommunity College\\nKlara Nelson, The University  \\nof Tampa\\nChiso Okafor, Roxbury Community \\nCollege\\nBrandon Olson, The College of  \\nSt. Scholastica\\nJames Reneau, Shawnee State  \\nUniversityJulio Rivera, University of Alabama  \\nat Birmingham\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4458ee80-0d26-4edf-a15d-b4c0a225f6fc', embedding=None, metadata={'page_label': 'xxiv', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xxiv  AcknowledgmentsRuth Robins, University of Houston, \\nDowntown\\nSamuel Sambasivam, Azusa Pacific \\nUniversity\\nPaul Seibert, North Greenville  \\nUniversity\\nRonghua Shan, Dakota State  \\nUniversityAndrew Smith, Marian University\\nAntonis Stylianou, University of North \\nCarolina, Charlotte\\nBrian West, University of Louisiana at \\nLafayette\\nNathan White, McKendree University\\nIn some respects, writing books resembles building construction: When 90 percent of the work \\nseems done, 90 percent of the work remains to be done. Fortunately for us, we had a great team \\non our side.\\n• We are deeply indebted to Deb Kaufmann for her help and guidance. Deb has been everything we could have hoped for in a development editor and more. Deb has been our editor for al-most all the editions of this book, and the quality of her work shows in the attention to detail and the cohesiveness and writing style of the material in this book.\\n• After writing so many books and twelve editions of this  book, we know just how difficult  \\nit can be to transform the authors’ work into an attractive product. The production team,  \\nboth at Cengage Learning (Nadia Saloom) and Cenveo Publisher Services (Saravanakumar Dharman), have done an excellent job.\\n• We also owe Jennifer King and Ted Knight, our Content Developers, special thanks for their ability to guide this book to a successful conclusion.\\nWe also thank our students for their comments and suggestions. They are the reason for writing \\nthis book in the first place. One comment stands out in particular: “I majored in systems for four years, and I finally discovered why when I took your course. ” And one of our favorite comments by a former student was triggered by a question about the challenges created by a real-world in-formation systems job: “Doc, it’s just like class, only easier. Y ou really prepared me well. Thanks!”\\nSpecial thanks go to a very unique and charismatic gentleman. For over 20 years, Peter Rob has \\nbeen the driving force behind the creation and evolution of this book. This book originated as a product of his drive and dedication to excellence. For over 22 years, he was the voice of Database Systems and the driving force behind its advancement. We wish him peace in his retirement, time with his loved ones, and luck on his many projects.\\nLast, and certainly not least, we thank our families for their solid support at home. They gra-\\nciously accepted the fact that during more than a year’s worth of rewriting, there would be no free weekends, rare free nights, and even rarer free days. We owe you much, and the dedications we wrote are but a small reflection of the important space you occupy in our hearts.\\nCarlos Coronel and Steven Morris\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9a9ac1b9-c27d-4eed-a264-92f4dce756b1', embedding=None, metadata={'page_label': '1', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 1\\nDatabase Concepts\\n1Database Systems\\n2 Data Models\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e63cedd4-7137-4fd1-8527-02b0a45d7eda', embedding=None, metadata={'page_label': '2', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 1\\nDatabase Systems\\nIn this chapter, you will learn:\\n• The difference between data and information\\n• What a database is, the various types of databases, and why they are valuable assets for  \\ndecision making\\n• The importance of database design\\n• How modern databases evolved from file systems\\n• About flaws in file system data management\\n• The main components of the database system\\n• The main functions of a database management system (DBMS)\\nPreviewOrganizations use data to keep track of their day-to-day operations. Such data is used to \\ngenerate information, which in turn is the basis for good decisions. Data is likely to be managed most efficiently when it is stored in a database. Databases are involved in almost all facets and activities of our daily lives: from school, to work, to medical care, govern-ment, nonprofit organizations, and houses of worship. In this chapter, you will learn what a database is, what it does, and why it yields better results than other data management methods. Y ou will also learn about various types of databases and why database design is so important.\\nDatabases evolved from computer file systems. Although file system data management \\nis now largely outmoded, understanding the characteristics of file systems is important because file systems are the source of serious data management limitations. In this chap-ter, you will also learn how the database system approach helps eliminate most of the \\nshortcomings of file system data management.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH01_Text              P\\t P\\t P\\t P\\nCH01_Design_Example  P\\t P\\t P\\t PCH01_Problems  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d5da2782-ae11-429d-a2ff-2e7edd70132c', embedding=None, metadata={'page_label': '3', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\nChapter 1    Database Systems\\n  \\n \\n3\\nData is not only ubiquitous and pervasive, it is essential for organizations to survive \\nand prosper. Imagine trying to operate a business without knowing who your customers \\nare, what products you are selling, who is working for you, who owes you money, and \\nto whom you owe money. All businesses have to keep this type of data and much more. \\nJust as important, they must have that data available to decision makers when necessary. \\nIt can be argued that the ultimate purpose of all business information systems is to help \\nbusinesses use information as an organizational resource. At the heart of all of these \\nsystems are the collection, storage, aggregation, manipulation, dissemination, and man\\n-\\nagement of data.\\nDepending on the type of information system and the characteristics of the busi\\n-\\nness, this data could vary from a few megabytes on just one or two topics to terabytes \\ncovering hundreds of topics within the business’s internal and external environment. \\n1-1\\n \\nWhy Databases?\\nSo, why do we need databases? In today’s world, data is ubiquitous (abundant, global, every\\n-\\nwhere) and pervasive (unescapable, prevalent, persistent). From birth to death, we generate \\nand consume data. The trail of data starts with the birth certificate and continues all the way \\nto a death certificate (and beyond!). In between, each individual produces and consumes \\nenormous amounts of data. As you will see in this book, databases are the best way to store \\nand manage data. Databases make data persistent and shareable in a secure way. As you look \\nat Figure 1.1, can you identify some of the data generated by your own daily activities?\\nFIGURE 1.1\\n \\n  THE PERVASIVE NATURE OF DATABASES\\nA Day In  Susan’s Life\\nSee how many databases she interacts with each day\\nWhere is the product\\ndata stored?\\nIs the product quantity in\\nstock updated at checkout?\\nDoes she pay with a credit\\ncard?\\nCO\\nCA\\nWhere is the pharmacy\\ninventory data stored?\\nWhat data about each\\nproduct will be in the\\ninventory data?\\nWhat data is kept about\\neach customer and \\nwh\\nere\\nis it stored?\\nWhere does the online\\ntr\\nav\\nel website get the\\nairline and hotel data from?\\nWhat customer data would\\nbe kept \\nby\\n the website?\\nWhere would the customer\\ndata be stored?\\nAt night\\n, \\nshe plans for a trip\\nand buys airline tickets and\\nhotel reser\\nva\\ntions online\\nWhere are the product\\nand stock data stored?\\nWhere does the system get\\nthe data to generate pr\\noduct\\n“recommendations” to the\\ncustomer?\\nWhere would credit card\\ninformation be stored?\\nThen she makes a few\\nonline purchases\\nwww.abc.com\\nW\\nhere is the data about the\\nfriends and gr\\noups stored?\\nW\\nhere are the “likes” stored\\nand w\\nhat would they be\\nused for?\\nBefore leaving for work,\\nSusan checks her\\nFacebook and\\nTwitter accounts\\nUsers\\nFriends\\nPosts\\nProducts\\nSales\\nCustomers\\nProducts\\nSales\\nCustomers\\nFlights\\nHotels\\nCustomers\\nProducts\\nSales\\nCustomers\\nOn her lunch break, \\nshe picks up her \\nprescription at the \\npharmacy\\nAfter work, Susan \\ngoes to the grocery \\nstore\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ce867922-79ee-4ad0-a02e-934f3aa70705', embedding=None, metadata={'page_label': '4', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4   Part 1    Database Concepts\\n Telecommunications companies, such as Sprint and AT&T, are known to have systems \\nthat keep data on trillions of phone calls, with new data being added to the system at speeds up to 70,000 calls per second! Not only do these \\n companies have to store and man-\\nage immense collections of data, they have to be able to find any given fact in that data quickly. Consider the case of Internet search staple Google. While Google is reluctant to disclose many details about its data storage specifications, it is estimated that the company responds to over 91 million searches per day across a collection of data that is several terabytes in size. Impressively, the results of these searches are available almost instantly.\\nHow can these businesses process this much data? How can they store it all, and then \\nquickly retrieve just the facts that decision makers want to know, just when they want to know it? The answer is that they use databases. Databases, as explained in detail through-out this book, are specialized structures that allow computer-based systems to store, manage, and retrieve data very quickly. Virtually all modern business systems rely on databases. Therefore, a good understanding of how these structures are created and their proper use is vital for any information systems professional. Even if your career does not take you down the amazing path of database design and development, databases will be a key component of the systems that you use. In any case, you will probably make decisions in your career based on information generated from data. Thus, it is important that you know the difference between data and information.\\n1-2 Data versus Information\\nTo understand what drives database design, you must understand the difference between data and information. Data consists of raw facts. The word raw  indicates that the facts \\nhave not yet been processed to reveal their meaning. For example, suppose that a uni-versity tracks data on faculty members for reporting to accrediting bodies. To get the data for each faculty member into the database, you would provide a screen to allow for convenient data entry, complete with drop-down lists, combo boxes, option buttons, and other data-entry validation controls. Figure\\xa01.2(a) shows a simple data-entry form from a software package named Sedona. When the data is entered into the form and saved, it is placed in the underlying database as raw data, as shown in Figure 1.2(b). Although you now have the facts in hand, they are not particularly useful in this format. Reading through hundreds of rows of data for faculty members does not provide much insight into the overall makeup of the faculty. Therefore, you transform the raw data into a data summary like the one shown in Figure 1.2(c). Now you can get quick answers to questions such as “What percentage of the faculty in the Information Systems (INFS) department are adjuncts?” In this case, you can quickly determine that 20 percent of the INFS faculty members are adjunct faculty. Because graphics can enhance your ability to quickly extract meaning from data, you show the data summary pie chart in Figure 1.2(d).\\nInformation is the result of processing raw data to reveal its meaning. Data process-\\ning can be as simple as organizing data to reveal patterns or as complex as making fore-casts or drawing inferences using statistical modeling. To reveal meaning, information requires context . For example, an average temperature reading of 105 degrees does not \\nmean much unless you also know its context: Is this reading in degrees Fahrenheit or Celsius? Is this a machine temperature, a body temperature, or an outside air tempera-ture? Information can be used as the foundation for decision making. For example, the data summary for the faculty can provide accrediting bodies with insights that are useful in determining whether to renew accreditation for the university.\\nKeep in mind that raw data must be properly formatted  for storage, processing, and \\n presentation. For example, dates might be stored in Julian calendar formats within the data-base, but displayed in a variety of formats, such as day-month-year or month/day/year, for data\\nRaw facts, or facts that have not yet been processed to reveal their meaning to the end user.\\ninformation\\nThe result of processing raw data to reveal its meaning. Information consists of transformed data and facilitates decision making.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9401156f-4487-463a-8261-a7465f060563', embedding=None, metadata={'page_label': '5', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    5\\ndifferent purposes. Respondents’ yes/no responses might need to be converted to a Y/N or \\n0/1 format for data storage. More complex formatting is required when working with com -\\nplex data types, such as sounds, videos, or images.\\nIn this “information age, ” production of accurate, relevant, and timely information is the \\nkey to good decision making. In turn, good decision making is the key to business survival in \\na global market. We are now said to be entering the “knowledge age. ”1 \\nData is the foundation of  information, which is the bedrock of knowledge —that \\nis, the body of information and facts about a specific subject. Knowledge implies \\nfamiliarity, awareness, and understanding of information as it applies to an envi -\\nronment. A key characteristic of knowledge is that “new” knowledge can be derived \\nfrom “old” knowledge.\\nLet’s summarize some key points:\\n• Data constitutes the building blocks of information.\\n• Information is produced by processing data.\\n• Information is used to reveal the meaning of data.\\n• Accurate, relevant, and timely information is the key to good decision making.\\n• Good decision making is the key to organizational survival in a global  environment.FIGURE 1.2   TRANSFORMING RAW DATA INTO INFORMATION\\na) Data entry screen b) Raw data\\nc) Information in summary format d) Information in graphical format\\n1  Peter Drucker coined the phrase “knowledge worker” in 1959 in his book Landmarks of Tomorrow.  In 1994, \\nEsther Dyson, George  Keyworth, and Dr. Alvin Toffler introduced the concept of the “knowledge age. ”knowledge\\nThe body of information \\nand facts about a \\nspecific subject. \\nKnowledge implies \\nfamiliarity, awareness, \\nand understanding of \\ninformation as it applies \\nto an environment. A \\nkey characteristic is that \\nnew knowledge can \\nbe derived from old \\nknowledge.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='934e0fa2-b4a7-411b-9869-984b83714f96', embedding=None, metadata={'page_label': '6', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6   Part 1    Database Concepts\\nTimely and useful information requires accurate data. Such data must be  properly gen-\\nerated and stored in a format that is easy to access and process. In addition, like any basic \\nresource, the data environment must be managed carefully. Data management is a disci-pline that focuses on the proper generation, storage, and retrieval of data. Given the crucial role that data plays, it should not surprise you that data management is a core activity for any business, government agency, service organization, or charity.\\n1-3 Introducing the Database\\nEfficient data management typically requires the use of a computer database. A  database is a \\nshared, integrated computer structure that stores a collection of the following:\\n• End-user data—that is, raw facts of interest to the end user\\n• Metadata, or data about data, through which the end-user data is integrated and \\n managed\\nThe metadata describes the data characteristics and the set of relationships that links \\nthe data found within the database. For example, the metadata component stores infor -\\nmation such as the name of each data element, the type of values (numeric, dates, or text) \\nstored on each data element, and whether the data element can be left empty. The meta-data provides information that complements and expands the value and use of the data. In short, metadata presents a more complete picture of the data in the database. Given the characteristics of metadata, you might hear a database described as a “collection of self-describing d a t a .”\\nA database management system (DBMS) is a collection of programs that manages \\nthe database structure and controls access to the data stored in the database. In a sense, a database resembles a very well-organized electronic filing cabinet in which powerful software (the DBMS) helps manage the cabinet’s contents.\\n1-3a  Role and Advantages of the DBMS\\nThe DBMS serves as the intermediary between the user and the database. The database structure itself is stored as a collection of files, and the only way to access the data in those files is through the DBMS. Figure 1.3 emphasizes the point that the DBMS presents the end user (or application program) with a single, integrated view of the data in the database. The DBMS receives all application requests and translates them into the com-plex operations required to fulfill those requests. The DBMS hides much of the database’s internal complexity from the application programs and users. The application program might be written by a programmer using a \\n programming language, such as Visual Basic.\\nNET, Java, or C#, or it might be created through a DBMS utility program.\\nHaving a DBMS between the end user’s applications and the database offers some \\nimportant advantages. First, the DBMS enables the data in the database to be shared among multiple applications or users. Second, the DBMS integrates  the many different \\nusers’ views of the data into a single all-encompassing data \\n repository.\\nBecause data is the crucial raw material from which information is derived, you must \\nhave a good method to manage such data. As you will discover in this book, the DBMS helps make data management more efficient and effective. In particular, a DBMS pro-vides these advantages:\\n•\\n Improved data sharing . The DBMS helps create an environment in which end users \\nhave better access to more and better-managed data. Such access makes it possible for \\nend users to respond quickly to changes in their environment.data management\\nA process that focuses on data collection, storage, and retrieval. Common data management functions include addition, deletion, modification, and listing.\\ndatabase\\nA shared, integrated computer structure that houses a collection of related data. A database contains two types of data: end-user data (raw facts) and metadata. \\nmetadata\\nData about data; that is, data about data characteristics and relationships. See also data dictionary.\\ndatabase \\n management  \\nsystem (DBMS)\\nThe collection of programs that manages the database structure and controls access to the data stored in the database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='05eaa368-945d-4e12-b72b-3c6a2d42e415', embedding=None, metadata={'page_label': '7', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    7\\n• Improved data security. The more users access the data, the greater the risks of data \\nsecurity breaches. Corporations invest considerable amounts of time, effort, and money to ensure that corporate data is used properly. A DBMS provides a framework for better enforcement of data privacy and security policies.\\n•\\n Better data integration . Wider access to well-managed data promotes an inte-\\ngrated view of the organization’s operations and a clearer view of the big picture. It becomes much easier to see how actions in one segment of the company affect other segments.\\n•\\n Minimized data inconsistency . Data inconsistency exists when different versions \\nof the same data appears in different places. For example, data inconsistency exists when a company’s sales department stores a sales representative’s name as Bill Brown and the company’s personnel department stores that same person’s name as William G. Brown, or when the company’s regional sales office shows the price of a product as $45.95 and its national sales office shows the same product’s price as $43.95. The probability of data inconsistency is greatly reduced in a prop-erly designed database.\\n•\\n Improved data access . The DBMS makes it possible to produce quick answers to ad hoc \\nqueries. From a database perspective, a query is a specific request issued to the DBMS for data manipulation—for example, to read or update the data. Simply put, a query is a question, and an ad hoc query is a spur-of-the-moment question. The DBMS sends back an answer (called the query result set) to the application. For example, when dealing with large amounts of sales data, end users might want quick answers to questions (ad hoc queries). Some examples include the following:\\n –What was the dollar volume of sales by product during the past six months?\\n –What is the sales bonus figure for each of our salespeople during the past three months?\\n –How many of our customers have credit balances of $3,000 or more?FIGURE 1.3    THE DBMS MANAGES THE INTERACTION BETWEEN THE END USER  \\nAND THE DATABASE\\nEnd users\\nEnd usersApplication\\nrequestData\\nApplication\\nrequestDataDatabase structure\\nDBMS\\n(Database\\nmanagement system)Customers\\nInvoices\\nProductsMetadata\\nEnd-user\\ndataSingle\\nIntegratedhttp://\\nView of data\\ndata inconsistency\\nA condition in which different versions of the same data yield different (inconsistent) results.\\nquery\\nA question or task asked by an end user of a database in the form of SQL code. A specific request for data manipulation issued by the end user or the application to the DBMS.\\nad hoc query\\nA “spur-of-the-moment” question.\\nquery result set\\nThe collection of data rows returned by a query.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a0df58b5-9936-477e-aaa7-0659cde47511', embedding=None, metadata={'page_label': '8', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='8   Part 1    Database Concepts\\n• Improved decision making . Better-managed data and improved data access make \\nit\\xa0 possible to generate better-quality information, on which better decisions are \\nbased. The quality of the information generated depends on the quality of the \\n underlying data. Data quality is a comprehensive approach to promoting the accu-\\nracy, validity, and timeliness of the data. While the DBMS does not guarantee data quality, it provides a framework to facilitate data quality initiatives. Data quality concepts will be covered in more detail in Chapter 16, Database Administration and Security.\\n•\\n Increased end-user productivity. The availability of data, combined with the tools that transform data into usable information, empowers end users to make quick, informed decisions that can make the difference between success and failure in the global economy.\\nThe advantages of using a DBMS are not limited to the few just listed. In fact, you \\nwill discover many more advantages as you learn more about the technical details of  \\ndatabases and their proper design.\\n1-3b  Types of Databases\\nA DBMS can be used to build many different types of databases. Each database stores a particular collection of data and is used for a specific purpose. Over the years, as tech-nology and innovative uses of databases have evolved, different methods have been used to classify databases. For example, databases can be classified by the number of users supported, where the data is located, the type of data stored, the intended data usage, and the degree to which the data is structured.\\nThe number of users determines whether the database is classified as single user or \\nmultiuser. A single-user database supports only one user at a time. In other words, if user A is using the database, users B and C must wait until user A is done. A single-user database that runs on a personal computer is called a desktop database. In contrast, a multiuser database supports multiple users at the same time. When the multiuser \\ndatabase supports a relatively small number of users (usually fewer than 50) or a specific department within an organization, it is called a workgroup database. When the data-base is used by the entire organization and supports many users (more than 50, usually hundreds) across many departments, the database is known as an enterprise database.\\nLocation might also be used to classify the database. For example, a database that \\nsupports data located at a single site is called a centralized database. A database that \\n supports data distributed across several different sites is called a distributed \\n database. The extent to which a database can be distributed and the way in which such distribution is managed are addressed in detail in Chapter 12, Distributed Data-base \\n Management Systems.\\nBoth centralized and decentralized (distributed) databases require a well-defined \\ninfrastructure (hardware, operating systems, network technologies, etc.) to implement and operate the database. Typically, the infrastructure is owned and maintained by the organization that creates and operates the database. But in recent years, the use of cloud databases has been growing in popularity. A cloud database is a database that is created and maintained using cloud data services, such as Microsoft Azure or Amazon AWS. These services, provided by third-party vendors, provide defined performance measures (data storage capacity, required throughput, and availability) for the database, but do not necessarily specify the underlying infrastructure to implement it. The data owner does not have to know, or be concerned about, what hardware and software is being used to support their database. The performance capabilities can be renegotiated with the data quality\\nA comprehensive \\n approach to ensuring the accuracy, validity, and timeliness of data.\\nsingle-user database\\nA database that supports only one user at a time.\\ndesktop database\\nA single-user database that runs on a personal computer.\\nmultiuser database\\nA database that supports multiple concurrent users.\\nworkgroup database\\nA multiuser database that usually supports fewer than 50 users or is used for a specific department in an organization.\\nenterprise database\\nThe overall company data representation, which provides support for present and expected future needs.\\ncentralized database\\nA database located at a single site.\\ndistributed database\\nA logically related database that is stored in two or more physically independent sites.\\ncloud database\\nA database that is created and maintained\\n using \\ncloud services, such as \\n Microsoft Azure \\nor  Amazon AWS.\\ngeneral-purpose database\\nA database that contains a wide variety of data used in multiple \\n disciplines.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d0eb2fdb-5803-4bfc-8b35-b1b8dd3dad21', embedding=None, metadata={'page_label': '9', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    9\\ncloud provider as the business demands on the database change. For example, during \\nthe 2012 presidential election in the United States, the Obama campaign used a cloud database hosted on infrastructure capabilities purchased from Amazon. The campaign did not have to buy, install, configure, or maintain any hardware, operating systems, or network devices. It simply purchased storage and processing capacity for its data and applications. As the demands on the database increased, additional processing and stor -\\nage capabilities could be purchased as needed.\\nIn some contexts, such as research environments, a popular way of classifying data-\\nbases is according to the type of data stored in them. Using this criterion, databases are grouped into two categories: general-purpose and discipline-specific databases. General-purpose databases contain a wide variety of data used in multiple disci-plines—for example, a census database that contains general demographic data and the LexisNexis and ProQuest databases that contain newspaper, magazine, and journal articles for a variety of topics. Discipline-specific databases contain data focused on specific subject areas. The data in this type of database is used mainly for academic or research purposes within a small set of disciplines. Examples of discipline-specific  \\ndatabases include financial data stored in databases such as CompuStat or CRSP (Center for Research in Security Prices), geographic information system (GIS) data-bases that store geospatial and other related data, and medical databases that store confidential \\n medical history data.\\nThe most popular way of classifying databases today, however, is based on how \\nthey will be used and on the time sensitivity of the information gathered from them. For example, transactions such as product or service sales, payments, and supply purchases reflect critical day-to-day operations. Such transactions must be recorded accurately and immediately. A database that is designed primarily to support a com-pany’s day-to-day operations is classified as an operational database, also known as an online transaction processing (OLTP) database, transactional database, \\nor production database. In contrast, an analytical database focuses primarily \\non storing historical data and business metrics used exclusively for tactical or stra-tegic decision making. Such analysis typically requires extensive “data massaging” (data manipulation) to produce information on which to base pricing decisions, sales forecasts, market strategies, and so on. Analytical databases allow the end user to perform advanced analysis of business data using sophisticated tools.\\nTypically, analytical databases comprise two main components: a data warehouse and \\nan online analytical processing front end. The data warehouse is a specialized data-\\nbase that stores data in a format optimized for decision support. The data warehouse contains historical data obtained from the operational databases as well as data from other external sources. Online analytical processing (OLAP) is a set of tools that work together to provide an advanced data analysis environment for retrieving, processing, and modeling data from the data warehouse. In recent times, this area of database appli-cation has grown in importance and usage, to the point that it has evolved into its own discipline: business intelligence. The term business intelligence describes a compre-hensive approach to capture and process business data with the purpose of generating information to support business decision making. Chapter 13, Business Intelligence and Data Warehouses, covers this topic in detail.\\nDatabases can also be classified to reflect the degree to which the data is structured. \\nUnstructured data is data that exists in its original (raw) state—that is, in the format in which it was collected. Therefore, unstructured data exists in a format that does not lend itself to the processing that yields information. Structured data is the result of for -\\nmatting unstructured data to facilitate storage, use, and the generation of information. Y ou apply structure (format) based on the type of processing that you intend to perform discipline-specific \\n database\\nA database that contains data focused on specific subject areas.\\noperational \\n database\\nA database designed primarily to support a company’s day-to-day operations. Also known as a transactional database, \\nOLTP database, or production database.\\nonline transaction \\n processing (OLTP) \\n database\\nSee operational database.\\ntransactional \\n database\\nSee operational database.\\nproduction database\\nSee operational database.\\nanalytical database\\nA database focused primarily on storing \\n historical data and business metrics used for tactical or strategic decision making.\\ndata warehouse\\nA specialized databasethat stores historical and aggregated data in a format optimized for decision support.\\nonline analytical processing (OLAP)\\nA set of tools that provide advanced data analysis for retrieving, processing, and modeling data from the data warehouse.\\nbusiness intelligence \\nA set of tools and processes used to capture, collect, integrate, store, and analyze data to support business decision making.\\nunstructured data\\nData that exists in its original, raw state; that is, in the format in which it was collected.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d200835f-a39d-4b2d-af9f-d7b06a24c934', embedding=None, metadata={'page_label': '10', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='10   Part 1    Database Concepts\\non the data. Some data might not be ready (unstructured) for some types of processing, \\nbut they might be ready (structured) for other types of processing. For example, the data value 37890 might refer to a zip code, a sales value, or a product code. If this value rep-resents a zip code or a product code and is stored as text, you cannot perform mathemat-ical computations with it. On the other hand, if this value represents a sales transaction, it must be formatted as numeric.\\nTo further illustrate the concept of structure, imagine a stack of printed paper \\ninvoices. If you want to merely store these invoices as images for future retrieval and display, you can scan them and save them in a graphic format. On the other hand, if you want to derive information such as monthly totals and average sales, such graphic storage would not be useful. Instead, you could store the invoice data in a (structured) spreadsheet format so that you can perform the requisite computations. Actually, most data you encounter is best classified as semistructured. \\n Semistructured data has \\nalready been processed to some extent. For example, if you look at a typical webpage, the data is presented in a prearranged format to convey some information. The data-base types mentioned thus far focus on the storage and management of highly struc-tured data. However, corporations are not limited to the use of structured data. They also use semistructured and unstructured data. Just think of the valuable information that can be found on company emails, memos, and documents such as procedures, rules, and webpages. Unstructured and semistructured data storage and management needs are being addressed through a new generation of databases known as XML data-bases. Extensible Markup \\n Language (XML) is a special language used to represent \\nand manipulate data elements in a textual format. An XML database supports the storage and management of \\n semistructured XML data.\\nTable 1.1 compares the features of several well-known database management systems.\\nPRODUCT NUMBER OF USERS DATA LOCATION DATA USAGE XML\\nSINGLE \\nUSERMULTIUSER\\nCENTRALIZED DISTRIBUTED OPERATIONAL ANALYTICAL WORKGROUP ENTERPRISE\\nMS Access X X X X\\nMS SQL Server X3X X X X X X X\\nIBM DB2 X3X X X X X X X\\nMySQL X X X X X X X X\\nOracle RDBMS X3X X X X X X XTYPES OF DATABASESTABLE 1.1  \\nWith the emergence of the World Wide Web and Internet-based technologies as the basis for the new “social media” generation, great amounts of data are being stored and analyzed. Social media refers to web and mobile technologies that enable “any-where, anytime, always on” human interactions. Websites such as Google, Facebook, Twitter, and LinkedIn capture vast amounts of data about end users and consumers. This data grows exponentially and requires the use of specialized database systems. For example, as of 2015, over 500 million tweets were posted every day on Twitter, and that number continues to grow. As a result, the MySQL database Twitter was using to store user content was frequently overloaded by \\n demand.2,3 Facebook faces \\n2 Vendor offers single-user/personal DBMS version.\\n3 www.internetlivestats.com/twitter-statistics/ structured data\\nData that has been formatted to facilitate storage, use, and information generation.\\nsemistructured data\\nData that has already been processed to some extent.\\nExtensible Markup Language (XML)\\nA metalanguage used to represent and manipulate data elements. Unlike other markup languages, XML permits the manipulation of a document’s data elements. \\nXML database\\nA database system that stores and manages semistructured XML data.\\nsocial media\\nWeb and mobile technologies that enable “anywhere, anytime, always on” human interactions.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7fba1b61-b6e3-473e-ace9-7ddfcdeed017', embedding=None, metadata={'page_label': '11', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    11\\nsimilar challenges. With over 500 terabytes of data coming in each day, it stores over \\n100 petabytes of data in a single data storage file system. From this data, its database scans over 200 terabytes of data each hour to process user actions, including status updates, picture requests, and billions of “Like” actions.\\n4 Over the past few years, \\nthis new breed of specialized database has grown in sophistication and widespread usage. Currently, this new type of database is known as a NoSQL database. The term NoSQL (Not only SQL) is generally used to describe a new generation of database management systems that is not based on the traditional relational database model. NoSQL databases are designed to handle the unprecedented volume of data, variety of data types and structures, and velocity of data operations that are characteristic of these new business requirements. Y ou will learn more about this type of system in \\n Chapter 2, Data Models.\\nThis section briefly mentioned the many different types of databases. As you learned \\nearlier, a database is a computer structure that houses and manages end-user data. One of the first tasks of a database professional is to ensure that end-user data is properly structured to derive valid and timely information. For this, good database design is \\n essential.\\n1-4 Why Database Design is Important\\nA problem that has evolved with the use of personal productivity tools such as spread-sheets and desktop database programs is that users typically lack proper data-modeling  \\nand database design skills. People naturally have a “narrow” view of the data  \\nin their environment. For example, consider a student’s class schedule. The sched-ule probably contains the student’s identification number and name, class code, class description, class credit hours, class instructor name, class meeting days and times, and class room number. In the mind of the student, these various data items compose a single unit. If a student organization wanted to keep a record of the schedules of its members, an end user might make a spreadsheet to store the schedule information. Even if the student makes a foray into the realm of desktop databases, he or she is likely to create a structure composed of a single table that mimics his or her view of the schedule data. As you will learn in the coming chapters, translating this type of narrow view of data into a single two-dimensional table structure is a poor database design choice.\\nDatabase design refers to the activities that focus on the design of the database \\nstructure that will be used to store and manage end-user data. A database that meets all user requirements does not just happen; its structure must be designed carefully. In fact, database design is such a crucial aspect of working with databases that most of this book is dedicated to the development of good database design techniques. Even a good DBMS will perform poorly with a badly designed database.\\nData is one of an organization’s most valuable assets. Data on customers, employees, \\norders, and receipts is all vital to the existence of a company. Tracking key growth and performance indicators are also vital to strategic and tactical plans to ensure future suc-cess; therefore, an organization’s data must not be handled lightly or carelessly. Thorough planning to ensure that data is properly used and leveraged to give the company the most benefit is just as important as proper financial planning to ensure that the company gets the best use from its financial resources.\\n4  Josh Constine, “How big is Facebook’s data? 2.5 billion pieces of content and 500+ terabytes of data ingested \\nevery day, ” Tech\\xa0Crunch,  August 22, 2012, http://techcrunch.com/2012/08/22/how-big-is-facebooks-data-2-5-\\nbillion-pieces-of-content-and-500-terabytes-ingested-  every-day/ NoSQL\\nA new generation of \\ndatabase management systems that is not based on the traditional relational database model.\\ndatabase design\\nThe process that yields the description of the database structure and determines the database components. The second phase of the Database Life Cycle.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d33d37b7-2b52-4af5-8c94-7f0222197a54', embedding=None, metadata={'page_label': '12', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='12   Part 1     Database Concepts\\nBecause current-generation DBMSs are easy to use, an unfortunate side effect is \\nthat many computer-savvy business users gain a false sense of confidence in their \\n ability to build a functional database. These users can effectively navigate the creation \\nof database objects, but without the proper understanding of database design, they \\ntend to produce flawed, overly simplified structures that prevent the system from \\n correctly storing data that corresponds to business realities, which produces incom -\\nplete or erroneous results when the data is retrieved. Consider the data shown in \\nFigure 1.4, which illustrates the efforts of an organization to keep records about its \\nemployees and their skills. Some employees have not passed a certification test in \\nany skill, while others have been certified in several skills. Some certified skills are \\nshared by several employees, while other skills have no employees that hold those \\n certifications.\\nFIGURE 1.4    EMPLOYEE SKILLS CERTIFICATION IN A POOR DESIGN   \\nWhy are there\\nblanks in rows\\n9 and 10?How to produce\\nan alphabetical\\nlisting of\\nemployees?How to count how\\nmany employees are\\ncertiﬁed in Basic\\nDatabase Manipulation?Is Basic Database\\nManipulation the\\nsame as Basic DB\\nManipulation?What if an employee\\nacquires a fourth\\ncertiﬁcation?\\nDo we add\\nanother column?\\nBased on this storage of the data, notice the following problems:\\n• It would be difficult, if not impossible, to produce an alphabetical listing of employees \\nbased on their last names.\\n• To determine how many employees are certified in Basic Database Manipula -\\ntion, you would need a program that counts the number of those certifications \\nrecorded in Skill1 and places it in a variable. Then the count of those certifications \\nin Skill2 could be calculated and added to the variable. Finally, the count of those \\ncertifications in Skill3 could be calculated and added to the variable to produce \\nthe total.\\n• If you redundantly store the name of a skill with each employee who is certified in \\nthat skill, you run the risk of spelling the name differently for different employees. For \\nexample, the skill Basic Database Manipulation  is also entered as Basic DB Manipula -\\ntion for at least one employee in Figure 1.4, which makes it difficult to get an accurate \\ncount of employees who have the certification.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5ef2ea3-c340-4218-81e6-71381ed12c09', embedding=None, metadata={'page_label': '13', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    13\\nFIGURE 1.5   EMPLOYEE SKILL CERTIFICATIONS IN A GOOD DESIGN\\nTable name: EMPLOYEE\\nTable name: SKILL• The structure of the database will have to be changed by adding more columns to the \\ntable when an employee is certified in a fourth skill. It will have to be modified again \\nif an employee is certified in a fifth skill.\\nContrast this poor design with that shown in Figure 1.5, where the design has been \\nimproved by decomposing the data into three related tables. These tables contain all of \\nthe same data that was represented in Figure 1.4, but the tables are structured so that you \\ncan easily manipulate the data to view it in different ways and answer simple questions.\\nWith the improved structure in Figure 1.5, you can use simple commands in a  standard \\ndata manipulation language to do the following:\\n• Produce an alphabetical listing of employees by last name: \\n  SELECT * FROM EMPLOYEE ORDER BY EMPLOYEE_LNAME;\\n• Determine how many employees are certified in Basic Database Manipulation:\\n  SELECT Count(*)\\n  FROM SKILL JOIN CERTIFIED ON SKILL.SKILL_ID = CERTIFIED.SKILL_ID  \\nWHERE SKILL_NAME = ‘Basic Database Manipulation’;\\nY ou will learn more about these commands in Chapter 7, Introduction to  Structured \\nQuery Language.\\nNote that because each skill name is stored only once, the names cannot be spelled \\nor abbreviated differently for different employees. Also, the additional  certification \\nTable name: CERTIFIEDDatabase name: Ch01_Text\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a49ee64c-e79e-4927-8e08-edbaf81bd0df', embedding=None, metadata={'page_label': '14', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='14   Part 1    Database Concepts\\nof an employee with a fourth or fifth skill does not require changes to the structure \\nof the tables.\\nProper database design requires the designer to identify precisely the database’s \\nexpected use. Designing a transactional database emphasizes accurate and con-sistent data and operational speed. Designing a data warehouse database empha-sizes the use of \\n historical and aggregated data. Designing a database to be used in a \\n centralized, single-user environment requires a different approach from that used in the design of a distributed, multiuser database. This book emphasizes the design of \\n transactional,  centralized, single-user, and multiuser databases. Chapters 12 and 13 \\nalso  examine\\xa0  critical issues confronting the designer of distributed and data warehouse \\ndatabases.\\nDesigning appropriate data repositories of integrated information using the two-  \\ndimensional table structures found in most databases is a process of decomposition. The integrated data must be decomposed properly into its constituent parts, with each part stored in its own table. Further, the relationships between these tables must be carefully considered and implemented so the integrated view of the data can be rec-reated later as information for the end user. A well-designed database facilitates data management and generates accurate and valuable information. A poorly designed database is likely to become a breeding ground for difficult-to-trace errors that may lead to poor decision making—and poor decision making can lead to the failure of an organization. Database design is simply too important to be left to luck. That’s why college students study database design, why organizations of all types and sizes send personnel to database design seminars, and why database design consultants often make an excellent living.\\n1-5 Evolution of File System Data Processing\\nUnderstanding what a database is, what it does, and the proper way to use it can be clar -\\nified by considering what a database is not. A brief explanation of the evolution of file system data processing can be helpful in understanding the data access limitations that databases attempt to overcome. Understanding these limitations is relevant to database designers and developers because database technologies do not make these problems magically disappear—database technologies simply make it easier to create solutions that avoid these problems. Creating database designs that avoid the pitfalls of earlier systems requires that the designer understand these problems and how to avoid them; otherwise, the database technologies are no better (and are potentially even worse!) than the tech-nologies and techniques they have replaced.\\n1-5a  Manual File Systems\\nTo be successful, an organization must develop systems for handling core business tasks. Historically, such systems were often manual, paper-and-pencil systems. The papers within these systems were organized to facilitate the expected use of the data. Typically, this was accomplished through a system of file folders and filing cabinets. As long as a collection of data was relatively small and an organization’s business users had few reporting requirements, the manual system served its role well as a data repository. However, as organizations grew and as reporting requirements became more complex, keeping track of data in a manual file system became more difficult. Therefore, compa-nies looked to computer \\n technology for help.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='39e0ba99-13d0-42d5-9f9f-d872cb06f850', embedding=None, metadata={'page_label': '15', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 1    Database Systems    15\\n1-5b  Computerized File Systems\\nGenerating reports from manual file systems was slow and cumbersome. In fact, some \\nbusiness managers faced government-imposed reporting requirements that led to weeks \\nof intensive effort each quarter, even when a well-designed manual system was used. \\nTherefore, a data processing (DP) specialist  was hired to create a computer-based sys -\\ntem that would track data and produce required reports.\\nInitially, the computer files within the file system were similar to the manual files. \\nA\\xa0simple example of a customer data file for a small insurance company is shown in \\n Figure 1.6. (Y ou will discover later that the file structure shown in Figure 1.6,  although \\n typically found in early file systems, is unsatisfactory for a database.)\\nThe description of computer files requires a specialized vocabulary. Every \\n discipline develops its own terminology to enable its practitioners to communicate \\nclearly. The basic file vocabulary shown in Table 1.2 will help you to understand \\nsubsequent discussions more easily.\\nBASIC FILE TERMINOLOGYTABLE 1.2  \\nTERM DEFINITION\\nData Raw facts, such as a telephone number, a birth date, a customer name, and a year-to-date (YTD) sales \\nvalue. Data has little meaning unless it has been organized in some logical manner.\\nField A character or group of characters (alphabetic or numeric) that has a specific meaning. A field is used to \\ndefine and store data.\\nRecord A logically connected set of one or more fields that describes a person, place, or thing. For example, \\nthe fields that constitute a record for a customer might consist of the customer's name, address, phone \\nnumber, date of birth, credit limit, and unpaid balance.\\nFile A collection of related records. For example, a file might contain data about the students currently \\nenrolled at Gigantic University.FIGURE 1.6  CONTENTS OF THE CUSTOMER FILE\\nC_NAME  = Customer name A_NAME = Agent name\\nC_PHONE = Customer phone A_PHONE = Agent phone\\nC_ADDRESS = Customer address TP = Insurance type\\nC_ZIP = Customer zip code AMT = Insurance policy amount, in thousands of $\\nREN = Insurance renewal date\\nDatabase name: Ch01_Textdata processing (DP) \\nspecialist\\nThe person responsible \\nfor developing \\nand managing a \\ncomputerized file \\nprocessing system. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f49f91a6-81d6-4ae0-b7b3-bd1d24c879ac', embedding=None, metadata={'page_label': '16', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"16   Part 1     Database Concepts\\nUsing the proper file terminology in Table 1.2, you can identify the file components \\nshown in Figure 1.6. The CUSTOMER file contains 10 records. Each record is composed \\nof 9 fields: C_NAME, C_PHONE, C_ADDRESS, C_ZIP , A_NAME, A_PHONE, TP , \\nAMT, and REN. The 10 records are stored in a named file. Because the file in Figure 1.6 \\ncontains customer data for the insurance company, its filename is CUSTOMER.\\nWhen business users wanted data from the computerized file, they sent requests \\nfor the data to the DP specialist. For each request, the DP specialist had to create pro -\\ngrams to retrieve the data from the file, manipulate it in whatever manner the user had \\nrequested, and present it as a printed report. If a request was for a report that had been \\nrun previously, the DP specialist could rerun the existing program and provide the \\nprinted results to the user. As other business users saw the new and innovative ways \\nin which customer data was being reported, they wanted to be able to view their data \\nin similar fashions. This generated more requests for the DP specialist to create more \\ncomputerized files of other business data, which in turn meant that more data man -\\nagement programs had to be created, which led to even more requests for reports. For \\nexample, the sales department at the insurance company created a file named SALES, \\nwhich helped track daily sales efforts. The sales department's success was so obvious \\nthat the personnel department manager demanded access to the DP specialist to auto -\\nmate payroll processing and other personnel functions. Consequently, the DP special -\\nist was asked to create the AGENT file shown in Figure 1.7. The data in the AGENT file \\nwas used to write checks, keep track of taxes paid, and summarize insurance coverage, \\namong other tasks.Online \\nContent\\nThe databases used \\nin each chapter are \\navailable at www.  \\ncengagebrain.com . \\nThroughout the book, \\nOnline Content boxes  \\nhighlight  material related  \\nto chapter  content on \\nthe website.\\nFIGURE 1.7  CONTENTS OF THE AGENT FILE\\nA_NAME = Agent name YTD_P AY = Year-to-date pay\\nA_PHONE = Agent phone YTD_FIT = Year-to-date federal income tax paid\\nA_ADDRESS = Agent address YTD_FI CA = Year-to-date Social Security taxes paid\\nZIP = Agent zip code YTD_SLS = Year-to-date sales\\nHIRED = Agent date of hire DEP = Number of dependents\\nDatabase name: Ch01_Text\\nAs more and more computerized files were developed, the problems with this type of file \\nsystem became apparent. While these problems are explored in detail in the next section, \\nthe problems basically centered on having many data files that contained related—often \\noverlapping—data with no means of controlling or managing the data consistently across \\nall of the files. As shown in Figure 1.8, each file in the system used its own application \\nprogram to store, retrieve, and modify data. Also, each file was owned by the individual \\nor the department that commissioned its creation.\\nThe advent of computer files to store company data was significant; it not only estab -\\nlished a landmark in the use of computer technologies, it also represented a huge step \\nforward in a business's ability to process data. Previously, users had direct, hands-on \\naccess to all of the business data. But they didn't have the tools to convert that data \\ninto the information they needed. The creation of computerized file systems gave them \\nimproved tools for manipulating the company data that  allowed them to create new \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='24bbe3b1-5b9e-4af0-a270-ef4af92b09a6', embedding=None, metadata={'page_label': '17', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    17\\ninformation. However, it had the additional effect of introducing a schism between \\nthe end users and their data. The desire to close the gap between the end users and the data influenced the development of many types of computer technologies, sys-tem designs, and uses (and misuses) of many technologies and techniques. However, such \\n developments also created a split between the ways DP specialists and end users \\nviewed the data. \\n• From the DP specialist’s perspective, the computer files within the file system were \\ncreated to be similar to the manual files. Data management programs were created to add to, update, and delete data from the file.\\n•\\n From the end user’s perspective, the systems separated the users from the data. As the users’ competitive environment pushed them to make more and more decisions in less time, users became frustrated by the delay between conceiving of a new way to create information from the data and the point when the DP specialist actually created  \\nthe programs to generate that information.\\n1-5c   File System Redux: Modern End-User   \\nProductivity Tools\\nThe users’ desire for direct, hands-on access to data helped to fuel the adoption of per -\\nsonal computers for business use. Although not directly related to file system evolution, the ubiquitous use of personal productivity tools can introduce the same problems as the old file systems.\\nPersonal computer spreadsheet programs such as Microsoft Excel are widely used by \\nbusiness users, and they allow the user to enter data in a series of rows and columns so the data can be manipulated using a wide range of functions. The popularity of spreadsheet applications has enabled users to conduct sophisticated data analysis that has greatly enhanced their ability to understand the data and make better decisions. \\n Unfortunately, \\nas in the old adage “When the only tool you have is a hammer, every problem looks like FIGURE 1.8  A SIMPLE FILE SYSTEM\\nSales department Personnel department\\nFile\\nManagement\\nProgramsFile\\nManagement\\nProgramsFile\\nReport\\nProgramsFile\\nReport\\nPrograms\\nAGENTSALES\\nCUSTOMER\\ne\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4db89c3e-7963-444a-ab03-04e58bab20d1', embedding=None, metadata={'page_label': '18', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='18   Part 1    Database Concepts\\na nail, ” users have become so adept at working with spreadsheets that they tend to use \\nthem to complete tasks for which spreadsheets are not appropriate.\\nA common misuse of spreadsheets is as a substitute for a database. Interestingly, \\nend users often take the limited data to which they have direct access and place it in a \\n spreadsheet format similar to that of the traditional, manual data storage systems—\\nwhich is precisely what the early DP specialists did when creating computerized data files. Due to the large number of users with spreadsheets, each making separate copies of the data, the resulting “file system” of spreadsheets suffers from the same problems as the file systems created by the early DP specialists, which are outlined in the next section.\\n1-6 Problems with File System Data Processing\\nThe file system method of organizing and managing data was a definite improvement over the manual system, and the file system served a useful purpose in data manage-ment for over two decades—a very long time in the computer era. Nonetheless, many problems and limitations became evident in this approach. A critique of the file system method serves two major purposes:\\n•\\n Understanding the shortcomings of the file system enables you to understand the \\ndevelopment of modern databases.\\n• Many of the problems are not unique to file systems. Failure to understand such prob-lems is likely to lead to their duplication in a database environment, even though database technology makes it easy to avoid them.\\nThe following problems associated with file systems, whether created by DP specialists or through a series of spreadsheets, severely challenge the types of information that can be created from the data as well as the accuracy of the information:\\n•\\n Lengthy development times. The first and most glaring problem with the file \\nsystem approach is that even the simplest data-retrieval task requires extensive  \\nprogramming. With the older file systems, programmers had to specify what must be done and how to do it. As you will learn in upcoming chapters, modern databases use a nonprocedural data manipulation language that allows the user to specify what must be done without specifying how.\\n•\\n Difficulty of getting quick answers. The need to write programs to produce even the simplest reports makes ad hoc queries impossible. Harried DP specialists who worked with mature file systems often received numerous requests for new reports. They were often forced to say that the report will be ready “next week” or even “next month. ” If you need the information now, getting it next week or next month will not serve your information needs.\\n•\\n Complex system administration . System administration becomes more difficult as \\nthe number of files in the system expands. Even a simple file system with a few files requires creating and maintaining several file management programs. Each file must have its own file management programs that allow the user to add, modify, and delete records; to list the file contents; and to generate reports. Because ad hoc queries are not possible, the file reporting programs can multiply quickly. The problem is com-pounded by the fact that each department in the organization “owns” its data by  \\ncreating its own files.\\n•\\n Lack of security and limited data sharing. Another fault of a file system data repos-itory is a lack of security and limited data sharing. Data sharing and security \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f2a70103-adca-42d7-b213-9ae5d6558fa0', embedding=None, metadata={'page_label': '19', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    19\\nare closely related. Sharing data among multiple geographically dispersed  users \\n introduces a lot of security risks. In terms of spreadsheet data, while many spread-\\nsheet  programs provide rudimentary security options, they are not always used, \\nand even when they are, they are insufficient for robust data sharing among users. In terms of creating data management and reporting programs, security and data-sharing features are difficult to program and consequently are often omitted from a file system environment. Such features include effective password protec-tion, the ability to lock out parts of files or parts of the system itself, and other mea-sures designed to safeguard data confidentiality. Even when an attempt is made to improve system and data security, the security devices tend to be limited in scope and effectiveness.\\n•\\n Extensive programming. Making changes to an existing file structure can be difficult in a file system environment. For example, changing just one field in the original CUSTOMER file would require a program that:\\n1.\\n Reads a record from the original file.\\n2. Transforms the original data to conform to the new structure’s storage  requirements.\\n3. Writes the transformed data into the new file structure.\\n4. Repeats the preceding steps for each record in the original file.\\nIn fact, any change to a file structure, no matter how minor, forces modifications in all \\nof the programs that use the data in that file. Modifications are likely to produce errors \\n(bugs), and additional time is spent using a debugging process to find those errors. Those limitations, in turn, lead to problems of structural and data dependence.\\n1-6a  Structural and Data Dependence\\nA file system exhibits structural dependence, which means that access to a file is dependent on its structure. For example, adding a customer date-of-birth field to the CUSTOMER file shown in Figure 1.6 would require the four steps described in the pre-vious section. Given this change, none of the previous programs will work with the new CUSTOMER file structure. Therefore, all of the file system programs must be modified to conform to the new file structure. In short, because the file system application programs are affected by changes in the file structure, they exhibit structural dependence. Con-versely, structural independence exists when you can change the file structure without \\naffecting the application’s ability to access the data.\\nEven changes in the characteristics of data, such as changing a field from integer to \\ndecimal, require changes in all the programs that access the file. Because all data access programs are subject to change when any of the file’s data storage characteristics change (that is, changing the data type), the file system is said to exhibit data dependence. Conversely, data independence exists when you can change the data storage character -\\nistics without affecting the program’s ability to access the data.\\nThe practical significance of data dependence is the difference between the \\n logical data format (how the human being views the data) and the physical data format (how the computer must work with the data). Any program that accesses a file system’s file must tell the computer not only what to do but how to do it. Con -\\nsequently, each program must contain lines that specify the opening of a specific file type, its record specification, and its field definitions. Data dependence makes the file system extremely cumbersome from the point of view of a programmer and database manager.structural \\n dependence\\nA data characteristic in which a change in the database schema affects data access, thus requiring changes in all access programs.\\nstructural \\n independence\\nA data characteristic in which changes in the database schema do not affect data access.\\ndata dependence\\nA data condition in which data representation and manipulation are dependent on the physical data storage characteristics.\\ndata independence\\nA condition in which data access is unaffected by changes in the physical data storage characteristics.\\nlogical data format\\nThe way a person views data within the context of a problem domain.\\nphysical data format\\nThe way a computer “sees” (stores) data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='818fe748-eee6-4944-9367-aefc3132e5a8', embedding=None, metadata={'page_label': '20', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='20   Part 1    Database Concepts\\n1-6b  Data Redundancy\\nThe file system’s structure makes it difficult to combine data from multiple sources, and \\nits lack of security renders the file system vulnerable to security breaches. The organi-zational structure promotes the storage of the same basic data in different locations. (Database professionals use the term islands of information for such scattered data locations.) The dispersion of data is exacerbated by the use of spreadsheets to store data. In a file system, the entire sales department would share access to the SALES data file through the data management and reporting programs created by the DP specialist. With the use of spreadsheets, each member of the sales department can create his or her own copy of the sales data. Because data stored in different locations will probably not be updated consistently, the islands of information often contain different versions of the same data. For example, in Figures 1.6 and 1.7, the agent names and phone num-bers occur in both the CUSTOMER and the AGENT files. Y ou only need one correct copy of the agent names and phone numbers. Having them occur in more than one place produces data redundancy. Data redundancy exists when the same data is stored unnecessarily at different places.\\nUncontrolled data redundancy sets the stage for the following:\\n•\\n Poor data security. Having multiple copies of data increases the chances for a copy of the data to be susceptible to unauthorized access. Chapter 16, Database Administra-tion and Security, explores the issues and techniques associated with securing data.\\n•\\n Data inconsistency . Data inconsistency exists when different and conflicting ver -\\nsions of the same data appear in different places. For example, suppose you change an agent’s phone number in the AGENT file. If you forget to make the correspond-ing change in the CUSTOMER file, the files contain different data for the same agent. \\n Reports will yield inconsistent results that depend on which version of the \\ndata is\\xa0used.\\n• Data-entry errors. Data-entry errors are more likely to occur when complex entries (such as 10-digit phone numbers) are made in several different files or recur frequently in one or more files. In fact, the CUSTOMER file shown in Figure 1.6 contains just such an entry error: the third record in the CUSTOMER file has transposed digits in the agent’s phone number (615-882-2144 rather than 615-882-1244).\\n•\\n Data integrity problems. It is possible to enter a nonexistent sales agent’s name and phone number into the CUSTOMER file, but customers are not likely to be impressed if the insurance agency supplies the name and phone number of an agent who does not exist. Should the personnel manager allow a nonexistent agent to accrue bonuses and benefits? In fact, a data-entry error such as an incorrectly spelled name or an incorrect phone number yields the same kind of data integrity problems.\\nNote\\nData that displays data inconsistency is also referred to as data that lacks data  integrity. \\nData integrity is defined as the condition in which all of the data in the database is consistent with the real-world events and conditions. In other words, data integrity means that:\\n• Data is accurate—there are no data inconsistencies.\\n• Data is verifiable—the data will always yield consistent results.islands of \\n information\\nIn the old file system environment, pools of independent, often duplicated, and inconsistent data created and managed by different departments.\\ndata redundancy\\nExists when the same data is stored unnecessarily at different places.\\ndata integrity\\nIn a relational database, a condition in which the data in the database complies with all entity and referential integrity constraints.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='93d4d142-d6f7-4719-94b1-e275a1d96e42', embedding=None, metadata={'page_label': '21', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    21\\n1-6c  Data Anomalies\\nThe dictionary defines anomaly  as “an abnormality. ” Ideally, a field value change should \\nbe made in only a single place. Data redundancy, however, fosters an abnormal condition \\nby forcing field value changes in many different locations. Look at the CUSTOMER file in Figure 1.6. If agent Leah F. Hahn decides to get married and move, the agent name, address, and phone number are likely to change. Instead of making these changes in a single file (AGENT), you must also make the change each time that agent’s name and phone number occur in the CUSTOMER file. Y ou could be faced with the prospect of making hundreds of corrections, one for each of the customers served by that agent! The same problem occurs when an agent decides to quit. Each customer served by that agent must be assigned a new agent. Any change in any field value must be correctly made in many places to maintain data integrity. A data anomaly develops when not all of the required changes in the redundant data are made successfully. The data anomalies found in Figure 1.6 are commonly defined as follows:\\n•\\n Update anomalies . If agent Leah F. Hahn has a new phone number, it must be entered \\nin each of the CUSTOMER file records in which Ms. Hahn’s phone number is shown. \\nIn this case, only four changes must be made. In a large file system, such a change might occur in hundreds or even thousands of records. Clearly, the potential for data inconsistencies is great.\\n•\\n Insertion anomalies. If only the CUSTOMER file existed and you needed to add a new\\xa0 agent, you would also add a dummy customer data entry to reflect the new\\xa0agent’s\\xa0addition. Again, the potential for creating data inconsistencies would be great.\\n•\\n Deletion anomalies . If you delete the customers Amy B. O’Brian, George  Williams, \\nand Olette K. Smith, you will also delete John T. Okon’s agent data. Clearly, this is not desirable.\\nOn a positive note, however, this book will help you develop the skills needed \\nto design and model a successful database that avoids the problems listed in this section.\\n1-7 Database Systems\\nThe problems inherent in file systems make using a database system very desirable. Unlike the file system, with its many separate and unrelated files, the database system consists of logically related data stored in a single logical data repository. (The “logical” label reflects the fact that the data repository appears to be a single unit to the end user, even though data might be physically distributed among multiple storage facilities and locations.) Because the database’s data repository is a single logical unit, the database represents a major change in the way end-user data is stored, accessed, and managed. The database’s DBMS, shown in Figure 1.9, provides numerous advantages over file sys-tem management, shown in Figure 1.8, by making it possible to eliminate most of the file system’s data inconsistency, data anomaly, data dependence, and structural depen-dence problems. Better yet, the current generation of DBMS software stores not only the data structures, but also the relationships between those structures and the access paths to those structures—all in a central location. The current generation of DBMS software also takes care of defining, storing, and managing all required access paths to those components.\\ndata anomaly\\nA data abnormality in which inconsistent changes have been made to a database. For example, an employee moves, but the address change is not corrected in all files in the database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ffd5a782-c9d0-4003-a488-070793844f13', embedding=None, metadata={'page_label': '22', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='22   Part 1    Database Concepts\\nRemember that the DBMS is just one of several crucial components of a database sys-\\ntem. The DBMS may even be referred to as the database system’s heart. However, just as \\nit takes more than a heart to make a human being function, it takes more than a DBMS to make a database system function. In the sections that follow, you’ll learn what a database system is, what its components are, and how the DBMS fits into the picture.\\n1-7a  The Database System Environment\\nThe term database system refers to an organization of components that define and regulate the collection, storage, management, and use of data within a database environ-ment. From a general management point of view, the database system is composed of the five major parts shown in Figure 1.10: hardware, software, people, procedures, and data.\\nLet’s take a closer look at the five components shown in Figure 1.10:\\n•\\n Hardware . Hardware refers to all of the system’s physical devices, including computers \\n(PCs, tablets, workstations, servers, and supercomputers), storage devices, printers, \\nnetwork devices (hubs, switches, routers, fiber optics), and other devices (automated teller machines, ID readers, and so on).\\n•\\n Software . Although the most readily identified software is the DBMS itself, three types \\nof software are needed to make the database system function fully: operating system software, DBMS software, and application programs and utilities.\\n –Operating system software manages all hardware components and makes it possible for all other software to run on the computers. Examples of operating system soft-ware include Microsoft Windows, Linux, Mac OS, UNIX, and MVS.FIGURE 1.9  CONTRASTING DATABASE AND FILE SYSTEMS\\nCengage Learning © 2015\\nA Database System\\nPersonnel dept.A File System\\nSales dept. Accounting dept.Database\\nAccountsInventorySalesCustomersEmployees\\nAccounts Employees Customers Sales InventoryDBMSPersonnel dept.\\nSales dept.\\nAccounting dept.\\ndatabase system\\nAn organization of components that defines and regulates the collection, storage, management, and use of data in a database environment.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68ec100f-d13f-4c6a-9f17-546c8a202c57', embedding=None, metadata={'page_label': '23', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    23\\n –DBMS software manages the database within the database system. Some examples \\nof DBMS software include Microsoft’s SQL Server, Oracle Corporation’s Oracle, Oracle’s MySQL, and IBM’s DB2.\\n –Application programs and utility software are used to access and manipulate data in the DBMS and to manage the computer environment in which data access and manipulation take place. Application programs are most commonly used to access data within the database to generate reports, tabulations, and other information to facilitate decision making. Utilities are the software tools used to help manage the database system’s computer components. For example, all of the major DBMS vendors now provide graphical user interfaces (GUIs) to help create database structures, control database access, and monitor database operations.\\n•\\n People . This component includes all users of the database system. On the basis of \\nprimary job functions, five types of users can be identified in a database system: sys-tem administrators, database administrators, database designers, system analysts and programmers, and end users. Each user type, described next, performs both unique and complementary functions.\\n –System administrators  oversee the database system’s general operations.\\n –Database administrators , also known as DBAs, manage the DBMS and ensure \\nthat the database is functioning properly. The DBA ’s role is sufficiently import-ant to warrant a detailed exploration in Chapter 16, Database Administration and \\n Security.\\n –Database designers  design the database structure. They are, in effect, the database \\narchitects. If the database design is poor, even the best application programmers and the most dedicated DBAs cannot produce a useful database \\n environment. \\nBecause organizations strive to optimize their data resources, the database \\n designer’s job description has expanded to cover new dimensions and growing \\n responsibilities.FIGURE 1.10  THE DATABASE SYSTEM ENVIRONMENT\\nDBMSDBMS utilitiesAnalysts\\nProgrammers End users\\nuse writedesignsDatabase\\ndesignerDatabase\\nadministrator\\nmanages\\naccessHardwar eSystem\\nadministratorwrites \\nand \\nenforces\\nApplication\\nprogramsProcedures\\nand standards\\nDatasupervises\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='53c40b62-8de0-44aa-bf8e-245c12bf049e', embedding=None, metadata={'page_label': '24', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='24   Part 1    Database Concepts\\n –System analysts and programmers design and implement the application programs. \\nThey design and create the data-entry screens, reports, and procedures through which end users access and manipulate the database’s data.\\n –End users are the people who use the application programs to run the organi-zation’s daily operations. For example, sales clerks, supervisors, managers, and \\n directors are all classified as end users. High-level end users employ the informa-tion obtained from the database to make tactical and strategic business decisions.\\n•\\n Procedures . Procedures are the instructions and rules that govern the design and use \\nof the database system. Procedures are a critical, although occasionally forgotten, component of the system. Procedures play an important role in a company because they enforce the standards by which business is conducted within the organization and with customers. Procedures also help to ensure that companies have an organized way to monitor and audit the data that enter the database and the information gener -\\nated from those data.\\n•\\n Data . The word data  covers the collection of facts stored in the database. Because data \\nis the raw material from which information  is generated, determining which data to \\nenter into the database and how to organize that data is a vital part of the database designer’s job.\\nA database system adds a new dimension to an organization’s management struc-\\nture. The complexity of this managerial structure depends on the organization’s size, its functions, and its corporate culture. Therefore, database systems can be created and managed at different levels of complexity and with varying adherence to precise stan-dards. For example, compare a local convenience store system with a national insur -\\nance claims system. The convenience store system may be managed by two people, the hardware used is probably a single computer, the procedures are probably simple, and the data volume tends to be low. The national insurance claims system is likely to have at least one systems administrator, several full-time DBAs, and many designers and programmers; the hardware probably includes several servers at multiple locations throughout the United States; the procedures are likely to be numerous, complex, and rigorous; and the data volume tends to be high.\\nIn addition to the different levels of database system complexity, managers must also \\ntake another important fact into account: database solutions must be cost-\\n effective as \\nwell as tactically and strategically effective. Producing a million-dollar solution to a thousand-dollar problem is hardly an example of good database system selection or of good database design and management. Finally, the database technology already in use is likely to affect the selection of a database system.\\n1-7b  DBMS Functions\\nA DBMS performs several important functions that guarantee the integrity and consis-tency of the data in the database. Most of those functions are transparent to end users, and most can be achieved only through the use of a DBMS. They include data dictio-nary management, data storage management, data transformation and presentation, security management, multiuser access control, backup and\\xa0 recovery management, data integrity management, database access languages and \\n application program-\\nming interfaces, and database communication interfaces. Each of these functions is explained as follows:\\n•\\n Data dictionary management. The DBMS stores definitions of the data elements \\nand their relationships (metadata) in a data dictionary. In turn, all programs that \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4738399-44df-420e-9654-b17717a485c9', embedding=None, metadata={'page_label': '25', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    25\\nFIGURE 1.11  ILLUSTRATING METADATA WITH MICROSOFT SQL SERVER EXPRESS\\naccess the data in the database work through the DBMS. The DBMS uses the data \\n dictionary to look up the required data component structures and relationships, \\nthus relieving you from having to code such complex relationships in each pro-gram. Additionally, any changes made in a database structure are automatically recorded in the data dictionary, thereby freeing you from having to modify all of the \\n programs that access the changed structure. In other words, the DBMS provides \\ndata abstraction, and it removes structural and data dependence from the system. For example, \\n Figure\\xa0 1.11 shows how Microsoft SQL Server Express presents the \\ndata definition for the  CUSTOMER table.\\n• Data storage management. The DBMS creates and manages the complex structures required for data storage, thus relieving you from the difficult task of defining and programming the physical data characteristics. A modern DBMS provides storage not only for the data but for related data-entry forms or screen definitions, report definitions, data validation rules, procedural code, structures to handle video and picture formats, and so on. Data storage management is also important for database performance tuning. Performance tuning relates to the activities that make the database perform more efficiently in terms of storage and access speed. Although the user sees the database as a single data storage unit, the DBMS actu-ally stores the database in multiple physical data files. (See Figure\\xa01.12.) Such data files may even be stored on different storage media. Therefore, the DBMS doesn’t have to wait for one disk request to finish before the next one starts. In other words, the DBMS can fulfill database requests \\n concurrently. Data storage man-\\nagement and performance tuning issues are  addressed in Chapter 11,  Database \\nPerformance Tuning and Query Optimization.data dictionary\\nA DBMS component that stores metadata—data about data. The data dictionary contains data definitions as well as data characteristics and relationships. May also include data that is external to the DBMS. \\nperformance tuning\\nActivities that make a database perform more efficiently in terms of storage and access speed.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d1894e57-b7ee-4789-bf55-cbfec41e0c39', embedding=None, metadata={'page_label': '26', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='26   Part 1    Database Concepts\\n• Data transformation and presentation . The DBMS transforms entered data to con-\\nform to required data structures. The DBMS relieves you of the chore of distin-\\nguishing between the logical data format and the physical data format. That is, the DBMS formats the physically retrieved data to make it conform to the user’s logical expectations. For example, imagine an enterprise database used by a multinational company. An end user in England would expect to enter the date July 11, 2017, as “11/07/2017. ” In contrast, the same date would be entered in the United States as “07/11/2017. ” Regardless of the data presentation format, the DBMS must manage the date in the proper format for each country.\\n•\\n Security management. The DBMS creates a security system that enforces user secu-rity and data privacy. Security rules determine which users can access the database, which data items each user can access, and which data operations (read, add, delete, or modify) the user can perform. This is especially important in multiuser database systems. Chapter 16, Database Administration and Security, examines data security and privacy issues in greater detail. All database users may be authenticated to the DBMS through a username and password or through biometric authentication such as a fingerprint scan. The DBMS uses this information to assign access privileges to various database components such as queries and reports.\\n•\\n Multiuser access control . To provide data integrity and data consistency, the DBMS \\nuses sophisticated algorithms to ensure that multiple users can access the database FIGURE 1.12  ILLUSTRATING DATA STORAGE MANAGEMENT WITH ORACLE\\nDatabase Name: PRODORA\\nThe PRODORA database isactually stored in six physicaldataﬁles organized into sixlogical tablespaces locatedon the E: dri ve of the\\ndatabase server computer\\nThe Oracle Enterprise Manager Express GUI shows the data\\nstorage management characteristics for the PRODORA database.The Oracle EnterpriseManager Express interfacealso shows the amount ofspace used by  each of the\\ndataﬁles.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e524da6b-75f6-47d6-97ab-7a5c08f4375d', embedding=None, metadata={'page_label': '27', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    27\\nconcurrently without compromising its integrity. Chapter 10, Transaction Manage-\\nment and Concurrency Control, covers the details of multiuser access control.\\n• Backup and recovery management. The DBMS provides backup and data recovery to ensure data safety and integrity. Current DBMS systems provide special utilities that allow the DBA to perform routine and special backup and restore procedures. Recovery management deals with the recovery of the database after a failure, such as a bad sector in the disk or a power failure. Such capability is critical to preserv-ing the database’s integrity. Chapter 16 covers backup and recovery issues.\\n•\\n Data integrity management. The DBMS promotes and enforces integrity rules, thus minimizing data redundancy and maximizing data consistency. The data relation-ships stored in the data dictionary are used to enforce data \\n integrity. Ensuring data \\nintegrity is especially important in transaction-oriented database systems. Data integrity and transaction management issues are addressed in Chapter 7, Intro -\\nduction to Structured Query Language (SQL), and Chapter 10.\\n•\\n Database access languages and application programming interfaces. The DBMS pro-vides data access through a query language. A query language is a nonprocedural \\nlanguage—one that lets the user specify what must be done without having to specify how. Structured Query Language (SQL) is the de facto query language and data \\naccess standard supported by the majority of DBMS vendors. Chapter 7, Introduction to Structure Query Language (SQL), and Chapter 8, Advanced SQL, address the use of SQL. The DBMS also provides application programming interfaces to procedural languages such as COBOL, C, Java, \\n Visual Basic.NET, and C#. In addition, the DBMS \\nprovides administrative utilities used by the DBA and the database designer to create, implement, monitor, and maintain the database.\\n•\\n Database communication interfaces . A current-generation DBMS accepts end-  user \\nrequests via multiple, different network environments. For example, the DBMS might provide access to the database via the Internet through the use of web browsers such as Mozilla Firefox, Google Chrome, or Microsoft Internet Explorer. In this environment, communications can be accomplished in several ways:\\n –End users can generate answers to queries by filling in screen forms through their preferred web browser.\\n –The DBMS can automatically publish predefined reports on a website.\\n –The DBMS can connect to third-party systems to distribute information via email or other productivity applications.\\nDatabase communication interfaces are examined in greater detail in Chapter 12, \\nDistributed Database Management Systems; in Chapter 15, Database Connectivity and Web Technologies; and in Appendix I, Databases in Electronic Commerce. (Appendixes are available at www.cengagebrain.com.)query language\\nA nonprocedural language that is used by a DBMS to manipulate its data. An example of a query language is SQL.\\nStructured Query Language (SQL)\\nA powerful and flexible relational database language composed of commands that enable users to create database and table structures, perform various types of data manipulation and data administration, and query the database to extract useful information.\\nNote\\nWhy a Spreadsheet Is Not a Database\\nWhile a spreadsheet allows for the manipulation of data in a tabular format, it does not support even the most basic database functionality such as support for self-\\n documentation through \\nmetadata, enforcement of data types or domains to ensure consistency of data within a col-umn, defined relationships among tables, or constraints to ensure consistency of data across related tables. Most users lack the necessary training to recognize the limitations of spread-sheets for these types of tasks.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='00520bc7-3def-4500-b876-f4ffb82f5786', embedding=None, metadata={'page_label': '28', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='28   Part 1    Database Concepts\\n1-7c  Managing the Database System: A Shift in Focus\\nThe introduction of a database system over the file system provides a framework in \\nwhich strict procedures and standards can be enforced. Consequently, the role of the human component changes from an emphasis on programming (in the file system) to a focus on the broader aspects of managing the organization’s data resources and on the administration of the complex database software itself.\\nThe database system makes it possible to tackle far more sophisticated uses of the data \\nresources, as long as the database is designed to make use of that power. The kinds of data structures created within the database and the extent of the relationships among them play a powerful role in determining the effectiveness of the database system.\\nAlthough the database system yields considerable advantages over previous data \\nmanagement approaches, database systems do carry significant disadvantages:\\n•\\n Increased costs. Database systems require sophisticated hardware and software and \\nhighly skilled personnel. The cost of maintaining the hardware, software, and person-nel required to operate and manage a database system can be substantial. Training, licensing, and regulation compliance costs are often overlooked when database sys-tems are implemented.\\n•\\n Management complexity. Database systems interface with many different technolo-gies and have a significant impact on a company’s resources and culture. The changes introduced by the adoption of a database system must be properly managed to ensure that they help advance the company’s objectives. Because database systems hold cru-cial company data that are accessed from multiple sources, security issues must be assessed constantly.\\n•\\n Maintaining currency . To maximize the efficiency of the database system, you must keep \\nyour system current. Therefore, you must perform frequent updates and apply the latest patches and security measures to all components. Because database technology advances rapidly, personnel training costs tend to be significant.\\n•\\n Vendor dependence . Given the heavy investment in technology and personnel train-\\ning, companies might be reluctant to change database vendors. As a consequence, vendors are less likely to offer pricing point advantages to existing customers, and those customers might be limited in their choice of database system components.\\n•\\n Frequent upgrade/replacement cycles. DBMS vendors frequently upgrade their prod-ucts by adding new functionality. Such new features often come bundled in new upgrade versions of the software. Some of these versions require hardware upgrades. Not only do the upgrades themselves cost money, it also costs money to train database users and administrators to properly use and manage the new features.\\nNow that you know what a database and DBMS are, and why they are necessary, you are ready to begin developing your career as a database professional.\\n1-8  Preparing for Y our Database  \\nProfessional  Career\\nIn this chapter, you were introduced to the concepts of data, information, databases, and DBMSs. Y ou also learned that, regardless of what type of database you use (OLTP , OLAP , or NoSQL), or what type of database environment you are working in (e.g., Oracle,  \\nMicrosoft, IBM, or Hadoop), the success of a database \\n system greatly depends on how \\nwell the database structure is designed.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e433306b-d31a-4a16-b1e3-cbe6dd8bda34', embedding=None, metadata={'page_label': '29', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    29\\nThroughout this book, you will learn the building blocks that lay the foundation for \\nyour career as a database professional. Understanding these building blocks and devel-\\noping the skills to use them effectively will prepare you to work with databases at many different levels within an organization. A small sample of such career \\n opportunities is \\nshown in Table 1.3.\\nJOB TITLE DESCRIPTION SAMPLE SKILLS REQUIRED\\nDatabase Developer Create and maintain database-based applicationsProgramming, database fundamentals, SQL\\nDatabase Designer Design and maintain databases Systems design, database design, SQL\\nDatabase Administrator Manage and maintain DBMS and \\n databasesDatabase fundamentals, SQL, vendor courses\\nDatabase Analyst Develop databases for decision support reportingSQL, query optimization, data \\n warehouses\\nDatabase Architect Design and implementation of database environments (conceptual, logical, and physical)DBMS fundamentals, data modeling, SQL, hardware knowledge, etc.\\nDatabase Consultant Help companies leverage database \\n technologies to improve business processes and achieve specific goalsDatabase fundamentals, data modeling, database design, SQL, DBMS, hardware, vendor-specific technologies, etc.\\nDatabase Security Officer Implement security policies for data \\nadministrationDBMS fundamentals, database \\n administration, SQL, data security \\n technologies, etc.\\nCloud Computing Data Architect Design and implement the  infrastructure \\nfor next-generation cloud database systemsInternet technologies, cloud storage technologies, data security, performance tuning, large databases, etc.DATABASE CAREER OPPORTUNITIESTABLE 1.3\\nAs you also learned in this chapter, database technologies are constantly evolving to \\naddress new challenges such as large databases, semistructured and unstructured data, increasing processing speed, and lowering costs. While database technologies can change quickly, the fundamental concepts and skills do not. It is our goal that after you learn the database essentials in this book, you will be ready to apply your knowledge and skills to work with traditional OLTP and OLAP systems as well as cutting-edge, complex data-base technologies such as the following:\\n•\\n Very Large Databases (VLDB). Many vendors are addressing the need for  databases \\nthat support large amounts of data, usually in the petabyte range. (A\\xa0petabyte is more \\nthan 1,000 terabytes.) VLDB vendors include Oracle Exadata, IBM’s Netezza, HP’s Vertica, and Teradata. VLDB are now being overtaken in market interest by Big Data databases.\\n•\\n Big Data databases . Products such as Cassandra (Facebook) and BigTable (Google) \\nare using “columnar-database” technologies to support the needs of database appli-cations that manage large amounts of “nontabular” data. See more about this topic in Chapter 2.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0bc53eeb-6ed7-468f-9911-8988c42a22bf', embedding=None, metadata={'page_label': '30', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='30   Part 1    Database Concepts\\n• In-memory databases. Most major database vendors also offer some type of in-memory  \\ndatabase support to address the need for faster database processing. In-memory \\ndatabases store most of their data in primary memory (RAM) rather than in slower secondary storage (hard disks). In-memory databases include IBM’s solidDB and \\n Oracle’s TimesTen.\\n• Cloud databases . Companies can now use cloud database services to quickly add \\ndatabase systems to their environment while simultaneously lowering the total cost of ownership of a new DBMS. A cloud database offers all the advantages of a local DBMS, but instead of residing within your organization’s network infrastructure, it resides on the Internet. See more about this topic in Chapter 15.\\nWe address some of these topics in this book, but not all—no single book can cover \\nthe entire realm of database technologies. This book’s primary focus is to help you learn database fundamentals, develop your database design skills, and master your SQL skills so you will have a head start in becoming a successful database professional. However, you first must learn about the tools at your disposal. In the next chapter, you will learn different approaches to data management and how these approaches influ-ence your designs.\\nSummary\\n• Data consists of raw facts. Information is the result of processing data to reveal its meaning. Accurate, relevant, and timely information is the key to good decision making, and good decision making is the key to organizational survival in a global \\n environment.\\n• Data is usually stored in a database. To implement a database and to manage its con-tents, you need a database management system (DBMS). The DBMS serves as the intermediary between the user and the database. The database contains the data you have collected and “data about data, ” known as metadata.\\n•\\n Database design defines the database structure. A well-designed database facili-tates data management and generates accurate and valuable information. A poorly designed database can lead to poor decision making, and poor decision making can lead to the failure of an organization.\\n•\\n Databases can be classified according to the number of users supported, where the data is located, the type of data stored, the intended data usage, and the degree to which the data is structured.\\n•\\n Databases evolved from manual and then computerized file systems. In a file system, data is stored in independent files, each requiring its own data management programs. Although this method of data management is largely outmoded, understanding its characteristics makes database design easier to comprehend.\\n•\\n Some limitations of file system data management are that it requires extensive pro-gramming, system administration can be complex and difficult, making changes to existing structures is difficult, and security features are likely to be inadequate. Also, independent files tend to contain redundant data, leading to problems of structural and data dependence.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e774a48-5754-4646-ab57-f9ed6c203c6f', embedding=None, metadata={'page_label': '31', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    31\\n• Database management systems were developed to address the file system’s inherent \\nweaknesses. Rather than depositing data in independent files, a DBMS presents the database to the end user as a single data repository. This arrangement promotes data sharing, thus eliminating the potential problem of islands of information. In addition, the DBMS enforces data integrity, eliminates redundancy, and promotes data security.\\n•\\n Knowledge of database technologies leads to many career opportunities in the \\n ever-expanding IT industry. There is a variety of specialization within the database \\narena for a wide range of skills and expertise.\\nad hoc query\\nanalytical databasebusiness intelligencecentralized databasecloud databasedatadata anomalydata dependencedata dictionarydata inconsistencydata independencedata integritydata managementdata processing (DP) \\n specialist\\ndata qualitydata redundancydata warehousedatabasedatabase designdatabase management \\nsystem (DBMS)database systemdesktop databasediscipline-specific \\n database\\ndistributed databaseenterprise databaseExtensible Markup \\n Language (XML)\\nfieldfilegeneral-purpose databaseinformationislands of informationknowledgelogical data formatmetadatamultiuser databaseNoSQLonline analytical processing \\n(OLAP)\\nonline transaction processing \\n(OLTP) databaseoperational databaseperformance tuningphysical data formatproduction databasequeryquery languagequery result setrecordsemistructured datasingle-user databasesocial mediastructural dependencestructural independencestructured dataStructured Query Language \\n(SQL)\\ntransactional databaseunstructured dataworkgroup databaseXML database\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at www.cengage brain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='713b494d-a39d-4b09-be08-c68ad0ddd2a0', embedding=None, metadata={'page_label': '32', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='32   Part 1     Database Concepts\\n1. Define each of the following terms:\\n  a. data\\n  b. field\\n  c. record\\n  d. file\\n2. What is data redundancy, and which characteristics of the file system can lead to it?\\n3. What is data independence, and why is it lacking in file systems?\\n4. What is a DBMS, and what are its functions?\\n5. What is structural independence, and why is it important?\\n6. Explain the differences among data, information, and a database.\\n7. What is the role of a DBMS, and what are its advantages? What are its disadvantages?\\n8. List and describe the different types of databases.\\n9. What are the main components of a database system?\\n10. What is metadata?\\n11. Explain why database design is important.\\n12. What are the potential costs of implementing a database system?\\n13. Use examples to compare and contrast unstructured and structured data. Which \\ntype is more prevalent in a typical business environment?\\n14. What are some basic database functions that a spreadsheet cannot perform?\\n15. What common problems does a collection of spreadsheets created by end users \\nshare with the typical file system?\\n16. Explain the significance of the loss of direct, hands-on access to business data that \\nend users experienced with the advent of computerized data repositories.\\n17. Explain why the cost of ownership may be lower with a cloud database than with a \\ntraditional, company database.Review Questions\\nProblems\\nOnline \\nContent\\nThe file structures you see \\nin this problem set are sim -\\nulated in a Microsoft Access  \\ndatabase named Ch01_  \\nProblems, which is available \\nat www.cengagebrain.com .FIGURE P1.1  THE FILE STRUCTURE FOR PROBLEMS 1–4\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='885e97b5-904d-4e2f-8e8c-50934b995686', embedding=None, metadata={'page_label': '33', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 1    Database Systems    33\\nGiven the file structure shown in Figure P1.1, answer Problems 1–4.\\n1. How many records does the file contain? How many fields are there per record?\\n2.  What problem would you encounter if you wanted to produce a listing by city? How \\nwould you solve this problem by altering the file structure?\\n3.  If you wanted to produce a listing of the file contents by last name, area code, city, \\nstate, or zip code, how would you alter the file structure?\\n4.  What data redundancies do you detect? How could those redundancies lead to \\nanomalies?\\nFIGURE P1.5  THE FILE STRUCTURE FOR PROBLEMS 5–8\\nFIGURE P1.9  THE FILE STRUCTURE FOR PROBLEMS 9–10\\n5.  Identify and discuss the serious data redundancy problems exhibited by the file \\nstructure shown in Figure P1.5.\\n6. Looking at the EMP_NAME and EMP_PHONE contents in Figure P1.5, what \\nchange(s) would you recommend?\\n7. Identify the various data sources in the file you examined in Problem 5.\\n8. Given your answer to Problem 7, what new files should you create to help eliminate \\nthe data redundancies found in the file shown in Figure P1.5?\\n9. Identify and discuss the serious data redundancy problems exhibited by the file \\nstructure shown in Figure P1.9. (The file is meant to be used as a teacher class \\nassignment schedule. One of the many problems with data redundancy is the likely \\noccurrence of data inconsistencies—two different initials have been entered for the \\nteacher named Maria Cordoza.)\\n10. Given the file structure shown in Figure P1.9, what problem(s) might you encounter \\nif building KOM were deleted?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e480592-46c6-41e9-beff-df123bb0e917', embedding=None, metadata={'page_label': '34', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='34   Part 1    Database Concepts\\n11. Using your school’s student information system, print your class schedule. The \\nschedule probably would contain the student identification number, student name, class code, class name, class credit hours, class instructor name, the class meeting days and times, and the class room number. Use  \\n Figure\\xa0P1.11  as a template to com-\\nplete the following actions.\\nFIGURE P1.11  STUDENT SCHEDULE DATA FORMAT\\nSTU_ID STU_\\nNAMECLASS_CODECLASS_NAMECLASS_CREDHRSINSTR_NAMECLASS_DAYSCLASS_TIMESROOM\\n  a. Create a spreadsheet using the template shown in Figure P1.11 and enter your current class schedule.\\n  b. Enter the class schedule of two of your classmates into the same spreadsheet.\\n  c. Discuss the redundancies and anomalies caused by this design.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2d2a6575-d00a-453f-8e1f-5d48dcc207de', embedding=None, metadata={'page_label': '35', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 2\\nData Models\\nIn this chapter, you will learn:\\n• About data modeling and why data models are important\\n• About the basic data-modeling building blocks\\n• What business rules are and how they influence database design\\n• How the major data models evolved\\n• About emerging alternative data models and the needs they fulfill\\n• How data models can be classified by their level of abstraction\\nPreviewThis chapter examines data modeling. Data modeling is the first step in the database \\ndesign journey, serving as a bridge between real-world objects and the computer database.\\nOne of the most vexing problems of database design is that designers, programmers, \\nand end users see data in different ways. Consequently, different views of the same data can lead to database designs that do not reflect an organization’s actual operation, thus failing to meet end-user needs and data efficiency requirements. To avoid such failures, database designers must obtain a precise description of the data’s nature and many uses within the organization. Communication among database designers, programmers, and end users should be frequent and clear. Data modeling clarifies such communication by reducing the complexities of database design to more easily understood abstractions that define entities, relations, and data transformations.\\nFirst, you will learn some basic data-modeling concepts and how current data models \\ndeveloped from earlier models. Tracing the development of those database models will help you understand the database design and implementation issues that are addressed in the rest of this book. In chronological order, you will be introduced to the hierarchical and network models, the relational model, and the entity relationship (ER) model. Y ou will also learn about the use of the entity relationship diagram (ERD) as a data-modeling tool and the different notations used for ER diagrams. Next, you will be introduced to the object-oriented model and the object/relational model. Then, you will learn about the emerging NoSQL data model and how it is being used to fulfill the current need to man-age very large social media data sets efficiently and effectively. Finally, you will learn how various degrees of data abstraction help reconcile varying views of the same data.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH02_InsureCo  P\\t P\\t P\\t P CH02_DealCo  P\\t P\\t P\\t P\\nCH02_TinyCollege  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='035cf9d2-fcad-4def-a6d2-02c8cb64e780', embedding=None, metadata={'page_label': '36', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='36   Part 1    Database Concepts\\n2-1 Data Modeling and Data Models\\nDatabase design focuses on how the database structure will be used to store and \\nmanage end-user data. Data modeling, the first step in designing a database, refers to the process of creating a specific data model for a determined problem domain. (A problem domain  is a clearly defined area within the real-world environment, \\nwith a well-defined scope and boundaries that will be systematically addressed.) A data model is a relatively simple representation, usually graphical, of more complex real-world data structures. In general terms, a model  is an abstraction of a more \\ncomplex real-world object or event. A model’s main function is to help you under -\\nstand the complexities of the real-world environment. Within the database environ-ment, a data model represents data structures and their characteristics, relations, constraints, transformations, and other constructs with the purpose of supporting  \\na specific problem domain.\\nNote\\nThe terms data model and database model are often used interchangeably. In this book, the term database model is used to refer to the implementation of a data model in a specific \\ndatabase system.Note\\nNote\\nAn implementation-ready data model should contain at least the following components:\\n• A description of the data structure that will store the end-user data\\n• A set of enforceable rules to guarantee the integrity of the data\\n• A data manipulation methodology to support the real-world data transformationsData modeling is an iterative, progressive process. Y ou start with a simple under -\\nstanding of the problem domain, and as your understanding increases, so does the level of detail of the data model. When done properly, the final data model effectively is a “blueprint” with all the instructions to build a database that will meet all end-user requirements. This blueprint is narrative and graphical in nature, meaning that it con-tains both text descriptions in plain, unambiguous language and clear, useful diagrams depicting the main data elements.\\nTraditionally, database designers relied on good judgment to help them develop a \\ngood data model. Unfortunately, good judgment is often in the eye of the beholder, and it often develops after much trial and error. For example, if each student in this class has to create a data model for a video store, it is very likely that each will come up with a different model. Which one would be correct? The simple answer is “the one that meets all the end-user requirements, ” and there may be more than one correct solution! For -\\ntunately, database designers make use of existing data-modeling constructs and power -\\nful database design tools that substantially diminish the potential for errors in database modeling. In the following sections, you will learn how existing data models are used to represent real-world data and how the different degrees of data abstraction facilitate data modeling.data modeling\\nThe process of creating a specific data model for a determined problem domain.\\ndata model\\nA representation, usually graphic, of a complex “real-world”  data structure. Data models are used in the database design phase of the Database Life Cycle.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='83f00fc1-76f6-4554-b146-b4e55856f4b7', embedding=None, metadata={'page_label': '37', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    37\\n2-2 The Importance of Data Models\\nData models can facilitate interaction among the designer, the applications programmer, \\nand the end user. A well-developed data model can even foster improved understanding of the organization for which the database design is developed. In short, data models are a communication tool. This important aspect of data modeling was summed up neatly by a client whose reaction was as follows: “I created this business, I worked with this business for years, and this is the first time I’ve really understood how all the pieces really fit together. ”\\nThe importance of data modeling cannot be overstated. Data constitutes the most \\nbasic information employed by a system. Applications are created to manage data and to help transform data into information, but data is viewed in different ways by different people. For example, contrast the view of a company manager with that of a company clerk. Although both work for the same company, the manager is more likely to have an enterprise-wide view of company data than the clerk.\\nEven different managers view data differently. For example, a company president is \\nlikely to take a universal view of the data because he or she must be able to tie the com-pany’s divisions to a common (database) vision. A purchasing manager in the same com-pany is likely to have a more restricted view of the data, as is the company’s inventory manager. In effect, each department manager works with a subset of the company’s data. The inventory manager is more concerned about inventory levels, while the purchasing manager is more concerned about the cost of items and about relationships with the suppliers of those items.\\nApplications programmers have yet another view of data, being more concerned with \\ndata location, formatting, and specific reporting requirements. Basically, applications programmers translate company policies and procedures from a variety of sources into appropriate interfaces, reports, and query screens.\\nThe different users and producers of data and information often reflect the fable of the \\nblind people and the elephant: the blind person who felt the elephant’s trunk had quite a different view from the one who felt the elephant’s leg or tail. A view of the whole ele-phant is needed. Similarly, a house is not a random collection of rooms; to build a house, a person should first have the overall view that is provided by blueprints. Likewise, a sound data environment requires an overall database blueprint based on an appropriate data model.\\nWhen a good database blueprint is available, it does not matter that an applications \\nprogrammer’s view of the data is different from that of the manager or the end user. Con-versely, when a good database blueprint is not available, problems are likely to ensue. For instance, an inventory management program and an order entry system may use con-flicting product-numbering schemes, thereby costing the company thousands or even millions of dollars.\\nKeep in mind that a house blueprint is an abstraction; you cannot live in the blueprint. \\nSimilarly, the data model is an abstraction; you cannot draw the required data out of the data model. Just as you are not likely to build a good house without a blueprint, you are equally unlikely to create a good database without first creating an appropriate data model.\\n2-3 Data Model Basic Building Blocks\\nThe basic building blocks of all data models are entities, attributes, relationships, and con -\\nstraints. An entity is a person, place, thing, or event about which data will be collected entity\\nA person, place, thing, concept, or event for which data can be stored. See also attribute.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29e1be47-f307-4cda-9d89-63c27c3d0f7d', embedding=None, metadata={'page_label': '38', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='38   Part 1    Database Concepts\\nand stored. An entity represents a particular type of object in the real world, which means \\nan entity is “distinguishable”—that is, each entity occurrence is unique and distinct. For example, a CUSTOMER entity would have many distinguishable customer occurrences, such as John Smith, Pedro Dinamita, and Tom Strickland. Entities may be physical objects, such as customers or products, but entities may also be abstractions, such as flight routes or musical concerts.\\nAn attribute is a characteristic of an entity. For example, a CUSTOMER entity would \\nbe described by attributes such as customer last name, customer first name, customer phone number, customer address, and customer credit limit. Attributes are the equiva-lent of fields in file systems.\\nA relationship describes an association among entities. For example, a relationship \\nexists between customers and agents that can be described as follows: an agent can serve many customers, and each customer may be served by one agent. Data models use three types of relationships: one-to-many, many-to-many, and one-to-one. Database designers usually use the shorthand notations 1:M or 1..*, M:N or *..*, and 1:1 or 1..1, respectively. (Although the M:N notation is a standard label for the many-to-many relationship, the label M:M may also be used.) The following examples illustrate the distinctions among the three relationships.\\n•\\n One-to-many (1:M or 1..*) relationship. A painter creates many different paintings, \\nbut each is painted by only one painter. Thus, the painter (the “one”) is related to the paintings (the “many”). Therefore, database designers label the relationship “PAINTER paints PAINTING” as 1:M. Note that entity names are often capitalized as a conven -\\ntion, so they are easily identified. Similarly, a customer (the “one”) may generate many invoices, but each invoice (the “many”) is generated by only a single customer. The “CUSTOMER generates INVOICE” relationship would also be labeled 1:M.\\n•\\n Many-to-many (M:N or *..*) relationship. An employee may learn many job skills, and each job skill may be learned by many employees. Database designers label the relationship “EMPLOYEE learns SKILL ” as M:N. Similarly, a student can take many classes and each class can be taken by many students, thus yielding the M:N label for the relationship expressed by “STUDENT takes CLASS. ”\\n•\\n One-to-one (1:1 or 1..1) relationship. A retail company’s management structure may require that each of its stores be managed by a single employee. In turn, each store manager, who is an employee, manages only a single store. Therefore, the rela-tionship “EMPLOYEE manages STORE” is labeled 1:1.\\nThe preceding discussion identified each relationship in both directions; that is, rela-\\ntionships are bidirectional:\\n•\\n One CUSTOMER can generate many  INVOICEs.\\n• Each of the many  INVOICEs is generated by only one  CUSTOMER.\\nA constraint is a restriction placed on the data. Constraints are important because \\nthey help to ensure data integrity. Constraints are normally expressed in the form of \\nrules:\\n• An employee’s salary must have values that are between 6,000 and 350,000.\\n• A student’s GPA must be between 0.00 and 4.00.\\n• Each class must have one and only one teacher.\\nHow do you properly identify entities, attributes, relationships, and constraints? \\nThe first step is to clearly identify the business rules for the problem domain you are \\nmodeling.attribute\\nA characteristic of an entity or object. An attribute has a name and a data type.\\nrelationship\\nAn association between entities.\\none-to-many (1:M or 1..*) relationship\\nAssociations among two or more entities that are used by data models. In a 1:M relationship, one entity instance is associated with many instances of the related entity.\\nmany-to-many (M:N or *..*) relationship\\nAssociation among two or more entities in which one occurrence of an entity is associated with many occurrences of a related entity and one occurrence of the related entity is associated with many occurrences of the first entity.\\none-to-one (1:1 or 1..1) relationship\\nAssociations among two or more entities that are used by data models. In a 1:1 relationship, one entity instance is associated with only one instance of the related entity.\\nconstraint\\nA restriction placed on data, usually expressed in the form of rules. For example, “A student’s GPA must be between 0.00 and 4.00.” Constraints are important because they help to ensure data integrity.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5a83d42f-7be3-4852-b4ce-89d9892f7bdb', embedding=None, metadata={'page_label': '39', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    39\\n2-4 Business Rules\\nWhen database designers go about selecting or determining the entities, attributes, \\nand relationships that will be used to build a data model, they might start by gaining a thorough understanding of what types of data exist in an organization, how the data is used, and in what time frames it is used. But such data and information do not, by themselves, yield the required understanding of the total business. From a database point of view, the collection of data becomes meaningful only when it reflects properly defined business rules . A business rule is a brief, precise, and unambiguous descrip-\\ntion of a policy, procedure, or principle within a specific organization. In a sense, busi-ness rules are misnamed: they apply to any  organization, large or small—a business, a \\ngovernment unit, a religious group, or a research laboratory—that stores and uses data to generate information.\\nBusiness rules derived from a detailed description of an organization’s operations \\nhelp to create and enforce actions within that organization’s environment. Business rules must be rendered in writing and updated to reflect any change in the organiza-tion’s operational environment.\\nProperly written business rules are used to define entities, attributes, relationships, \\nand constraints. Any time you see relationship statements such as “an agent can serve many customers, and each customer can be served by only one agent, ” business rules are at work. Y ou will see the application of business rules throughout this book, especially in the chapters devoted to data modeling and database design.\\nTo be effective, business rules must be easy to understand and widely disseminated \\nto ensure that every person in the organization shares a common interpretation of the rules. Business rules describe, in simple language, the main and distinguishing charac-teristics of the data as viewed by the company. Examples of business rules are as follows:\\n•\\n A customer may generate many invoices.\\n• An invoice is generated by only one customer.\\n• A training session cannot be scheduled for fewer than 10 employees or for more than \\n30 employees.\\nNote that those business rules establish entities, relationships, and constraints. For \\nexample, the first two business rules establish two entities (CUSTOMER and INVOICE) and a 1:M relationship between those two entities. The third business rule estab-lishes a constraint (no fewer than 10 people and no more than 30 people), two entities (EMPLOYEE and TRAINING), and also implies a relationship between EMPLOYEE and TRAINING.\\n2-4a  Discovering Business Rules\\nThe main sources of business rules are company managers, policy makers, department managers, and written documentation such as a company’s procedures, standards, and operations manuals. A faster and more direct source of business rules is direct interviews with end users. Unfortunately, because perceptions differ, end users are sometimes a less reliable source when it comes to specifying business rules. For example, a maintenance department mechanic might believe that any mechanic can initiate a maintenance pro-cedure, when actually only mechanics with inspection authorization can perform such a task. Such a distinction might seem trivial, but it can have major legal consequences. Although end users are crucial contributors to the development of business rules, it pays to verify end-user perceptions. Too often, interviews with several people who perform the business rule\\nA description of a policy, procedure, or principle within an organization. For example, a pilot cannot be on duty for more than 10 hours during a 24-hour period, or a professor may teach up to four classes during a semester.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='824453ff-a9a9-4c0b-894f-7b4ada2c8b5d', embedding=None, metadata={'page_label': '40', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='40   Part 1    Database Concepts\\nsame job yield very different perceptions of what the job components are. While such a \\ndiscovery may point to “management problems, ” that general diagnosis does not help the database designer. The database designer’s job is to reconcile such differences and verify the results of the reconciliation to ensure that the business rules are appropriate and accurate.\\nThe process of identifying and documenting business rules is essential to database \\ndesign for several reasons:\\n•\\n It helps to standardize the company’s view of data.\\n• It can be a communication tool between users and designers.\\n• It allows the designer to understand the nature, role, and scope of the data.\\n• It allows the designer to understand business processes.\\n• It allows the designer to develop appropriate relationship participation rules and \\nconstraints and to create an accurate data model.\\nOf course, not all business rules can be modeled. For example, a business rule that \\nspecifies “no pilot can fly more than 10 hours within any 24-hour period” cannot be modeled in the database model directly. However, such a business rule can be repre-sented and enforced by application software.\\n2-4b   Translating Business Rules into Data Model  Components\\nBusiness rules set the stage for the proper identification of entities, attributes, rela-tionships, and constraints. In the real world, names are used to identify objects. If the business environment wants to keep track of the objects, there will be specific business rules for the objects. As a general rule, a noun in a business rule will translate into an entity in the model, and a verb (active or passive) that associates the nouns will trans-late into a relationship among the entities. For example, the business rule “a customer may generate many invoices” contains two nouns (customer  and invoices ) and a verb \\n(generate) that associates the nouns. From this business rule, you could deduce the \\nfollowing:\\n•\\n Customer  and invoice  are objects of interest for the environment and should be repre-\\nsented by their respective entities.\\n• There is a generate relationship between customer and invoice.\\nTo properly identify the type of relationship, you should consider that relationships \\nare bidirectional; that is, they go both ways. For example, the business rule “a cus-\\ntomer may generate many invoices” is complemented by the business rule “an invoice is generated by only one customer. ” In that case, the relationship is one-to-many (1:M). Customer is the “1” side, and invoice is the “many” side.\\nAs a general rule, to properly identify the relationship type, you should ask two \\nquestions:\\n•\\n How many instances of B are related to one instance of A?\\n• How many instances of A are related to one instance of B?\\nFor example, you can assess the relationship between student and class by asking two \\nquestions:•\\n In how many classes can one student enroll? Answer: many classes.\\n• How many students can enroll in one class? Answer: many students.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f18d7e06-8dac-49e7-b478-dcb574981529', embedding=None, metadata={'page_label': '41', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    41\\nTherefore, the relationship between student and class is many-to-many (M:N). Y ou \\nwill have many opportunities to determine the relationships between entities as you  \\nproceed through this book, and soon the process will become second nature.\\n2-4c  Naming Conventions\\nDuring the translation of business rules to data model components, you identify entities, \\nattributes, relationships, and constraints. This identification process includes naming the object in a way that makes it unique and distinguishable from other objects in the prob-lem domain. Therefore, it is important to pay special attention to how you name the objects you are discovering.\\nEntity names should be descriptive of the objects in the business environment and \\nuse terminology that is familiar to the users. An attribute name should also be descrip-tive of the data represented by that attribute. It is also a good practice to prefix the name of an attribute with the name or abbreviation of the entity in which it occurs. For example, in the CUSTOMER entity, the customer’s credit limit may be called  \\nCUS_CREDIT_LIMIT. The CUS indicates that the attribute is descriptive of the  \\nCUSTOMER entity, while CREDIT_LIMIT makes it easy to recognize the data that will be contained in the attribute. This will become increasingly important in later chapters when you learn about the need to use common attributes to specify relation-ships between entities. The use of a proper naming convention will improve the data model’s ability to facilitate communication among the designer, application program-mer, and the end user. In fact, a proper naming convention can go a long way toward making your model self-documenting.\\n2-5 The Evolution of Data Models\\nThe quest for better data management has led to several models that attempt to resolve the previous model’s critical shortcomings and to provide solutions to ever-evolving data management needs. These models represent schools of thought as to what a database is, what it should do, the types of structures that it should employ, and the technology that would be used to implement these structures. Perhaps confusingly, these models are called data models, as are the graphical data models discussed earlier in this chapter. This section gives an overview of the major data models in roughly chronological order. Y ou will discover that many of the “new” database concepts and structures bear a remarkable resemblance to some of the “old” data model concepts and structures. Table 2.1 traces the evolution of the major data models.\\n2-5a  Hierarchical and Network Models\\nThe hierarchical model was developed in the 1960s to manage large amounts of data for \\ncomplex manufacturing projects, such as the Apollo rocket that landed on the moon in 1969. The model’s basic logical structure is represented by an upside-down tree. The hierarchical structure contains levels, or segments. A segment is the equivalent of a file system’s record type. Within the hierarchy, a higher layer is perceived as the parent of the segment directly beneath it, which is called the child. The hierarchical model depicts a set of one-to-many (1:M) relationships between a parent and its children segments. (Each parent can have many children, but each child has only one parent.)\\nThe network model was created to represent complex data relationships more effec-\\ntively than the hierarchical model, to improve database performance, and to impose a database standard. In the network model, the user perceives the network database as a hierarchical model\\nAn early database model whose basic concepts and characteristics formed the basis for subsequent database development. This model is based on an upside-down tree structure in which each record is called a segment. The top record is the root segment. Each segment has a  1:M relationship to  the segment directly below it.\\nsegment\\nIn the hierarchical data model, the equivalent of a file system’s record type.The hierarchical and network models are largely of historical interest, yet they do contain some ele -\\nments and features that interest current database profession-als. The technical details of those two models are discussed in Appendixes K and L, respectively, which are available at www.  \\ncengagebrain.com. Appendix G is devoted to the object-oriented (OO) model. However, given the dominant market presence of the relational model, most of the book focuses on the relational model.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f5f40d90-3bf1-4f01-aaca-6cde62d42354', embedding=None, metadata={'page_label': '42', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='42   Part 1    Database Concepts\\nTABLE 2.1  \\nEVOLUTION OF MAJOR DATA MODELS\\nGENERATION TIME DATA MODEL EXAMPLES COMMENTS\\nFirst 1960s–1970s File system VMS/VSAM Used mainly on IBM mainframe systems\\nManaged records, not relationships\\nSecond 1970s Hierarchical and \\nnetworkIMS, ADABAS, IDS-II Early database systems\\nNavigational access\\nThird Mid-1970s Relational DB2\\nOracleMSSQL ServerMySQLConceptual simplicityEntity relationship (ER) modeling and support for relational data modeling\\nFourth Mid-1980s Object-oriented\\nObject/relational(O/R)VersantObjectivity/DBDB2 UDBOracle 12cObject/relational supports object data typesStar Schema support for data warehousingWeb databases become common\\nFifth Mid-1990s XML Hybrid DBMS dbXML\\nTaminoDB2 UDBOracle 12cMS SQL ServerUnstructured data supportO/R model supports XMLdocumentsHybrid DBMS adds object front end to relational databasesSupport large databases (terabyte size)\\nEmerging Models:NoSQLEarly 2000s to presentKey-value storeColumn storeSimpleDB (Amazon)BigTable (Google)Cassandra (Apache)MongoDBRiakDistributed, highly scalableHigh performance, fault tolerant  Very large storage (petabytes)Suited for sparse dataProprietary application programming interface (API)\\ncollection of records in 1:M relationships. However, unlike the hierarchical model, the network model allows a record to have more than one parent. While the network data-base model is generally not used today, the definitions of standard database concepts  \\nthat emerged with the network model are still used by modern data models:\\n•\\n The schema is the conceptual organization of the entire database as viewed by the \\ndatabase administrator.\\n• The subschema defines the portion of the database “seen” by the application programs \\nthat actually produce the desired information from the data within the database.\\n• A data manipulation language (DML) defines the environment in which data can \\nbe managed and is used to work with the data in the database.\\n• A schema data definition language (DDL) enables the database administrator to \\ndefine the schema components.\\nAs information needs grew and more sophisticated databases and applications were \\nrequired, the network model became too cumbersome. The lack of ad hoc query capa-bility put heavy pressure on programmers to generate the code required to produce even the simplest reports. Although the existing databases provided limited data indepen-dence, any structural change in the database could still produce havoc in all application programs that drew data from the database. Because of the disadvantages of the hierar -\\nchical and network models, they were largely replaced by the relational data model in the 1980s.network model\\nAn early data model that represented data as a collection of record types in 1:M relationships.\\nschema\\nA logical grouping of database objects, such as tables, indexes, views, and queries, that are related to each other.\\nsubschema\\nThe portion of the database that interacts with application programs.\\ndata manipulation language (DML)\\nThe set of commands that allows an end user to manipulate the data in the database, such as SELECT, INSERT, UPDATE, DELETE, COMMIT, and ROLLBACK.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c6ac965-8d47-4db4-bef8-a286539db8a9', embedding=None, metadata={'page_label': '43', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    43\\nNote\\nThe relational database model presented in this chapter is an introduction and an over -\\nview. A more detailed discussion is in Chapter 3, The Relational Database Model. In fact, \\nthe relational model is so important that it will serve as the basis for discussions in most of the remaining chapters.2-5b  The Relational Model\\nThe relational model was introduced in 1970 by E. F. Codd of IBM in his landmark \\npaper “ A Relational Model of Data for Large Shared Databanks” (Communications of the ACM , June 1970, pp. 377–387). The relational model represented a major breakthrough \\nfor both users and designers. To use an analogy, the relational model produced an “auto-matic transmission” database to replace the “standard transmission” databases that pre-ceded it. Its conceptual simplicity set the stage for a genuine database revolution.\\nThe relational model’s foundation is a mathematical concept known as a relation. \\nTo avoid the complexity of abstract mathematical theory, you can think of a relation  \\n(sometimes called a table) as a two-dimensional structure composed of intersecting rows and columns. Each row in a relation is called a tuple. Each column represents an attribute. The relational model also describes a precise set of data manipulation con-structs based on advanced mathematical concepts.\\nIn 1970, Codd’s work was considered ingenious but impractical. The relational \\nmodel’s conceptual simplicity was bought at the expense of computer overhead; com-puters at that time lacked the power to implement the relational model. Fortunately, computer power grew exponentially, as did operating system efficiency. Better yet, the cost of computers diminished rapidly as their power grew. Today, even PCs, which cost a fraction of what their mainframe ancestors cost, can run sophisticated relational database software such as Oracle, DB2, Microsoft SQL Server, MySQL, and other mainframe relational software.\\nThe relational data model is implemented through a very sophisticated relational \\ndatabase management system (RDBMS). The RDBMS performs the same basic func-tions provided by the hierarchical and network DBMS systems, in addition to a host of other functions that make the relational data model easier to understand and implement (as outlined in Chapter 1, in the DBMS Functions section).\\nArguably the most important advantage of the RDBMS is its ability to hide the com-\\nplexities of the relational model from the user. The RDBMS manages all of the physical details, while the user sees the relational database as a collection of tables in which data is stored. The user can manipulate and query the data in a way that seems intuitive and logical.\\nTables are related to each other through the sharing of a common attribute (a value in \\na column). For example, the CUSTOMER table in Figure 2.1 might contain a sales agent’s number that is also contained in the AGENT table.\\nThe common link between the CUSTOMER and AGENT tables enables you to match \\nthe customer to his or her sales agent, even though the customer data is stored in one table and the sales representative data is stored in another table. For example, you can easily determine that customer Dunne’s agent is Alex Alby because for customer Dunne, the CUSTOMER table’s AGENT_CODE is 501, which matches the AGENT table’s data definition language (DDL)\\nThe language that allows a database administrator to define the database structure, schema, and subschema.\\nrelational model\\nDeveloped by E. F. Codd of IBM in 1970, the relational model is based on mathematical set theory and represents data as independent relations. Each relation (table) is conceptually represented as a two-dimensional structure of intersecting rows and columns. The relations are related to each other through the sharing of common entity characteristics (values in columns).\\ntable (relation)\\nA logical construct perceived to be a two-dimensional structure composed of intersecting rows (entities) and columns (attributes) that represents an entity set in the relational model. \\ntuple\\nIn the relational model, a table row.\\nrelational database management system (RDBMS)\\nA collection of programs that manages a relational database. The RDBMS software translates a user’s logical requests (queries) into commands that physically locate and retrieve the requested data. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='feab8e74-26d7-4d0b-8120-34ae590ec563', embedding=None, metadata={'page_label': '44', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='44   Part 1     Database Concepts\\nFIGURE 2.1  LINKING RELATIONAL TABLES\\nTable name: AGENT (ﬁrst six attributes)\\nTable name: CUSTOMERLink through AGENT_CODE\\nDatabase name: Ch02_InsureCo\\nAGENT_CODE for Alex Alby. Although the tables are independent of one another, you \\ncan easily associate the data between tables. The relational model provides a minimum \\nlevel of controlled redundancy to eliminate most of the redundancies commonly found \\nin file systems.\\nThe relationship type (1:1, 1:M, or M:N) is often shown in a relational schema, an \\nexample of which is shown in Figure 2.2. A relational diagram  is a representation of the \\nrelational database’s entities, the attributes within those entities, and the relationships \\nbetween those entities.\\nIn Figure 2.2, the relational diagram shows the connecting fields (in this case, \\nAGENT_CODE) and the relationship type (1:M). Microsoft Access, the database soft -\\nware application used to generate Figure 2.2, employs the infinity symbol (∞) to indicate \\nthe “many” side. In this example, the CUSTOMER represents the “many” side because \\nan AGENT can have many CUSTOMERs. The AGENT represents the “1” side because \\neach CUSTOMER has only one AGENT.\\nA relational table stores a collection of related entities. In this respect, the relational \\ndatabase table resembles a file, but there is a crucial difference between a table and a file: Online \\nContent\\nThis chapter’s data -\\nbases are available at \\nwww.cengagebrain  \\n.com . For example, the \\ncontents of the AGENT \\nand CUSTOMER tables \\nshown in Figure 2.1 are \\nin the database named \\nCh02_InsureCo.\\nFIGURE 2.2  A RELATIONAL DIAGRAM\\nrelational diagram\\nA graphical \\nrepresentation of a \\nrelational database’s \\nentities, the attributes \\nwithin those entities,  \\nand the relationships \\namong the entities.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='63d9ac3f-7342-42d8-83b1-74c1a7484d77', embedding=None, metadata={'page_label': '45', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    45\\na table yields complete data and structural independence because it is a purely logical \\nstructure. How the data is physically stored in the database is of no concern to the user or the designer; the perception is what counts. This property of the relational data model, which is explored in depth in the next chapter, became the source of a real database revolution.\\nAnother reason for the relational data model’s rise to dominance is its powerful and \\nflexible query language. Most relational database software uses Structured Query Lan-guage (SQL), which allows the user to specify what must be done without specifying how. The RDBMS uses SQL to translate user queries into instructions for retrieving the requested data. SQL makes it possible to retrieve data with far less effort than any other database or file environment.\\nFrom an end-user perspective, any SQL-based relational database application involves \\nthree parts: a user interface, a set of tables stored in the database, and the SQL “engine. ” Each of these parts is explained as follows:\\n•\\n The end-user interface. Basically, the interface allows the end user to interact with \\nthe data (by automatically generating SQL code). Each interface is a product of the software vendor’s idea of meaningful interaction with the data. Y ou can also design your own customized interface with the help of application generators that are now standard fare in the database software arena.\\n•\\n A collection of tables stored in the database . In a relational database, all data is per -\\nceived to be stored in tables. The tables simply “present” the data to the end user in a way that is easy to understand. Each table is independent. Rows in different tables are related by common values in common attributes.\\n•\\n SQL engine. Largely hidden from the end user, the SQL engine executes all que-ries, or data requests. Keep in mind that the SQL engine is part of the DBMS software. The end user uses SQL to create table structures and to perform data access and table maintenance. The SQL engine processes all user requests—largely behind the scenes and without the end user’s knowledge. Hence, SQL is said to be a declarative language that tells what must be done but not how. (Y ou will learn more about the SQL engine in Chapter 11, Database Performance Tuning and Query Optimization.)\\nBecause the RDBMS performs some tasks behind the scenes, it is not necessary to \\nfocus on the physical aspects of the database. Instead, the following chapters concentrate on the logical portion of the relational database and its design. Furthermore, SQL is cov-ered in detail in Chapter 7, Introduction to Structured Query Language (SQL), and in Chapter 8, Advanced SQL.\\n2-5c  The Entity Relationship Model\\nThe conceptual simplicity of relational database technology triggered the demand for RDBMSs. In turn, the rapidly increasing requirements for transaction and information created the need for more complex database implementation structures, thus creating the need for more effective database design tools. (Building a skyscraper requires more detailed design activities than building a doghouse, for example.)\\nComplex design activities require conceptual simplicity to yield successful results. \\nAlthough the relational model was a vast improvement over the hierarchical and net-work models, it still lacked the features that would make it an effective database design  \\ntool. Because it is easier to examine structures graphically than to describe them in text, \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4c5bd401-f4e9-4743-9522-6a274d7727b7', embedding=None, metadata={'page_label': '46', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='46   Part 1    Database Concepts\\ndatabase designers prefer to use a graphical tool in which entities and their relationships \\nare pictured. Thus, the entity relationship (ER) model, or  ERM, has become a widely \\naccepted standard for data modeling.\\nPeter Chen first introduced the ER data model in 1976; the graphical representa-\\ntion of entities and their relationships in a database structure quickly became popu-lar because it complemented  the relational data model concepts. The relational data \\nmodel and ERM combined to provide the foundation for tightly structured database design. ER models are normally represented in an entity relationship diagram (ERD), which uses graphical representations to model database components. Y ou will learn how to use ERDs to design databases in Chapter 4, Entity Relationship (ER) Modeling.\\nThe ER model is based on the following components:\\n•\\n Entity . Earlier in this chapter, an entity was defined as anything about which data \\nwill be collected and stored. An entity is represented in the ERD by a rectangle, also known as an entity box. The name of the entity, a noun, is written in the center of the rectangle. The entity name is generally written in capital letters and in singular form: PAINTER rather than PAINTERS, and EMPLOYEE rather than EMPLOYEES. Usually, when applying the ERD to the relational model, an entity is mapped to a rela-tional table. Each row in the relational table is known as an entity instance or entity occurrence in the ER model. A collection of like entities is known as an entity set. For example, you can think of the AGENT file in Figure 2.1 as a collection of three agents (entities ) in the AGENT entity set. Technically speaking, the ERD depicts entity \\nsets. Unfortunately, ERD designers use the word entity as a substitute for entity set, and this book will conform to that established practice when discussing any ERD and its components.\\n•\\n Each entity consists of a set of attributes  that describes particular characteristics of \\nthe entity. For example, the entity EMPLOYEE will have attributes such as a Social Security number, a last name, and a first name. (Chapter 4 explains how attributes are included in the ERD.)\\n•\\n Relationships . Relationships describe associations among data. Most relationships \\ndescribe associations between two entities. When the basic data model compo-nents were introduced, three types of data relationships were illustrated: one-to-many (1:M), many-to-many (M:N), and one-to-one (1:1). The ER model uses the term connectivity to label the relationship types. The name of the relation-ship is usually an active or passive verb. For example, a PAINTER paints  many \\nPAINTINGs, an EMPLOYEE learns  many SKILLs, and an EMPLOYEE manages  \\na STORE.\\nFigure 2.3 shows the different types of relationships using three ER notations: the \\noriginal Chen notation, the Crow’s Foot notation, and the newer class diagram \\nnotation, which is part of the Unified Modeling Language (UML).\\nThe left side of the ER diagram shows the Chen notation, based on Peter Chen’s \\nlandmark paper. In this notation, the connectivities are written next to each entity box. Relationships are represented by a diamond connected to the related entities through a relationship line. The relationship name is written inside the diamond.\\nThe middle of Figure 2.3 illustrates the Crow’s Foot notation. The name Crow’s Foot  \\nis derived from the three-pronged symbol used to represent the “many” side of the relationship. As you examine the basic Crow’s Foot ERD in Figure 2.3, note that the connectivities are represented by symbols. For example, the “1” is represented by a short line segment, and the “M” is represented by the three-pronged “crow’s foot. ” In this example, the relationship name is written above the relationship line.entity relationship (ER) model (ERM)\\nA data model that describes relationships (1:1, 1:M, and M:N) among entities at the conceptual level with the help of ER diagrams. The model was developed by  Peter Chen.\\nentity relationship diagram (ERD)\\nA diagram that depicts an entity relationship model’s entities, attributes, and relations.\\nentity instance (entity occurrence) \\nA row in a relational table.\\nentity set \\nA collection of like entities.\\nconnectivity\\nThe type of relationship between entities. Classifications include 1:1, 1:M, and M:N.\\nChen notation\\nSee entity relationship (ER) model.\\nCrow’s Foot notation\\nA representation of the entity relationship diagram that uses a three-pronged symbol to represent the “many” sides of the relationship.\\nclass diagram notation\\nThe set of symbols used in the creation of class diagrams.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7d803bcb-364f-4501-988f-de6a0411ab7c', embedding=None, metadata={'page_label': '47', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    47\\nNote\\nMany-to-many (M:N) relationships exist at a conceptual level, and you should know how to \\nrecognize them. However, you will learn in Chapter 3 that M:N relationships are not appro -\\npriate in a relational model. For that reason, Microsoft Visio does not support the M:N rela -\\ntionship directly. Therefore, to illustrate the existence of an M:N relationship using Visio, you \\nhave to change the line style of the connector (see Appendix A, Designing Databases with \\nVisio Professional: A Tutorial, at www.cengagebrain.com ).The right side of Figure 2.3 shows the UML notation (also known as the UML \\nclass notation). Note that the connectivities are represented by lines with symbols \\n(1..1, 1..*). Also, the UML notation uses names in both sides of the relationship. \\nFor example, to read the relationship between PAINTER and PAINTING, note the \\nfollowing:\\n• A PAINTER “paints” one to many PAINTINGs, as indicated by the 1..* symbol.\\n• A PAINTING is “painted by” one and only one PAINTER, as indicated by the 1..1 symbol.FIGURE 2.3  THE ER MODEL NOTATIONS\\nUML Class \\nDiagram NotationCrow’s Foot Notation Chen Notation\\nIn Figure 2.3, entities and relationships are shown in a horizontal format, but they \\nmay also be oriented vertically. The entity location and the order in which the entities are \\npresented are immaterial; just remember to read a 1:M relationship from the “1” side to \\nthe “M” side.\\nThe Crow’s Foot notation is used as the design standard in this book. However, the \\nChen notation is used to illustrate some of the ER modeling concepts whenever necessary. \\nMost data modeling tools let you select the Crow’s Foot or UML class diagram notation. Online \\nContent\\nAside from the Chen, \\nCrow’s Foot, and UML \\nnotations, there are  \\nother ER model nota -\\ntions. For a summary of \\nER model notation sym -\\nbols, see Appendix E, \\nComparison of ER Model \\nNotations, at www.  \\ncengagebrain.com .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3c16243b-ffeb-4494-9fda-58c44089abbb', embedding=None, metadata={'page_label': '48', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='48   Part 1    Database Concepts\\nMicrosoft Visio Professional software was used to generate the Crow’s Foot designs you \\nwill see in subsequent chapters.\\nThe ER model’s exceptional visual simplicity makes it the dominant database model-\\ning and design tool. Nevertheless, the search for better data-modeling tools continues as the data environment continues to evolve.\\n2-5d  The Object-Oriented (OO) Model\\nIncreasingly complex real-world problems demonstrated a need for a data model that more closely represented the real world. In the object-oriented data model (OODM), both data and its relationships are contained in a single structure known as an object. In turn, the OODM is the basis for the object-oriented database management system (OODBMS).\\nAn OODM reflects a very different way to define and use entities. Like the relational \\nmodel’s entity, an object is described by its factual content. But, quite unlike  an entity, an \\nobject includes information about relationships between the facts within the object, as well as information about its relationships with other objects. Therefore, the facts within the object are given greater meaning . The OODM is said to be a semantic data model \\nbecause semantic  indicates meaning.\\nSubsequent OODM development has allowed an object also to contain all operations  \\nthat can be performed on it, such as changing its data values, finding a specific data value, and printing data values. Because objects include data, various types of relationships, and operational procedures, the object becomes self-contained, thus making it—at least potentially—a basic building block for autonomous structures.\\nThe OO data model is based on the following components:\\n•\\n An object is an abstraction of a real-world entity. In general terms, an object may be considered equivalent to an ER model’s entity. More precisely, an object represents only one occurrence of an entity. (The object’s semantic content is defined through several of the items in this list.)\\n•\\n Attributes describe the properties of an object. For example, a PERSON object includes the attributes Name, Social Security Number, and Date of Birth.\\n•\\n Objects that share similar characteristics are grouped in classes. A class is a collec-tion of similar objects with shared structure (attributes) and behavior (methods). In a general sense, a class resembles the ER model’s entity set. However, a class is different from an entity set in that it contains a set of procedures known as methods . A class’s \\nmethod represents a real-world action such as finding  a selected PERSON’s name, \\nchanging  a PERSON’s name, or printing  a PERSON’s address. In other words, meth-\\nods are the equivalent of procedures  in traditional programming languages. In OO \\nterms, methods define an object’s behavior .\\n•\\n Classes are organized in a class hierarchy. The class hierarchy resembles an upside-down tree in which each class has only one parent. For example, the  \\nCUSTOMER class and the EMPLOYEE class share a parent PERSON class. (Note the  \\nsimilarity to the hierarchical data model in this respect.)\\n•\\n Inheritance is the ability of an object within the class hierarchy to inherit the attri-butes and methods of the classes above it. For example, two classes, CUSTOMER and EMPLOYEE, can be created as subclasses from the class PERSON. In this case, CUSTOMER and EMPLOYEE will inherit all attributes and methods from PERSON.\\n•\\n Object-oriented data models are typically depicted using Unified Modeling  \\nLanguage (UML) class diagrams. UML is a language based on OO concepts that \\ndescribes a set of diagrams and symbols you can use to graphically model a system. Online \\nContent\\nThis chapter introduces \\nonly basic OO con-cepts. You can exam-ine object-orientation  \\nconcepts and princi-ples in detail in Appen-dix G, Object-Oriented Databases, at www.  \\ncengagebrain.com.\\nobject-oriented data model (OODM)\\nA data model whose basic modeling structure is an object.\\nobject\\nAn abstract representation of a real-world entity that has a unique identity, embed-ded properties, and the ability to interact with other objects and itself.\\nobject-oriented database management system (OODBMS)\\nData management software used to manage data in an object-oriented database model.\\nsemantic data model\\nThe first of a series of data models that more closely represented the real world, modeling both data and their relationships in a single structure known as an object. The SDM, published in 1981, was developed by M. Hammer and D. McLeod.\\nclass\\nA collection of similar objects with shared structure (attributes) and  \\nbehavior (methods). A class encapsulates an object’s data representation and a method’s implementation. Classes are organized in a class hierarchy.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e0f94870-f2a7-404b-bf2b-2e8dc520d4f3', embedding=None, metadata={'page_label': '49', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    49\\nFIGURE 2.4  A COMPARISON OF OO, UML AND ER MODELSUML class diagrams  are used to represent data and its relationships within the \\nlarger UML object-oriented system’s modeling language. For a more complete \\ndescription of UML, see Appendix H, Unified Modeling Language (UML).\\nTo illustrate the main concepts of the object-oriented data model, consider a simple \\ninvoicing problem. In this case, invoices are generated by customers, each invoice ref -\\nerences one or more lines, and each line represents an item purchased by a customer. \\nFigure 2.4 illustrates the object representation for this simple invoicing problem, as well \\nas the equivalent UML class diagram and ER model. The object representation is a simple \\nway to visualize a single object occurrence.\\nER Model Object Representation UML Class Diagram\\nAs you examine Figure 2.4, note the following:\\n• The object representation of the INVOICE includes all related objects within the same  \\nobject box. Note that the connectivities (1 and M) indicate the relationship of the \\nrelated objects to the INVOICE. For example, the “1” next to the CUSTOMER object \\nindicates that each INVOICE is related to only one CUSTOMER. The “M” next to the \\nLINE object indicates that each INVOICE contains many LINEs.\\n• The UML class diagram uses three separate object classes (CUSTOMER, INVOICE, \\nand LINE) and two relationships to represent this simple invoicing problem. Note \\nthat the relationship connectivities are represented by the 1..1, 0..*, and 1..* symbols, \\nand that the relationships are named in both ends to represent the different “roles” \\nthat the objects play in the relationship.\\n• The ER model also uses three separate entities and two relationships to represent this \\nsimple invoice problem.\\nThe OODM advances influenced many areas, from system modeling to program -\\nming. (Most contemporary programming languages have adopted OO concepts, includ -\\ning Java, Ruby, Perl, C#, and Visual Studio .NET.) The added semantics of the OODM \\nallowed for a richer representation of complex objects. This in turn enabled applications \\nto support increasingly complex objects in innovative ways. As you will see in the next \\nsection, such evolutionary advances also affected the relational model.\\n2-5e  Object/Relational and XML\\nFacing the demand to support more complex data representations, the relational \\nmodel’s main vendors evolved the model further and created the extended method\\nIn the object-oriented \\ndata model, a named \\nset of instructions to \\nperform an action. \\nMethods represent \\nreal-world actions, and \\nare invoked through \\nmessages.\\nclass hierarchy\\nThe organization of \\nclasses in a hierarchical \\ntree in which each \\nparent class is a \\nsuperclass  and each child \\nclass is a subclass . See \\nalso inheritance .\\ninheritance\\nIn the object-oriented data \\nmodel, the ability of an \\nobject to inherit the data \\nstructure and methods of \\nthe classes above it in the \\nclass hierarchy. See also \\nclass hierarchy .\\nUnified Modeling \\nLanguage (UML)\\nA language based on \\nobject-oriented concepts \\nthat provides tools such \\nas diagrams and symbols \\nto graphically model a \\nsystem.\\nclass diagram\\nA diagram used to \\nrepresent data and their \\nrelationships in UML \\nobject notation.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc2ab141-6323-4df3-8f97-0554eb86e919', embedding=None, metadata={'page_label': '50', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='50   Part 1    Database Concepts\\nrelational data model (ERDM). The ERDM adds many of the OO model’s features \\nwithin the inherently simpler relational database structure. The ERDM gave birth \\nto a new generation of relational databases that support OO features such as objects (encapsulated data and methods), extensible data types based on classes, and inher -\\nitance. That’s why a DBMS based on the ERDM is often described as an object/relational database management system (O/R DBMS).\\nToday, most relational database products can be classified as object/relational, and \\nthey represent the dominant market share of OLTP and OLAP database applications. The success of the O/R DBMSs can be attributed to the model’s conceptual simplicity, data integrity, easy-to-use query language, high transaction performance, high availabil-ity, security, scalability, and expandability. In contrast, the OO DBMS is popular in niche markets such as computer-aided drawing/computer-aided manufacturing (CAD/CAM), geographic information systems (GIS), telecommunications, and multimedia, which require support for more complex objects.\\nFrom the start, the OO and relational data models were developed in response to \\ndifferent problems. The OO data model was created to address very specific engineer -\\ning needs, not the wide-ranging needs of general data management tasks. The relational model was created with a focus on better data management based on a sound mathemat-ical foundation. Given its focus on a smaller set of problem areas, it is not surprising that the OO market has not grown as rapidly as the relational data model market.\\nThe use of complex objects received a boost with the Internet revolution. When orga-\\nnizations integrated their business models with the Internet, they realized its potential to access, distribute, and exchange critical business information. This resulted in the widespread adoption of the Internet as a business communication tool. Within this environment, Extensible Markup Language (XML) emerged as the de facto standard \\nfor the efficient and effective exchange of structured, semistructured, and unstructured data. Organizations that used XML data soon realized that they needed to manage large amounts of unstructured data such as word-processing documents, webpages, emails, and diagrams. To address this need, XML databases emerged to manage unstructured data within a native XML format. (See Chapter 15, Database Connectivity and Web Tech-nologies, for more information about XML.) At the same time, O/R DBMSs added sup-port for XML-based documents within their relational data structure. Due to its robust foundation in broadly applicable principles, the relational model is easily extended to include new classes of capabilities, such as objects and XML.\\nAlthough relational and object/relational databases address most current data pro-\\ncessing needs, a new generation of databases has emerged to address some very specific challenges found in some Internet-era organizations.\\n2-5f  Emerging Data Models: Big Data and NoSQL\\nDeriving usable business information from the mountains of web data that organizations have accumulated over the years has become an imperative need. Web data in the form of browsing patterns, purchasing histories, customer preferences, behavior patterns, and social media data from sources such as Facebook, Twitter, and LinkedIn have inundated organizations with combinations of structured and unstructured data. In addition, mobile technologies such as smartphones and tablets, plus sensors of all types—GPS, RFID sys -\\ntems, weather sensors, biomedical devices, space research probes, car and aviation black boxes—as well as other Internet and cellular-connected devices, have created new ways to automatically collect massive amounts data in multiple formats (text, pictures, sound, video, etc.). The amount of data being collected grows exponentially every day. According to IBM, “Every day we create 2.5 quintillion bytes of data—so much that 90 percent of the extended relational data model (ERDM)\\nA model that includes the object-oriented model’s best features in an inherently simpler relational database structural environment. See extended entity relationship model (EERM).\\nobject/relational database management system (O/R DBMS)\\nA DBMS based on the extended relational model (ERDM). The ERDM, championed by many relational database researchers, constitutes the relational model’s response to the OODM. This model includes many of the object-oriented model’s best features within an inherently simpler relational database structure.\\nExtensible Markup Language (XML)\\nA metalanguage used to represent and manipulate data elements. Unlike other markup languages, XML permits the manipulation of a document’s data elements. XML facilitates the exchange of structured documents such as orders and invoices over the Internet.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4a4233d5-903d-4c76-9030-386d3070ed48', embedding=None, metadata={'page_label': '51', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    51\\ndata in the world today has been created in the last two years alone. ”1 According to some \\nstudies, the rapid pace of data growth is the top challenge for organizations,2 with system \\nperformance and scalability as the next biggest challenges. Today’s information technology \\n(IT) managers are constantly balancing the need to manage this rapidly growing data with shrinking budgets. The need to manage and leverage all these converging trends (rapid data growth, performance, scalability, and lower costs) has triggered a phenomenon called  \\n“Big Data. ” Big Data refers to a movement to find new and better ways to manage large amounts of web and sensor-generated data and derive business insight from it, while simultaneously providing high performance and scalability at a reasonable cost.\\nThe term Big Data  has been used in many different frameworks, from law to statis-\\ntics to economics to computing. The term seems to have been first used in a computing framework by John Mashey, a Silicon Graphics scientist in the 1990s.\\n3 However, it seems \\nto be Douglas Laney, a data analyst from the Gartner Group, who first described the basic characteristics of Big Data databases:\\n4 volume, velocity, and variety, or the 3 Vs . \\n• Volume  refers to the amounts of data being stored. With the adoption and growth of \\nthe Internet and social media, companies have multiplied the ways to reach custom-ers. Over the years, and with the benefit of technological advances, data for millions of e-transactions were being stored daily on company databases. Furthermore, orga-nizations are using multiple technologies to interact with end users and those tech-nologies are generating mountains of data. This ever-growing volume of data quickly reached petabytes in size, and it’s still growing.\\n•\\n Velocity  refers not only to the speed with which data grows but also to the need to process \\nthis data quickly in order to generate information and insight. With the advent of the Internet and social media, business response times have shrunk considerably. Organiza-tions need not only to store large volumes of quickly accumulating data, but also need to process such data quickly. The velocity of data growth is also due to the increase in the number of different data streams from which data is being piped to the organization (via the web, e-commerce, Tweets, Facebook posts, emails, sensors, GPS, and so on).\\n•\\n Variety  refers to the fact that the data being collected comes in multiple different data \\nformats. A great portion of these data comes in formats not suitable to be handled by the typical operational databases based on the relational model.\\nThe 3 Vs framework illustrates what companies now know, that the amount of data \\nbeing collected in their databases has been growing exponentially in size and complexity. Traditional relational databases are good at managing structured data but are not well suited to managing and processing the amounts and types of data being collected in today’s business environment.\\nThe problem is that the relational approach does not always match the needs of orga-\\nnizations with Big Data challenges.\\n•\\n It is not always possible to fit unstructured, social media and sensor-generated data \\ninto the conventional relational structure of rows and columns.\\n• Adding millions of rows of multiformat (structured and nonstructured) data on a daily basis will inevitably lead to the need for more storage, processing power, and \\n1  IBM, “What is big data? Bringing big data to the enterprise, ” http://www-01.ibm.com/software/data/ \\nbigdata/, accessed April 2013. \\n2  “Gartner survey shows data growth as the largest data center infrastructure challenge, ” www.gartner.com/it/page.jsp?id=1460213, accessed March 2015. \\n3  Steve Lohr, “The origins of ‘Big Data’: An etymological detective story, ” New Y ork Times, February 1, 2013.\\n4  Douglas Laney, “3D data management controlling data volume, velocity and variety, ” META Group,  \\nFebruary 6, 2011.Big Data\\nA movement to find \\nnew and better ways to manage large amounts of web-generated data and derive business insight from it, while simultaneously providing high performance and scalability at a reasonable cost.\\n3 Vs\\nThree basic characteristics of Big Data databases: volume, velocity, and variety.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='36b87fb2-71c8-4f61-962c-5817dd3f69fb', embedding=None, metadata={'page_label': '52', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='52   Part 1    Database Concepts\\nsophisticated data analysis tools that may not be available in the relational environ-\\nment. Generally speaking, the type of high-volume implementations required in the RDBMS environment for the Big Data problem comes with a hefty price tag for expanding hardware, storage, and software licenses.\\n•\\n Data analysis based on OLAP tools has proven to be very successful in relational environments with highly structured data. However, mining for usable data in the vast amounts of unstructured data collected from web sources requires a different approach.\\nThere is no “one-size-fits-all” cure to data management needs (although many estab-\\nlished database vendors will probably try to sell you on the idea). For some organizations, creating a highly scalable, fault-tolerant infrastructure for Big Data analysis could prove to be a matter of business survival. The business world has many examples of companies that leverage technology to gain a competitive advantage, and others that miss it. Just ask yourself how the business landscape would be different if:\\n•\\n Blackberry had responded quickly to the emerging Apple smartphone technology.\\n• MySpace had responded to Facebook’s challenge in time.\\n• Blockbuster had reacted to the Netflix business model sooner.\\n• Barnes & Noble had developed a viable Internet strategy before Amazon.\\nWill broadcast television networks be able to adapt to streaming services such as \\nHulu, AppleTV , and Roku? Will traditional news outlets be able to adapt to the changing \\nnews consumption patterns of the millennial generation?\\nBig Data analytics are being used to create new types of services by all types of com-\\npanies. For example: TXU Energy,5 a Texas electricity provider, and OPower,6 a service \\ncompany that provides managed solutions for utility providers, are using Big Data and emerging technologies to reduce consumption and provide energy savings to their cus-tomers. Their data comes from multiple sources (intelligent sensors, weather feeds, demographics data banks, public sector data, and geographical data), and it is being used to create value for both companies and customers.\\nIn order to create value from their previously unused Big Data stores, companies are \\nusing new Big Data technologies. These emerging technologies allow organizations to process massive data stores of multiple formats in cost-effective ways. Some of the most frequently used Big Data technologies are Hadoop, MapReduce, and NoSQL databases.\\n•\\n Hadoop is a Java based, open source, high speed, fault-tolerant distributed storage \\nand computational framework. Hadoop uses low-cost hardware to create clusters of thousands of computer nodes to store and process data. Hadoop originated from Google’s work on distributed file systems and parallel processing and is currently sup-ported by the Apache Software Foundation.\\n7 Hadoop has several modules, but the \\ntwo main components are Hadoop Distributed File System (HDFS) and MapReduce.\\n• Hadoop Distributed File System (HDFS) is a highly distributed, fault-tolerant file storage system designed to manage large amounts of data at high speeds. In order to achieve high throughput, HDFS uses the write-once, read many model. This means that once the data is written, it cannot be modified. HDFS uses three types of nodes: a name node that stores all the metadata about the file system, a data node that \\n5  Harish Kotadia, “4 excellent big data case studies, ” http://hkotadia.com/archives/5021, July 22, 2012.\\n6  Katie Fehrenbacher, “How big data can curb the world’s energy consumption, ” http://gigaom.\\ncom/2012/03/11/10-ways-big-data-is-changing-everything/3/\\n7  For more information about Hadoop visit hadoop.apache.org.Hadoop\\nA Java based, open \\nsource, high speed, fault-tolerant distributed storage and com-putational framework. Hadoop uses low-cost hardware to create clusters of thousands of computer nodes to store and process data.\\nHadoop Distributed File System (HDFS)\\nA highly distributed, fault-tolerant file storage system designed to manage large amounts of data at high speeds.\\nname node\\nOne of three types of nodes used in the Hadoop Distributed File System (HDFS). The name node stores all the metadata about the file system. See also client node and data node.\\ndata node\\nOne of three types of nodes used in the Hadoop Distributed File System (HDFS). The data node stores fixed-size data blocks (that could be replicated to other da-ta nodes). See also client node and name node.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='169a5fb3-73e7-4425-a919-e4af55bf5224', embedding=None, metadata={'page_label': '53', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    53\\nstores fixed-size data blocks (that could be replicated to other data nodes), and a \\nclient node that acts as the interface between the user application and the HDFS.\\n• MapReduce is an open source application programming interface (API) that pro-vides fast data analytics services. MapReduce distributes the processing of the data among thousands of nodes in parallel. MapReduce works with structured and non-structured data. The MapReduce framework provides two main functions, Map and Reduce. In general terms, the Map function takes a job and divides it into smaller units of work; the Reduce function collects all the output results generated from the nodes and integrates them into a single result set.\\n•\\n NoSQL is a large-scale distributed database system that stores structured and unstruc-tured data in efficient ways. NoSQL databases are discussed in more detail later in this section.\\nHadoop technologies provide a framework for Big Data analytics in which data \\n(structured or unstructured) is distributed, replicated, and processed in parallel using a network of low-cost commodity hardware. Hadoop introduced new ways to store and manage data and Hadoop-related technologies gave rise to a new generation of database systems. NoSQL databases provide distributed, fault-tolerant databases for processing nonstructured data.\\nWith the potential of big gains derived from Big Data analytics, it is not surprising that \\nsome organizations are turning to emerging Big Data technologies, such as NoSQL databases, to mine the wealth of information hidden in mountains of web data and gain a competitive advantage.\\nNote\\nDoes this mean that relational databases don’t have a place in organizations with Big Data challenges? No, relational databases remain the preferred and dominant databases to sup -\\nport most day-to-day transactions and structured data analytics needs. Each DBMS tech-nology has its areas of application, and the best approach is to use the best tool for the job. In perspective, object/relational databases serve 98 percent of operational market needs. For Big Data needs, Hadoop, MapReduce, and NoSQL databases are the options.\\nChapter 14, Big Data Analytics and NoSQL, discusses these options in greater detail. client node\\nOne of three types \\nof nodes used in the Hadoop Distributed File System (HDFS). The client node acts as the interface between the user application and the HDFS. See also name node and data node.\\nMapReduce\\nAn open-source application programming interface (API) that provides fast data analytics services; one of the main Big Data technologies that allows organizations to process massive data stores.\\nNoSQL\\nA new generation of database management systems that is not based on the traditional relational database model.NoSQL Databases  Every time you search for a product on Amazon, send messages \\nto friends in Facebook, watch a video on Y ouTube, or search for directions in Google Maps, you are using a NoSQL database. As with any new technology, the term NoSQL can be loosely applied to many different types of technologies. However, this chapter uses NoSQL to refer to a new generation of databases that address the specific challenges of the Big Data era and have the following general characteristics:\\n•\\n They are not based on the relational model and SQL, hence the name NoSQL.\\n• They support distributed database architectures.\\n• They provide high scalability, high availability, and fault tolerance.\\n• They support very large amounts of sparse data.\\n• They are geared toward performance rather than transaction consistency.\\nLet’s examine these characteristics in more detail.\\nNoSQL databases are not based on the relational model. In fact, there is no standard \\nNoSQL data model. To the contrary, many different data models are grouped under the \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b0956e2-95e8-491f-9bc5-4f61a8361fe5', embedding=None, metadata={'page_label': '54', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='54   Part 1     Database Concepts\\nNoSQL umbrella, from document databases to graph stores, column stores, and key-value \\nstores. It is still too early to know which, if any, of these data models will survive and grow \\nto become a dominant force in the database arena. However, the early success of prod -\\nucts such as Amazon’s SimpleDB, Google’s BigTable, and Apache’s Cassandra points to the \\nkey-value stores  and column stores  as the early leaders. The word stores  indicates that these \\ndata models permanently store data in secondary storage, just like any other database. This \\nadded emphasis comes from the fact that these data models originated from programming \\nlanguages (such as LISP), in which in-memory arrays of values are used to hold data.\\nThe key-value  data model is based on a structure composed of two data elements: a \\nkey and a value, in which every key has a corresponding value or set of values. The key-\\nvalue data model is also referred to as the attribute-value or associative data model. To \\nbetter understand the key-value model, look at the simple example in Figure 2.5.\\nFIGURE 2.5  A SIMPLE KEY-VALUE REPRESENTATION\\nTrucks-R-Us\\nData stored using traditional relational model\\n• In the relational model:\\n • Each row represents one entity instance.\\n • Each column represents one attribute of the entity.\\n • The values in a column are of the same data type.\\n• In the key-value model:\\n • Each row represents one attribute/value of one entity \\ninstance.\\n • The “key” column could represent any entity’s attribute.\\n • The values in the “value” column could be of any data \\ntype and therefore it is generally assigned a long string \\ndata type.Data stored using \\nkey-value model\\nDriver 2732\\nFigure 2.5 shows the example of a small truck-driving company called Trucks-R-Us. \\nEach of the three drivers has one or more certifications and other general information. \\nUsing this example, we can draw the following important points:\\n• In the relational model, every row represents a single entity occurrence and every \\ncolumn represents an attribute of the entity occurrence. Each column has a defined \\ndata type.\\n• In the key-value data model, each row represents one attribute of one entity instance. \\nThe “key” column points to an attribute, and the “value” column contains the actual \\nvalue for the attribute.\\n• The data type of the “value” column is generally a long string to accommodate the \\nvariety of actual data types of the values placed in the column.\\n• To add a new entity attribute in the relational model, you need to modify the table \\ndefinition. To add a new attribute in the key-value store, you add a row to the key-value \\nstore, which is why it is said to be “schema-less. ”\\n• NoSQL databases do not store or enforce relationships among entities. The program -\\nmer is required to manage the relationships in the program code. Furthermore, all \\ndata and integrity validations must be done in the program code (although some \\nimplementations have been expanded to support metadata).key-value\\nA data model based on \\na structure composed \\nof two data elements: \\na key and a value, in \\nwhich every key has a \\ncorresponding value or \\nset of values. The key-\\nvalue data model is also \\ncalled the associative \\nor attribute-value data \\nmodel.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b1e13de3-6c4e-4d6b-af3c-b8d5eb5d45ae', embedding=None, metadata={'page_label': '55', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    55\\n• NoSQL databases use their own native application programming interface (API) \\nwith simple data access commands, such as put , read , and delete . Because there is \\nno declarative SQL-like syntax to retrieve data, the program code must take care of retrieving related data in the correct way.\\n•\\n Indexing and searches can be difficult. Because the “value” column in the key-value data model could contain many different data types, it is often difficult to create indexes on the data. At the same time, searches can become very complex.\\nAs a matter of fact, you could use the key-value structure as a general data modeling \\ntechnique when attributes are numerous but actual data values are scarce. The key-value data model is not exclusive to NoSQL databases; actually, key-value data structures could reside inside a relational database. However, because of the problems with maintaining relationships and integrity within the data, and the increased complexity of even simple queries, key-value structures would be a poor design for most structured business data.\\nSeveral NoSQL database implementations, such as Google’s BigTable and Apache’s \\nCassandra, have extended the key-value data model to group multiple key-value sets into column families or column stores. In addition, such implementations support features such as versioning using a date/time stamp. For example, BigTable stores data in the syntax of [row, column, time, value], where row, column, and value are string data types, and time is a date/time data type. The key used to access the data is composed of (row, column, time), where time can be left blank to indicate the most recent stored value.\\nNoSQL supports distributed database architecture . One of the big advantages of NoSQL \\ndatabases is that they generally use a distributed architecture. In fact, several of them (Cassandra and BigTable, for example) are designed to use low-cost commodity serv-ers to form a complex network of distributed database nodes. Remember that several NoSQL databases originated in the research labs of some of the most successful web companies, and most started on very small budgets!\\nNoSQL supports very large amounts of sparse data. NoSQL databases can handle very \\nhigh volumes of data. In particular, they are suited for sparse data—that is, for cases in which the number of attributes is very large but the number of actual data instances is low. Using the preceding example, drivers can take any certification exam, but they are not required to take all. In this case, if there are three drivers and three possible certifi-cates for each driver, there will be nine possible data points. In practice, however, there are only four data instances. Now extrapolate this example for the case of a clinic with 15,000 patients and more than 500 possible tests, remembering that each patient can take a few tests but is not required to take all.\\nNoSQL provides high scalability, high availability, and fault tolerance. True to its web \\norigins, NoSQL databases are designed to support web operations, such as the ability to add capacity in the form of nodes to the distributed database when the demand is high, and to do it transparently and without downtime. Fault tolerance means that if one of the nodes in the distributed database fails, it will keep operating as normal.\\nMost NoSQL databases are geared toward performance rather than transaction consis-\\ntency . One of the biggest problems of very large distributed databases is enforcing data \\nconsistency. Distributed databases automatically make copies of data elements at multi-ple nodes to ensure high availability and fault tolerance. If the node with the requested data goes down, the request can be served from any other node with a copy of the data. However, what happens if the network goes down during a data update? In a relational database, transaction updates are guaranteed to be consistent or the transaction is rolled back. NoSQL databases sacrifice consistency to attain high levels of performance. (See Chapter 14, Big Data Analytics and NoSQL, to learn more about this topic.) Some NoSQL databases provide a feature called eventual consistency, which means that updates to the database will propagate through the system and eventually all data copies will be \\nsparse data\\nA case in which the number of table attributes is very large but the number of actual data instances is low.\\neventual consistency\\nA model for database consistency in which updates to the database will propagate through the system so that all data copies will be consistent eventually.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ad3adfe5-375d-4ad4-8c6f-1877cb38a44f', embedding=None, metadata={'page_label': '56', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='56   Part 1     Database Concepts\\nconsistent. With eventual consistency, data is not guaranteed to be consistent across all \\ncopies of the data immediately after an update.\\nNoSQL is one of the hottest items in database technologies today. But it is only one of \\nmany emerging trends in data management. Whatever database technology you use, you \\nneed to be able to select the best tool for the job by understanding the pros and cons of \\neach technology. The following section briefly summarizes the evolution of data models \\nand provides some advantages and disadvantages of each.\\n2-5g  Data Models: A Summary\\nThe evolution of DBMSs has always been driven by the search for new ways of modeling \\nand managing increasingly complex real-world data. A summary of the most commonly \\nrecognized data models is shown in Figure 2.6.\\nFIGURE 2.6  THE EVOLUTION OF DATA MODELS\\nmostleastSemantics in\\nData ModelComments\\nHierarchical\\nNetwork\\nRelational\\nEntity Relationship\\nSemantic1960\\n1969\\n1970\\n1976\\n1978\\n1985 1990\\nObject-OrientedExtended Relational\\n(O/R DBMS)• Difﬁcult to represent M:N relationships  \\n   (hierarchical only)\\n• Structural level dependency\\n• No ad hoc queries (record-at-a-time access)\\n• Access path predeﬁned (navigational access)\\n• Conceptual simplicity (structural independence)\\n• Provides ad hoc queries (SQL)\\n• Set-oriented access\\nNoSQL Big Data2009 • Addresses Big Data problem\\n• Less semantics in data model\\n• Based on schema-less key-value data model\\n• Best suited for large sparse data stores• Easy to understand (more semantics)\\n• Limited to conceptual modeling\\n   (no implementation component)\\n• More semantics in data model\\n• Support for complex objects\\n• Inheritance (class hierarchy)\\n• Behavior\\n• Unstructured data (XML)\\n• XML data exchanges\\n1983\\nInternet is \\nborn\\nIn the evolution of data models, some common characteristics have made them \\nwidely accepted:\\n• A data model must show some degree of conceptual simplicity without compro -\\nmising the semantic completeness of the database. It does not make sense to have \\na data model that is more difficult to conceptualize than the real world . At the same \\ntime, the model should show clarity and relevance; that is, the data model should \\nbe unambiguous and applicable to the problem domain. A data model must repre -\\nsent the real world as closely as possible. This goal is more easily realized by adding \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cbf140f6-3cc2-4c3d-81af-ea171cfe0f83', embedding=None, metadata={'page_label': '57', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    57\\nmore semantics to the model’s data representation. (Semantics concern dynamic \\ndata behavior, while data representation constitutes the static aspect of the real-world scenario.) In other words, the model should be accurate and complete—all the needed data is included and properly described.\\n•\\n Representation of the real-world transformations (behavior) must be in compliance with the consistency and integrity characteristics required by the intended use of the data model.\\nEach new data model addresses the shortcomings of previous models. The network \\nmodel replaced the hierarchical model because the former made it much easier to repre-sent complex (many-to-many) relationships. In turn, the relational model offers several advantages over the hierarchical and network models through its simpler data repre-sentation, superior data independence, and easy-to-use query language; these features made it the preferred data model for business applications. The OO data model intro-duced support for complex data within a rich semantic framework. The ERDM added many OO features to the relational model and allowed it to maintain strong market share within the business environment. In recent years, the Big Data phenomenon has stim-ulated the development of alternative ways to model, store, and manage data that rep-resents a break with traditional data management.\\nIt is important to note that not all data models are created equal; some data models \\nare better suited than others for some tasks. For example, conceptual  models are better \\nsuited for high-level data modeling, while implementation  models are better for manag-\\ning stored data for implementation purposes. The entity relationship model is an exam-ple of a conceptual model, while the hierarchical and network models are examples of implementation models. At the same time, some models, such as the relational model and the OODM, could be used as both conceptual and implementation models. Table 2.2 summarizes the advantages and disadvantages of the various database models.\\nThus far, you have been introduced to the basic constructs of the more prominent data \\nmodels. Each model uses such constructs to capture the meaning of the real-world data environment. Table 2.3 shows the basic terminology used by the various data models.\\n2-6 Degrees of Data Abstraction\\nIf you ask 10 database designers what a data model is, you will end up with 10 different answers—depending on the degree of data abstraction. To illustrate the meaning of data abstraction, consider the example of automotive design. A car designer begins by draw-ing the concept of the car to be produced. Next, engineers design the details that help transfer the basic concept into a structure that can be produced. Finally, the engineering drawings are translated into production specifications to be used on the factory floor. As you can see, the process of producing the car begins at a high level of abstraction and proceeds to an ever-increasing level of detail. The factory floor process cannot proceed unless the engineering details are properly specified, and the engineering details cannot \\nNote\\nAll databases assume the use of a common data pool within the database. Therefore, all database models promote data sharing, thus reducing the potential problem of islands of information.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a602f5da-410c-4931-a955-910caddcf8b4', embedding=None, metadata={'page_label': '58', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='58   Part 1    Database Concepts\\nTABLE 2.2\\nADVANTAGES AND DISADVANTAGES OF VARIOUS DATABASE MODELS\\nDATA \\nMODELDATA  \\nINDEPENDENCESTRUCTURAL  \\nINDEPENDENCEADVANTAGES DISADVANTAGES\\nHierarchical Yes No 1. It promotes data sharing.\\n2. Parent/child relationship promotes conceptual simplicity.\\n3. Database security is provided and enforced by DBMS.\\n4. Parent/child relationship promotes data integrity.\\n5. It is efficient with 1:M relationships.1. Complex implementation requires knowledge of physical data storage characteristics.\\n2.\\n Navigational system yields complex application development, management, and use; requires knowledge of hierarchical path.\\n3.\\n Changes in structure require changes in all application programs.\\n4. There are implementation limitations (no multiparent or M:N relationships).\\n5. There is no data definition or data manipulation language in the DBMS.\\n6. There is a lack of standards.\\nNetwork Yes No 1. Conceptual simplicity is at least equal to that of the hierarchical model.\\n2.\\n It handles more relationship types, such as M:N and multiparent.\\n3.\\n Data access is more flexible than in hierarchical and file system models.\\n4.\\n Data owner/member relationship promotes data integrity.\\n5. There is conformance to standards.\\n6. It includes data definition language (DDL) and data manipulation language (DML) in DBMS.1.\\n System complexity limits efficiency—still a navigational system.\\n2. Navigational system yields complex implementation, application development, and management.\\n3.\\n Structural changes require changes in all application programs.\\nRelational Yes Yes 1. Structural independence is promoted by the use of independent tables. Changes in a table’s structure do not affect data access or application programs.\\n2.\\n Tabular view substantially improves conceptual simplicity, thereby promoting easier database design, implementation, management, and use.\\n3.\\n Ad hoc query capability is based on SQL.\\n4. Powerful RDBMS isolates the end user from physical-level details and improves implementation and management simplicity.1.\\n The RDBMS requires substantial hardware and system software overhead.\\n2. Conceptual simplicity gives relatively untrained people the tools to use a good system poorly, and if unchecked, it may produce the same data anomalies found in file systems.\\n3.\\n It may promote islands of information problems as individuals and departments can easily develop their own applications.\\nEntity  relationshipYes Yes 1.\\n Visual modeling yields exceptional conceptual simplicity.\\n2. Visual representation makes it an effective communication tool.\\n3.\\n It is integrated with the dominant relational model.1. There is limited constraint representation.\\n2. There is limited relationship representation.\\n3. There is no data manipulation language.\\n4. Loss of information content occurs when attributes are removed from entities to avoid crowded displays. (This limitation has been addressed in subsequent graphical versions.)\\nObject- orientedYes Yes 1.\\n Semantic content is added.\\n2. Visual representation includes semantic content.\\n3. Inheritance promotes data integrity.1. Slow development of standards caused vendors to supply their own enhancements, thus eliminating a widely accepted standard.\\n2.\\n It is a complex navigational system.\\n3. There is a steep learning curve.\\n4. High system overhead slows transactions.\\nNoSQL Yes Yes 1. High scalability, availability, and fault tolerance are provided.\\n2. It uses low-cost commodity hardware.\\n3. It supports Big Data.\\n4. Key-value model improves storage efficiency.1. Complex programming is required.\\n2. There is no relationship support—only by application code.\\n3. There is no transaction integrity support.\\n4. In terms of data consistency, it provides an eventually consistent model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b230b09-24eb-4a77-873e-9729c015de64', embedding=None, metadata={'page_label': '59', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    59\\nexist without the basic conceptual framework created by the designer. Designing a \\nusable database follows the same basic process. That is, a database designer starts with an \\nabstract view of the overall data environment and adds details as the design comes closer \\nto implementation. Using levels of abstraction can also be very helpful in integrating \\nmultiple (and sometimes conflicting) views of data at different levels of an organization.\\nIn the early 1970s, the American National Standards Institute  (ANSI)  Standards \\nPlanning and Requirements Committee (SPARC) defined a framework for data mod -\\neling based on degrees of data abstraction. The resulting ANSI/SPARC architecture \\ndefines three levels of data abstraction: external, conceptual, and internal. Y ou can use \\nthis framework to better understand database models, as shown in Figure 2.7. In the \\nfigure, the ANSI/SPARC framework has been expanded with the addition of a physical  \\nmodel to explicitly address physical-level implementation details of the internal model.TABLE 2.3\\nDATA MODEL BASIC TERMINOLOGY COMPARISON\\nREAL WORLD EXAMPLE FILE  \\nPROCESSINGHIERARCHICAL \\nMODELNETWORK \\nMODELRELATIONAL \\nMODELER MODEL OO MODEL\\nA group of \\nvendorsVendor file \\ncabinetFile Segment type Record type Table Entity set Class\\nA single \\nvendorGlobal  \\nsuppliesRecord Segment \\noccurrenceCurrent record Row (tuple) Entity  \\noccurrenceObject  \\ninstance\\nThe contact \\nnameJohnny  \\nVenturaField Segment field Record field Table \\nattributeEntity  \\nattributeObject  \\nattribute\\nThe vendor \\nidentifierG12987 Index Sequence field Record key Key Entity  \\nidentifierObject  \\nidentifier\\nNote:  For additional information about the terms used in this table, consult the corresponding chapters and online appendixes that \\naccompany this book. For example, if you want to know more about the OO model, refer to Appendix G, Object-Oriented Databases.\\nFIGURE 2.7  DATA ABSTRACTION LEVELS\\nEnd-User View End-User View\\nExternal\\nModelExternal\\nModel\\nConceptual\\nModel\\nInternal\\nModel\\nPhysical \\nModelDesigner’s\\nView\\nDBMS\\nView\\nPhysical independenceLogical independenceDegree of \\nAbstraction Characteristics\\nHigh ER\\nRelational\\nNetwork \\nHierarchical LowMediumHardware-independent\\nSoftware-independent\\nHardware-independent\\nSoftware-dependent\\nHardware-dependent\\nSoftware-dependentObject-OrientedAmerican National \\nStandards Institute \\n(ANSI)\\nThe group that \\naccepted the DBTG \\nrecommendations and \\naugmented database \\nstandards in 1975 \\nthrough its SPARC \\ncommittee.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9019af6-b411-4822-a8ad-ceeb3dbda479', embedding=None, metadata={'page_label': '60', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='60   Part 1     Database Concepts\\n2-6a  The External Model\\nThe external model  is the end users’ view of the data environment. The term end users  \\nrefers to people who use the application programs to manipulate the data and generate \\ninformation. End users usually operate in an environment in which an application has a \\nspecific business unit focus. Companies are generally divided into several business units, \\nsuch as sales, finance, and marketing. Each business unit is subject to specific constraints \\nand requirements, and each one uses a subset of the overall data in the organization. \\nTherefore, end users within those business units view their data subsets as separate from \\nor external to other units within the organization.\\nBecause data is being modeled, ER diagrams will be used to represent the external \\nviews. A specific representation of an external view is known as an external schema . \\nTo illustrate the external model’s view, examine the data environment of Tiny College.\\nFigure 2.8 presents the external schemas for two Tiny College business units: student \\nregistration and class scheduling. Each external schema includes the appropriate entities, \\nrelationships, processes, and constraints imposed by the business unit. Also note that \\nalthough the application views are isolated from each other, each view shares a common \\nentity with the other view . For example, the registration and scheduling external schemas \\nshare the entities CLASS and COURSE.\\nFIGURE 2.8  EXTERNAL MODELS FOR TINY COLLEGE\\nNote the entity relationships represented in Figure 2.8:\\n• A PROFESSOR may teach many CLASSes, and each CLASS is taught by only one \\nPROFESSOR; there is a 1:M relationship between PROFESSOR and CLASS.\\n• A CLASS may ENROLL many students, and each STUDENT may ENROLL in many \\nCLASSes, thus creating an M:N relationship between STUDENT and CLASS. (Y ou \\nwill learn about the precise nature of the ENROLL entity in Chapter 4.)\\n• Each COURSE may generate many CLASSes, but each CLASS references a single \\nCOURSE. For example, there may be several classes (sections) of a database course \\nthat have a course code of CIS-420. One of those classes might be offered on MWF external model\\nThe application \\nprogrammer’s view of \\nthe data environment. \\nGiven its business focus, \\nan external model works \\nwith a data subset of the \\nglobal database schema.\\nexternal schema\\nThe specific \\nrepresentation of an \\nexternal view; the end \\nuser’s view of the data \\nenvironment.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5689f1ad-66dd-4a41-b654-3f5b681b6c5b', embedding=None, metadata={'page_label': '61', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    61\\nfrom 8:00 a.m. to 8:50 a.m., another might be offered on MWF from 1:00 p.m. to 1:50 \\np.m., while a third might be offered on Thursdays from 6:00 p.m. to 8:40 p.m. Y et, all \\nthree classes have the course code CIS-420.\\n• Finally, a CLASS requires one ROOM, but a ROOM may be scheduled for many \\nCLASSes. That is, each classroom may be used for several classes: one at 9:00 a.m., \\none at 11:00 a.m., and one at 1:00 p.m., for example. In other words, there is a 1:M \\nrelationship between ROOM and CLASS.\\nThe use of external views that represent subsets of the database has some important \\nadvantages:\\n• It is easy to identify specific data required to support each business unit’s operations.\\n• It makes the designer’s job easy by providing feedback about the model’s adequacy. \\nSpecifically, the model can be checked to ensure that it supports all processes as defined \\nby their external models, as well as all operational requirements and constraints.\\n• It helps to ensure security  constraints in the database design. Damaging an entire \\ndatabase is more difficult when each business unit works with only a subset of data.\\n• It makes application program development much simpler.\\n2-6b  The Conceptual Model\\nThe conceptual model  represents a global view of the entire database by the entire orga -\\nnization. That is, the conceptual model integrates all external views (entities, relationships, \\nconstraints, and processes) into a single global view of the data in the enterprise, as shown \\nin Figure 2.9. Also known as a conceptual schema , it is the basis for the identification and \\nhigh-level description of the main data objects (avoiding any database model-specific details).\\nThe most widely used conceptual model is the ER model. Remember that the ER \\nmodel is illustrated with the help of the ERD, which is effectively the basic database blue -\\nprint. The ERD is used to graphically represent  the conceptual schema.\\nThe conceptual model yields some important advantages. First, it provides a bird’s-\\neye (macro level) view of the data environment that is relatively easy to understand. For \\nexample, you can get a summary of Tiny College’s data environment by examining the \\nconceptual model in Figure 2.9.\\nFIGURE 2.9  CONCEPTUAL MODEL FOR TINY COLLEGE\\nconceptual model\\nThe output of the \\nconceptual design \\nprocess. The conceptual \\nmodel provides a \\nglobal view of an entire \\ndatabase and describes \\nthe main data objects, \\navoiding details.\\nconceptual schema\\nA representation of \\nthe conceptual model, \\nusually expressed \\ngraphically. See also \\nconceptual model .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4c36b0a-1ce0-49ef-8585-9781347b8789', embedding=None, metadata={'page_label': '62', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='62   Part 1     Database Concepts\\nSecond, the conceptual model is independent of both software and hardware. Soft-\\nware independence  means that the model does not depend on the DBMS software \\nused to implement the model. Hardware independence  means that the model does not \\ndepend on the hardware used in the implementation of the model. Therefore, changes \\nin either the hardware or the DBMS software will have no effect on the database design \\nat the conceptual level. Generally, the term logical design  refers to the task of creating a \\nconceptual data model that could be implemented in any DBMS.\\n2-6c  The Internal Model\\nOnce a specific DBMS has been selected, the internal model maps the conceptual model \\nto the DBMS. The internal model  is the representation of the database as “seen” by the \\nDBMS. In other words, the internal model requires the designer to match the conceptual \\nmodel’s characteristics and constraints to those of the selected implementation model. \\nAn internal schema  depicts a specific representation of an internal model, using the \\ndatabase constructs supported by the chosen database.\\nBecause this book focuses on the relational model, a relational database was chosen to \\nimplement the internal model. Therefore, the internal schema should map the concep -\\ntual model to the relational model constructs. In particular, the entities in the concep -\\ntual model are mapped to tables in the relational model. Likewise, because a relational \\ndatabase has been selected, the internal schema is expressed using SQL, the standard \\nlanguage for relational databases. In the case of the conceptual model for Tiny College \\ndepicted in Figure 2.9, the internal model was implemented by creating the tables PRO -\\nFESSOR, COURSE, CLASS, STUDENT, ENROLL, and ROOM. A simplified version of \\nthe internal model for Tiny College is shown in Figure 2.10.\\nThe development of a detailed internal model is especially important to database \\ndesigners who work with hierarchical or network models because those models require \\nFIGURE 2.10  INTERNAL MODEL FOR TINY COLLEGE\\nsoftware \\nindependence\\nA property of any model or \\napplication that does not \\ndepend on the software \\nused to implement it.\\nhardware \\nindependence\\nA condition in which \\na model does not \\ndepend on the hardware \\nused in the model’s \\nimplementation. Therefore, \\nchanges in the hardware \\nwill have no effect on the \\ndatabase design at the \\nconceptual level.\\nlogical design\\nA stage in the design \\nphase that matches \\nthe conceptual design \\nto the requirements of \\nthe selected DBMS and \\nis therefore software-\\ndependent. Logical \\ndesign is used to translate \\nthe conceptual design \\ninto the internal model \\nfor a selected database \\nmanagement system, \\nsuch as DB2, SQL Server, \\nOracle, IMS, Informix, \\nAccess, or Ingress.\\ninternal model\\nIn database modeling, a \\nlevel of data abstraction \\nthat adapts the conceptual \\nmodel to a specific DBMS \\nmodel for implementation. \\nThe internal model is  \\nthe representation of  \\na database as “seen” \\nby the DBMS. In other \\nwords, the internal model \\nrequires a designer to \\nmatch the conceptual \\nmodel’s characteristics and \\nconstraints to those of the \\nselected implementation \\nmodel.\\ninternal schema\\nA representation of an \\ninternal model using the \\ndatabase constructs sup-\\nported by the chosen \\ndatabase.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c42088e4-9ae6-43ce-a4ce-ba7db7dcc190', embedding=None, metadata={'page_label': '63', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    63\\nprecise specification of data storage location and data access paths. In contrast, the rela-\\ntional model requires less detail in its internal model because most RDBMSs handle data access path definition transparently ; that is, the designer need not be aware of the data \\naccess path details. Nevertheless, even relational database software usually requires spec-ifications of data storage locations, especially in a mainframe environment. For example, DB2 requires that you specify the data storage group, the location of the database within the storage group, and the location of the tables within the database.\\nBecause the internal model depends on specific database software, it is said to be \\nsoftware dependent. Therefore, a change in the DBMS software requires that the inter -\\nnal model be changed to fit the characteristics and requirements of the implementation database model. When you can change the internal model without affecting the concep-tual model, you have logical independence. However, the internal model is still hard-ware independent because it is unaffected by the type of computer on which the software is installed. Therefore, a change in storage devices or even a change in operating systems will not affect the internal model.\\n2-6d  The Physical Model\\nThe physical model operates at the lowest level of abstraction, describing the way data is \\nsaved on storage media such as magnetic, solid state, or optical media. The physical model requires the definition of both the physical storage devices and the (physical) access meth-ods required to reach the data within those storage devices, making it both software and hardware dependent. The storage structures used are dependent on the software (the DBMS and the operating system) and on the type of storage devices the computer can handle. The precision required in the physical model’s definition demands that database designers have a detailed knowledge of the hardware and software used to implement the database design.\\nEarly data models forced the database designer to take the details of the physical \\nmodel’s data storage requirements into account. However, the now dominant relational model is aimed largely at the logical level rather than the physical level; therefore, it does not require the physical-level details common to its predecessors.\\nAlthough the relational model does not require the designer to be concerned about the \\ndata’s physical storage characteristics, the implementation  of a relational model may require \\nphysical-level fine-tuning for increased performance. Fine-tuning is especially important when very large databases are installed in a mainframe environment, yet even such perfor -\\nmance fine-tuning at the physical level does not require knowledge of physical data storage characteristics.\\nAs noted earlier, the physical model is dependent on the DBMS, methods of accessing \\nfiles, and types of hardware storage devices supported by the operating system. When you can change the physical model without affecting the internal model, you have physi-cal independence. Therefore, a change in storage devices or methods and even a change in operating system will not affect the internal model.\\nThe levels of data abstraction are summarized in Table 2.4.\\nTABLE 2.4\\nLEVELS OF DATA ABSTRACTION\\nMODEL DEGREE OF ABSTRACTION FOCUS INDEPENDENT OF\\nExternal High\\nLowEnd-user views Hardware and software\\nConceptual Global view of data (database model independent) Hardware and software\\nInternal Specific database model Hardware\\nPhysical Storage and access methods Neither hardware nor softwarelogical independence\\nA condition in which the internal model can be changed without af-fecting the conceptual model. (The internal model is hardware-independent because it is unaffected by the computer on which the software is installed. Therefore, a change in storage devices or operating systems will not affect the internal model.)\\nphysical model\\nA model in which physical characteristics such as location, path, and format are described for the data. The physical model is both hardware- and software-dependent. See also physical design.\\nphysical independence\\nA condition in which the physical model can be changed without affecting the internal model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc8e66fd-7da5-45ec-93e2-7c6ce9500507', embedding=None, metadata={'page_label': '64', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='64   Part 1    Database Concepts\\n• A data model is an abstraction of a complex real-world data environment. Database \\ndesigners use data models to communicate with programmers and end users. The basic data-modeling components are entities, attributes, relationships, and con-straints. Business rules are used to identify and define the basic modeling components within a specific real-world environment.\\n•\\n The hierarchical and network data models were early models that are no longer used, but some of the concepts are found in current data models.\\n•\\n The relational model is the current database implementation standard. In the rela-tional model, the end user perceives the data as being stored in tables. Tables are related to each other by means of common values in common attributes. The entity relationship (ER) model is a popular graphical tool for data modeling that comple-ments the relational model. The ER model allows database designers to visually pres-ent different views of the data—as seen by database designers, programmers, and end users—and to integrate the data into a common framework.\\n•\\n The object-oriented data model (OODM) uses objects as the basic modeling struc-ture. Like the relational model’s entity, an object is described by its factual content. Unlike an entity, however, the object also includes information about relationships between the facts, as well as relationships with other objects, thus giving its data more meaning.\\n•\\n The relational model has adopted many object-oriented (OO) extensions to become the extended relational data model (ERDM). Object/relational database management systems (O/R DBMS) were developed to implement the ERDM. At this point, the OODM is largely used in specialized engineering and scientific applications, while the ERDM is primarily geared to business applications.\\n•\\n Emerging Big Data technologies such as Hadoop, MapReduce, and NoSQL provide distributed, fault-tolerant, and cost-efficient support for Big Data analytics. NoSQL databases are a new generation of databases that do not use the relational model and are geared to support the very specific needs of Big Data organizations. NoSQL data-bases offer distributed data stores that provide high scalability, availability, and fault tolerance by sacrificing data consistency and shifting the burden of maintaining rela-tionships and data integrity to the program code.\\n•\\n Data-modeling requirements are a function of different data views (global versus local) and the level of data abstraction. The American National Standards Institute Standards Planning and Requirements Committee (ANSI/SPARC) describes three levels of data abstraction: external, conceptual, and internal. The fourth and lowest level of data abstraction, called the physical level, is concerned exclusively with phys-ical storage methods.\\nSummary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3522bebe-e4fc-4829-8473-0816ed296525', embedding=None, metadata={'page_label': '65', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    65\\n3 Vs\\nAmerican National \\nStandards Institute (ANSI)\\nattributeBig Databusiness ruleChen notationclassclass diagramclass diagram notationclass hierarchyclient nodeconceptual modelconceptual schemaconnectivityconstraintCrow’s Foot notationdata definition language \\n(DDL)\\ndata manipulation language \\n(DML)\\ndata modeldata modelingdata nodeentityentity instanceentity occurrenceentity relationship (ER) \\nmodel (ERM)entity relationship diagram \\n(ERD)\\nentity seteventual consistencyextended relational data \\nmodel (ERDM)\\nExtensible Markup \\nLanguage (XML)\\nexternal modelexternal schemaHadoopHadoop Distributed File \\nSystem (HDFS)\\nhardware independencehierarchical modelinheritanceinternal modelinternal schemakey-valuelogical designlogical independenceMapReducemany-to-many (M:N or *..*) \\nrelationship\\nmethodname nodenetwork modelNoSQLobjectobject/relational  \\ndatabase management \\nsystem (O/R DBMS)\\nobject-oriented data  \\nmodel (OODM)\\nobject-oriented database \\nmanagement system (OODBMS)\\none-to-many (1:M or 1..*) \\nrelationship\\none-to-one (1:1 or 1..1) \\nrelationship\\nphysical independence\\nphysical modelrelationrelational database \\nmanagement system \\n(RDBMS)\\nrelational diagram\\nrelational modelrelationshipschemasegmentsemantic data modelsoftware independencesparse datasubschematabletupleUnified Modeling Language \\n(UML)\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. Discuss the importance of data models.\\n2. What is a business rule, and what is its purpose in data modeling?\\n3. How do you translate business rules into data model components?\\n4. Describe the basic features of the relational data model and discuss their importance \\nto the end user and the designer.Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4cd2a673-5ee3-4657-b3d0-c89079562995', embedding=None, metadata={'page_label': '66', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='66   Part 1    Database Concepts\\nProblems\\nUse the contents of Figure 2.1 to work Problems 1–3.\\n1. Write the business rule(s) that govern the relationship between AGENT and \\nCUSTOMER.\\n2. Given the business rule(s) you wrote in Problem 1, create the basic Crow’s Foot ERD.\\n3.\\n Using the ERD you drew in Problem 2, create the equivalent object representation and UML class diagram. (Use Figure 2.4 as your guide.)\\nUsing Figure P2.4 as your guide, work Problems 4–5. The DealCo relational diagram shows the initial entities and attributes for the DealCo stores, which are located in two regions of the country.5.\\n Explain how the entity relationship (ER) model helped produce a more structured relational database design environment.\\n6.\\n Consider the scenario described by the statement “ A customer can make many pay-ments, but each payment is made by only one customer. ” Use this scenario as the basis for an entity relationship diagram (ERD) representation.\\n7.\\n Why is an object said to have greater semantic content than an entity?\\n8. What is the difference between an object and a class in the object-oriented data model (OODM)?\\n9.\\n How would you model Question 6 with an OODM? (Use Figure 2.4 as your guide.)\\n10. What is an ERDM, and what role does it play in the modern (production) database environment?\\n11.\\n What is a relationship, and what three types of relationships exist?\\n12. Give an example of each of the three types of relationships.\\n13. What is a table, and what role does it play in the relational model?\\n14. What is a relational diagram? Give an example.\\n15. What is connectivity? (Use a Crow’s Foot ERD to illustrate connectivity.)\\n16. Describe the Big Data phenomenon.\\n17. What does the term 3 Vs refer to?\\n18. What is Hadoop and what are its basic components?\\n19. What is sparse data? Give an example.\\n20. Define and describe the basic characteristics of a NoSQL database.\\n21. Using the example of a medical clinic with patients and tests, provide a simple representation of how to model this example using the relational model and how it would be represented using the key-value data modeling technique.\\n22.\\n What is logical independence?\\n23. What is physical independence?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='265e8fd1-4e98-4b1d-994f-c4677ff2f21f', embedding=None, metadata={'page_label': '67', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    67\\nFIGURE P2.4  THE DEALCO RELATIONAL DIAGRAM\\nFIGURE P2.6  THE TINY COLLEGE RELATIONAL DIAGRAM4. Identify each relationship type and write all of the business rules.\\n5. Create the basic Crow’s Foot ERD for DealCo.\\nUsing Figure P2.6 as your guide, work Problems 6–8. The Tiny College relational dia-\\ngram shows the initial entities and attributes for the college.\\n6. Identify each relationship type and write all of the business rules.\\n7. Create the basic Crow’s Foot ERD for Tiny College.\\n8. Create the UML class diagram that reflects the entities and relationships you identi -\\nfied in the relational diagram.\\n9. Typically, a hospital patient receives medications that have been ordered by a particular \\ndoctor. Because the patient often receives several medications per day, there is a 1:M \\nrelationship between PATIENT and ORDER. Similarly, each order can include several \\nmedications, creating a 1:M relationship between ORDER and MEDICATION.\\n   a. Identify the business rules for PATIENT, ORDER, and MEDICATION.\\n  b.  Create a Crow’s Foot ERD that depicts a relational database model to capture \\nthese business rules.\\n10. United Broke Artists (UBA) is a broker for not-so-famous artists. UBA maintains \\na small database to track painters, paintings, and galleries. A painting is created by \\na particular artist and then exhibited in a particular gallery. A gallery can exhibit \\nmany paintings, but each painting can be exhibited in only one gallery. Similarly, a \\npainting is created by a single painter, but each painter can create many paintings. \\nUsing PAINTER, PAINTING, and GALLERY , in terms of a relational database:\\n   a. What tables would you create, and what would the table components be?\\n  b.  How might the (independent) tables be related to one another?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6543766b-2f87-48b4-a6b1-5f6df9d76655', embedding=None, metadata={'page_label': '68', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='68   Part 1     Database Concepts\\n11. Using the ERD from Problem 10, create the relational schema. (Create an appropri-\\nate collection of attributes for each of the entities. Make sure you use the appropriate \\nnaming conventions to name the attributes.)\\n12. Convert the ERD from Problem 10 into a corresponding UML class diagram.\\n13. Describe the relationships (identify the business rules) depicted in the Crow’s Foot \\nERD shown in Figure P2.13.\\nFIGURE P2.13  THE CROW’S FOOT ERD FOR PROBLEM 13\\n14. Create a Crow’s Foot ERD to include the following business rules for the ProdCo \\ncompany:\\n  a. Each sales representative writes many invoices.\\n  b. Each invoice is written by one sales representative.\\n  c. Each sales representative is assigned to one department.\\n  d. Each department has many sales representatives.\\n  e. Each customer can generate many invoices.\\n  f. Each invoice is generated by one customer.\\n15. Write the business rules that are reflected in the ERD shown in Figure P2.15. (Note \\nthat the ERD reflects some simplifying assumptions. For example, each book is writ -\\nten by only one author. Also, remember that the ERD is always read from the “1” to \\nthe “M” side, regardless of the orientation of the ERD components.)\\nFIGURE P2.15  THE CROW’S FOOT ERD FOR PROBLEM 15\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='69443f31-e766-4add-b5bf-803224b950c0', embedding=None, metadata={'page_label': '69', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 2    Data Models    69\\n16. Create a Crow’s Foot ERD for each of the following descriptions. (Note that the word \\nmany  merely means more than one  in the database modeling environment.)\\n  a.  Each of the MegaCo Corporation’s divisions is composed of many departments. \\nEach department has many employees assigned to it, but each employee works \\nfor only one department. Each department is managed by one employee, and \\neach of those managers can manage only one department at a time.\\n  b.  During some period of time, a customer can download many ebooks from \\nBooksOnline. Each of the ebooks can be downloaded by many customers during \\nthat period of time.\\n  c.  An airliner can be assigned to fly many flights, but each flight is flown by only \\none airliner.\\n  d.  The KwikTite Corporation operates many factories. Each factory is located in a \\nregion, and each region can be “home” to many of KwikTite’s factories. Each fac -\\ntory has many employees, but each employee is employed by only one factory.\\n  e.  An employee may have earned many degrees, and each degree may have been \\nearned by many employees.\\n17. Write the business rules that are reflected in the ERD shown in Figure P2.17.\\nFIGURE P2.17  THE CROW’S FOOT ERD FOR PROBLEM 17\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dbd1d729-6759-41a8-955f-7606c110daec', embedding=None, metadata={'page_label': '70', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Copyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f8759914-1522-4faa-8156-eac13170f7b7', embedding=None, metadata={'page_label': '71', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 2\\nDesign Concepts\\n3The Relational Database Model\\n4\\n5\\n6Entity Relationship (ER) Modeling\\nAdvanced Data Modeling\\nNormalization of Database Tables\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e5d83956-162a-4c4d-ae59-07a77967cadf', embedding=None, metadata={'page_label': '72', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 3\\nThe Relational Database Model\\nIn this chapter, you will learn:\\n• That the relational database model offers a logical view of data\\n• About the relational model’s basic component: relations\\n• That relations are logical constructs composed of rows (tuples) and columns (attributes)\\n• That relations are implemented as tables in a relational DBMS\\n• About relational database operators, the data dictionary, and the system catalog\\n• How data redundancy is handled in the relational database model\\n• Why indexing is important\\nPreviewIn this chapter, you will learn about the relational model’s logical structure and more \\nabout how ERDs (entity relationship diagrams) can be used to design a relational data-base. Y ou will also learn how the relational database’s basic data components fit into a logical construct known as a table, and how tables within a database can be related to one another.\\nAfter learning about tables, their components, and their relationships, you will be intro-\\nduced to basic table design concepts and the characteristics of well-designed and poorly designed tables. These concepts will become your gateway to the next few chapters.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH03_CollegeTry  P\\t P\\t P\\t P\\nCH03_CollegeTry2  P\\t P\\t P\\t P\\nCH03_InsureCo  P\\t P\\t P\\t P\\nCH03_Museum  P\\t P\\t P\\t P\\nCH03_SaleCo  P\\t P\\t P\\t P\\nCH03_TinyCollege  P\\t P\\t P\\t P\\nCH03_Relational_DB  P\\t P\\t P\\t PCH03_AviaCo  P\\t P\\t P\\t P\\nCH03_BeneCo  P\\t P\\t P\\t P\\nCH03_CollegeQue  P\\t P\\t P\\t P\\nCH03_NoComp  P\\t P\\t P\\t P\\nCH03_StoreCo  P\\t P\\t P\\t P\\nCH03_Theater  P\\t P\\t P\\t P\\nCH03_TransCo  P\\t P\\t P\\t P\\nCH03_VendingCo  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='26f01c59-30f3-4bc3-8506-4e8df220e97c', embedding=None, metadata={'page_label': '73', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    73\\n3-1 A Logical View of Data\\nIn Chapter 1, Database Systems, you learned that a database stores and manages both \\ndata and metadata. Y ou also learned that the DBMS manages and controls access to the data and the database structure. Such an arrangement—placing the DBMS between the application and the database—eliminates most of the file system’s inherent limitations. The result of such flexibility, however, is a far more complex physical structure. In fact, the database structures required by both the hierarchical and network database models often become complicated enough to diminish efficient database design. The relational data model changed all of that by allowing the designer to focus on the logical represen-tation of the data and its relationships, rather than on the physical storage details. To use an automotive analogy, the relational database uses an automatic transmission to relieve you of the need to manipulate clutch pedals and gearshifts. In short, the relational model enables you to view data logically  rather than physically .\\nThe practical significance of taking the logical view is that it serves as a reminder of \\nthe simple file concept of data storage. Although the use of a table, quite unlike that of a file, has the advantages of structural and data independence, a table does resemble a file from a conceptual point of view. Because you can think of related records as being stored in independent tables, the relational database model is much easier to understand than the hierarchical and network models. Logical simplicity tends to yield simple and effective database design methodologies.\\nBecause the table plays such a prominent role in the relational model, it deserves a \\ncloser look. Therefore, our discussion begins by exploring the details of table structure and contents.\\n3-1a  Tables and Their Characteristics\\nThe logical view of the relational database is facilitated by the creation of data relation-ships based on a logical construct known as a relation. Because a relation is a mathemat-ical construct, end users find it much easier to think of a relation as a table. A table  is \\nperceived as a two-dimensional structure composed of rows and columns. A table is also \\nThe relational model, introduced by E. F. Codd in 1970, is based on predicate logic and set theory. \\nPredicate logic , used extensively in mathematics, provides a framework in which \\nan assertion (statement of fact) can be verified as either true or false. For example, suppose that a student with a student ID of 12345678 is named Melissa Sanduski. This assertion can easily be demonstrated to be true or false. \\nSet theory  is a mathematical science that \\ndeals with sets, or groups of things, and is used as the basis for data manipulation in the relational model. For example, assume that set A contains three numbers: 16, 24, and 77. This set is represented as A(16, 24, 77). Furthermore, set B contains four numbers: 44, 77, 90, and 11, and so is represented as B(44, 77, 90, 11). Given this information, you can conclude that the intersection of A and B yields a result set with a single number, 77. This result can be expressed as A ∩ B = 77. In other words, A and B share a common value, 77.\\nBased on these concepts, the relational model has three well-defined components:\\n1.\\n A logical data structure represented by relations (see Sections 3-1, 3-2, and 3-5)\\n2.  A set of integrity rules to enforce that the data is consistent and remains consistent over time (see Sections 3-3, 3-6, 3-7, and 3-8)\\n3.\\n A set of operations that defines how data is manipulated (see Section 3-4)Note\\npredicate logic\\nUsed extensively in mathematics to provide a framework in which an assertion (statement of fact) can be verified as either true or false.\\nset theory\\nA part of mathematical science that deals with sets, or groups of things, and is used as the basis for data manipulation in the relational model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0710ae1a-19ea-448e-871f-a3911be08dc4', embedding=None, metadata={'page_label': '74', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='74   Part 2    Design Concepts\\ncalled a relation  because the relational model’s creator, E. F. Codd, used the two terms as \\nsynonyms. Y ou can think of a table as a persistent  representation of a logical relation—\\nthat is, a relation whose contents can be permanently saved for future use. As far as the \\ntable’s user is concerned, a table contains a group of related entity occurrences—that is, \\nan entity set. For example, a STUDENT table contains a collection of entity occurrences, each representing a student. For that reason, the terms entity set and table  are often used \\ninterchangeably.\\nY ou will discover that the table view of data makes it easy to spot and define entity rela-\\ntionships, thereby greatly simplifying the task of database design. The characteristics of a relational table are summarized in Table 3.1.\\nTABLE 3.1\\nCHARACTERISTICS OF A RELATIONAL TABLE\\n1 A table is perceived as a two-dimensional structure composed of rows and columns.\\n2 Each table row (tuple) represents a single entity occurrence within the entity set.\\n3 Each table column represents an attribute, and each column has a distinct name.\\n4 Each intersection of a row and column represents a single data value.\\n5 All values in a column must conform to the same data format.\\n6 Each column has a specific range of values known as the attribute domain.\\n7 The order of the rows and columns is immaterial to the DBMS.\\n8 Each table must have an attribute or combination of attributes that uniquely identifies each row.\\nThe word relation, also known as a dataset in Microsoft Access, is based on the mathe -\\nmatical set theory from which Codd derived his model. Because the relational model uses attribute values to establish relationships among tables, many database users incorrectly assume that the term relation refers to such relationships. Many then incorrectly conclude that only the relational model permits the use of relationships.Note\\nThe database table shown in Figure 3.1 illustrates the characteristics listed in  \\nTable 3.1.\\nRelational database terminology is very precise. Unfortunately, file system terminology sometimes creeps into the database environment. Thus, rows are sometimes referred to as records, and columns are sometimes labeled as fields. Occasionally, tables are labeled files. Technically speaking, this substitution of terms is not always appropriate. The database table is a logical concept rather than a physical concept, and the terms file, record , and field \\ndescribe physical concepts. Nevertheless, as long as you recognize that the table is actually a logical concept rather than a physical construct, you may think of table rows as records and of table columns as fields. In fact, many database software vendors still use this familiar file system terminology.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38dafea1-692f-4fe9-aa19-1c3f12e765a1', embedding=None, metadata={'page_label': '75', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    75\\nUsing the STUDENT table shown in Figure 3.1, you can draw the following conclu -\\nsions corresponding to the points in Table 3.1:\\n1. The STUDENT table is perceived to be a two-dimensional structure composed of \\n8 rows (tuples) and 12 columns (attributes).\\n2. Each row in the STUDENT table describes a single entity occurrence within the \\nentity set. (The entity set is represented by the STUDENT table.) For example, row \\n4 in Figure 3.1 describes a student named Walter H. Oblonski. Given the table con -\\ntents, the STUDENT entity set includes eight distinct entities (rows), or students.\\n3. Each column represents an attribute, and each column has a distinct name.\\n4. All of the values in a column match the attribute’s characteristics. For example, \\nthe grade point average (STU_GPA) column contains only STU_GPA entries for \\neach of the table rows. Data must be classified according to its format and func -\\ntion. Although various DBMSs can support different data types, most support at \\nleast the following:\\na. Numeric . Y ou can use numeric data to perform meaningful arithmetic procedures. \\nFor example, in Figure 3.1, STU_HRS and STU_GPA are numeric attributes.\\nb. Character . Character data, also known as text data or string data, can contain any \\ncharacter or symbol not intended for mathematical manipulation. In Figure 3.1, \\nSTU_CLASS and STU_PHONE are examples of character attributes.\\nc. Date . Date attributes contain calendar dates stored in a special format known as \\nthe Julian date format. In Figure 3.1, STU_DOB is a date attribute.\\nd. Logical . Logical data can only have true or false (yes or no) values. In Figure 3.1, \\nthe STU_TRANSFER attribute uses a logical data format.\\n5. The column’s range of permissible values is known as its domain . Because the \\nSTU_GPA values are limited to the range 0–4, inclusive, the domain is [0,4].\\n6. The order of rows and columns is immaterial to the user.FIGURE 3.1  STUDENT TABLE ATTRIBUTE VALUES  \\nDatabase name: Ch03_ TinyCollege\\nSTU_NUM  = Student number\\nSTU_LNAME  = Student last name\\nSTU_FNAME  = Student ﬁrst name\\nSTU_INIT  = Student middle initial\\nSTU_DOB  = Student date of birth\\nSTU_HRS  = Credit hours earned\\nSTU_CLASS  = Student classiﬁcation\\nSTU_GPA  = Grade point average\\nSTU_TRANSFER = Student transferred from another institution\\nDEPT_CODE  = Department code\\nSTU_PHONE  = 4-digit campus phone extension\\nPROF_NUM  = Number of the professor who is the student’s advisorTable name: STUDENT\\nAll of the databases \\nused to illustrate the \\nmaterial in this chapter \\n(see the Data Files list \\nat the beginning of the \\nchapter) are available \\nat www.cengagebrain.\\ncom . The database \\nnames match the data -\\nbase names shown in \\nthe figures.Online \\nContent\\ntuple\\nIn the relational model,  \\na table row.\\ndomain\\nIn data modeling, \\nthe construct used to \\norganize and describe an \\nattribute’s set of possible \\nvalues.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3098a8cf-3565-40ce-8001-2e6384359016', embedding=None, metadata={'page_label': '76', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='76   Part 2    Design Concepts\\n7. Each table must have a primary key. In general terms, the primary key (PK) is \\nan attribute or combination of attributes that uniquely identifies any given row. In this case, STU_NUM (the student number) is the primary key. Using the data in Figure 3.1, observe that a student’s last name (STU_LNAME) would not be a good primary key because several students have the last name of Smith. Even the combination of the last name and first name (STU_FNAME) would not be an appropriate primary key because more than one student is named John Smith.\\n3-2 Keys\\nIn the relational model, keys are important because they are used to ensure that each row in a table is uniquely identifiable. They are also used to establish relationships among tables and to ensure the integrity of the data. A key  consists of one or more attributes that \\ndetermine other attributes. For example, an invoice number identifies all of the invoice attributes, such as the invoice date and the customer name.\\nOne type of key, the primary key, has already been introduced. Given the structure of \\nthe STUDENT table shown in Figure 3.1, defining and describing the primary key seem simple enough. However, because the primary key plays such an important role in the relational environment, you will examine the primary key’s properties more carefully. In this section, you also will become acquainted with superkeys, candidate keys, and secondary keys.\\n3-2a  Dependencies\\nThe role of a key is based on the concept of determination. Determination is the state in which knowing the value of one attribute makes it possible to determine the value of another. The idea of determination is not unique to the database environment. Y ou are familiar with the formula revenue − cost = profit. This is a form of determination, because if you are given the revenue  and the cost , you can determine the profit . Given \\nprofit  and revenue , you can determine the cost . Given any two values, you can determine \\nthe third. Determination in a database environment, however, is not normally based on a formula but on the relationships among the attributes.\\nIf you consider what the attributes of the STUDENT table in Figure 3.1 actually \\nrepresent, you will see a relationship among the attributes. If you are given a value for STU_NUM, then you can determine the value for STU_LNAME because one and only one value of STU_LNAME is associated with any given value of STU_NUM. A specific terminology and notation is used to describe relationships based on determination. The relationship is called functional dependence, which means that the value of one or more attributes determines the value of one or more other attributes. The standard notation for representing the relationship between STU_NUM and STU_LNAME is as follows:\\nSTU_NUM → STU_LNAMEIn this functional dependency, the attribute whose value determines another is called the \\ndeterminant or the key. The attribute whose value is determined by the other attribute is called the dependent. Using this terminology, it would be correct to say that STU_NUM is the determinant and STU_LNAME is the dependent. STU_NUM functionally determines STU_LNAME, and STU_LNAME is functionally dependent on STU_NUM. As stated earlier, functional dependence can involve a determinant that comprises more than one attribute and multiple dependent attributes. Refer to the STUDENT table for the following example:primary key (PK)\\nIn the relational model, an identifier composed of one or more attributes that uniquely identifies a row. Also, a candidate key selected as a unique entity identifier. See also key .\\nkey\\nOne or more attributes that determine other attributes. See also superkey, candidate key, primary key (PK), \\nsecondary key, and foreign key.\\ndetermination\\nThe role of a key. In the context of a database table, the statement “A determines B” indicates that knowing the value of attribute A means that the value of attribute B can be looked up.\\nfunctional dependence\\nWithin a relation R, an attribute B is functionally dependent on an attribute A if and only if a given value of attribute A determines exactly one value of attribute B. The relationship “B is dependent on A” is equivalent to “A determines B,” and is written as A → B.\\ndeterminant\\nAny attribute in a specific row whose value directly determines other values in that row. See also Boyce-Codd normal form (BCNF).\\ndependent\\nAn attribute whose value is determined by another attribute.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='099c7570-eff3-42ae-b2bf-6d3eb93f373d', embedding=None, metadata={'page_label': '77', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    77\\nSTU_NUM → (STU_LNAME, STU_FNAME, STU_GPA)\\nand\\n(STU_FNAME, STU_LNAME, STU_INIT, STU_PHONE) → (STU_DOB, STU_HRS, \\nSTU_GPA)\\nDeterminants made of more than one attribute require special consideration. It is \\npossible to have a functional dependency in which the determinant contains attri-butes that are not necessary for the relationship. Consider the following two functional  \\ndependencies:\\nSTU_NUM → STU_GPA(STU_NUM, STU_LNAME) → STU_GPAIn the second functional dependency, the determinant includes STU_LNAME, but this \\nattribute is not necessary for the relationship. The functional dependency is valid because given a pair of values for STU_NUM and STU_LNAME, only one value would occur for STU_GPA. A more specific term, full functional dependence, is used to refer to func-tional dependencies in which the entire collection of attributes in the determinant is nec-essary for the relationship. Therefore, the dependency shown in the preceding example is a functional dependency, but not a full functional dependency.\\n3-2b  Types of Keys\\nRecall that a key is an attribute or group of attributes that can determine the values of other attributes. Therefore, keys are determinants in functional dependencies. Several different types of keys are used in the relational model, and you need to be familiar with them.\\nA composite key is a key that is composed of more than one attribute. An attribute \\nthat is a part of a key is called a key attribute. For example,\\nSTU_NUM → STU_GPA\\n(STU_LNAME, STU_FNAME, STU_INIT, STU_PHONE) → STU_HRS\\nIn the first functional dependency, STU_NUM is an example of a key composed of only \\none key attribute. In the second functional dependency, (STU_LNAME, STU_FNAME, STU_INIT, STU_PHONE) is a composite key composed of four key attributes.\\nA superkey is a key that can uniquely identify any row in the table. In other words, \\na superkey functionally determines every attribute in the row. In the STUDENT table, STU_NUM is a superkey, as are the composite keys (STU_NUM, STU_LNAME), (STU_NUM, STU_LNAME, STU_INIT), and (STU_LNAME, STU_FNAME, STU_INIT, STU_PHONE). In fact, because STU_NUM alone is a superkey, any composite key that has STU_NUM as a key attribute will also be a superkey. Be careful, however, because not all keys are superkeys. For example, Gigantic State University determines its student classification based on hours completed, as shown in Table 3.2.\\nTherefore, you can write STU_HRS → STU_CLASS.However, the specific number of hours is not dependent on the classification. It is quite \\npossible to find a junior with 62 completed hours or one with 84 completed hours. In other words, the classification (STU_CLASS) does not determine one and only one value for completed hours (STU_HRS).full functional dependence\\nA condition in which an attribute is functionally dependent on a composite key but not on any subset of the key.\\ncomposite key\\nA multiple-attribute key.\\nkey attributes\\nThe attributes that form a primary key. See also prime attribute.\\nsuperkey\\nAn attribute or attributes that uniquely identify each entity in a table. See key .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58fa68f3-6f93-4de7-a25c-840a2b42a704', embedding=None, metadata={'page_label': '78', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='78   Part 2    Design Concepts\\nOne specific type of superkey is called a candidate key. A candidate key is a minimal \\nsuperkey—that is, a superkey without any unnecessary attributes. A candidate key is \\nbased on a full functional dependency. For example, STU_NUM would be a candidate key, as would (STU_LNAME, STU_FNAME, STU_INIT, STU_PHONE). On the other hand, (STU_NUM, STU_LNAME) is a superkey, but it is not a candidate key because STU_LNAME could be removed and the key would still be a superkey. A table can have many different candidate keys. If the STUDENT table also included the students’ Social Security numbers as STU_SSN, then it would appear to be a candidate key. Candidate keys are called candidates  because they are the eligible options from which the designer \\nwill choose when selecting the primary key. The primary key is the candidate key chosen to be the primary means by which the rows of the table are uniquely identified.\\nEntity integrity is the condition in which each row (entity instance) in the table has \\nits own unique identity. To ensure entity integrity, the primary key has two requirements: (1) all of the values in the primary key must be unique, and (2) no key attribute in the primary key can contain a null.\\nNull values are problematic in the relational model. A null is the absence of any \\ndata value, and it is never allowed in any part of the primary key. From a theoretical perspective, it can be argued that a table that contains a null is not properly a relational table at all. From a practical perspective, however, some nulls cannot be reasonably avoided. For example, not all students have a middle initial. As a general rule, nulls should be avoided as much as reasonably possible. In fact, an abundance of nulls is often a sign of a poor design. Also, nulls should be avoided in the database because their meaning is not always identifiable. For example, a null could represent any of the following:\\n•\\n An unknown attribute value\\n• A known, but missing, attribute value\\n• A “not applicable” condition\\nDepending on the sophistication of the application development software, nulls can \\ncreate problems when functions such as COUNT, AVERAGE, and SUM are used. In \\naddition, nulls can create logical problems when relational tables are linked.\\nIn addition to its role in providing a unique identity to each row in the table, the \\nprimary key may play an additional role in the controlled redundancy that allows the TABLE 3.2\\nSTUDENT CLASSIFICATION\\nHOURS COMPLETED CLASSIFICATION\\nLess than 30 Fr\\n30–59 So\\n60–89 Jr\\n90 or more Sr\\nA null is no value at all. It does not mean a zero or a space. A null is created when you press \\nthe Enter key or the Tab key to move to the next entry without making an entry of any kind. Pressing the Spacebar creates a blank (or a space).Note\\ncandidate key\\nA minimal superkey; that is, a key that does not contain a subset of attributes that is itself a superkey. See key .\\nentity integrity\\nThe property of a relational table that guarantees each entity has a unique value in a primary key and that the key has no null values.\\nnull\\nThe absence of an attribute value. Note that a null is not a blank.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4920f56-8b08-4208-b88a-a517c482f35e', embedding=None, metadata={'page_label': '79', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    79\\nrelational model to work. Recall from Chapter 2 that a hallmark of the relational model \\nis that relationships between tables are implemented through common attributes as a \\nform of controlled redundancy. For example, Figure 3.2 shows PRODUCT and VEN -\\nDOR tables that are linked through a common attribute, VEND_CODE. VEND_CODE \\nis referred to as a foreign key in the PRODUCT table. A foreign key (FK)  is the primary \\nkey of one table that has been placed into another table to create a common attribute. In \\nFigure 3.2, the primary key of VENDOR, VEND_CODE, was placed in the PRODUCT \\ntable; therefore, VEND_CODE is a foreign key in PRODUCT. One advantage of using a \\nproper naming convention for table attributes is that you can identify foreign keys more \\neasily. For example, because the STUDENT table in Figure 3.1 used a proper naming \\nconvention, you can identify two foreign keys in the table (DEPT_CODE and PROF_\\nNUM) that imply the existence of two other tables in the database (DEPARTMENT and \\nPROFESSOR) related to STUDENT.\\nFIGURE 3.2  AN EXAMPLE OF A SIMPLE RELATIONAL DATABASE  \\nDatabase name: Ch03_SaleCo\\nTable name: VENDOR\\nPrimar y key: VEND_CODE\\nForeign key: noneTable name: PRODUCT\\nPrimar y key: PROD_CODE\\nForeign key: VEND_CODE\\nlink\\nJust as the primary key has a role in ensuring the integrity of the database, so does \\nthe foreign key. Foreign keys are used to ensure referential integrity , the condition in \\nwhich every reference to an entity instance by another entity instance is valid. In other \\nwords, every foreign key entry must either be null or a valid value in the primary key of \\nthe related table. Note that the PRODUCT table has referential integrity because every \\nentry in VEND_CODE in the PRODUCT table is either null or a valid value in VEND_\\nCODE in the VENDOR table. Every vendor referred to by a row in the PRODUCT table \\nis a valid vendor.\\nFinally, a secondary key  is defined as a key that is used strictly for data retrieval \\npurposes. Suppose that customer data is stored in a CUSTOMER table in which \\nthe customer number is the primary key. Do you think that most customers will \\nremember their numbers? Data retrieval for a customer is easier when the cus -\\ntomer’s last name and phone number are used. In that case, the primary key is \\nthe customer number; the secondary key is the combination of the customer’s last \\nname and phone number. Keep in mind that a secondary key does not necessarily \\nyield a unique outcome. For example, a customer’s last name and home telephone \\nnumber could easily yield several matches in which one family lives together and \\nshares a phone line. A less efficient secondary key would be the combination of the \\nlast name and zip code; this could yield dozens of matches, which could then be \\ncombed for a specific match.foreign key (FK)\\nAn attribute or attributes \\nin one table whose \\nvalues must match the \\nprimary key in another \\ntable or whose values \\nmust be null. See key.\\nreferential integrity\\nA condition by which \\na dependent table’s \\nforeign key must have \\neither a null entry or a \\nmatching entry in the \\nrelated table. \\nsecondary key\\nA key used strictly for \\ndata retrieval purposes. \\nFor example, customers \\nare not likely to know \\ntheir customer number \\n(primary key), but the \\ncombination of last \\nname, first name, middle \\ninitial, and telephone \\nnumber will probably \\nmatch the appropriate \\ntable row. See also key.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3f2425fd-9b0e-416e-8eb0-18437146e0e8', embedding=None, metadata={'page_label': '80', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='80   Part 2    Design Concepts\\nA secondary key’s effectiveness in narrowing down a search depends on how restric-\\ntive the key is. For instance, although the secondary key CUS_CITY is legitimate from a \\ndatabase point of view, the attribute values New York  or Sydney  are not likely to produce \\na usable return unless you want to examine millions of possible matches. (Of course, CUS_CITY is a better secondary key than CUS_COUNTRY .)\\nTable 3.3 summarizes the various relational database table keys.\\n3-3 Integrity Rules\\nRelational database integrity rules are very important to good database design. RDBMSs enforce integrity rules automatically, but it is much safer to make sure your application design conforms to the entity and referential integrity rules mentioned in this chapter. Those rules are summarized in Table 3.4.TABLE 3.3\\nRELATIONAL DATABASE KEYS\\nKEY TYPE DEFINITION\\nSuperkey An attribute or combination of attributes that uniquely identifies each row in a table\\nCandidate key A minimal (irreducible) superkey; a superkey that does not contain a subset of attributes that is \\nitself a superkey\\nPrimary key A candidate key selected to uniquely identify all other attribute values in any given row; cannot contain null entries\\nForeign key An attribute or combination of attributes in one table whose values must either match the primary key in another table or be null\\nSecondary key An attribute or combination of attributes used strictly for data retrieval purposes\\nTABLE 3.4\\nINTEGRITY RULES\\nENTITY INTEGRITY DESCRIPTION\\nRequirement All primary key entries are unique, and no part of a primary key may be null.\\nPurpose Each row will have a unique identity, and foreign key values can properly reference primary key values.\\nExample No invoice can have a duplicate number, nor can it be null; in short, all invoices are uniquely identified by their invoice number.\\nREFERENTIAL INTEGRITY DESCRIPTION\\nRequirement A foreign key may have either a null entry, as long as it is not a part of its table’s primary key, or an entry that matches the primary key value in a table to which it is related; (every non-null foreign key value must reference an existing primary key value).\\nPurpose It is possible for an attribute not to have a corresponding value, but it will be impossible to have an invalid entry; the enforcement of the referential integrity rule makes it impossible to delete a row in one table whose primary key has mandatory matching foreign key values in another table.\\nExample A customer might not yet have an assigned sales representative (number), but it will be impossible to have an invalid sales representative (number).\\nThe integrity rules summarized in Table 3.4 are illustrated in Figure 3.3.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f04981fc-9b9c-4461-8179-d26d81286569', embedding=None, metadata={'page_label': '81', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    81\\nNote the following features of Figure 3.3.\\n• Entity integrity . The CUSTOMER table’s primary key is CUS_CODE. The CUS -\\nTOMER primary key column has no null entries, and all entries are unique. Similarly, \\nthe AGENT table’s primary key is AGENT_CODE, and this primary key column is \\nalso free of null entries.\\n• Referential integrity . The CUSTOMER table contains a foreign key, AGENT_CODE, \\nthat links entries in the CUSTOMER table to the AGENT table. The CUS_CODE row \\nidentified by the (primary key) number 10013 contains a null entry in its AGENT_\\nCODE foreign key because Paul F. Olowski does not yet have a sales representative \\nassigned to him. The remaining AGENT_CODE entries in the CUSTOMER table all \\nmatch the AGENT_CODE entries in the AGENT table.\\nTo avoid nulls, some designers use special codes, known as flags , to indicate the \\nabsence of some value. Using Figure 3.3 as an example, the code –99 could be used as the \\nAGENT_CODE entry in the fourth row of the CUSTOMER table to indicate that cus -\\ntomer Paul Olowski does not yet have an agent assigned to him. If such a flag is used, the \\nAGENT table must contain a dummy row with an AGENT_CODE value of −99. Thus, \\nthe AGENT table’s first record might contain the values shown in Table 3.5.\\nTABLE 3.5\\nA DUMMY VARIABLE VALUE USED AS A FLAG\\nAGENT_CODE AGENT_AREACODE AGENT_PHONE AGENT_LNAME AGENT_YTD_SLS\\n−99 000 000–0000 None $0.00FIGURE 3.3  AN ILLUSTRATION OF INTEGRITY RULES  \\nDatabase name: Ch03_InsureCo\\nTable name: AGENT (only ﬁve selected ﬁelds are shown)\\nPrimar y key: AGENT_CODE\\nForeign key: noneTable name: CUSTOMER\\nPrimar y key: CUS_CODE\\nForeign key: AGENT_CODE\\nChapter 4, Entity Relationship (ER) Modeling, discusses several ways to handle nulls.\\nOther integrity rules that can be enforced in the relational model are the NOT \\nNULL and UNIQUE constraints. The NOT NULL constraint can be placed on a col -\\numn to ensure that every row in the table has a value for that column. The UNIQUE \\nconstraint is a restriction placed on a column to ensure that no duplicate values exist \\nfor that column.flags\\nSpecial codes \\nimplemented by \\ndesigners to trigger a \\nrequired response, alert \\nend users to specified \\nconditions, or encode \\nvalues. Flags may be \\nused to prevent nulls by \\nbringing attention to the \\nabsence of a value in a \\ntable.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6c29a12a-156e-4ff0-9bc4-49126c49f3f9', embedding=None, metadata={'page_label': '82', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='82   Part 2    Design Concepts\\n3-4 Relational Algebra\\nThe data in relational tables is of limited value unless the data can be manipulated to gen-\\nerate useful information. This section describes the basic data manipulation capabilities of the relational model. Relational algebra defines the theoretical way of manipulating table contents using relational operators. In Chapter 7, Introduction to Structured Query Language (SQL), and Chapter 8, Advanced SQL, you will learn how SQL commands can be used to accomplish relational algebra operations.\\n3-4a  Formal Definitions and Terminology\\nRecall that the relational model is actually based on mathematical principles, and manip-ulating the data in the database can be described in mathematical terms. The good news is that, as database professionals, we do not have to write mathematical formulas to work with our data. Data is manipulated by database developers and programmers using  \\npowerful languages like SQL that hide the underlying math. However, understanding the underlying principles can give you a good feeling for the types of operations that can be performed, and it can help you to understand how to write your queries more efficiently and effectively.\\nOne advantage of using formal mathematical representations of operations is that \\nmathematical statements are unambiguous. These statements are very specific, and they require that database designers be specific in the language used to explain them. As previously explained, it is common to use the terms relation and table  interchangeably. \\nHowever, since the mathematical terms need to be precise, we will use the more specific term relation when discussing the formal definitions of the various relational algebra operators.\\nBefore considering the specific relational algebra operators, it is necessary to formal-\\nize our understanding of a table.\\nOne important aspect of using the specific term relation  is that it acknowledges the \\ndistinction between the relation and the relation variable, or relvar , for short. A relation \\nis the data that we see in our tables. A relvar is a variable that holds a relation. For exam-ple, imagine you were writing a program and created a variable named qty for holding integer data. The variable qty is not an integer itself; it is a container for holding integers. Similarly, when you create a table, the table structure holds the table data. The structure is properly called a relvar, and the data in the structure would be a relation. The relvar is a container (variable) for holding relation data, not the relation itself. The data in the table is a relation.\\nA relvar has two parts: the heading and the body. The relvar heading contains the \\nnames of the attributes, while the relvar body contains the relation. To conveniently maintain this distinction in formulas, an unspecified relation is often assigned a lower -\\ncase letter (e.g., “r”), while the relvar is assigned an uppercase letter (e.g., “R”). We could then say that r is a relation of type R, or r(R).\\nThe degree of relational completeness can be defined by the extent to which relational algebra is supported. To be considered minimally relational, the DBMS must support the key relational operators SELECT, PROJECT, and JOIN.Note\\nrelational algebra\\nA set of mathematical principles that form the basis for manipulating relational table contents; the eight main functions are SELECT, PROJECT, JOIN, INTERSECT, UNION, DIFFERENCE, PRODUCT, and DIVIDE.\\nrelvar\\nShort for relation variable, a variable that holds a relation. A relvar is a container (variable) for holding relation data, not the relation itself.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b9ffbb1f-ccd6-4be4-801d-156cb64b3aef', embedding=None, metadata={'page_label': '83', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    83\\n3-4b  Relational Set Operators\\nThe relational operators have the property of closure ; that is, the use of relational alge -\\nbra operators on existing relations (tables) produces new relations. Numerous operators \\nhave been defined. Some operators are fundamental, while others are convenient but \\ncan be derived using the fundamental operators. In this section, the focus will be on the \\nSELECT (or RESTRICT), PROJECT, UNION, INTERSECT, DIFFERENCE, PRODUCT, \\nJOIN, and DIVIDE operators.\\nSelect (Restrict)  SELECT , also known as RESTRICT , is referred to as a unary oper -\\nator because it only uses one table as input. It yields values for all rows found in the \\ntable that satisfy a given condition. SELECT can be used to list all of the rows, or it \\ncan yield only rows that match a specified criterion. In other words, SELECT yields \\na horizontal subset of a table. SELECT will not limit the attributes returned so all \\nattributes of the table will be included in the result. The effect of a SELECT operation \\nis shown in Figure 3.4.\\nFIGURE 3.4  SELECT  \\nOriginal table\\n New table\\nSELECT ALL yields\\nSELECT only PRICE less than $2.00 yields\\nSELECT only P_CODE = 311452 yields\\nFormally, SELECT is denoted by the lowercase Greek letter sigma (σ). Sigma is followed by \\nthe condition to be evaluated (called a predicate) as a subscript, and then the relation is \\nlisted in parentheses. For example, to SELECT all of the rows in the CUSTOMER table that \\nhave the value ‘10010’ in the CUS_CODE attribute, you would write the following:\\nσcus_code = 10010 (customer)Note\\nProject  PROJECT  yields all values for selected attributes. It is also a unary operator, \\naccepting only one table as input. PROJECT will return only the attributes requested, \\nin the order in which they are requested. In other words, PROJECT yields a vertical \\nsubset of a table. PROJECT will not limit the rows returned so all rows of the specified \\nattributes will be included in the result. The effect of a PROJECT operation is shown \\nin Figure 3.5.closure\\nA property of relational \\noperators that permits \\nthe use of relational \\nalgebra operators on \\nexisting tables (relations) \\nto produce new relations.\\nSELECT\\nIn relational algebra, an \\noperator used to select \\na subset of rows. Also \\nknown as RESTRICT .\\nRESTRICT \\nSee SELECT .\\nPROJECT\\nIn relational algebra, an \\noperator used to select a \\nsubset of columns.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='56eae5dc-741a-43f5-96fe-1bd051f7217b', embedding=None, metadata={'page_label': '84', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='84   Part 2     Design Concepts\\nUnion  UNION  combines all rows from two tables, excluding duplicate rows. To be used in the \\nUNION, the tables must have the same attribute characteristics; in other words, the columns \\nand domains must be compatible. When two or more tables share the same number of col -\\numns, and when their corresponding columns share the same or compatible domains, they are \\nsaid to be union-compatible . The effect of a UNION operation is shown in Figure 3.6.FIGURE 3.5  PROJECT  \\nOriginal table\\n New table\\nPROJECT PRICE yields\\nPROJECT P_DESCRIPT and PRICE yields\\nPROJECT P_CODE and PRICE yields\\nFormally, PROJECT is denoted by the Greek letter pi (π). Some sources use the uppercase \\nletter, and other sources use the lowercase letter. Codd used the lowercase π in his origi -\\nnal article on the relational model, and that is what we use here. Pi is followed by the list \\nof attributes to be returned as subscripts, and then the relation listed in parentheses. For \\nexample, to PROJECT the CUS_FNAME and CUS_LNAME attributes in the CUSTOMER \\ntable, you would write the following:\\nπcus_fname, cus_lname (customer)\\nSince relational operators have the property of closure, that is, they accept relations as \\ninput and produce relations as output, it is possible to combine operators. For example, \\nyou can combine the two previous operators to find the customer first and last name of \\nthe customer with customer code 10010:\\nπcus_fname, cus_lname (σcus_code = 10010 (customer))Note\\nFIGURE 3.6  UNION  \\nUNION yields\\nUNION\\nIn relational algebra, an \\noperator used to merge \\n(append) two tables into \\na new table, dropping \\nthe duplicate rows. The \\ntables must be union-\\ncompatible .\\nunion-compatible\\nTwo or more tables that \\nhave the same number \\nof columns and the \\ncorresponding columns \\nhave compatible domains.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='77ad4dd9-597a-492f-ae6c-7b7b1bb3aa19', embedding=None, metadata={'page_label': '85', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    85\\nIntersect  INTERSECT  yields only the rows that appear in both tables. As with UNION, \\nthe tables must be union-compatible to yield valid results. For example, you cannot use \\nINTERSECT if one of the attributes is numeric and one is character-based. For the rows \\nto be considered the same in both tables and appear in the result of the INTERSECT, the \\nentire rows must be exact duplicates. The effect of an INTERSECT operation is shown \\nin Figure 3.7.\\nUNION is denoted by the symbol ∪. If the relations SUPPLIER and VENDOR are union-  \\ncompatible, then a UNION between them would be denoted as follows:\\nsupplier ∪ vendor\\nIt is rather unusual to find two relations that are union-compatible in a database. Typically, \\nPROJECT operators are applied to relations to produce results that are union-compatible. For \\nexample, assume the SUPPLIER and VENDOR tables are not union-compatible. If you wish to \\nproduce a listing of all vendor and supplier names, then you can PROJECT the names from \\neach table and then perform a UNION with them.\\nπsupplier_name (supplier) ∪ πvendor_name (vendor)Note\\nFIGURE 3.7  INTERSECT  \\nINTERSECT yields\\nINTERSECT is denoted by the symbol ∩. If the relations SUPPLIER and VENDOR are \\nunion-compatible, then an INTERSECT between them would be denoted as follows:\\nsupplier ∩ vendor\\nJust as with the UNION operator, it is unusual to find two relations that are union-  \\ncompatible in a database, so PROJECT operators are applied to relations to produce \\nresults that can be manipulated with an INTERSECT operator. For example, again assume \\nthe SUPPLIER and VENDOR tables are not union-compatible. If you wish to produce a \\nlisting of any vendor and supplier names that are the same in both tables, then you can \\nPROJECT the names from each table and then perform an INTERSECT with them.\\nπsupplier_name (supplier) ∩ πvendor_name (vendor)Note\\nDifference  DIFFERENCE  yields all rows in one table that are not found in the \\nother table; that is, it subtracts one table from the other. As with UNION, the \\ntables must be union-compatible to yield valid results. The effect of a DIFFER -\\nENCE operation is shown in Figure 3.8. However, note that subtracting the first \\ntable from the second table is not the same as subtracting the second table from \\nthe first table.INTERSECT\\nIn relational algebra, an \\noperator used to yield \\nonly the rows that are \\ncommon to two union-\\ncompatible tables.\\nDIFFERENCE\\nIn relational algebra, an \\noperator used to yield all \\nrows from one table that \\nare not found in another \\nunion-compatible table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='212d2631-ca01-4611-8acb-174d332ed0d5', embedding=None, metadata={'page_label': '86', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='86   Part 2     Design Concepts\\nProduct  PRODUCT  yields all possible pairs of rows from two tables—also known as \\nthe Cartesian product. Therefore, if one table has 6 rows and the other table has 3 rows, \\nthe PRODUCT yields a list composed of 6 × 3 = 18rows. The effect of a PRODUCT \\noperation is shown in Figure 3.9.FIGURE 3.8  DIFFERENCE\\nDIFFERENCE yields\\nDIFFERENCE is denoted by the minus symbol −. If the relations SUPPLIER and VENDOR are \\nunion-compatible, then an DIFFERENCE of SUPPLIER minus VENDOR would be written as \\nfollows:\\nsupplier − vendor\\nAssuming the SUPPLIER and VENDOR tables are not union-compatible, producing a list of \\nany supplier names that do not appear as vendor names, then you can use a DIFFERENCE \\noperator.\\nπsupplier_name (supplier) − πvendor_name (vendor)Note\\nPRODUCT is denoted by the multiplication symbol ×. The PRODUCT of the CUSTOMER \\nand AGENT relations would be written as follows:\\ncustomer × agent\\nA Cartesian product produces a set of sequences in which every member of one set is \\npaired with every member of another set. In terms of relations, this means that every \\ntuple in one relation is paired with every tuple in the second relation.NoteFIGURE 3.9  PRODUCT\\nPRODUCT yields\\nPRODUCT\\nIn relational algebra, an \\noperator used to yield all \\npossible pairs of rows from \\ntwo tables. Also known as \\nthe Cartesian product.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a86dc19b-f8fa-4bbd-a755-ab25badc91b6', embedding=None, metadata={'page_label': '87', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    87\\nJoin  JOIN  allows information to be intelligently combined from two or more tables. \\nJOIN is the real power behind the relational database, allowing the use of independent \\ntables linked by common attributes. The CUSTOMER and AGENT tables shown in \\nFigure 3.10 will be used to illustrate several types of joins.\\nFIGURE 3.10  TWO TABLES THAT WILL BE USED IN JOIN ILLUSTRATIONS\\nTable name: CUSTOMER\\n Table name: AGENT\\nA natural join  links tables by selecting only the rows with common values in their com -\\nmon attribute(s). A natural join is the result of a three-stage process:\\n1. First, a PRODUCT of the tables is created, yielding the results shown in  \\nFigure 3.11.\\nJOIN\\nIn relational algebra, a \\ntype of operator used \\nto yield rows from two \\ntables based on criteria. \\nThere are many types \\nof joins, such as natural \\njoin, theta join, equijoin, \\nand outer join.\\nnatural join\\nA relational operation \\nthat yields a new table \\ncomposed of only the \\nrows with common \\nvalues in their common \\nattribute(s).\\njoin columns\\nColumns that are used \\nin the criteria of join \\noperations. The join \\ncolumns generally share \\nsimilar values.FIGURE 3.11  NATURAL JOIN, STEP 1: PRODUCT\\n2. Second, a SELECT is performed on the output of Step 1 to yield only the \\nrows for which the AGENT_CODE values are equal. The common col -\\numns are referred to as the join columns . Step 2 yields the results shown in  \\nFigure 3.12.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ea69924-ed19-4d99-8ae1-7b788d431287', embedding=None, metadata={'page_label': '88', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='88   Part 2     Design Concepts\\n3. A PROJECT is performed on the results of Step 2 to yield a single copy of each \\nattribute, thereby eliminating duplicate columns. Step 3 yields the output shown \\nin Figure 3.13.FIGURE 3.12  NATURAL JOIN, STEP 2: SELECT\\nFIGURE 3.13  NATURAL JOIN, STEP 3: PROJECT\\nThe final outcome of a natural join yields a table that does not include unmatched \\npairs and provides only the copies of the matches.\\nNote a few crucial features of the natural join operation:\\n• If no match is made between the table rows, the new table does not include the \\nunmatched row. In that case, neither AGENT_CODE 421 nor the customer whose \\nlast name is Smithson is included. Smithson’s AGENT_CODE 421 does not match \\nany entry in the AGENT table.\\n• The column on which the join was made—that is, AGENT_CODE—occurs only once \\nin the new table.\\n• If the same AGENT_CODE were to occur several times in the AGENT table, a \\ncustomer would be listed for each match. For example, if the AGENT_CODE 167 \\noccurred three times in the AGENT table, the customer named Rakowski would also \\noccur three times in the resulting table because Rakowski is associated with AGENT_\\nCODE 167. (Of course, a good AGENT table cannot yield such a result because it \\nwould contain unique primary key values.)\\nNatural join is normally just referred to as JOIN in formal treatments. JOIN is denoted by the \\nsymbol ⨝. The JOIN of the CUSTOMER and AGENT relations would be written as follows:\\ncustomer ⨝ agent\\nNotice that the JOIN of two relations returns all of the attributes of both relations, except \\nonly one copy of the common attribute is returned. Formally, this is described as a UNION \\nof the relvar headings. Therefore, the JOIN of the relations (c ⨝ a) includes the UNION of \\nthe relvars (C ∪ A). Also note that, as described above, JOIN is not a fundamental relational \\nalgebra operator. It can be derived from other operators as follows:\\n πcus_code, cus_lname, cus_fname, cus_initial, cus_renew_date, agent_code, agent_areacode, agent_phone, agent_lname, agent_ytd_sls  \\n(σcustomer.agent_code = agent.agent_code (customer × agent))Noteequijoin\\nA join operator that \\nlinks tables based on \\nan equality condition \\nthat compares specified \\ncolumns of the tables.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='40efb194-f602-4be3-bbd3-30f1807480c3', embedding=None, metadata={'page_label': '89', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    89\\nAnother form of join, known as an equijoin , links tables on the basis of an equality con -\\ndition that compares specified columns of each table. The outcome of the equijoin does \\nnot eliminate duplicate columns, and the condition or criterion used to join the tables \\nmust be explicitly defined. In fact, the result of an equijoin looks just like the outcome \\nshown in Figure 3.12 for Step 2 of a natural join. The equijoin takes its name from the \\nequality comparison operator (=) used in the condition. If any other comparison opera-\\ntor is used, the join is called a theta join .\\nFIGURE 3.14  LEFT OUTER JOIN\\nFIGURE 3.15  RIGHT OUTER JOIN\\nIn formal terms, theta join is considered an extension of natural join. Theta join is denoted \\nby adding a theta subscript after the JOIN symbol: ⨝θ. Equijoin is then a special type of \\ntheta join.Note\\nEach of the preceding joins is often classified as an inner join. An inner join  only \\nreturns matched records from the tables that are being joined. In an outer join , the \\nmatched pairs would be retained, and any unmatched values in the other table would be \\nleft null. It is an easy mistake to think that an outer join is the opposite of an inner join. \\nHowever, it is more accurate to think of an outer join as an “inner join plus. ” The outer \\njoin still returns all of the matched records that the inner join returns, plus it returns the \\nunmatched records from one of the tables. More specifically, if an outer join is produced \\nfor tables CUSTOMER and AGENT, two scenarios are possible:\\n•  A left outer join  yields all of the rows in the CUSTOMER table, including those that \\ndo not have a matching value in the AGENT table. An example of such a join is shown \\nin Figure 3.14.\\n• A right outer join  yields all of the rows in the AGENT table, including those that \\ndo not have matching values in the CUSTOMER table. An example of such a join is \\nshown in Figure 3.15.\\nOuter joins are especially useful when you are trying to determine what values in \\nrelated tables cause referential integrity problems. Such problems are created when foreign \\nkey values do not match the primary key values in the related table(s). In fact, if you are \\nasked to convert large spreadsheets or other “nondatabase” data into relational database theta join\\nA join operator that \\nlinks tables using an \\ninequality comparison \\noperator (<, >, <=, >=) in \\nthe join condition.\\ninner join\\nA join operation in \\nwhich only rows that \\nmeet a given criterion \\nare selected. The join \\ncriterion can be an \\nequality condition \\n(natural join or equijoin) \\nor an inequality \\ncondition (theta join). \\nThe inner join is the \\nmost commonly used \\ntype of join. Contrast \\nwith outer join .\\nouter join\\nA relational algebra join \\noperation that produces \\na table in which all \\nunmatched pairs are \\nretained; unmatched \\nvalues in the related \\ntable are left null. \\nContrast with inner join . \\nSee also left outer join  \\nand right outer join .\\nleft outer join\\nIn a pair of tables to be \\njoined, a join that yields \\nall the rows in the left \\ntable, including those \\nthat have no matching \\nvalues in the other table. \\nFor example, a left outer \\njoin of CUSTOMER with \\nAGENT will yield all of \\nthe CUSTOMER rows, \\nincluding the ones that \\ndo not have a matching \\nAGENT row. See also outer \\njoin and right outer join .\\nright outer join\\nIn a pair of tables to be \\njoined, a join that yields \\nall of the rows in the right \\ntable, including the ones \\nwith no matching values \\nin the other table. For \\nexample, a right outer \\njoin of CUSTOMER with \\nAGENT will yield all of the \\nAGENT rows, including \\nthe ones that do not have \\na matching CUSTOMER \\nrow. See also left outer join  \\nand outer join .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e874e39-9c7e-4450-b953-c8cdc1b75837', embedding=None, metadata={'page_label': '90', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='90   Part 2     Design Concepts\\ntables, you will discover that the outer joins save you vast amounts of time and uncounted  \\nheadaches when you encounter referential integrity errors after the conversions.\\nY ou may wonder why the outer joins are labeled “left” and “right. ” The labels refer to \\nthe order in which the tables are listed in the SQL command. Chapter 8 explores such \\njoins in more detail.\\nOuter join is also an extension of JOIN. Outer joins are the application of JOIN, DIFFERENCE, \\nUNION, and PRODUCT. A JOIN returns the matched tuples, DIFFERENCE finds the tuples \\nin one table that have values in the common attribute that do not appear in the com -\\nmon attribute of the other relation, these unmatched tuples are combined with NULL val -\\nues through a PRODUCT, and then a UNION combines these results into a single relation. \\nClearly, a defined outer join is a great simplification! Left and right outer joins are denoted \\nby the symbols ⟕ and ⟖, respectively.Note\\nDivide  The DIVIDE  operator is used to answer questions about one set of data being \\nassociated with all values of data in another set of data. The DIVIDE operation uses one \\n2-column table (Table 1) as the dividend and one single-column table (Table 2) as the \\ndivisor. For example, Figure 3.16 shows a list of customers and the products purchased \\nin Table 1 on the left. Table 2 in the center contains a set of products that are of interest to \\nthe users. A DIVIDE operation can be used to determine which customers, if any, pur -\\nchased every product shown in Table 2. In the figure, the dividend contains the P_CODE \\nand CUS_CODE columns. The divisor contains the P_CODE column. The tables must \\nhave a common column—in this case, the P_CODE column. The output of the DIVIDE \\noperation on the right is a single column that contains all values from the second column \\nof the dividend (CUS_CODE) that are associated with every row in the divisor.\\nUsing the example shown in Figure 3.16, note the following:\\nFIGURE 3.16  DIVIDE\\nDIVIDE yields\\n• Table 1 is “divided” by Table 2 to produce Table 3. Tables 1 and 2 both contain the \\nP_CODE column but do not share the CUS_CODE column.\\n• To be included in the resulting Table 3, a value in the unshared column (CUS_CODE) \\nmust be associated with every value in Table 2.\\n• The only customers associated with all of products 123456, 234567, and 567890 are \\ncustomers 10030 and 12550.DIVIDE\\nIn relational algebra, an \\noperator that answers \\nqueries about one set of \\ndata being associated \\nwith all values of data in \\nanother set of data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='24ed3f72-acc3-4558-b558-0667123334ef', embedding=None, metadata={'page_label': '91', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    91\\n3-5 The Data Dictionary and the System Catalog\\nThe data dictionary provides a detailed description of all tables in the database created \\nby the user and designer. Thus, the data dictionary contains at least all of the attribute \\nnames and characteristics for each table in the system. In short, the data dictionary con-tains metadata—data about data. Using the small database presented in Figure 3.3, you might picture its data dictionary as shown in Table 3.6.\\nThe DIVIDE operator is denoted by the division symbol ÷. Given two relations, R and S, the DIVISION of them would be written: r ÷ s.Note\\nThe data dictionary in Table 3.6 is an example of the human view of the entities, attributes, and relationships. The purpose of this data dictionary is to ensure that all members of database design and implementation teams use the same table and attribute names and characteristics. The DBMS’s internally stored data dictionary contains additional informa-tion about relationship types, entity and referential integrity checks and enforcement, and index types and components. This additional information is generated during the data-base implementation stage.Note\\nThe data dictionary is sometimes described as “the database designer’s database” \\nbecause it records the design decisions about tables and their structures.\\nLike the data dictionary, the system catalog contains metadata. The system catalog  \\ncan be described as a detailed system data dictionary that describes all objects within the database, including data about table names, table’s creator and creation date, num-ber of columns in each table, data type corresponding to each column, index filenames, index creators, authorized users, and access privileges. Because the system catalog con-tains all required data dictionary information, the terms system catalog and data dic-tionary  are often used interchangeably. In fact, current relational database software \\ngenerally provides only a system catalog, from which the designer’s data dictionary information may be derived. The system catalog is actually a system-created database whose tables store the user/designer-created database characteristics and contents. Therefore, the system catalog tables can be queried just like any user/designer-created table.\\nIn effect, the system catalog automatically produces database documenta-\\ntion. As new tables are added to the database, that documentation also allows the RDBMS to check for and eliminate homonyms and synonyms. In general terms, homonyms are similar-sounding words with different meanings, such as boar  and \\nbore , or a word with different meanings, such as fair  (which means “just” in some \\ncontexts and “festival” in others). In a database context, the word homonym  indi-\\ncates the use of the same name to label different attributes. For example, you might use C_NAME to label a customer name attribute in a CUSTOMER table and use C_NAME to label a consultant name attribute in a CONSULTANT table. To lessen confusion, you should avoid database homonyms; the data dictionary is very use-ful in this regard.data dictionary\\nA DBMS component that stores metadata—data about data. Thus, the data dictionary contains the data definition as well as their characteristics and relationships. A data dictionary may also include data that are external to the DBMS. Also known as an information resource dictionary. See also active data dictionary, metadata, and passive data dictionary.\\nsystem catalog\\nA detailed system data dictionary that describes all objects in a database.\\nhomonym\\nThe use of the same name to label different attributes. Homonyms generally should be avoided. Some relational software automatically checks for homonyms and either alerts the user to their existence or automatically makes the appropriate adjustments. See also synonym.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='33d5865c-654a-436c-802a-84c4f797394c', embedding=None, metadata={'page_label': '92', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='92   Part 2    Design ConceptsTABLE 3.6\\nA SAMPLE DATA DICTIONARY\\nTABLE NAME ATTRIBUTE NAME CONTENTS TYPE FORMAT RANGE REQUIRED PK OR FK FK \\nREFERENCED TABLE\\nCUSTOMER CUS_CODE Customer account code CHAR(5) 99999 10000–99999 Y PK\\nCUS_LNAME Customer last name VARCHAR(20) Xxxxxxxx Y\\nCUS_FNAME Customer first name VARCHAR(20) Xxxxxxxx Y\\nCUS_INITIAL Customer initial CHAR(1) X\\nCUS_RENEW_DATE Customer insurance \\nrenewal dateDATE dd-mmm-yyyy\\nAGENT_CODE Agent code CHAR(3) 999 FK AGENT\\nAGENT AGENT_CODE Agent code CHAR(3) 999 Y PK\\nAGENT_AREACODE Agent area code CHAR(3) 999 Y\\nAGENT_PHONE Agent telephone \\nnumberCHAR(8) 999–9999 Y\\nAGENT_LNAME Agent last name VARCHAR(20) Xxxxxxxx Y\\nAGENT_YTD_SLS Agent year-to-date sales NUMBER(9,2) 9,999,999.99\\nFK = Foreign key\\nPK = Primary key\\nCHAR = Fixed character length data (1 – 255 characters)VARCHAR = Variable character length data (1 – 2,000 characters)NUMBER = Numeric data. NUMBER (9,2) is used to specify numbers with up to nine digits, including two digits to the right of the decimal place. Some \\nRDBMS permit the use of a MONEY or CURRENCY data type.\\nTelephone area codes are always composed of digits 0−9, but because area codes are not used arithmetically, they are most efficiently \\nstored as character data. Also, the area codes are always composed of three digits. Therefore, the area code data type is defined as CHAR(3). On the other hand, names do not conform to a standard length. Therefore, the customer first names are defined as VARCHAR(20), indicating that up to 20 characters may be used to store the names. Character data are shown as left-aligned.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba98f498-940a-4b5b-bede-1dfed52df087', embedding=None, metadata={'page_label': '93', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    93\\nIn a database context, a synonym  is the opposite of a homonym, and indicates the use \\nof different names to describe the same attribute. For example, car and auto  refer to the \\nsame object. Synonyms must be avoided whenever possible.\\n3-6  Relationships within the Relational \\nDatabase\\nY ou already know that relationships are classified as one-to-one (1:1), one-to-many \\n(1:M), and many-to-many (M:N or M:M). This section explores those relationships fur -\\nther to help you apply them properly when you start developing database designs. This \\nsection focuses on the following points:\\n• The 1:M relationship is the relational modeling ideal. Therefore, this relationship type \\nshould be the norm in any relational database design.\\n• The 1:1 relationship should be rare in any relational database design.\\n• M:N relationships cannot be implemented as such in the relational model. Later in \\nthis section, you will see how any M:N relationship can be changed into two 1:M \\nrelationships.\\n3-6a  The 1:M Relationship\\nThe 1:M relationship is the norm for relational databases. To see how such a relationship \\nis modeled and implemented, consider the PAINTER and PAINTING example shown \\nin Figure 3.17.\\nsynonym\\nThe use of different \\nnames to identify the \\nsame object, such as an \\nentity, an attribute, or a \\nrelationship; synonyms \\nshould generally be \\navoided. See also \\nhomonym .FIGURE 3.17  THE 1:M RELATIONSHIP BETWEEN PAINTER AND PAINTING\\nCompare the data model in Figure 3.17 with its implementation in Figure 3.18.\\nAs you examine the PAINTER and PAINTING table contents in Figure 3.18, note the \\nfollowing features:\\n•  Each painting was created by one and only one painter, but each painter could have \\ncreated many paintings. Note that painter 123 (Georgette P . Ross) has three works \\nstored in the PAINTING table.\\n• There is only one row in the PAINTER table for any given row in the PAINTING \\ntable, but there may be many rows in the PAINTING table for any given row in the \\nPAINTER table.\\nThe one-to-many (1:M) relationship is easily implemented in the relational model by put -\\nting the primary key of the “1” side in the table of the “many” side as a foreign key .Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a0197516-a92e-4bc7-8a4f-a5240057c458', embedding=None, metadata={'page_label': '94', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='94   Part 2     Design Concepts\\nThe 1:M relationship is found in any database environment. Students in a typical \\ncollege or university will discover that each COURSE can generate many CLASSes but \\nthat each CLASS refers to only one COURSE. For example, an Accounting II course \\nmight yield two classes: one offered on Monday, Wednesday, and Friday (MWF) from \\n10:00 a.m. to 10:50 a.m., and one offered on Thursday (Th) from 6:00 p.m. to 8:40 p.m. \\nTherefore, the 1:M relationship between COURSE and CLASS might be described this \\nway:\\n• Each COURSE can have many CLASSes, but each CLASS references only one \\nCOURSE.\\n• There will be only one row in the COURSE table for any given row in the CLASS table, \\nbut there can be many rows in the CLASS table for any given row in the COURSE \\ntable.\\nFigure 3.19 maps the ERM (entity relationship model) for the 1:M relationship \\nbetween COURSE and CLASS.FIGURE 3.18  THE IMPLEMENTED 1:M RELATIONSHIP BETWEEN PAINTER AND PAINTING\\nDatabase name: Ch03_Museum\\nTable name: PAINTING\\nPrimar y key: PAINTING_NUM\\nForeign key: PAINTER_NUMTable name: PAINTER\\nPrimar y key: PAINTER_NUM\\nForeign key: none\\nFIGURE 3.19  THE 1:M RELATIONSHIP BETWEEN COURSE AND CLASS  \\nThe 1:M relationship between COURSE and CLASS is further illustrated in  \\nFigure 3.20.\\nUsing Figure 3.20, take a minute to review some important terminology. Note that \\nCLASS_CODE in the CLASS table uniquely identifies each row. Therefore, CLASS_\\nCODE has been chosen to be the primary key. However, the combination CRS_CODE \\nand CLASS_SECTION will also uniquely identify each row in the class table. In other \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='14e8cb66-8535-4cf1-927f-b8063f928c1b', embedding=None, metadata={'page_label': '95', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    95\\nwords, the composite key  composed of CRS_CODE and CLASS_SECTION is a candidate \\nkey. Any candidate key  must have the not-null and unique constraints enforced. (Y ou will \\nsee how this is done when you learn SQL in Chapter 7.)\\nFor example, note in Figure 3.18 that the PAINTER table’s primary key, PAINTER_\\nNUM, is included in the PAINTING table as a foreign key. Similarly, in Figure 3.20, the \\nCOURSE table’s primary key, CRS_CODE, is included in the CLASS table as a foreign \\nkey.\\n3-6b  The 1:1 Relationship\\nAs the 1:1 label implies, one entity in a 1:1 relationship can be related to only one other \\nentity, and vice versa. For example, one department chair—a professor—can chair only \\none department, and one department can have only one department chair. The entities \\nPROFESSOR and DEPARTMENT thus exhibit a 1:1 relationship. (Y ou might argue that \\nnot all professors chair a department and professors cannot be required  to chair a depart -\\nment. That is, the relationship between the two entities is optional. However, at this stage \\nof the discussion, you should focus your attention on the basic 1:1 relationship. Optional \\nrelationships will be addressed in Chapter 4.) The basic 1:1 relationship is modeled in \\nFigure 3.21, and its implementation is shown in Figure 3.22.FIGURE 3.20  THE IMPLEMENTED 1:M RELATIONSHIP BETWEEN COURSE AND CLASS  \\nDatabase name: Ch03_ TinyCollege\\nTable name: CLASS\\nPrimar y key: CLASS_CODE\\nForeign key: CRS_CODETable name: COURSE\\nPrimar y key: CRS_CODE\\nForeign key: none\\nFIGURE 3.21   THE 1:1 RELATIONSHIP BETWEEN PROFESSOR \\nAND DEPARTMENT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4126183a-78d8-4248-9c75-2b5d3d547db8', embedding=None, metadata={'page_label': '96', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='96   Part 2     Design Concepts\\nAs you examine the tables in Figure 3.22, note several important features:\\n• Each professor is a Tiny College employee. Therefore, the professor identification \\nis through the EMP_NUM. (However, note that not all employees are professors—\\nthere’s another optional relationship.)\\n• The 1:1 “PROFESSOR chairs DEPARTMENT” relationship is implemented by \\nhaving the EMP_NUM foreign key in the DEPARTMENT table. Note that the \\n1:1 relationship is treated as a special case of the 1:M relationship in which the \\n“many” side is restricted to a single occurrence. In this case, DEPARTMENT con -\\ntains the EMP_NUM as a foreign key to indicate that it is the department  that has \\na chair.\\nFIGURE 3.22  THE IMPLEMENTED 1:1 RELATIONSHIP BETWEEN PROFESSOR AND DEPARTMENT  \\nTable name: DEPARTMENT\\nPrimar y key: DEPT_CODE\\nForeign key: EMP_NUMTable name: PROFESSOR\\nPrimar y key: EMP_NUM\\nForeign key: DEPT_CODEDatabase name: Ch03_ TinyCollege\\nThe 1:M DEPARTMENT employs PROFESSOR relationship is implemented through\\nthe placement of the DEPT_CODE foreign key in the PROFESSOR table.\\nThe 1:1 PROFESSOR chairs DE PARTMENT relationshi p\\nis implemented through the placement of the\\nEMP_NUM fo reign key in the DEPARTMENT table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fdca0c33-1937-4068-9f82-33f3b978b091', embedding=None, metadata={'page_label': '97', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    97\\nNote the features of the ERM in Figure 3.23. \\n• Each CLASS can have many STUDENTs, and each STUDENT can take many \\nCLASSes.\\n• There can be many rows in the CLASS table for any given row in the STUDENT table, \\nand there can be many rows in the STUDENT table for any given row in the CLASS \\ntable.\\nTo examine the M:N relationship more closely, imagine a small college with two students, \\neach of whom takes three classes. Table 3.7 shows the enrollment data for the two students.\\nGiven such a data relationship and the sample data in Table 3.7, you could wrongly \\nassume that you could implement this M:N relationship simply by adding a foreign key \\nin the “many” side of the relationship that points to the primary key of the related table, \\nas shown in Figure 3.24.\\nHowever, the M:N relationship should not be implemented as shown in Figure 3.24 \\nfor two good reasons:\\n• The tables create many redundancies. For example, note that the STU_NUM values \\noccur many times in the STUDENT table. In a real-world situation, additional stu -\\ndent attributes such as address, classification, major, and home phone would also \\nbe contained in the STUDENT table, and each of those attribute values would be \\nrepeated in each of the records shown here. Similarly, the CLASS table contains much \\nFIGURE 3.23   THE ERM’S M:N RELATIONSHIP BETWEEN STUDENT \\nAND CLASS  • Also note that the PROFESSOR table contains the DEPT_CODE foreign key to \\nimplement the 1:M “DEPARTMENT employs PROFESSOR” relationship. This is a \\ngood example of how two entities can participate in two (or even more) relationships \\nsimultaneously.\\nThe preceding “PROFESSOR chairs DEPARTMENT” example illustrates a proper 1:1 \\nrelationship. In fact, the use of a 1:1 relationship ensures that two entity sets are not placed \\nin the same table when they should not be . However, the existence of a 1:1 relationship \\nsometimes means that the entity components were not defined properly. It could indicate \\nthat the two entities actually belong in the same table!\\nAlthough 1:1 relationships should be rare, certain conditions absolutely require their \\nuse. In Chapter 5, Advanced Data Modeling, you will explore a concept called a general -\\nization hierarchy, which is a powerful tool for improving database designs under specific \\nconditions to avoid a proliferation of nulls. One characteristic of generalization hierar -\\nchies is that they are implemented as 1:1 relationships.\\n3-6c  The M:N Relationship\\nA many-to-many (M:N) relationship is not supported directly in the relational environ -\\nment. However, M:N relationships can be implemented by creating a new entity in 1:M \\nrelationships with the original entities.\\nTo explore the many-to-many relationship, consider a typical college environment. \\nThe ER model in Figure 3.23 shows this M:N relationship.If you open the Ch03_\\nTinyCollege database \\nat www.cengagebrain.\\ncom , you will see that \\nthe STUDENT and \\nCLASS entities still use \\nPROF_NUM as their \\nforeign key. PROF_\\nNUM and EMP_NUM \\nare labels for the same \\nattribute, which is an \\nexample of the use of \\nsynonyms—that is, \\ndifferent names for the \\nsame attribute. These \\nsynonyms will be elim -\\ninated in future chap -\\nters as the Tiny College \\ndatabase continues to \\nbe improved.Online \\nContent\\nIf you look at the \\nCh03_AviaCo database \\nat www.cengagebrain.\\ncom , you will see the \\nimplementation of the \\n1:1 PILOT to EMPLOYEE \\nrelationship. This rela -\\ntionship is based on a \\ngeneralization hierar -\\nchy, which you will learn \\nabout in Chapter 5.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='37797944-dccf-4e37-81e0-0946a36aba53', embedding=None, metadata={'page_label': '98', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='98   Part 2     Design Concepts\\nduplication: each student taking the class generates a CLASS record. The problem \\nwould be even worse if the CLASS table included such attributes as credit hours and \\ncourse description. Those redundancies lead to the anomalies discussed in Chapter 1.\\n• Given the structure and contents of the two tables, the relational operations become \\nvery complex and are likely to lead to system efficiency errors and output errors.\\nFortunately, the problems inherent in the many-to-many relationship can easily be \\navoided by creating a composite entity  (also referred to as a bridge entity  or an \\nassociative entity ). Because such a table is used to link the tables that were origi -\\nnally related in an M:N relationship, the composite entity structure includes—as for -\\neign keys— at least  the primary keys of the tables that are to be linked. The database \\ndesigner has two main options when defining a composite table’s primary key: use the \\ncombination of those foreign keys or create a new primary key.\\nRemember that each entity in the ERM is represented by a table. Therefore, you \\ncan create the composite ENROLL table shown in Figure 3.25 to link the tables \\nCLASS and STUDENT. In this example, the ENROLL table’s primary key is the \\ncombination of its foreign keys CLASS_CODE and STU_NUM. However, the \\ndesigner could have decided to create a single-attribute new primary key such as \\nENROLL_LINE, using a different line value to identify each ENROLL table row \\nuniquely. (Microsoft Access users might use the Autonumber data type to generate \\nsuch line values automatically.)FIGURE 3.24   THE WRONG IMPLEMENTATION OF THE M:N RELATIONSHIP BETWEEN STUDENT \\nAND CLASS  \\nDatabase name: Ch03_CollegeT ry\\nTable name: STUDENT\\nPrimar y key: STU_NUM\\nForeign key: none\\nTable name: CLASS\\nPrimar y key: CLASS_CODE\\nForeign key: STU_NUM\\ncomposite entity\\nAn entity designed \\nto transform an M:N \\nrelationship into two \\n1:M relationships. The \\ncomposite entity’s \\nprimary key comprises \\nat least the primary keys \\nof the entities that it \\nconnects. Also known \\nas a bridge entity or \\nassociative entity . See \\nalso linking table .\\nbridge entity\\nSee composite entity .\\nassociative entity\\nSee composite entity .TABLE 3.7\\nSAMPLE STUDENT ENROLLMENT DATA\\nSTUDENT’S LAST NAME SELECTED CLASSES\\nBowser Accounting 1, ACCT-211, code 10014 Intro to Microcomputing, CIS-220,  \\ncode 10018 Intro to Statistics, QM-261, code 10021\\nSmithson Accounting 1, ACCT-211, code 10014 Intro to Microcomputing, CIS-220,  \\ncode 10018 Intro to Statistics, QM-261, code 10021\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f1bda352-775d-472e-8d48-26445bd98eba', embedding=None, metadata={'page_label': '99', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    99\\nThe ENROLL table shown in Figure 3.25 yields the required M:N to 1:M con -\\nversion. Observe that the composite entity represented by the ENROLL table must \\ncontain at least the primary keys of the CLASS and STUDENT tables (CLASS_\\nCODE and STU_NUM, respectively) for which it serves as a connector. Also note \\nthat the STUDENT and CLASS tables now contain only one row per entity. The \\nENROLL table contains multiple occurrences of the foreign key values, but those \\ncontrolled redundancies are incapable of producing anomalies as long as referen -\\ntial integrity is enforced. Additional attributes may be assigned as needed. In this \\ncase, ENROLL_GRADE is selected to satisfy a reporting requirement. Also note \\nthat ENROLL_GRADE is fully dependent on the composite primary key. Naturally, \\nthe conversion is reflected in the ERM, too. The revised relationship is shown in \\nFigure 3.26.\\nAs you examine Figure 3.26, note that the composite entity named ENROLL rep -\\nresents the linking table between STUDENT and CLASS.linking table\\nIn the relational model, \\na table that implements \\nan M:M relationship. See \\nalso composite entity .FIGURE 3.25  CONVERTING THE M:N RELATIONSHIP INTO TWO 1:M RELATIONSHIPS  \\nTable name: ENROLL\\nPrimar y key: CLASS_CODE + STU_NUM\\nForeign key: CLASS_CODE, STU_NUMTable name: STUDENT\\nPrimar y key: STU_NUM\\nForeign key: noneDatabase name: Ch03_CollegeT ry2\\nTable name: CLASS\\nPrimar y key: CLASS_CODE\\nForeign key: CRS_CODE\\nIn addition to the linking attributes, the composite ENROLL table can also contain such \\nrelevant attributes as the grade earned in the course. In fact, a composite table can contain \\nany number of attributes that the designer wants to track. Keep in mind that the compos -\\nite entity, although implemented as an actual table , is conceptually  a logical entity that was \\ncreated as a means to an end: to eliminate the potential for multiple redundancies in the \\noriginal M:N relationship.NoteBecause the ENROLL table in Figure 3.25 links two tables, STUDENT and CLASS, \\nit is also called a linking table . In other words, a linking table is the implementation \\nof a composite entity.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='854cbbac-7363-45d9-be9d-b13ad36e9d5c', embedding=None, metadata={'page_label': '100', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='100   Part 2     Design Concepts\\nThe 1:M relationship between COURSE and CLASS was first illustrated in Figure 3.19 \\nand Figure 3.20. Y ou can increase the amount of available information even as you control \\nthe database’s redundancies. Thus, Figure 3.27 shows the expanded ERM, including the \\n1:M relationship between COURSE and CLASS shown in Figure 3.19. Note that the model \\ncan handle multiple sections of a CLASS while controlling redundancies by making sure \\nthat all of the COURSE data common to each CLASS are kept in the COURSE table.\\nFIGURE 3.28  THE RELATIONAL DIAGRAM FOR THE CH03_TINYCOLLEGE DATABASE  FIGURE 3.27  THE EXPANDED ER MODEL\\nThe relational diagram that corresponds to the ERM in Figure 3.27 is shown in \\nFigure 3.28.\\nThe ERM will be examined in greater detail in Chapter 4 to show you how it is used \\nto design more complex databases. The ERM will also be used as the basis for developing \\nand implementing a realistic database design of a university computer lab in Appendixes \\nB and C. These appendixes are available at www.cengagebrain.com .\\nFIGURE 3.26   CHANGING THE M:N RELATIONSHIPS TO TWO  \\n1:M RELATIONSHIPS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0d2b4fb1-818c-4b7e-acea-ee5bf30e160e', embedding=None, metadata={'page_label': '101', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    101\\n3-7 Data Redundancy Revisited\\nIn Chapter 1, you learned that data redundancy leads to data anomalies, which can \\ndestroy the effectiveness of the database. Y ou also learned that the relational database makes it possible to control data redundancies by using common attributes that are shared by tables, called foreign keys.\\nThe proper use of foreign keys is crucial to controlling data redundancy, although \\nthey do not totally eliminate the problem because the foreign key values can be repeated many times. However, the proper use of foreign keys minimizes  data redundancies and \\nthe chances that destructive data anomalies will develop.\\nThe real test of redundancy is not how many copies of a given attribute are stored, but whether the elimination of an attribute will eliminate information. Therefore, if you delete an attribute and the original information can still be generated through relational alge -\\nbra, the inclusion of that attribute would be redundant. Given that view of redundancy, proper foreign keys are clearly not redundant in spite of their multiple occurrences in a table. However, even when you use this less restrictive view of redundancy, keep in mind that controlled redundancies are often designed as part of the system to ensure transaction \\nspeed and/or information requirements.Note\\nY ou will learn in Chapter 4 that database designers must reconcile three often contra-\\ndictory requirements: design elegance, processing speed, and information requirements. Also, you will learn in Chapter 13, Business Intelligence and Data Warehouses, that proper data warehousing design requires carefully defined and controlled data redun-dancies to function properly. Regardless of how you describe data redundancies, the potential for damage is limited by proper implementation and careful control.\\nAs important as it is to control data redundancy, sometimes the level of data redun-\\ndancy must actually be increased to make the database serve crucial information pur -\\nposes. Y ou will learn about such redundancies in Chapter 13. Also, data redundancies sometimes seem  to exist to preserve the historical accuracy of the data. For example, \\nconsider a small invoicing system. The system includes the CUSTOMER, who may buy one or more PRODUCTs, thus generating an INVOICE. Because a customer may buy more than one product at a time, an invoice may contain several invoice LINEs, each providing details about the purchased product. The PRODUCT table should contain the product price to provide a consistent pricing input for each product that appears on the invoice. The tables that are part of such a system are shown in Figure 3.29. The system’s relational diagram is shown in Figure 3.30.\\nAs you examine the tables and relationships in the two figures, note that you can \\nkeep track of typical sales information. For example, by tracing the relationships among the four tables, you discover that customer 10014 (Myron Orlando) bought two items on March 8, 2016, that were written to invoice number 1001: one Houselite chain saw with a 16-inch bar and three rat-tail files. In other words, trace the CUS_CODE number 10014 in the CUSTOMER table to the matching CUS_CODE value in the INVOICE table. Next, trace the INV_NUMBER 1001 to the first two rows in the LINE table. Finally, match the two PROD_CODE values in LINE with the PROD_CODE values in PRODUCT. Application software will be used to write the correct bill by multiplying each invoice line item’s LINE_UNITS by its LINE_PRICE, adding the results, and applying appropriate taxes. Later, other application software \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e6584dd2-4c03-4cf1-8082-c28c054e3167', embedding=None, metadata={'page_label': '102', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='102   Part 2     Design Concepts\\nmight use the same technique to write sales reports that track and compare sales by \\nweek, month, or year.\\nAs you examine the sales transactions in Figure 3.29, you might reasonably suppose \\nthat the product price billed to the customer is derived from the PRODUCT table \\nbecause the product data is stored there. But why does that same product price occur \\nagain in the LINE table? Is that not a data redundancy?  It certainly appears to be, but \\nthis time, the apparent redundancy is crucial to the system’s success. Copying the prod -\\nuct price from the PRODUCT table to the LINE table maintains the historical accuracy \\nof the transactions . Suppose, for instance, that you fail to write the LINE_PRICE in the \\nLINE table and that you use the PROD_PRICE from the PRODUCT table to calculate \\nthe sales revenue. Now suppose that the PRODUCT table’s PROD_PRICE changes, as \\nprices frequently do. This price change will be properly reflected in all subsequent sales \\nrevenue calculations. However, the calculations of past sales revenues will also reflect \\nthe new product price, which was not in effect when the transaction took place! As a FIGURE 3.30  THE RELATIONAL DIAGRAM FOR THE INVOICING SYSTEM  \\nFIGURE 3.29  A SMALL INVOICING SYSTEM  \\nTable name: INVOICE\\nPrimar y key: INV_NUMBER\\nForeign key: CUS_CODETable name: LINE\\nPrimary key: INV_NUMBER + LINE_NUMBER\\nForeign key: INV_NUMBER, PROD_CODETable name: CUSTOMER\\nPrimar y key: CUS_CODE\\nForeign key: noneDatabase name: Ch03_SaleCo\\nTable name: PRODUCT\\nPrimary key: PROD_CODE\\nForeign key: none\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='153d52df-20e1-4abf-b701-76c41bb6485f', embedding=None, metadata={'page_label': '103', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    103\\nresult, the revenue calculations for all past transactions will be incorrect, thus elim-\\ninating the possibility of making proper sales comparisons over time. On the other hand, if the price data is copied from the PRODUCT table and stored with the transac-tion in the LINE table, that price will always accurately reflect the transaction that took place at that time . Y ou will discover that such planned “redundancies” are common in \\ngood database design.\\nFinally, you might wonder why the LINE_NUMBER attribute was used in the LINE \\ntable in Figure 3.29. Wouldn’t the combination of INV_NUMBER and PROD_CODE be a sufficient composite primary key—and, therefore, isn’t the LINE_NUMBER redundant? Y es, it is, but this redundancy is common practice on invoicing software that typically generates such line numbers automatically. In this case, the redundancy is not necessary, but given its automatic generation, the redundancy is not a source of anomalies. The inclusion of LINE_NUMBER also adds another benefit: the order of the retrieved invoic-ing data will always match the order in which the data was entered. If product codes are used as part of the primary key, indexing will arrange those product codes as soon as the invoice is completed and the data is stored. Y ou can imagine the potential confusion when a customer calls and says, “The second item on my invoice has an incorrect price, ” and you are looking at an invoice whose lines show a different order from those on the customer’s copy!\\n3-8 Indexes\\nSuppose you want to locate a book in a library. Does it make sense to look through every book until you find the one you want? Of course not; you use the library’s cat -\\nalog, which is indexed by title, topic, and author. The index (in either a manual or computer library catalog) points you to the book’s location, making retrieval a quick and simple matter. An index is an orderly arrangement used to logically access rows in a table.\\nOr, suppose you want to find a topic in this book, such as ER model . Does it make \\nsense to read through every page until you stumble across the topic? Of course not; it is much simpler to go to the book’s index, look up the phrase ER model , and read the ref-\\nerences that point you to the appropriate page(s). In each case, an index is used to locate a needed item quickly.\\nIndexes in the relational database environment work like the indexes described in \\nthe preceding paragraphs. From a conceptual point of view, an index is composed of an index key and a set of pointers. The index key is, in effect, the index’s reference point. More formally, an index is an ordered arrangement of keys and pointers. Each key points to the location of the data identified by the key.\\nFor example, suppose you want to look up all of the paintings created by a given \\npainter in the Ch03_Museum database in Figure 3.18. Without an index, you must read each row in the PAINTING table and see if the PAINTER_NUM matches the requested painter. However, if you index the PAINTER table and use the index key PAINTER_NUM, you merely need to look up the appropriate PAINTER_NUM in the index and find the matching pointers. Conceptually speaking, the index would resemble the pre-sentation in Figure 3.31.\\nAs you examine Figure 3.31, note that the first PAINTER_NUM index key value (123) \\nis found in records 1, 2, and 4 of the PAINTING table. The second PAINTER_NUM index key value (126) is found in records 3 and 5 of the PAINTING table.\\nDBMSs use indexes for many different purposes. Y ou just learned that an index \\ncan be used to retrieve data more efficiently, but indexes can also be used by a DBMS \\nindex\\nAn ordered array of index key values and row ID values (pointers). Indexes are generally used to speed up and facilitate data retrieval. Also known as an index key.\\nindex key\\nSee index.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0b449d10-c482-4bd3-b200-f7b7e6943803', embedding=None, metadata={'page_label': '104', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='104   Part 2     Design Concepts\\nto retrieve data ordered by a specific attribute or attributes. For example, creating an \\nindex on a customer’s last name will allow you to retrieve the customer data alphabet -\\nically by the customer’s last name. Also, an index key can be composed of one or more \\nattributes. For example, in Figure 3.29, you can create an index on VEND_CODE and \\nPROD_CODE to retrieve all rows in the PRODUCT table ordered by vendor, and \\nwithin vendor, ordered by product.\\nIndexes play an important role in DBMSs for the implementation of primary keys. \\nWhen you define a table’s primary key, the DBMS automatically creates a unique index \\non the primary key column(s) you declared. For example, in Figure 3.29, when you \\ndeclare CUS_CODE to be the primary key of the CUSTOMER table, the DBMS auto -\\nmatically creates a unique index on that attribute. In a unique index , as its name implies, \\nthe index key can have only one pointer value (row) associated with it. (The index in Fig -\\nure 3.31 is not a unique index because the PAINTER_NUM has multiple pointer values \\nassociated with it. For example, painter number 123 points to three rows—1, 2, and 4—in \\nthe PAINTING table.)\\nA table can have many indexes, but each index is associated with only one table. \\nThe index key can have multiple attributes (a composite index). Creating an index \\nis easy. Y ou will learn in Chapter 7 that a simple SQL command produces any \\nrequired index.\\n3-9 Codd’s Relational Database Rules\\nIn 1985, Dr. E. F. Codd published a list of 12 rules to define a relational database  \\nsystem.1 He published the list out of concern that many vendors were marketing products \\nas “relational” even though those products did not meet minimum relational standards.  \\nDr. Codd’s list, shown in Table 3.8, is a frame of reference for what a truly relational \\ndatabase should be. Bear in mind that even the dominant database vendors do not fully \\nsupport all 12 rules.\\n1 Codd, E., “Is Y our DBMS Really Relational?” and “Does Y our DBMS Run by the Rules?” Computerworld , \\nOctober 14 and October 21, 1985.FIGURE 3.31  COMPONENTS OF AN INDEX  \\nunique index\\nAn index in which the \\nindex key can have only \\none associated pointer \\nvalue (row).\\nPAINTER_NUM\\n(index key)126\\nPointers to the\\nPAINTING\\ntable rows3, 5PAINTING table\\n123 1, 2, 4PAINTING table index\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7c994d3e-1196-4dfc-943c-dd1cd3a2a49a', embedding=None, metadata={'page_label': '105', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    105\\nTABLE 3.8\\nDR. CODD’S 12 RELATIONAL DATABASE RULES\\nRULE RULE NAME DESCRIPTION\\n1 Information All information in a relational database must be logically represented as \\ncolumn values in rows within tables.\\n2 Guaranteed access Every value in a table is guaranteed to be accessible through a combination of table name, primary key value, and column name.\\n3 Systematic treatment of nulls Nulls must be represented and treated in a systematic way, independent of \\ndata type.\\n4 Dynamic online catalog based on the relational modelThe metadata must be stored and managed as ordinary data—that is, in tables within the database; such data must be available to authorized users using the standard database relational language.\\n5 Comprehensive data sublanguageThe relational database may support many languages; however, it must support one well-defined, declarative language as well as data definition, view definition, data manipulation (interactive and by program), integrity constraints, authorization, and transaction management (begin, commit, and rollback).\\n6 View updating Any view that is theoretically updatable must be updatable through the system.\\n7 High-level insert, update, and deleteThe database must support set-level inserts, updates, and deletes.\\n8 Physical data independence Application programs and ad hoc facilities are logically unaffected when \\nphysical access methods or storage structures are changed.\\n9 Logical data independence Application programs and ad hoc facilities are logically unaffected when \\nchanges are made to the table structures that preserve the original table values (changing order of columns or inserting columns).\\n10 Integrity independence All relational integrity constraints must be definable in the relational \\nlanguage and stored in the system catalog, not at the application level.\\n11 Distribution independence The end users and application programs are unaware of and unaffected by \\nthe data location (distributed vs. local databases).\\n12 Nonsubversion If the system supports low-level access to the data, users must not be allowed to bypass the integrity rules of the database.\\n13 Rule zero All preceding rules are based on the notion that to be considered relational, a database must use its relational facilities exclusively for management.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='499c5404-aebc-4d58-8460-0f5345263578', embedding=None, metadata={'page_label': '106', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='106   Part 2    Design Concepts\\n• Tables are the basic building blocks of a relational database. A grouping of related \\nentities, known as an entity set, is stored in a table. Conceptually speaking, the rela-tional table is composed of intersecting rows (tuples) and columns. Each row rep-resents a single entity, and each column represents the characteristics (attributes) of the entities.\\n•\\n Keys are central to the use of relational tables. Keys define functional dependencies; that is, other attributes are dependent on the key and can therefore be found if the key value is known. A key can be classified as a superkey, a candidate key, a primary key, a secondary key, or a foreign key.\\n•\\n Each table row must have a primary key. The primary key is an attribute or combina-tion of attributes that uniquely identifies all remaining attributes found in any given row. Because a primary key must be unique, no null values are allowed if entity integ-rity is to be maintained.\\n•\\n Although tables are independent, they can be linked by common attributes. Thus, the primary key of one table can appear as the foreign key in another table to which it is linked. Referential integrity dictates that the foreign key must contain values that match the primary key in the related table, or must contain nulls.\\n•\\n The relational model supports several relational algebra functions, including SELECT, PROJECT, JOIN, INTERSECT, UNION, DIFFERENCE, PRODUCT, and DIVIDE. Understanding the basic mathematical forms of these functions gives a broader understanding of the data manipulation options.\\n•\\n A relational database performs much of the data manipulation work behind the scenes. For example, when you create a database, the RDBMS automatically produces a structure to house a data dictionary for your database. Each time you create a new table within the database, the RDBMS updates the data dictionary, thereby providing the database documentation.\\n•\\n Once you know the basics of relational databases, you can concentrate on design. Good design begins by identifying appropriate entities and their attributes and then the relationships among the entities. Those relationships (1:1, 1:M, and M:N) can be represented using ERDs. The use of ERDs allows you to create  \\nand evaluate simple logical design. The 1:M relationship is most easily incorpo-rated in a good design; just make sure that the primary key of the “1” is included in the table of the “many. ”Summary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='99e9869d-f065-498b-aee1-1506afcffaf8', embedding=None, metadata={'page_label': '107', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    107\\nassociative entity\\nattribute domainbridge entitycandidate keyclosurecomposite entitycomposite keydata dictionarydependentdeterminantdetermination\\nDIFFERENCEDIVIDE\\ndomainentity integrityequijoinflagsforeign key (FK)full functional dependencefunctional dependencehomonymindexindex keyinner join\\nINTERSECTJOIN\\njoin column(s)keykey attributeleft outer joinlinking tablenatural joinnullouter joinpredicate logicprimary key (PK)PRODUCTPROJECT\\nreferential integrityrelational algebrarelvar\\nRESTRICT\\nright outer joinsecondary key\\nSELECT\\nset theorysuperkeysynonymsystem catalogtheta jointuple\\nUNION\\nunion-compatibleunique index\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\nAll of the databases used \\nin the questions and prob -\\nlems are available at www.  \\ncengagebrain.com. The data-base names match the  \\ndatabase names shown in the figures.Online \\nContent\\n1. What is the difference between a database and a table?\\n2. What does it mean to say that a database displays both entity integrity and  \\nreferential integrity?\\n3. Why are entity integrity and referential integrity important in a database?\\n4. What are the requirements that two relations must satisfy to be considered \\nunion-compatible?\\n5. Which relational algebra operators can be applied to a pair of tables that are  \\nnot union-compatible?\\n6. Explain why the data dictionary is sometimes called “the database designer’s  \\nd a t a b a s e .”\\n7. A database user manually notes that “The file contains two hundred records, each record containing nine fields. ” Use appropriate relational database terminology to “translate” that statement.\\nUse Figure Q3.8 to answer Questions 8–12.\\n8.\\n Using the STUDENT and PROFESSOR tables, illustrate the difference between a natural join, an equijoin, and an outer join.\\n9.\\n Create the table that would result from πstu_code (student).\\n10. Create the table that would result from πstu_code, dept_code (student ⨝ professor).\\nReview Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ab4ed6a-2df3-49f1-9f87-270b0ef9da75', embedding=None, metadata={'page_label': '108', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='108   Part 2     Design Concepts\\nFIGURE Q3.8  THE CH03_COLLEGEQUE DATABASE TABLES  \\nDatabase name: Ch03_CollegeQue\\nTable name: PROFESSORTable name: STUDENT\\nFIGURE Q3.13  THE CH03_VENDINGCO DATABASE TABLES  \\nDatabase name: Ch03_VendingCo\\nTable name: MACHINE Table name: BOOTH\\n11. Create the basic ERD for the database shown in Figure Q3.8.\\n12. Create the relational diagram for the database shown in Figure Q3.8.\\nUse Figure Q3.13 to answer Questions 13–17.\\nFIGURE Q3.18  THE CROW’S FOOT ERD FOR QUESTION 14  \\n13. Write the relational algebra formula to apply a UNION relational operator to the \\ntables shown in Figure Q3.13.\\n14. Create the table that results from applying a UNION relational operator to the tables \\nshown in Figure Q3.13.\\n15. Write the relational algebra formula to apply an INTERSECT relational operator to \\nthe tables shown in Figure Q3.13.\\n16. Create the table that results from applying an INTERSECT relational operator to the \\ntables shown in Figure Q3.13.\\n17. Using the tables in Figure Q3.13, create the table that results from MACHINE  \\nDIFFERENCE BOOTH.\\nUse Figure Q3.18 to answer Question 18.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7002a72c-f29e-4bc9-99e1-85b0c58dd319', embedding=None, metadata={'page_label': '109', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    109\\n18. Suppose you have the ERD shown in Figure Q3.18. How would you convert this \\nmodel into an ERM that displays only 1:M relationships? (Make sure you create the \\nrevised ERD.)\\n19. What are homonyms and synonyms, and why should they be avoided in database \\ndesign?\\n20. How would you implement a l:M relationship in a database composed of two tables? \\nGive an example.\\nUse Figure Q3.21 to answer Question 21.\\n21. Identify and describe the components of the table shown in Figure Q3.21, using cor -\\nrect terminology. Use your knowledge of naming conventions to identify the table’s \\nprobable foreign key(s).\\nUse the database shown in Figure Q3.22 to answer Questions 22–27.FIGURE Q3.21  THE CH03_NOCOMP DATABASE EMPLOYEE TABLE  \\nTable name: EMPLOYEE Database name: Ch03_NoComp\\nFIGURE Q3.22  THE CH03_THEATER DATABASE TABLES  \\nDatabase name: Ch03_Theater\\nTable name: PLAYTable name: DIRECTOR\\n22. Identify the primary keys.\\n23. Identify the foreign keys.\\n24. Create the ERM.\\n25. Create the relational diagram to show the relationship between DIRECTOR and PLAY .\\n26. Suppose you wanted quick lookup capability to get a listing of all plays directed by a \\ngiven director. Which table would be the basis for the INDEX table, and what would \\nbe the index key?\\n27. What would be the conceptual view of the INDEX table described in Question 26? \\nDepict the contents of the conceptual INDEX table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ab10ce0e-6860-4784-9385-1be7a6ebaa3b', embedding=None, metadata={'page_label': '110', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='110   Part 2     Design Concepts\\nUse the database shown in Figure P3.1 to answer Problems 1–9.\\n1. For each table, identify the primary key and the foreign key(s). If a table does not \\nhave a foreign key, write None .\\n2. Do the tables exhibit entity integrity? Answer yes or no, and then explain your \\nanswer.\\n3. Do the tables exhibit referential integrity? Answer yes or no, and then explain \\nyour answer. Write NA (Not Applicable) if the table does not have a foreign key.\\n4. Describe the type(s) of relationship(s) between STORE and REGION.\\n5. Create the ERD to show the relationship between STORE and REGION.\\n6. Create the relational diagram to show the relationship between STORE and \\nREGION.Problems\\nFIGURE P3.1  THE CH03_STORECO DATABASE TABLES  \\nTable name: EMPLOYEE Database name: Ch03_StoreCo\\nTable name: STORE\\nTable name: REGION\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04c16ec8-4623-483e-a859-4d811da72d3c', embedding=None, metadata={'page_label': '111', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    111\\n7. Describe the type(s) of relationship(s) between EMPLOYEE and STORE. \\n(Hint : Each store employs many employees, one of whom manages the store.)\\n8. Create the ERD to show the relationships among EMPLOYEE, STORE, and \\nREGION.\\n9. Create the relational diagram to show the relationships among EMPLOYEE, STORE, \\nand REGION.\\nUse the database shown in Figure P3.10 to work Problems 10–16. Note that the database \\nis composed of four tables that reflect these relationships:\\n• An EMPLOYEE has only one JOB_CODE, but a JOB_CODE can be held by many \\nEMPLOYEEs.\\n• An EMPLOYEE can participate in many PLANs, and any PLAN can be assigned to \\nmany EMPLOYEEs.\\nNote also that the M:N relationship has been broken down into two 1:M relationships for \\nwhich the BENEFIT table serves as the composite or bridge entity.\\n10. For each table in the database, identify the primary key and the foreign key(s). If a \\ntable does not have a foreign key, write None .\\n11. Create the ERD to show the relationship between EMPLOYEE and JOB.\\n12. Create the relational diagram to show the relationship between EMPLOYEE and \\nJOB.\\n13. Do the tables exhibit entity integrity? Answer yes or no, and then explain your \\nanswer.\\n14. Do the tables exhibit referential integrity? Answer yes or no, and then explain your \\nanswer. Write NA (Not Applicable) if the table does not have a foreign key.\\n15. Create the ERD to show the relationships among EMPLOYEE, BENEFIT, JOB, and \\nPLAN.\\n16. Create the relational diagram to show the relationships among EMPLOYEE,  \\nBENEFIT, JOB, and PLAN.FIGURE P3.10  THE CH03_BENECO DATABASE TABLES   \\nDatabase name: Ch03_BeneCo\\nTable name: EMPLOYEE\\nTable name: JOB\\nTable name: BENEFIT\\nTable name: PLAN\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fe91076d-d1c7-44fc-8286-7989c02b26d7', embedding=None, metadata={'page_label': '112', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='112   Part 2     Design Concepts\\nUse the database shown in Figure P3.17 to answer Problems 17–23.\\n17. For each table, identify the primary key and the foreign key(s). If a table does not \\nhave a foreign key, write None .\\n18. Do the tables exhibit entity integrity? Answer yes or no, and then explain your \\nanswer.\\n19. Do the tables exhibit referential integrity? Answer yes or no, and then explain your \\nanswer. Write NA (Not Applicable) if the table does not have a foreign key.\\n20. Identify the TRUCK table’s candidate key(s).\\n21. For each table, identify a superkey and a secondary key.\\n22. Create the ERD for this database.\\n23. Create the relational diagram for this database.FIGURE P3.17  THE CH03_TRANSCO DATABASE TABLES  \\nDatabase name: Ch03_ TransCo\\n Table name: TRUCK\\nPrimar y key: TRUCK_NUM\\nForeign key: BASE_CODE, TYPE_CODE\\nTable name: BASE\\nPrimar y key: BASE_CODE\\nForeign key: none\\nTable name: TYPE\\nPrimar y key: TYPE_CODE\\nForeign key: none\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b0c63966-65a4-48ab-b9ef-3410ef941aab', embedding=None, metadata={'page_label': '113', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    113\\nUse the database shown in Figure P3.24 to answer Problems 24–31. AviaCo is an air -\\ncraft charter company that supplies on-demand charter flight services using a fleet \\nof four aircraft. Aircraft are identified by a unique registration number. Therefore, \\nthe aircraft registration number is an appropriate primary key for the AIRCRAFT \\ntable.FIGURE P3.24  THE CH03_AVIACO DATABASE TABLES  \\nTable name: CHARTER Database name: Ch03_AviaCo\\nThe destinations are indicated by standard three-letter airport codes. For example,\\nSTL = St. Louis, MO ATL = Atlanta, GA BNA = Nashville, TN\\nAC-TTAF   = Aircraft total time, airframe (hours)\\nAC-TTEL  = Total time, left engine (hours)\\nAC_TTER  = Total time, right engine (hours)\\nIn a fully developed system, such attribute values\\nwould be updated by application software when the\\nCHARTER table entries were posted.\\nTable name: MODELTable name: AIRCRAFT\\nCustomers are charged per round-trip mile, using the MOD_CHG_MILE rate. The MOD_SEATS column lists the total \\nnumber of seats in the airplane, including the pilot and copilot seats. Therefore, a PA31-350 trip that is ﬂown by a pilot \\nand a copilot has eight passenger seats available.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4bbbdd88-aca6-4b25-8f31-367844e137ca', embedding=None, metadata={'page_label': '114', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='114   Part 2     Design Concepts\\nThe nulls in the CHARTER table’s CHAR_COPILOT column indicate that a copilot is \\nnot required for some charter trips or for some aircraft. Federal Aviation Administration \\n(FAA) rules require a copilot on jet aircraft and on aircraft that have a gross take-off  \\nweight over 12,500 pounds. None of the aircraft in the AIRCRAFT table are governed \\nby this requirement; however, some customers may require the presence of a copilot for \\ninsurance reasons. All charter trips are recorded in the CHARTER table.FIGURE P3.24  THE CH03_AVIACO DATABASE TABLES (CONTINUED)  \\nTable name: PIL OT\\nTable name: EMPLOYEE\\nTable name: CUSTOMERDatabase name: Ch03_AviaCo\\nThe pilot licenses shown in the PIL OT table include ATP = Airline Transport Pilot and COMM = Commercial Pilot.\\nBusinesses that operate on-demand air services are governed by Part 135 of the Federal Air Regulations (FARs), which \\nare enforced by the Federal Aviation Administration (FAA). Su ch businesses are kn own as “Part 135 operators .” Part 135\\noperations require that pilots successfully complete ﬂight proﬁcien cy checks every six months. The “Part 135” ﬂight\\nproﬁciency check date is recorded in PIL_PT135_ DATE. To ﬂy commercial ly, pilots must ha ve at least a commercial\\nlicense and a second-class medical certiﬁcate (PIL_MED_TYPE = 2).\\nThe PIL_RATINGS include:\\nSEL = Single Engine, Land MEL  = Multiengine, Land\\nSES = Single Engine, Sea Instr. = Instrument\\nCFI = Certiﬁed Flight Instructor CFII   = Certiﬁed Flight Instructor, Instrument\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dfa63882-b04d-4fc3-97aa-31eeff4a47c8', embedding=None, metadata={'page_label': '115', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 3    The Relational Database Model    115\\n24. For each table, identify each of the following when possible:\\na. The primary key\\nb. A superkey\\nc. A candidate key\\nd. The foreign key(s)\\ne. A secondary key\\n25. Create the ERD. (Hint:  Look at the table contents. Y ou will discover that an AIR -\\nCRAFT can fly many CHARTER trips but that each CHARTER trip is flown by one \\nAIRCRAFT, that a MODEL references many AIRCRAFT but that each AIRCRAFT references a single MODEL, and so on.)\\n26.\\n Create the relational diagram.\\n27. Modify the ERD you created in Problem 25 to eliminate the problems created by the use of synonyms. (Hint:  Modify the CHARTER table structure by eliminating \\nthe CHAR_PILOT and CHAR_COPILOT attributes; then create a composite table named CREW to link the CHARTER and EMPLOYEE tables. Some crew members, such as flight attendants, may not be pilots. That’s why the EMPLOYEE table enters into this relationship.)\\n28.\\n Create the relational diagram for the design you revised in Problem 27.\\nY ou want to see data on charters flown by either Robert Williams (employee number 105) or Elizabeth Travis (employee number 109) as pilot or copilot, but not charters flown by both of them. Complete Problems 29–31 to find this information.\\nEarlier in the chapter, you were instructed to avoid homonyms and synonyms. In this prob -\\nlem, both the pilot and the copilot are listed in the PILOT table, but EMP_NUM cannot be used for both in the CHARTER table. Therefore, the synonyms CHAR_PILOT and CHAR_COPILOT were used in the CHARTER table.\\nAlthough the solution works in this case, it is very restrictive, and it generates nulls \\nwhen a copilot is not required. Worse, such nulls proliferate as crew requirements change. For example, if the AviaCo charter company grows and starts using larger air-craft, crew requirements may increase to include flight engineers and load masters. The CHARTER table would then have to be modified to include the additional crew assignments; such attributes as CHAR_FLT_ENGINEER and CHAR_LOADMASTER would have to be added to the CHARTER table. Given this change, each time a smaller aircraft flew a charter trip without the number of crew members required in larger aircraft, the missing crew members would yield additional nulls in the CHARTER table.\\nYou will have a chance to correct those design shortcomings in Problem 27. The problem \\nillustrates two important points:\\n1.\\n Don’t use synonyms. If your design requires the use of synonyms, revise the design!\\n2.  To the greatest possible extent, design the database to accommodate growth without \\nrequiring structural changes in the database tables. Plan ahead and try to anticipate the effects of change on the database.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='756f6b3c-3fa6-4b4f-a4f2-24ed9851b70f', embedding=None, metadata={'page_label': '116', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='116   Part 2    Design Concepts\\n29. Create the table that would result from applying the SELECT and PROJECT \\nrelational operators to the CHARTER table to return only the CHAR_TRIP , CHAR_PILOT, and CHAR_COPILOT attributes for charters flown by either employee 105 or employee 109.\\n30.\\n Create the table that would result from applying the SELECT and PROJECT rela-tional operators to the CHARTER table to return only the CHAR_TRIP , CHAR_PILOT, and CHAR_COPILOT attributes for charters flown by both employee 105 and employee 109.\\n31.\\n Create the table that would result from applying a DIFFERENCE relational operator of your result from Problem 29 to your result from Problem 30.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='36aa3f31-decc-4932-a4cd-82d5be873791', embedding=None, metadata={'page_label': '117', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 4\\nEntity Relationship (ER) Modeling\\nIn this chapter, you will learn:\\n• The main characteristics of entity relationship components\\n• How relationships between entities are defined, refined, and incorporated into the  \\ndatabase design process\\n• How ERD components affect database design and implementation\\n• That real-world database design often requires the reconciliation of conflicting goals\\nPreviewThis chapter expands coverage of the data-modeling aspect of database design. Data \\nmodeling is the first step in the database design journey, serving as a bridge between real-world objects and the database model that is implemented in the computer. There-fore, the importance of data-modeling details, expressed graphically through entity relationship diagrams (ERDs), cannot be overstated.\\nMost of the basic concepts and definitions used in the entity relationship model (ERM) \\nwere introduced in Chapter 2, Data Models. For example, the basic components of entities and relationships and their representation should now be familiar to you. This chapter goes much deeper, analyzing the graphic depiction of relationships among the entities and showing how those depictions help you summarize the wealth of data required to implement a successful design.\\nFinally, the chapter illustrates how conflicting goals can be a challenge in database \\ndesign and might require design compromises.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH04_TinyCollege  P\\t P\\t P\\t P\\nCH04_TinyCollege_Alt  P\\t P\\t P\\t P\\nCH04_ShortCo  P\\t P\\t P\\t PCH04_Clinic  P\\t P\\t P\\t P\\nCH04_PartCo  P\\t P\\t P\\t P\\nCH04_CollegeTry  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1aeb5a25-ef86-4b56-b7a1-3380672d1dc7', embedding=None, metadata={'page_label': '118', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='118   Part 2    Design Concepts\\n4-1 The Entity Relationship Model (ERM)\\nY ou should remember from Chapter 2, Data Models, and Chapter 3, The Relational Data-\\nbase Model, that the ERM forms the basis of an ERD. The ERD represents the concep-tual database as viewed by the end user. ERDs depict the database’s main components: entities, attributes, and relationships. Because an entity represents a real-world object, the words entity and object  are often used interchangeably. Thus, the entities (objects) \\nof the Tiny College database design developed in this chapter include students, classes, teachers, and classrooms. The order in which the ERD components are covered in the chapter is dictated by the way the modeling tools are used to develop ERDs that can form the basis for successful database design and implementation.\\nIn Chapter 2, you also learned about the various notations used with ERDs—the \\noriginal Chen notation and the newer Crow’s Foot and UML notations. The first two notations are used at the beginning of this chapter to introduce some basic ER model-ing concepts. Some conceptual database modeling concepts can be expressed only using the Chen notation. However, because the emphasis is on design and implementation  of \\ndatabases, the Crow’s Foot and UML class diagram notations are used for the final Tiny College ER diagram example. Because of its emphasis on implementation, the Crow’s Foot notation can represent only what could be implemented. In other words:\\n•\\n The Chen notation favors conceptual modeling.\\n• The Crow’s Foot notation favors a more implementation-oriented approach.\\n• The UML notation can be used for both conceptual and implementation modeling.\\n4-1a  Entities\\nRecall that an entity is an object of interest to the end user. In Chapter 2, you learned \\nthat, at the ER modeling level, an entity actually refers to the entity set and not to a single \\nentity occurrence. In other words, an entity in the ERM corresponds to a table—not to a row—in the relational environment. The ERM refers to a table row as an entity instance or entity occurrence. In the Chen, Crow’s Foot, and UML notations, an entity is repre-\\nsented by a rectangle that contains the entity’s name. The entity name, a noun, is usually written in all capital letters.\\n4-1b  Attributes\\nAttributes are characteristics of entities. For example, the STUDENT entity includes the attributes STU_LNAME, STU_FNAME, and STU_INITIAL, among many others. In the original Chen notation, attributes are represented by ovals and are connected \\nBecause this book generally focuses on the relational model, you might be tempted to conclude that the ERM is exclusively a relational tool. Actually, conceptual models such as the ERM can be used to understand and design the data requirements of an organization. Therefore, the ERM is independent of the database type. Conceptual models are used in the conceptual design of databases, while relational models are used in the logical design of databases. However, because you are familiar with the relational model from the pre -\\nvious chapter, the relational model is used extensively in this chapter to explain ER con-structs and the way they are used to develop database designs.Note\\nOnline \\nContent\\nTo learn how to create ER \\ndiagrams with the help of Microsoft Visio, go to www.cengagebrain.com:Appendix A, Designing Databases with Visio Professional: A Tutorial, shows you how to cre -\\nate Crow’s Foot ERDs.Appendix H, Unified Modeling Language (UML), shows you how to create UML class diagrams.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='390fa006-b675-46ab-9b77-c53f716f727e', embedding=None, metadata={'page_label': '119', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    119\\nto the entity rectangle with a line. Each oval contains the name of the attribute it \\nrepresents. In the Crow’s Foot notation, the attributes are written in the attribute box \\nbelow the entity rectangle. (See Figure 4.1.) Because the Chen representation con -\\nsumes more space, software vendors have adopted the Crow’s Foot attribute display.\\nRequired and Optional Attributes  A required attribute  is an attribute that must \\nhave a value; in other words, it cannot be left empty. As shown in Figure 4.1, the two \\nboldfaced attributes in the Crow’s Foot notation indicate that data entry will be required. \\nSTU_LNAME and STU_FNAME require data entries because all students are assumed \\nto have a last name and a first name. However, students might not have a middle name, \\nand perhaps they do not yet have a phone number and an email address. Therefore, those \\nattributes are not presented in boldface in the entity box. An optional attribute  is an \\nattribute that does not require a value; therefore, it can be left empty.\\nDomains  Attributes have a domain. As you learned in Chapter 3, a domain  is the set of \\npossible values for a given attribute. For example, the domain for a grade point average \\n(GPA) attribute is written (0,4) because the lowest possible GPA value is 0 and the highest \\npossible value is 4. The domain for a gender attribute consists of only two possibilities: M \\nor F (or some other equivalent code). The domain for a company’s date of hire attribute \\nconsists of all dates that fit in a range (for example, company startup date to current date).\\nAttributes may share a domain. For instance, a student address and a professor address \\nshare the same domain of all possible addresses. In fact, the data dictionary may let a \\nnewly declared attribute inherit the characteristics of an existing attribute if the same \\nattribute name is used. For example, the PROFESSOR and STUDENT entities may each \\nhave an attribute named ADDRESS and could therefore share a domain.\\nIdentifiers (Primary Keys)  The ERM uses identifiers —one or more attributes that \\nuniquely identify each entity instance. In the relational model, entities are mapped to tables, \\nand the entity identifier is mapped as the table’s primary key (PK). Identifiers are underlined \\nin the ERD. Key attributes are also underlined in a frequently used shorthand notation for the \\ntable structure, called a relational schema , that uses the following format:\\nTABLE NAME ( KEY_ATTRIBUTE 1 , ATTRIBUTE 2, ATTRIBUTE 3, … ATTRIBUTE K)\\nFor example, a CAR entity may be represented by:\\nCAR ( CAR_VIN , MOD_CODE, CAR_YEAR, CAR_COLOR)\\nEach car is identified by a unique vehicle identification number, or CAR_VIN.\\nComposite Identifiers  Ideally, an entity identifier is composed of only a single attri -\\nbute. For example, the table in Figure 4.2 uses a single-attribute primary key named required attribute\\nIn ER modeling, an \\nattribute that must have \\na value. In other words, it \\ncannot be left empty.\\noptional attribute\\nIn ER modeling, an \\nattribute that does not \\nrequire a value; therefore, \\nit can be left empty.\\nidentifiers\\nOne or more attributes \\nthat uniquely identify \\neach entity instance.\\nrelational schema\\nThe organization of \\na relational database \\nas described by the \\ndatabase administrator.FIGURE 4.1  THE ATTRIBUTES OF THE STUDENT ENTITY: CHEN AND CROW’S FOOT  \\nChen Model Crow’s Foot Model\\nSTU_LNAMESTU_FNAMESTU_INITIAL\\nSTU_EMAIL\\nSTU_PHONE STUDENT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6aa5b53-bc93-4dd0-8049-f954c44d5b1f', embedding=None, metadata={'page_label': '120', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='120   Part 2     Design Concepts\\nCLASS_CODE. However, it is possible to use a composite identifier , a primary key \\ncomposed of more than one attribute. For instance, the Tiny College database admin -\\nistrator may decide to identify each CLASS entity instance (occurrence) by using a \\ncomposite primary key of CRS_CODE and CLASS_SECTION instead of using CLASS_\\nCODE. Either approach uniquely identifies each entity instance. Given the structure of \\nthe CLASS table shown in Figure 4.2, CLASS_CODE is the primary key, and the combi -\\nnation of CRS_CODE and CLASS_SECTION is a proper candidate key. If the CLASS_\\nCODE attribute is deleted from the CLASS entity, the candidate key (CRS_CODE and \\nCLASS_SECTION) becomes an acceptable composite primary key.\\nFIGURE 4.2  THE CLASS TABLE (ENTITY) COMPONENTS AND CONTENTS\\nDatabase name: Ch04_TinyCollege\\nRemember that Chapter 3 made a commonly accepted distinction between COURSE \\nand CLASS. A CLASS constitutes a specific time and place of a COURSE offering. A class \\nis defined by the course description and its time and place, or section. Consider a profes -\\nsor who teaches Database I, Section 2; Database I, Section 5; Database I, Section 8; and  \\nSpreadsheet II, Section 6. The professor teaches two courses (Database I and Spreadsheet II),  \\n but four classes. Typically, the COURSE offerings are printed in a course catalog, while the \\nCLASS offerings are printed in a class schedule for each term.Note\\nIf the CLASS_CODE in Figure 4.2 is used as the primary key, the CLASS entity may \\nbe represented in shorthand form as follows:\\nCLASS ( CLASS_CODE , CRS_CODE, CLASS_SECTION, CLASS_TIME,  \\nROOM_CODE, PROF_NUM)\\nOn the other hand, if CLASS_CODE is deleted, and the composite primary key is the \\ncombination of CRS_CODE and CLASS_SECTION, the CLASS entity may be repre -\\nsented as follows:\\nCLASS ( CRS_CODE , CLASS_SECTION , CLASS_TIME, ROOM_CODE, PROF_NUM)\\nNote that both  key attributes are underlined in the entity notation.\\nComposite and Simple Attributes  Attributes are classified as simple or composite. \\nA composite attribute , not to be confused with a composite key, is an attribute that can composite identifier\\nIn ER modeling, a key \\ncomposed of more than \\none attribute.\\ncomposite attribute\\nAn attribute that can be \\nfurther subdivided to \\nyield additional attributes. \\nFor example, a phone \\nnumber such as 615-898-\\n2368 may be divided \\ninto an area code (615), \\nan exchange number \\n(898), and a four-digit \\ncode (2368). Compare to \\nsimple attribute .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4625f0f0-a785-410d-b9c3-cda04d47d80a', embedding=None, metadata={'page_label': '121', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    121\\nbe further subdivided to yield additional attributes. For example, the attribute ADDRESS \\ncan be subdivided into street, city, state, and zip code. Similarly, the attribute PHONE_\\nNUMBER can be subdivided into area code and exchange number. A simple attribute  \\nis an attribute that cannot be subdivided. For example, age, sex, and marital status would \\nbe classified as simple attributes. To facilitate detailed queries, it is wise to change com -\\nposite attributes into a series of simple attributes.\\nThe database designer must always be on the lookout for composite attributes. It is \\ncommon for business rules to use composite attributes to simplify policies, and users \\noften describe entities in their environment using composite attributes. For example, a \\nuser at Tiny College might need to know a student’s name, address, and phone number. \\nThe designer must recognize that these are composite attributes and determine the cor -\\nrect way to decompose the composite into simple attributes.\\nSingle-Valued Attributes  A single-valued attribute  is an attribute that can have \\nonly a single value. For example, a person can have only one Social Security number, and \\na manufactured part can have only one serial number. Keep in mind that a single-valued \\nattribute is not necessarily a simple attribute . For instance, a part’s serial number (such as \\nSE-08-02-189935) is single-valued, but it is a composite attribute because it can be sub -\\ndivided into the region in which the part was produced (SE), the plant within that region \\n(08), the shift within the plant (02), and the part number (189935).\\nMultivalued Attributes  Multivalued attributes  are attributes that can have many \\nvalues. For instance, a person may have several college degrees, and a household may \\nhave several different phones, each with its own number. Similarly, a car’s color may be \\nsubdivided into many colors for the roof, body, and trim. In the Chen ERM, multivalued \\nattributes are shown by a double line connecting the attribute to the entity. The Crow’s \\nFoot notation does not identify multivalued attributes. The ERD in Figure 4.3 contains \\nall of the components introduced thus far; note that CAR_VIN is the primary key, and \\nCAR_COLOR is a multivalued attribute of the CAR entity.\\nIn the ERD models in Figure 4.3, the CAR entity’s foreign key (FK) has been typed as MOD_\\nCODE. This attribute was manually added to the entity. Actually, proper use of database \\nmodeling software will automatically produce the FK when the relationship is defined. \\nIn addition, the software will label the FK appropriately and write the FK’s implementa -\\ntion details in a data dictionary. Therefore, when you use professional database modeling \\nsoftware, never type the FK attribute yourself ; let the software handle that task when the \\nrelationship between the entities is defined. (You can see how this works in Appendix A, \\nDesigning Databases with Visio Professional: A Tutorial, at www.cengagebrain.com .)Notesimple attribute\\nAn attribute that \\ncannot be subdivided \\ninto meaningful \\ncomponents. Compare \\nto composite attribute .\\nsingle-valued \\nattribute\\nAn attribute that can \\nhave only one value.\\nmultivalued \\nattribute\\nAn attribute that can \\nhave many values for a \\nsingle entity occurrence. \\nFor example, an EMP_\\nDEGREE attribute might \\nstore the string “BBA, \\nMBA, PHD” to indicate \\nthree different degrees \\nheld.\\nFIGURE 4.3  A MULTIVALUED ATTRIBUTE IN AN ENTITY  \\nChen Model Crow’s Foot Model\\nCAR CAR_VINMOD_CODE CAR_YEAR\\nCAR_COLOR\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3007f87d-c39c-4f80-8881-fc7a51a5b04b', embedding=None, metadata={'page_label': '122', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='122   Part 2     Design Concepts\\nImplementing Multivalued Attributes  Although the conceptual model can han -\\ndle M:N relationships and multivalued attributes, you should not implement them in the \\nRDBMS . Remember from Chapter 3 that in the relational table, each column and row \\nintersection represents a single data value. So, if multivalued attributes exist, the designer \\nmust decide on one of two possible courses of action:\\n1. Within the original entity, create several new attributes, one for each component \\nof the original multivalued attribute. For example, the CAR entity’s attribute CAR_\\nCOLOR can be split to create the new attributes CAR_TOPCOLOR, CAR_BODY -\\nCOLOR, and CAR_TRIMCOLOR, which are then assigned to the CAR entity.  \\n(See Figure 4.4.)\\nFIGURE 4.4  SPLITTING THE MULTIVALUED ATTRIBUTE INTO NEW ATTRIBUTES  \\nChen Model Crow’s Foot Model\\nCAR CAR_VINMOD_CODECAR_YEAR\\nCAR_TOPCOLOR\\nCAR_TRIMCOLOR\\nCAR_BODYCOLOR\\n Although this solution seems to work, its adoption can lead to major structural prob -\\nlems in the table. It is only acceptable if every instance will have the same number \\nof values for the multivalued attribute, and no instance will ever have more values. \\nHowever, even in this case, it is a gamble that new changes in the environment will \\nnever create a situation where an instance would have more values than before. For \\nexample, if additional color components—such as a logo color—are added for some \\ncars, the table structure must be modified to accommodate the new color section. In \\nthat case, cars that do not have such color sections generate nulls for the nonexistent \\ncomponents, or their color entries for those sections are entered as N/A to indicate \\n“not applicable. ” (The solution in Figure 4.4 is to split a multivalued attribute into \\nnew attributes, but imagine the problems this type of solution would cause if it were \\napplied to an employee entity that contains employee degrees and certifications. If \\nsome employees have 10 degrees and certifications while most have fewer or none, \\nthe number of degree/certification attributes would be 10, and most of those attribute \\nvalues would be null for most employees.) In short, although you have seen solution 1  \\napplied, it is not always acceptable.\\n2. Create a new entity composed of the original multivalued attribute’s components. \\nThis new entity allows the designer to define color for different sections of the car. \\n(See Table 4.1.) Then, this new CAR_COLOR entity is related to the original CAR \\nentity in a 1:M relationship.\\nUsing the approach illustrated in Table 4.1, you even get a fringe benefit: you can now \\nassign as many colors as necessary without having to change the table structure. The \\nERM shown in Figure 4.5 reflects the components listed in Table 4.1. This is the preferred \\nway to deal with multivalued attributes. Creating a new entity in a 1:M relationship with \\nthe original entity yields several benefits: it is a more flexible, expandable solution, and it \\nis compatible with the relational model!\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ea71bf30-07de-49b6-b41b-1d603b289efd', embedding=None, metadata={'page_label': '123', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    123\\nDerived Attributes  Finally, a derived attribute  is an attribute whose value is calculated \\n(derived) from other attributes. The derived attribute need not be physically stored within \\nthe database; instead, it can be derived by using an algorithm. For example, an employee’s \\nage, EMP_AGE, may be found by computing the integer value of the difference between \\nthe current date and the EMP_DOB. If you use Microsoft Access, you would use the for -\\nmula INT((DATE() – EMP_DOB)/365). In Microsoft SQL Server, you would use SELECT \\nDATEDIFF(“YEAR” , EMP_DOB, GETDATE()), where DATEDIFF is a function that \\ncomputes the difference between dates. The first parameter indicates the measurement (in \\nthis case, years). If you use Oracle, you would use SYSDATE instead of DATE(). (Y ou are \\nassuming, of course, that EMP_DOB was stored in the Julian date format.)\\nSimilarly, the total cost of an order can be derived by multiplying the quantity ordered \\nby the unit price. Or, the estimated average speed can be derived by dividing trip distance \\nby the time spent en route. A derived attribute is indicated in the Chen notation by a dashed \\nline that connects the attribute and the entity. (See Figure 4.6.) The Crow’s Foot notation \\ndoes not have a method for distinguishing the derived attribute from other attributes.\\nDerived attributes are sometimes referred to as computed attributes . Computing a \\nderived attribute can be as simple as adding two attribute values located on the same \\nrow, or it can be the result of aggregating the sum of values located on many table rows \\n(from the same table or from a different table). The decision to store derived attributes in TABLE 4.1\\nCOMPONENTS OF THE MUL TIVALUED ATTRIBUTE\\nSECTION COLOR\\nTop White\\nBody Blue\\nTrim Gold\\nInterior Blue\\nIf you are used to looking at relational diagrams such as the ones produced by Microsoft \\nAccess, you expect to see the relationship line in the relational diagram  drawn from the PK \\nto the FK. However, the relational diagram convention is not necessarily reflected in the \\nERD. In an ERD, the focus is on the entities and the relationships between them, rather than \\nhow those relationships are anchored graphically. In a complex ERD that includes both \\nhorizontally and vertically placed entities, the placement of the relationship lines is largely \\ndictated by the designer’s decision to improve the readability of the design. (Remember \\nthat the ERD is used for communication between designers and end users.)Note\\nderived attribute\\nAn attribute that does \\nnot physically exist \\nwithin the entity and is \\nderived via an algorithm. \\nFor example, the Age \\nattribute might be \\nderived by subtracting \\nthe birth date from the \\ncurrent date.\\nFIGURE 4.5   A NEW ENTITY SET COMPOSED OF A MULTIVALUED \\nATTRIBUTE’S COMPONENTS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cf7929de-0f4c-49a0-b3f2-95fa23930695', embedding=None, metadata={'page_label': '124', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='124   Part 2     Design Concepts\\ndatabase tables depends on the processing requirements and the constraints placed on a \\nparticular application. The designer should be able to balance the design in accordance \\nwith such constraints. Table 4.2 shows the advantages and disadvantages of storing (or \\nnot storing) derived attributes in the database.\\n4-1c  Relationships\\nRecall from Chapter 2 that a relationship is an association between entities. The entities \\nthat participate in a relationship are also known as participants , and each relationship is \\nidentified by a name that describes the relationship. The relationship name is an active or \\npassive verb; for example, a STUDENT takes  a CLASS, a PROFESSOR teaches  a CLASS, \\na DEPARTMENT employs  a PROFESSOR, a DIVISION is managed by  an EMPLOYEE, \\nand an AIRCRAFT is flown by  a CREW .\\nRelationships between entities always operate in both directions. To define the relation -\\nship between the entities named CUSTOMER and INVOICE, you would specify that:\\n• A CUSTOMER may generate many INVOICEs.\\n• Each INVOICE is generated by one CUSTOMER.\\nBecause you know both directions of the relationship between CUSTOMER and \\nINVOICE, it is easy to see that this relationship can be classified as 1:M.\\nThe relationship classification is difficult to establish if you know only one side of the \\nrelationship. For example, if you specify that:\\nA DIVISION is managed by one EMPLOYEE.TABLE 4.2\\nADVANTAGES AND DISADVANTAGES OF STORING DERIVED ATTRIBUTES\\nDERIVED ATTRIBUTE\\nSTORED NOT STORED\\nAdvantage Saves CPU processing cycles\\nSaves data access time\\nData value is readily available\\nCan be used to keep track of historical dataSaves storage space\\nComputation always yields current value\\nDisadvantage Requires constant maintenance to ensure \\nderived value is current, especially if any values \\nused in the calculation changeUses CPU processing cycles\\nIncreases data access time\\nAdds coding complexity to queriesFIGURE 4.6  DEPICTION OF A DERIVED ATTRIBUTE  \\nEMPLOYEECrow’s Foot Model\\nEMP_NUMEMP_LNAMEEMP_INITIAL\\nEMP_DOB\\nEMP_AGEEMP_FNAMEChen Model\\nparticipants\\nAn ER term for entities \\nthat participate in \\na relationship. For \\nexample, in the \\nrelationship “PROFESSOR \\nteaches CLASS,” the \\nteaches  relationship \\nis based on the \\nparticipants PROFESSOR \\nand CLASS.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a1dfa0ec-0980-498f-8ca0-4c701de1e99e', embedding=None, metadata={'page_label': '125', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    125\\nY ou don’t know if the relationship is 1:1 or 1:M. Therefore, you should ask the ques -\\ntion “Can an employee manage more than one division?” If the answer is yes, the rela -\\ntionship is 1:M, and the second part of the relationship is then written as:\\nAn EMPLOYEE may manage many DIVISIONs.\\nIf an employee cannot manage more than one division, the relationship is 1:1, and the \\nsecond part of the relationship is then written as:\\nAn EMPLOYEE may manage only one DIVISION.\\n4-1d  Connectivity and Cardinality\\nY ou learned in Chapter 2 that entity relationships may be classified as one-to-one, one-to-\\nmany, or many-to-many. Y ou also learned how such relationships were depicted in the Chen and  \\nCrow’s Foot notations. The term connectivity  is used to describe the relationship classification.\\nCardinality  expresses the minimum and maximum number of entity occurrences \\nassociated with one occurrence of the related entity. In the ERD, cardinality is indicated \\nby placing the appropriate numbers beside the entities, using the format (x,y). The first \\nvalue represents the minimum number of associated entities, while the second value rep -\\nresents the maximum number of associated entities. Many database designers who use \\nCrow’s Foot modeling notation do not depict the specific cardinalities on the ER diagram \\nitself because the specific limits described by the cardinalities cannot be implemented \\ndirectly through the database design. Correspondingly, some Crow’s Foot ER modeling \\ntools do not print the numeric cardinality range in the diagram; instead, you can add it as \\ntext if you want to have it shown. When the specific cardinalities are not included on the \\ndiagram in Crow’s Foot notation, cardinality is implied by the use of the symbols shown \\nin Figure 4.7, which describe the connectivity and participation (discussed next). The \\nnumeric cardinality range has been added using the Microsoft Visio text drawing tool.\\nconnectivity\\nThe classification of the \\nrelationship between \\nentities. Classifications \\ninclude 1:1, 1:M, and \\nM:N.\\ncardinality\\nA property that assigns \\na specific value to \\nconnectivity and \\nexpresses the range \\nof allowed entity \\noccurrences associated \\nwith a single occurrence \\nof the related entity.FIGURE 4.7  CONNECTIVITY AND CARDINALITY IN AN ERD  \\nKnowing the minimum and maximum number of entity occurrences is very useful at \\nthe application software level. For example, Tiny College might want to ensure that a class \\nis not taught unless it has at least 10 students enrolled. Similarly, if the classroom can hold \\nonly 30 students, the application software should use that cardinality to limit enrollment \\nin the class. However, keep in mind that the DBMS cannot handle the implementation of \\nthe cardinalities at the table level—that capability is provided by the application software or \\nby triggers. Y ou will learn how to create and execute triggers in Chapter 8, Advanced SQL.\\nAs you examine the Crow’s Foot diagram in Figure 4.7, keep in mind that the cardinalities \\nrepresent the number of occurrences in the related  entity. For example, the cardinality (1,4) \\nnext to the CLASS entity in the “PROFESSOR teaches CLASS” relationship indicates that \\neach professor teaches up to four classes, which means that the PROFESSOR table’s primary \\nkey value occurs at least once and no more than four times as foreign key values in the CLASS \\ntable. If the cardinality had been written as (1,N), there would be no upper limit to the num -\\nber of classes a professor might teach. Similarly, the cardinality (1,1) next to the PROFESSOR \\nentity indicates that each class is taught by one and only one professor. That is, each CLASS \\nentity occurrence is associated with one and only one entity occurrence in PROFESSOR.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a14a0b5f-1ea8-4c7c-9f78-2827dce40e07', embedding=None, metadata={'page_label': '126', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='126   Part 2    Design Concepts\\nConnectivities and cardinalities are established by concise statements known as busi-\\nness rules, which were introduced in Chapter 2. Such rules, derived from a precise and \\ndetailed description of an organization’s data environment, also establish the ERM’s enti-ties, attributes, relationships, connectivities, cardinalities, and constraints. Because busi-ness rules define the ERM’s components, making sure that all appropriate business rules are identified is an important part of a database designer’s job.\\nThe placement of the cardinalities in the ER diagram is a matter of convention. The Chen notation places the cardinalities on the side of the related entity. The Crow’s Foot and  \\nUML diagrams place the cardinalities next to the entity to which they apply.Note\\nThe concept of relationship strength is not part of the original ERM. Instead, this con-cept applies directly to Crow’s Foot diagrams. Because Crow’s Foot diagrams are used extensively to design relational databases, it is important to understand relationship strength as it affects database implementation. The Chen ERD notation is oriented toward conceptual modeling and therefore does not distinguish between weak and strong relationships.Note\\nexistence-dependent\\nA property of an entity whose existence depends on one or more other entities. In such an environment, the existence-independent table must be created and loaded first because the existence-dependent key cannot reference a table that does not yet exist.4-1e  Existence Dependence\\nAn entity is said to be existence-dependent if it can exist in the database only when it is associated with another related entity occurrence. In implementation terms, an entity is existence-dependent if it has a mandatory foreign key—that is, a foreign key attribute that cannot be null. For example, if an employee wants to claim one or more dependents for tax-withholding purposes, the relationship “EMPLOYEE claims DEPENDENT” would be appropriate. In that case, the DEPENDENT entity is clearly existence-dependent on the EMPLOYEE entity because it is impossible for the dependent to exist apart from the  \\nEMPLOYEE in the database.\\nIf an entity can exist apart from all of its related entities, then it is existence-  \\nindependent, and it is referred to as a strong entity or regular entity. For example, sup-pose that the XYZ Corporation uses parts to produce its products. Furthermore, suppose that some of those parts are produced in-house and other parts are bought from vendors. In that scenario, it is quite possible for a PART to exist independently from a VENDOR in the relationship “PART is supplied by VENDOR” because at least some of the parts are not supplied by a vendor. Therefore, PART is existence-independent from VENDOR.Online \\nContent\\nBecause the careful \\ndefinition of complete and accurate business rules is crucial to good database design, their derivation is examined in detail in Appendix B,  \\nThe University Lab: Conceptual Design. The modeling skills you are learning in this chapter are applied in the devel-opment of a real data-base design in Appendix B. The initial design shown in Appendix B is then modified in Appen-dix C, The University Lab: Conceptual Design Verification, Logical Design, and Implemen-tation. (Both appendixes are available at www.  \\ncengagebrain.com.)\\n4-1f  Relationship Strength\\nThe concept of relationship strength is based on how the primary key of a related entity is defined. To implement a relationship, the primary key of one entity (the parent entity, normally on the “one” side of the one-to-many relationship) appears as a foreign key in the related entity (the child entity, mostly the entity on the “many” side of the one-to-many relationship). Sometimes the foreign key also is a primary key component in the related entity. For example, in Figure 4.5, the CAR entity primary key (CAR_VIN) appears as both a primary key component and a foreign key in the CAR_COLOR entity. In this section, you will learn how various relationship strength decisions affect primary key arrangement in database design.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6dfdb8fd-8daa-42b6-8b06-4856583aa1ac', embedding=None, metadata={'page_label': '127', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    127\\nWeak (Non-Identifying) Relationships  A weak relationship , also known as a \\nnon-identifying relationship , exists if the primary key of the related entity does not \\ncontain a primary key component of the parent entity. By default, relationships are estab -\\nlished by having the primary key of the parent entity appear as a foreign key (FK) on the \\nrelated entity (also known as the child entity). For example, suppose the 1:M relationship \\nbetween COURSE and CLASS is defined as:\\nCOURSE ( CRS_CODE , DEPT_CODE, CRS_DESCRIPTION, CRS_CREDIT)\\nCLASS ( CLASS_CODE , CRS_CODE, CLASS_SECTION, CLASS_TIME,  \\nROOM_CODE, PROF_NUM)\\nIn this case, a weak relationship exists between COURSE and CLASS because CRS_CODE \\n(the primary key of the parent entity) is only a foreign key in the CLASS entity. In this example, \\nthe CLASS primary key did not inherit a primary key component from the COURSE entity.\\nFigure 4.8 shows how the Crow’s Foot notation depicts a weak relationship by placing \\na dashed relationship line between the entities. The tables shown below the ERD illus -\\ntrate how such a relationship is implemented.\\nexistence-\\nindependent\\nA property of an entity \\nthat can exist apart from \\none or more related \\nentities. Such a table must \\nbe created first when \\nreferencing an existence-\\ndependent table.\\nstrong entity\\nAn entity that is \\nexistence-independent, \\nthat is, it can exist apart \\nfrom all of its related \\nentities. Also called a \\nregular entity .\\nregular entity\\nSee strong entity .\\nweak (non-\\nidentifying) \\nrelationship\\nA relationship in which \\nthe primary key of the \\nrelated entity does \\nnot contain a primary \\nkey component of the \\nparent entity.\\nTable name: COURSE\\nTable name: CLASSDatabase name: Ch04_TinyCollege\\nFIGURE 4.8   A WEAK (NON-IDENTIFYING) RELATIONSHIP BETWEEN \\nCOURSE AND CLASS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d541f1fa-c250-43e7-8b2c-7fd95978a5bf', embedding=None, metadata={'page_label': '128', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='128   Part 2     Design Concepts\\nStrong (Identifying) Relationships  A strong (identifying) relationship  exists \\nwhen the primary key of the related entity contains a primary key component of \\nthe parent entity. For example, suppose the 1:M relationship between COURSE and \\nCLASS is defined as:\\nCOURSE ( CRS_CODE , DEPT_CODE, CRS_DESCRIPTION, CRS_CREDIT)\\nCLASS ( CRS_CODE, CLASS_SECTION , CLASS_TIME, ROOM_CODE, PROF_NUM)\\nIn this case, the CLASS entity primary key is composed of CRS_CODE and CLASS_SEC -\\nTION. Therefore, a strong relationship exists between COURSE and CLASS because CRS_\\nCODE (the primary key of the parent entity) is a primary key component in the CLASS \\nentity. In other words, the CLASS primary key did inherit a primary key component from the \\nCOURSE entity. (Note that the CRS_CODE in CLASS is also the FK to the COURSE entity.)\\nThe Crow’s Foot notation depicts the strong (identifying) relationship with a solid line \\nbetween the entities, as shown in Figure 4.9.\\nstrong (identifying) \\nrelationship\\nA relationship that \\noccurs when two \\nentities are existence-\\ndependent; from \\na database design \\nperspective, this \\nrelationship exists \\nwhenever the primary \\nkey of the related entity \\ncontains the primary key \\nof the parent entity.FIGURE 4.9   A STRONG (IDENTIFYING) RELATIONSHIP BETWEEN \\nCOURSE AND CLASS  \\nTable name: COURSE\\nTable name: CLASSDatabase name: Ch04_TinyCollege_Alt \\nAs you examine Figure 4.9, you might wonder what the O symbol next to the CLASS \\nentity signifies. Y ou will discover the meaning of this cardinality in Section 4-1h, Rela -\\ntionship Participation.\\nIn summary, whether the relationship between COURSE and CLASS is strong or weak \\ndepends on how the CLASS entity’s primary key is defined. Remember that the nature of \\nthe relationship is often determined by the database designer, who must use professional \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='843b783e-026b-4546-8606-e2da716b1276', embedding=None, metadata={'page_label': '129', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    129\\njudgment to determine which relationship type and strength best suit the database trans -\\naction, efficiency, and information requirements. That point will be emphasized in detail!\\n4-1g  Weak Entities\\nIn contrast to the strong or regular entity mentioned in Section 4-1f, a weak entity  is \\none that meets two conditions:\\n1. The entity is existence-dependent; it cannot exist without the entity with which it has \\na relationship.\\n2. The entity has a primary key that is partially or totally derived from the parent entity \\nin the relationship.\\nFor example, a company insurance policy insures an employee and any dependents. \\nFor the purpose of describing an insurance policy, an EMPLOYEE might or might not \\nhave a DEPENDENT, but the DEPENDENT must be associated with an EMPLOYEE. \\nMoreover, the DEPENDENT cannot exist without the EMPLOYEE; that is, a person \\ncannot get insurance coverage as a dependent unless the person is a dependent of \\nan employee. DEPENDENT is the weak entity in the relationship “EMPLOYEE has  \\nDEPENDENT. ” This relationship is shown in Figure 4.10.\\nKeep in mind that the order in which the tables are created and loaded is very important . \\nFor example, in the “COURSE generates CLASS” relationship, the COURSE table must be \\ncreated before the CLASS table. After all, it would not be acceptable to have the CLASS \\ntable’s foreign key refer to a COURSE table that did not yet exist. In fact, you must load the \\ndata of the “1” side first in a 1:M relationship to avoid the possibility of referential integrity \\nerrors , regardless of whether the relationships are weak or strong.Note\\nweak entity\\nAn entity that displays \\nexistence dependence \\nand inherits the primary \\nkey of its parent \\nentity. For example, a \\nDEPENDENT requires \\nthe existence of an \\nEMPLOYEE.FIGURE 4.10  A WEAK ENTITY IN AN ERD  \\nEMPLOYEE DEPENDENT has1 M\\n(0,N) (1,1)Chen Model\\nEMP_NUM\\nDEP_NUM\\nDEP_FNAME\\nDEP_DOBEMP_NUM\\nEMP_LNAME\\nEMP_FNAME\\nEMP_INITIAL\\nEMP_DOB\\nEMP_HIREDATE\\nCrow’s Foot Model\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6a00ec00-db93-454d-93d9-5aa4ff4a16c5', embedding=None, metadata={'page_label': '130', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='130   Part 2     Design Concepts\\nNote that the Chen notation in Figure 4.10 identifies the weak entity by using a dou -\\nble-walled entity rectangle. The Crow’s Foot notation generated by Visio Professional \\nuses the relationship line and the PK/FK designation to indicate whether the related \\nentity is weak. A strong (identifying) relationship indicates that the related entity is \\nweak. Such a relationship means that both conditions have been met for the weak \\nentity definition—the related entity is existence-dependent, and the PK of the related \\nentity contains a PK component of the parent entity.\\nRemember that the weak entity inherits part of its primary key from its strong coun -\\nterpart. For example, at least part of the DEPENDENT entity’s key shown in Figure 4.10 \\nwas inherited from the EMPLOYEE entity:\\nEMPLOYEE ( EMP_NUM , EMP_LNAME, EMP_FNAME, EMP_INITIAL,  \\nEMP_DOB, EMP_HIREDATE)\\nDEPENDENT ( EMP_NUM, DEP_NUM , DEP_FNAME, DEP_DOB)\\nFigure 4.11 illustrates the implementation of the relationship between the weak entity \\n(DEPENDENT) and its parent or strong counterpart (EMPLOYEE). Note that DEPEN -\\nDENT’s primary key is composed of two attributes, EMP_NUM and DEP_NUM, and \\nthat EMP_NUM was inherited from EMPLOYEE.\\nFIGURE 4.11  A WEAK ENTITY IN A STRONG RELATIONSHIP  \\nTable name: EMPLOYEE\\nTable name: DEPENDENT\\nDatabase name: Ch04_ShortCo\\nGiven this scenario, and with the help of this relationship, you can determine that:\\nJeanine J. Callifante claims two dependents, Annelise and Jorge.\\nKeep in mind that the database designer usually determines whether an entity can \\nbe described as weak based on the business rules. An examination of Figure 4.8 might \\ncause you to conclude that CLASS is a weak entity to COURSE. After all, it seems \\nclear that a CLASS cannot exist without a COURSE, so there is existence dependence. \\nFor example, a student cannot enroll in the Accounting I class ACCT-211, Section 3 \\n(CLASS_CODE 10014), unless there is an ACCT-211 course. However, note that the \\nCLASS table’s primary key is CLASS_CODE, which is not derived from the COURSE \\nparent entity. That is, CLASS may be represented by:\\nCLASS ( CLASS_CODE , CRS_CODE, CLASS_SECTION, CLASS_TIME,  \\nROOM_CODE, PROF_NUM)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9fd5ec4-c553-4247-9a0c-a7e9ecb6b0a8', embedding=None, metadata={'page_label': '131', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    131\\nRemember that the burden of establishing the relationship is always placed on the \\nentity that contains the foreign key. In most cases, that entity is on the “many” side of the relationship.NoteThe second weak entity requirement has not been met; therefore, by definition, the \\nCLASS entity in Figure 4.8 may not be classified as weak. On the other hand, if the CLASS entity’s primary key had been defined as a composite key composed of the com-bination CRS_CODE and CLASS_SECTION, CLASS could be represented by:\\nCLASS (CRS_CODE, CLASS_SECTION, CLASS_TIME, ROOM_CODE, PROF_NUM)\\nIn that case, as illustrated in Figure 4.9, the CLASS primary key is partially derived \\nfrom COURSE because CRS_CODE is the COURSE table’s primary key. Given this \\ndecision, CLASS is a weak entity by definition. (In Visio Professional Crow’s Foot terms, the relationship between COURSE and CLASS is classified as strong, or  \\nidentifying.) In any case, CLASS is always existence-dependent on COURSE, whether or not it is defined as weak.\\n4-1h  Relationship Participation\\nParticipation in an entity relationship is either optional or mandatory. Recall that relationships are bidirectional; that is, they operate in both directions. If COURSE is related to CLASS, then by definition, CLASS is related to COURSE. Because of the bidirectional nature of relationships, it is necessary to determine the con-nectivity of the relationship from COURSE to CLASS and the connectivity of the relationship from CLASS to COURSE. Similarly, the specific maximum and mini-mum cardinalities must be determined in each direction for the relationship. Once again, you must consider the bidirectional nature of the relationship when deter -\\nmining participation.\\nOptional participation means that one entity occurrence does not require  a \\ncorresponding entity occurrence in a particular relationship. For example, in the “COURSE generates CLASS” relationship, you noted that at least some courses do not generate a class. In other words, an entity occurrence (row) in the COURSE table does not necessarily require the existence of a corresponding entity occur -\\nrence in the CLASS table. (Remember that each entity is implemented as a table.) Therefore, the CLASS entity is considered to be optional  to the COURSE entity. \\nIn Crow’s Foot notation, an optional relationship between entities is shown by drawing a small circle (O) on the side of the optional entity, as illustrated in Figure 4.9. The existence of an optional entity  indicates that its minimum cardinality is 0. \\n(The term optionality  is used to label any condition in which one or more optional \\nrelationships exist.)\\nMandatory participation means that one entity occurrence requires  a corresponding \\nentity occurrence in a particular relationship. If no optionality symbol is depicted with the entity, the entity is assumed to exist in a mandatory relationship with the related entity. If the mandatory participation is depicted graphically, it is typically shown as a small hash mark across the relationship line, similar to the Crow’s Foot depiction of a connectivity of 1. The existence of a mandatory relationship indicates that the minimum cardinality is at least 1 for the mandatory entity.optional participation\\nIn ER modeling, a condition in which one entity occurrence does not require a corresponding entity occurrence in a particular relationship.\\nmandatory participation\\nA relationship in which one entity occurrence must have a corresponding occurrence in another entity. For example, an EMPLOYEE works in a DIVISION. (A person cannot be an employee without being assigned to a company’s division.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='02c9c1f4-800b-4e01-8485-f1104757fdd4', embedding=None, metadata={'page_label': '132', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='132   Part 2     Design Concepts\\nWhen you create a relationship in Microsoft Visio, the default relationship will be \\nmandatory on the “1” side and optional on the “many” side. Table 4.3 shows the various \\nconnectivity and participation combinations that are supported by the Crow’s Foot nota -\\ntion. Recall that these combinations are often referred to as cardinality in Crow’s Foot \\nnotation when specific cardinalities are not used.\\nBecause relationship participation is an important component of database design, you \\nshould examine a few more scenarios. Suppose that Tiny College employs some professors \\nwho conduct research without teaching classes. If you examine the “PROFESSOR teaches \\nCLASS” relationship, it is quite possible for a PROFESSOR not to teach a CLASS. There -\\nfore, CLASS is optional  to PROFESSOR. On the other hand, a CLASS must be taught by a \\nPROFESSOR. Therefore, PROFESSOR is mandatory  to CLASS. Note that the ERD model \\nin Figure 4.12 shows the cardinality next to CLASS to be (0,3), indicating that a professor \\nmay teach no classes or as many as three classes. Also, each CLASS table row references \\none and only one PROFESSOR row—assuming each class is taught by one and only one \\nprofessor—represented by the (1,1) cardinality next to the PROFESSOR table.\\nYou might be tempted to conclude that relationships are weak when they occur between \\nentities in an optional relationship and that relationships are strong when they occur \\nbetween entities in a mandatory relationship. However, this conclusion is not warranted. \\nKeep in mind that relationship participation and relationship strength do not describe the \\nsame thing. You are likely to encounter a strong relationship when one entity is optional \\nto another. For example, the relationship between EMPLOYEE and DEPENDENT is clearly a \\nstrong one, but DEPENDENT is clearly optional to EMPLOYEE. After all, you cannot require \\nemployees to have dependents. Also, it is just as possible for a weak relationship to be estab -\\nlished when one entity is mandatory to another. The relationship strength depends on how \\nthe PK of the related entity is formulated, while the relationship participation depends on \\nhow the business rule is written. For example, the business rules “Each part must be supplied \\nby a vendor” and “A part may or may not be supplied by a vendor” create different option -\\nalities for the same entities! Failure to understand this distinction may lead to poor design \\ndecisions that cause major problems when table rows are inserted or deleted.Note\\nTABLE 4.3\\nCROW’S FOOT SYMBOLS\\nSYMBOL CARDINALITY COMMENT\\n(0,N) Zero or many; the “many” side is optional.\\n(1,N) One or many; the “many” side is mandatory.\\n(1,1) One and only one; the “1” side is mandatory.\\n(0,1) Zero or one; the “1” side is optional.\\nFIGURE 4.12   AN OPTIONAL CLASS ENTITY IN THE RELATIONSHIP \\n“PROFESSOR TEACHES CLASS”  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='067be59e-d113-4d42-bf5c-82239c39bebc', embedding=None, metadata={'page_label': '133', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    133\\nIt is important that you clearly understand the distinction between mandatory and \\noptional participation in relationships. Otherwise, you might develop designs in which \\nawkward and unnecessary temporary rows (entity instances) must be created just to \\naccommodate the creation of required entities.\\nIt is also important to understand that the semantics of a problem might determine \\nthe type of participation in a relationship. For example, suppose that Tiny College offers \\nseveral courses; each course has several classes. Note again the distinction between class  \\nand course  in this discussion: a CLASS constitutes a specific offering (or section) of a \\nCOURSE. Typically, courses are listed in the university’s course catalog, while classes are \\nlisted in the class schedules that students use to register for their classes.\\nBy analyzing the CLASS entity’s contribution to the “COURSE generates CLASS” \\nrelationship, it is easy to see that a CLASS cannot exist without a COURSE. Therefore, \\nyou can conclude that the COURSE entity is mandatory  in the relationship. However, \\ntwo scenarios for the CLASS entity may be written, as shown in Figures 4.13 and 4.14.\\nFIGURE 4.13  CLASS IS OPTIONAL TO COURSE  \\nThe different scenarios are a function of the problem’s semantics; that is, they depend \\non how the relationship is defined.\\n1. CLASS is optional . It is possible for the department to create the COURSE entity first \\nand then create the CLASS entity after making the teaching assignments. In the real \\nworld, such a scenario is very likely; there may be courses for which sections (classes) \\nhave not yet been defined. In fact, some courses are taught only once a year and do not \\ngenerate classes each semester.\\n2. CLASS is mandatory . This condition is created by the constraint imposed by the \\nsemantics of the statement “Each COURSE generates one or more CLASSes. ” In ER \\nterms, each COURSE in the “generates” relationship must have at least one CLASS. \\nTherefore, a CLASS must be created as the COURSE is created to comply with the \\nsemantics of the problem.\\nKeep in mind the practical aspects of the scenario presented in Figure 4.14. Given the \\nsemantics of this relationship, the system should not accept a course that is not associated with \\nat least one class section. Is such a rigid environment desirable from an operational point of \\nview? For example, when a new COURSE is created, the database first updates the COURSE \\ntable, thereby inserting a COURSE entity that does not yet have a CLASS associated with it. FIGURE 4.14  COURSE AND CLASS IN A MANDATORY RELATIONSHIP  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a98aeb51-7a1c-4abd-a04e-75b7ef3659c2', embedding=None, metadata={'page_label': '134', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='134   Part 2     Design Concepts\\nNaturally, the apparent problem seems to be solved when CLASS entities are inserted into the \\ncorresponding CLASS table. However, because of the mandatory relationship, the system will \\ntemporarily violate the business rule constraint. For practical purposes, it would be desirable \\nto classify the CLASS as optional to produce a more flexible design.\\nFinally, as you examine the scenarios in Figures 4.13 and 4.14, keep in mind the role \\nof the DBMS. To maintain data integrity, the DBMS must ensure that the “many” side \\n(CLASS) is associated with a COURSE through the foreign key rules.\\n4-1i Relationship Degree\\nA relationship degree  indicates the number of entities or participants associated with a \\nrelationship. A unary relationship  exists when an association is maintained within a single \\nentity. A binary relationship  exists when two entities are associated. A ternary relationship  \\nexists when three entities are associated. Although higher degrees exist, they are rare and are \\nnot specifically named. (For example, an association of four entities is described simply as a \\nfour-degree relationship .) Figure 4.15 shows these types of relationship degrees.\\nFIGURE 4.15  THREE TYPES OF RELATIONSHIP DEGREE  \\nrelationship degree\\nThe number of \\nentities or participants \\nassociated with \\na relationship. A \\nrelationship degree can \\nbe unary, binary, ternary, \\nor higher.\\nunary relationship\\nAn ER term used to \\ndescribe an association \\nwithin  an entity. For \\nexample, an EMPLOYEE \\nmight manage another \\nEMPLOYEE.\\nbinary relationship\\nAn ER term for an \\nassociation (relationship) \\nbetween two entities. \\nFor example, PROFESSOR \\nteaches CLASS.\\nternary relationship\\nAn ER term used to \\ndescribe an association \\n(relationship) between \\nthree entities. For \\nexample, a DOCTOR \\nprescribes a DRUG for a \\nPATIENT.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='686aba42-7491-4a19-a37e-d0f2ca946707', embedding=None, metadata={'page_label': '135', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    135\\nUnary Relationships  In the case of the unary relationship shown in Figure 4.15, an \\nemployee within the EMPLOYEE entity is the manager for one or more employees \\nwithin that entity. In this case, the existence of the “manages” relationship means that \\nEMPLOYEE requires another EMPLOYEE to be the manager—that is, EMPLOYEE has \\na relationship with itself. Such a relationship is known as a recursive relationship . The \\nvarious cases of recursive relationships are explained in Section 4-1j.\\nBinary Relationships  A binary relationship exists when two entities are associated \\nin a relationship. Binary relationships are the most common type of relationship. In \\nfact, to simplify the conceptual design, most higher-order (ternary and higher) rela -\\ntionships are decomposed into appropriate equivalent binary relationships whenever \\npossible. In Figure 4.15, “a PROFESSOR teaches one or more CLASSes” represents a \\nbinary relationship.\\nTernary and Higher-Order Relationships  Although most relationships are binary, \\nthe use of ternary and higher-order relationships does allow the designer some latitude \\nregarding the semantics of a problem. A ternary relationship implies an association \\namong three different entities. For example, in Figure 4.16, note the relationships and \\ntheir consequences, which are represented by the following business rules:\\n• A DOCTOR writes one or more PRESCRIPTIONs.\\n• A PATIENT may receive one or more PRESCRIPTIONs.\\n• A DRUG may appear in one or more PRESCRIPTIONs. (To simplify this example, \\nassume that the business rule states that each prescription contains only one drug. \\nIn short, if a doctor prescribes more than one drug, a separate prescription must be \\nwritten for each drug.)\\nFIGURE 4.16  THE IMPLEMENTATION OF A TERNARY RELATIONSHIP  recursive \\nrelationship\\nA relationship found \\nwithin a single entity \\ntype. For example, an \\nEMPLOYEE is married \\nto an EMPLOYEE or a \\nPART is a component of \\nanother PART.\\nDatabase name: Ch04_Clinic\\nTable name: DRUG Table name: PATIENT\\nTable name: DOCTOR Table name: PRESCRIPTION\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eb5af656-83aa-4430-9c42-77f26e071108', embedding=None, metadata={'page_label': '136', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='136   Part 2     Design Concepts\\nAs you examine the table contents in Figure 4.16, note that it is possible to track all \\ntransactions. For instance, you can tell that the first prescription was written by doctor \\n32445 for patient 102, using the drug DRZ.\\n4-1j Recursive Relationships\\nAs you just learned, a recursive relationship  is one in which a relationship can exist \\nbetween occurrences of the same entity set. (Naturally, such a condition is found within \\na unary relationship.) For example, a 1:M unary relationship can be expressed by “an \\nEMPLOYEE may manage many EMPLOYEEs, and each EMPLOYEE is managed by \\none EMPLOYEE. ” Also, as long as polygamy is not legal, a 1:1 unary relationship may be \\nexpressed by “an EMPLOYEE may be married to one and only one other EMPLOYEE. ” \\nFinally, the M:N unary relationship may be expressed by “a COURSE may be a prereq -\\nuisite to many other COURSEs, and each COURSE may have many other COURSEs as \\nprerequisites. ” Those relationships are shown in Figure 4.17.\\nFIGURE 4.17  AN ER REPRESENTATION OF RECURSIVE RELATIONSHIPS  \\nThe 1:1 relationship shown in Figure 4.17 can be implemented in the single table \\nshown in Figure 4.18. Note that you can determine that James Ramirez is married to \\nLouise Ramirez, who is married to James Ramirez. Also, Anne Jones is married to Anton \\nShapiro, who is married to Anne Jones.\\nUnary relationships are common in manufacturing industries. For example, Figure \\n4.19 illustrates that a rotor assembly (C-130) is composed of many parts, but each part \\nis used to create only one rotor assembly. Figure 4.19 indicates that a rotor assembly is \\ncomposed of four 2.5-cm washers, two cotter pins, one 2.5-cm steel shank, four 10.25-cm \\nrotor blades, and two 2.5-cm hex nuts. The relationship implemented in Figure 4.19 thus \\nenables you to track each part within each rotor assembly.\\nIf a part can be used to assemble several different kinds of other parts and is itself composed \\nof many parts, two tables are required to implement the “PART contains PART” relationship. \\nFigure 4.20 illustrates such an environment. Parts tracking is increasingly important as manag -\\ners become more aware of the legal ramifications of producing more complex output. In many \\nindustries, especially those involving aviation, full parts tracking is required by law.FIGURE 4.18   THE 1:1 RECURSIVE RELATIONSHIP “EMPLOYEE IS  \\nMARRIED TO EMPLOYEE”  \\nDatabase name: Ch04_PartCo\\nTable name: EMPLOYEE_V1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ad748d5-dbce-4340-8289-ed52daaa47c4', embedding=None, metadata={'page_label': '137', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    137\\nThe M:N recursive relationship might be more familiar in a school environment. For \\ninstance, note how the M:N “COURSE requires COURSE” relationship illustrated in Fig -\\nure 4.17 is implemented in Figure 4.21. In this example, MATH-243 is a prerequisite to \\nQM-261 and QM-362, while both MATH-243 and QM-261 are prerequisites to QM-362.FIGURE 4.19  ANOTHER UNARY RELATIONSHIP: “PART CONTAINS PART”  \\nDatabase name: Ch04_PartCo Table name: PART_V1\\nDatabase name: Ch04_PartCo\\nTable name: P ARTTable name: COMPONENT\\nFIGURE 4.20   THE IMPLEMENTATION OF THE M:N RECURSIVE \\nRELATIONSHIP “PART CONTAINS PART”  \\nFIGURE 4.21   IMPLEMENTATION OF THE M:N RECURSIVE RELATIONSHIP \\n“COURSE REQUIRES COURSE”  \\nDatabase name: Ch04_TinyCollege Table name: COURSE\\nTable name: PREREQ\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eee41af7-0c57-4589-bf6f-6583857a6abe', embedding=None, metadata={'page_label': '138', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='138   Part 2     Design Concepts\\nFor the data shown in Figure 4.18, the correct answer to both questions is “No. ” It is \\npossible to be an employee and not have another employee as a spouse. Also, it is possible \\nto be an employee and not be the spouse of another employee.\\nReferential integrity deals with the correspondence of values in the foreign key with \\nvalues in the related primary key. Referential integrity is not bidirectional, and therefore \\nanswers only one question:\\n• Must every employee spouse be a valid employee?\\nFor the data shown in Figure 4.18, the correct answer is “Y es. ” Another way to frame \\nthis question is to consider whether every value provided for the EMP_SPOUSE attri -\\nbute must match some value in the EMP_NUM attribute.\\nIn practical terms, both participation and referential integrity involve the values used as \\nprimary keys and foreign keys to implement the relationship. Referential integrity requires \\nthat the values in the foreign key correspond to values in the primary key. In one direction, \\nparticipation considers whether the foreign key can contain a null. In Figure 4.18, for example, \\nemployee Robert Delaney is not required to have a value in EMP_SPOUSE. In the other direc -\\ntion, participation considers whether every value in the primary key must appear as a value in \\nthe foreign key. In Figure 4.18, for example, employee Robert Delaney’s value for EMP_NUM \\n(348) is not required to appear as a value in EMP_SPOUSE for any other employee.\\n4-1k  Associative (Composite) Entities\\nM:N relationships are a valid construct at the conceptual level, and therefore are found fre -\\nquently during the ER modeling process. However, implementing the M:N relationship, Finally, the 1:M recursive relationship “EMPLOYEE manages EMPLOYEE, ” shown in \\nFigure 4.17, is implemented in Figure 4.22.\\nOne common pitfall when working with unary relationships is to confuse participa -\\ntion with referential integrity. In theory, participation and referential integrity are very \\ndifferent concepts and are normally easy to distinguish in binary relationships. In practi -\\ncal terms, conversely, participation and referential integrity are very similar because they \\nare both implemented through constraints on the same set of attributes. This similarity \\noften leads to confusion when the concepts are applied within the limited structure of \\na unary relationship. Consider the unary 1:1 spousal relationship between employees, \\nwhich is described in Figure 4.18. Participation, as described previously, is bidirectional, \\nmeaning that it must be addressed in both directions along the relationship. Participa -\\ntion in Figure 4.18 addresses the following questions:\\n• Must every employee have a spouse who is an employee?\\n• Must every employee be a spouse to another employee?\\nFIGURE 4.22   IMPLEMENTATION OF THE 1:M RECURSIVE RELATIONSHIP \\n“EMPLOYEE MANAGES EMPLOYEE”  \\nDatabase name: Ch04_PartCo\\nTable name: EMPLOYEE_V2\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c20f4f9e-2484-474c-9877-75560f2d9923', embedding=None, metadata={'page_label': '139', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    139\\nparticularly in the relational model, requires the use of an additional entity, as you learned \\nin Chapter 3. The ER model uses the associative entity to represent an M:N relationship \\nbetween two or more entities. This associative entity, also called a composite  or bridge entity , \\nis in a 1:M relationship with the parent entities and is composed of the primary key attributes \\nof each parent entity. Furthermore, the associative entity can have additional attributes of its \\nown, as shown by the ENROLL associative entity in Figure 4.23. When using the Crow’s \\nFoot notation, the associative entity is identified as a strong (identifying) relationship, as \\nindicated by the solid relationship lines between the parents and the associative entity.\\nNote that the composite ENROLL entity in Figure 4.23 is existence-dependent on the \\nother two entities; the composition of the ENROLL entity is based on the primary keys \\nof the entities that are connected by the composite entity. The composite entity may also \\ncontain additional attributes that play no role in the connective process. For example, \\nalthough the entity must be composed of at least the STUDENT and CLASS primary \\nkeys, it may also include such additional attributes as grades, absences, and other data \\nuniquely identified by the student’s performance in a specific class.\\nFinally, keep in mind that the ENROLL table’s key (CLASS_CODE and STU_NUM) \\nis composed entirely of the primary keys of the CLASS and STUDENT tables. Therefore, \\nno null entries are possible in the ENROLL table’s key attributes.\\nImplementing the small database shown in Figure 4.23 requires that you define the \\nrelationships clearly. Specifically, you must know the “1” and the “M” sides of each rela -\\ntionship, and you must know whether the relationships are mandatory or optional. For \\nexample, note the following point:\\n• A class may exist (at least at the start of registration) even though it contains no stu -\\ndents. Therefore, in Figure 4.24, an optional symbol should appear on the STUDENT \\nside of the M:N relationship between STUDENT and CLASS.\\nY ou might argue that to be classified as a STUDENT, a person must be enrolled in at least \\none CLASS. Therefore, CLASS is mandatory to STUDENT from a purely conceptual point \\nof view. However, when a student is admitted to college, that student has not yet signed \\nup for any classes. Therefore, at least initially , CLASS is optional to STUDENT. Note that \\nthe practical considerations in the data environment help dictate the use of optionalities. Database name: Ch04_CollegeT ry Table name: STUDENT\\nTable name: ENROLL\\nTable name: CLASS\\nFIGURE 4.23   CONVERTING THE M:N RELATIONSHIP INTO TWO 1:M  \\nRELATIONSHIPS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='903865ef-a575-456b-b258-f7ce2751b996', embedding=None, metadata={'page_label': '140', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='140   Part 2     Design Concepts\\nIf CLASS is not optional to STUDENT from a database point of view, a class assignment \\nmust be made when the student is admitted. However, that’s not how the process actually \\nworks, and the database design must reflect this. In short, the optionality reflects practice.\\nBecause the M:N relationship between STUDENT and CLASS is decomposed into two \\n1:M relationships through ENROLL, the optionalities must be transferred to ENROLL. \\n(See Figure 4.25.) In other words, it now becomes possible for a class not to occur in \\nENROLL if no student has signed up for that class. Because a class need not occur in \\nENROLL, the ENROLL entity becomes optional to CLASS. Also, because the ENROLL \\nentity is created before any students have signed up for a class, the ENROLL entity is also \\noptional to STUDENT, at least initially.\\n• As students begin to sign up for their classes, they will be entered into the ENROLL \\nentity. Naturally, if a student takes more than one class, that student will occur more \\nthan once in ENROLL. For example, note that in the ENROLL table in Figure 4.23, \\nSTU_NUM = 321452 occurs three times. On the other hand, each student occurs only \\nonce in the STUDENT entity. (Note that the STUDENT table in Figure 4.23 has only \\none STU_NUM = 321452 entry.) Therefore, in Figure 4.25, the relationship between \\nSTUDENT and ENROLL is shown to be 1:M, with the “M” on the ENROLL side.\\n• As you can see in Figure 4.23, a class can occur more than once in the ENROLL table. \\nFor example, CLASS_CODE = 10014 occurs twice. However, CLASS_CODE = 10014 \\noccurs only once in the CLASS table to reflect that the relationship between CLASS \\nand ENROLL is 1:M. Note that in Figure 4.25, the “M” is located on the ENROLL side, \\nwhile the “1” is located on the CLASS side.\\n4-2 Developing an ER Diagram\\nThe process of database design is iterative rather than a linear or sequential process. The verb \\niterate  means “to do again or repeatedly. ” Thus, an iterative process  is based on repetition of \\nprocesses and procedures. Building an ERD usually involves the following activities:\\n• Create a detailed narrative of the organization’s description of operations.\\n• Identify the business rules based on the description of operations.FIGURE 4.25  A COMPOSITE ENTITY IN AN ERD  \\niterative process\\nA process based on \\nrepetition of steps and \\nprocedures.FIGURE 4.24  THE M:N RELATIONSHIP BETWEEN STUDENT AND CLASS\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4927117e-3086-4a0f-ba68-3804b54db8bc', embedding=None, metadata={'page_label': '141', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    141\\n• Identify the main entities and relationships from the business rules.\\n• Develop the initial ERD.\\n• Identify the attributes and primary keys that adequately describe the entities.\\n• Revise and review the ERD.\\nDuring the review process, additional objects, attributes, and relationships proba -\\nbly will be uncovered. Therefore, the basic ERM will be modified to incorporate the \\nnewly discovered ER components. Subsequently, another round of reviews might yield \\nadditional components or clarification of the existing diagram. The process is repeated \\nuntil the end users and designers agree that the ERD is a fair representation of the \\norganization’s activities and functions.\\nDuring the design process, the database designer does not depend simply on inter -\\nviews to help define entities, attributes, and relationships. A surprising amount of infor -\\nmation can be gathered by examining the business forms and reports that an organization \\nuses in its daily operations.\\nTo illustrate the use of the iterative process that ultimately yields a workable ERD, \\nstart with an initial interview with the Tiny College administrators. The interview pro -\\ncess yields the following business rules:\\n1. Tiny College (TC) is divided into several schools: business, arts and sciences, educa -\\ntion, and applied sciences. Each school is administered by a dean who is a professor. \\nEach professor can be the dean of only one school, and a professor is not required to be \\nthe dean of any school. Therefore, a 1:1 relationship exists between PROFESSOR and \\nSCHOOL. Note that the cardinality can be expressed by writing (1,1) next to the entity \\nPROFESSOR and (0,1) next to the entity SCHOOL.\\n2. Each school comprises several departments. For example, the school of business has an \\naccounting department, a management/marketing department, an economics/finance \\ndepartment, and a computer information systems department. Note again the cardinal -\\nity rules: The smallest number of departments operated by a school is one, and the larg -\\nest number of departments is indeterminate (N). On the other hand, each department \\nbelongs to only a single school; thus, the cardinality is expressed by (1,1). That is, the \\nminimum number of schools to which a department belongs is one, as is the maximum \\nnumber. Figure 4.26 illustrates these first two business rules.\\nFIGURE 4.26  THE FIRST TINY COLLEGE ERD SEGMENT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='70d2d467-dc33-48f7-b87c-2f8af2c80de8', embedding=None, metadata={'page_label': '142', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='142   Part 2     Design Concepts\\n3. Each department may offer courses. For example, the management/marketing depart -\\nment offers courses such as Introduction to Management, Principles of Marketing, \\nand Production Management. The ERD segment for this condition is shown in Fig -\\nure 4.27. Note that this relationship is based on the way Tiny College operates. For \\nexample, if Tiny College had some departments that were classified as “research only, ” \\nthey would not offer courses; therefore, the COURSE entity would be optional to the \\nDEPARTMENT entity.\\n4. The relationship between COURSE and CLASS was illustrated in Figure 4.9. Nev -\\nertheless, it is worth repeating that a CLASS is a section of a COURSE. That is, a \\ndepartment may offer several sections (classes) of the same database course. Each \\nof those classes is taught by a professor at a given time in a given place. In short, \\na 1:M relationship exists between COURSE and CLASS. Additionally, each class \\nis offered during a given semester. SEMESTER defines the year and the term that \\nthe class will be offered. Note that this is different from the date when the student \\nactually enrolls in a class. For example, students are able to enroll in summer and \\nfall term classes near the end of the spring term. It is possible that the Tiny Col -\\nlege calendar is set with semester beginning and ending dates prior to the creation \\nof the semester class schedule so CLASS is optional to SEMESTER. This design \\nwill also help for reporting purposes, for example, you could answer questions \\nsuch as: what classes were offered X semester? Or, what classes did student Y take \\non semester X? Because a course may exist in Tiny College’s course catalog even \\nwhen it is not offered as a class in a given semester, CLASS is optional to COURSE. \\nTherefore, the relationships between SEMESTER, COURSE, and CLASS look like \\nFigure 4.28.\\nIt is again appropriate to evaluate the reason for maintaining the 1:1 relationship between \\nPROFESSOR and SCHOOL in the “PROFESSOR is dean of SCHOOL” relationship. It is worth \\nrepeating that the existence of 1:1 relationships often indicates a misidentification of attri -\\nbutes as entities. In this case, the 1:1 relationship could easily be eliminated by storing the \\ndean’s attributes in the SCHOOL entity. This solution would also make it easier to answer \\nthe queries “Who is the dean?” and “What are the dean’s credentials?” The downside of this \\nsolution is that it requires the duplication of data that is already stored in the PROFESSOR \\ntable, thus setting the stage for anomalies. However, because each school is run by a single \\ndean, the problem of data duplication is rather minor. The selection of one approach over \\nanother often depends on information requirements, transaction speed, and the database \\ndesigner’s professional judgment. In short, do not use 1:1 relationships lightly, and make \\nsure that each 1:1 relationship within the database design is defensible.Note\\nFIGURE 4.27  THE SECOND TINY COLLEGE ERD SEGMENT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b12cf39-ba07-4ce9-be08-fb3e3cdd1a76', embedding=None, metadata={'page_label': '143', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    143\\n5. Each department should have one or more professors assigned to it. One and only \\none of those professors chairs the department, and no professor is required to \\naccept the chair position. Therefore, DEPARTMENT is optional to PROFESSOR \\nin the “chairs” relationship. Those relationships are summarized in the ER segment \\nshown in Figure 4.29.FIGURE 4.28  THE THIRD TINY COLLEGE ERD SEGMENT  \\nFIGURE 4.29  THE FOURTH TINY COLLEGE ERD SEGMENT  \\n6. Each professor may teach up to four classes; each class is a section of a course. A pro -\\nfessor may also be on a research contract and teach no classes at all. The ERD segment \\nin Figure 4.30 depicts those conditions.\\n7. A student may enroll in several classes but take each class only once during any \\ngiven enrollment period. For example, during the current enrollment period, a \\nstudent may decide to take five classes—Statistics, Accounting, English, Data -\\nbase, and History—but that student would not be enrolled in the same Statistics \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2dfaf779-d7fe-41bc-af9d-6b4d9dfc9b2a', embedding=None, metadata={'page_label': '144', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='144   Part 2     Design Concepts\\nclass five times during the enrollment period! Each student may enroll in up to \\nsix classes, and each class may have up to 35 students, thus creating an M:N rela -\\ntionship between STUDENT and CLASS. Because a CLASS can initially exist at \\nthe start of the enrollment period even though no students have enrolled in it, \\nSTUDENT is optional to CLASS in the M:N relationship. This M:N relationship \\nmust be divided into two 1:M relationships through the use of the ENROLL entity, \\nshown in the ERD segment in Figure 4.31. However, note that the optional sym -\\nbol is shown next to ENROLL. If a class exists but has no students enrolled in \\nit, that class does not occur in the ENROLL table. Note also that the ENROLL \\nentity is weak: it is existence-dependent, and its (composite) PK is composed of \\nthe PKs of the STUDENT and CLASS entities. Y ou can add the cardinalities (0,6) \\nand (0,35) next to the ENROLL entity to reflect the business rule constraints, as \\nshown in Figure 4.31. (Visio Professional does not automatically generate such \\ncardinalities, but you can use a text box to accomplish that task.)FIGURE 4.30  THE FIFTH TINY COLLEGE ERD SEGMENT  \\nFIGURE 4.31  THE SIXTH TINY COLLEGE ERD SEGMENT  \\n8. Each department has several (or many) students whose major is offered by that \\ndepartment. However, each student has only a single major and is therefore asso -\\nciated with a single department. (See Figure 4.32.) However, in the Tiny College \\nenvironment, it is possible—at least for a while—for a student not to declare a major \\nfield of study. Such a student would not be associated with a department; therefore, \\nDEPARTMENT is optional to STUDENT. It is worth repeating that the relation -\\nships between entities and the entities themselves reflect the organization’s operat -\\ning environment. That is, the business rules define the ERD components.\\n9. Each student has an advisor in his or her department; each advisor counsels several \\nstudents. An advisor is also a professor, but not all professors advise students. There -\\nfore, STUDENT is optional to PROFESSOR in the “PROFESSOR advises STUDENT” \\nrelationship. (See Figure 4.33.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='56ea4439-bf96-41a0-a4a6-e978a0fa4aa2', embedding=None, metadata={'page_label': '145', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    145\\n10.  As you can see in Figure 4.34, the CLASS entity contains a ROOM_CODE attribute. \\nGiven the naming conventions, it is clear that ROOM_CODE is an FK to another \\nentity. Clearly, because a class is taught in a room, it is reasonable to assume that \\nthe ROOM_CODE in CLASS is the FK to an entity named ROOM. In turn, each \\nroom is located in a building. So, the last Tiny College ERD is created by observing \\nthat a BUILDING can contain many ROOMs, but each ROOM is found in a single \\nBUILDING. In this ERD segment, it is clear that some buildings do not contain \\n(class) rooms. For example, a storage building might not contain any named rooms \\nat all.FIGURE 4.32  THE SEVENTH TINY COLLEGE ERD SEGMENT  \\nFIGURE 4.33  THE EIGHTH TINY COLLEGE ERD SEGMENT  \\nFIGURE 4.34  THE NINTH TINY COLLEGE ERD SEGMENT  \\nUsing the preceding summary, you can identify the following entities:\\nPROFESSOR SCHOOL DEPARTMENT\\nCOURSE CLASS SEMESTER\\nSTUDENT BUILDING ROOM\\nENROLL (the associative entity between STUDENT and CLASS)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7e146e80-fe9f-4ef5-97f6-5e6a825fa0c7', embedding=None, metadata={'page_label': '146', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='146   Part 2    Design Concepts\\nOnce you have discovered the relevant entities, you can define the initial set of \\nrelationships among them. Next, you describe the entity attributes. Identifying the \\nattributes of the entities helps you to better understand the relationships among enti-ties. Table 4.4 summarizes the ERM’s components, and names the entities and their relations.\\nTABLE 4.4\\nCOMPONENTS OF THE ERM\\nENTITY RELATIONSHIP CONNECTIVITY ENTITY\\nSCHOOL operates 1:M DEPARTMENT\\nDEPARTMENT has 1:M STUDENT\\nDEPARTMENT employs 1:M PROFESSOR\\nDEPARTMENT offers 1:M COURSE\\nCOURSE generates 1:M CLASS\\nSEMESTER includes 1:M CLASS\\nPROFESSOR is dean of 1:1 SCHOOL\\nPROFESSOR chairs 1:1 DEPARTMENT\\nPROFESSOR teaches 1:M CLASS\\nPROFESSOR advises 1:M STUDENT\\nSTUDENT enrolls in M:N CLASS\\nBUILDING contains 1:M ROOM\\nROOM is used for 1:M CLASS\\nNote: ENROLL is the composite entity that implements the M:N relationship “STUDENT enrolls in CLASS. ”\\nY ou must also define the connectivity and cardinality for the just-discovered rela-\\ntions based on the business rules. However, to avoid crowding the diagram, the car -\\ndinalities are not shown. Figure 4.35 shows the Crow’s Foot ERD for Tiny College. Note that this is an implementation-ready model, so it shows the ENROLL compos-ite entity.\\nFigure 4.36 shows the conceptual UML class diagram for Tiny College. Note that \\nthis class diagram depicts the M:N relationship between STUDENT and CLASS. Fig-ure 4.37 shows the implementation-ready UML class diagram for Tiny College (note that the ENROLL composite entity is shown in this class diagram). If you are a good observer, you will also notice that the UML class diagrams in Figures 4.36 and 4.37 show the entity and attribute names but do not identify the primary key attributes. The reason goes back to UML ’s roots. UML class diagrams are an object-oriented modeling language, and therefore do not support the notion of “primary or foreign keys” found mainly in the relational world. Rather, in the object-oriented world, objects inherit a unique object identifier at creation time. For more information, see Appendix G,  \\nObject-Oriented Databases.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bbb41185-ca9e-4930-88c7-ae5c22ae4777', embedding=None, metadata={'page_label': '147', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    147\\nFIGURE 4.35  THE COMPLETED TINY COLLEGE ERD\\n4-3 Database Design Challenges: Conflicting Goals\\nDatabase designers must often make design compromises that are triggered by conflict -\\ning goals, such as adherence to design standards (design elegance), processing speed, and \\ninformation requirements. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='856607d8-4dcd-4bbc-b0fb-60527b2b2210', embedding=None, metadata={'page_label': '148', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='148   Part 2     Design Concepts\\n• Design standards . The database design must conform to design standards. Such stan -\\ndards guide you in developing logical structures that minimize data redundancies, \\nthereby minimizing the likelihood that destructive data anomalies will occur. Y ou \\nhave also learned how standards prescribe avoiding nulls to the greatest extent pos -\\nsible. In fact, you have learned that design standards govern the presentation of all \\ncomponents within the database design. In short, design standards allow you to work \\nwith well-defined components and to evaluate the interaction of those components \\nwith some precision. Without design standards, it is nearly impossible to formulate \\na proper design process, to evaluate an existing design, or to trace the likely logical \\nimpact of changes in design.\\n• Processing speed . In many organizations, particularly those that generate large num -\\nbers of transactions, high processing speeds are often a top priority in database \\ndesign. High processing speed means minimal access time, which may be achieved \\nby minimizing the number and complexity of logically desirable relationships. FIGURE 4.36  THE CONCEPTUAL UML CLASS DIAGRAM FOR TINY COLLEGE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8cea3e64-4701-4243-a685-d66faec68507', embedding=None, metadata={'page_label': '149', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    149\\nFor example, a “perfect” design might use a 1:1 relationship to avoid nulls, while a \\ndesign that emphasizes higher transaction speed might combine the two tables to \\navoid the use of an additional relationship, using dummy entries to avoid the nulls. \\nIf the focus is on data-retrieval speed, you might also be forced to include derived \\nattributes in the design.\\n• Information requirements . The quest for timely information might be the focus of \\ndatabase design. Complex information requirements may dictate data transfor -\\nmations, and they may expand the number of entities and attributes within the \\ndesign. Therefore, the database may have to sacrifice some of its “clean” design \\nstructures and high transaction speed to ensure maximum information genera -\\ntion. For example, suppose that a detailed sales report must be generated period -\\nically. The sales report includes all invoice subtotals, taxes, and totals; even the \\ninvoice lines include subtotals. If the sales report includes hundreds of thousands \\n(or even millions) of invoices, computing the totals, taxes, and subtotals is likely FIGURE 4.37  THE IMPLEMENTATION-READY UML CLASS DIAGRAM FOR TINY COLLEGE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0cb30aac-c3bb-4607-ba59-85308a68296f', embedding=None, metadata={'page_label': '150', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='150   Part 2    Design Concepts\\nto take some time. If those computations had been made and the results had been \\nstored as derived attributes in the INVOICE and LINE tables at the time of the transaction, the real-time transaction speed might have declined. However, that loss of speed would only be noticeable if there were many simultaneous transac-tions. The cost of a slight loss of transaction speed at the front end and the addi-tion of multiple derived attributes is likely to pay off when the sales reports are generated (not to mention that it will be simpler to generate the queries).\\nA design that meets all logical requirements and design conventions is an import-\\nant goal. However, if this perfect design fails to meet the customer’s transaction speed and information requirements, the designer will not have done a proper job from the end user’s point of view. Compromises are a fact of life in the real world of database design.\\nEven while focusing on the entities, attributes, relationships, and constraints, the \\ndesigner should begin thinking about end-user requirements such as performance, secu-rity, shared access, and data integrity. The designer must consider processing require-ments and verify that all update, retrieval, and deletion options are available. Finally, a design is of little value unless the end product can deliver all specified query and report-ing requirements.\\nY ou will probably discover that even the best design process produces an ERD that \\nrequires further changes mandated by operational requirements. Such changes should not discourage you from using the process. ER modeling is essential in the development of a sound design that can meet the demands of adjustment and growth. Using ERDs yields perhaps the richest bonus of all: a thorough understanding of how an organization really functions.\\nOccasionally, design and implementation problems do not yield “clean” implemen-\\ntation solutions. To get a sense of the design and implementation choices a database designer faces, you will revisit the 1:1 recursive relationship “EMPLOYEE is married to EMPLOYEE, ” first examined in Figure 4.18. Figure 4.38 shows three different ways of implementing such a relationship.\\nNote that the EMPLOYEE_V1 table in Figure 4.38 is likely to yield data anomalies. \\nFor example, if Anne Jones divorces Anton Shapiro, two records must be updated—by setting the respective EMP_SPOUSE values to null—to properly reflect that change. If only one record is updated, inconsistent data occurs. The problem becomes even worse if several of the divorced employees then marry each other. In addition, that implementa-tion also produces undesirable nulls for employees who are not  married to other employ-\\nees in the company.\\nAnother approach would be to create a new entity shown as MARRIED_V1 in a 1:M \\nrelationship with EMPLOYEE. (See Figure 4.38.) This second implementation does eliminate the nulls for employees who are not married to other employees in the same company. (Such employees would not be entered in the MARRIED_V1 table.) However, this approach still yields possible duplicate values. For example, the marriage between employees 345 and 347 may still appear twice, once as 345,347 and once as 347,345. (Because each of those permutations is unique the first time it appears, the creation of a unique index will not solve the problem.)\\nAs you can see, the first two implementations yield several problems:\\n•\\n  Both solutions use synonyms. The EMPLOYEE_V1 table uses EMP_NUM and EMP_SPOUSE to refer to an employee. The MARRIED_V1 table uses the same synonyms.\\n•\\n Both solutions are likely to produce redundant data. For example, it is possible to enter employee 345 as married to employee 347 and to enter employee 347 as married to employee 345.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6c340169-b266-4428-a1a1-99c1dde4b177', embedding=None, metadata={'page_label': '151', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    151\\n• Both solutions are likely to produce inconsistent data. For example, it is possible to \\nhave data pairs such as 345,347 and 348,345 and 347,349, none of which will vio -\\nlate entity integrity requirements because they are all unique. However, this solution \\nwould allow any one employee to be married to multiple employees.\\nA third approach would be to have two new entities, MARRIAGE and MARPART, in a \\n1:M relationship. MARPART contains the EMP_NUM foreign key to EMPLOYEE. (See \\nthe relational diagram in Figure 4.38.) However, even this approach has issues. It requires \\nthe collection of additional data regarding the employees’ marriage—the marriage date. \\nIf the business users do not need this data, then requiring them to collect it would be \\ninappropriate. To ensure that an employee occurs only once in any given marriage, you \\nwould have to create a unique index on the EMP_NUM attribute in the MARPART table. \\nAnother potential problem with this solution is that the database implementation would \\ntheoretically allow more than two employees to “participate” in the same marriage.\\nAs you can see, a recursive 1:1 relationship yields many different solutions with \\nvarying degrees of effectiveness and adherence to basic design principles. Any of \\nthe preceding solutions would likely involve the creation of program code to help \\nensure the integrity and consistency of the data. In a later chapter, you will exam -\\nine the creation of database triggers that can do exactly that. Y our job as a database \\ndesigner is to use your professional judgment to yield a solution that meets the  FIGURE 4.38  VARIOUS IMPLEMENTATIONS OF THE 1:1 RECURSIVE RELATIONSHIP  \\nTable name: EMPLOYEE_V1 Database name: Ch04_PartCo\\nFirst implementation\\nTable name: EMPLOYEE Table name: MARRIED_V1\\nSecond implementation\\nTable name: MARRIAGE Table name: MARP ART\\n Table name: EMPLOYEE\\nThe relational diagram for the third implementation\\nThird implementation\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b57ffe3-baa9-45d3-89f5-a6c9224dc82f', embedding=None, metadata={'page_label': '152', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='152   Part 2    Design Concepts\\nrequirements imposed by business rules, processing requirements, and basic \\ndesign principles.\\nFinally, document, document, and document! Put all design activities in writing, \\nand then review what you have written. Documentation not only helps you stay on track during the design process, it also enables you and your coworkers to pick up the design thread when the time comes to modify the design. Although the need for doc-umentation should be obvious, one of the most vexing problems in database and sys-tems analysis work is that this need is often ignored in the design and implementation stages. The development of organizational documentation standards is an important aspect of ensuring data compatibility and coherence.\\nSummary\\n• The ERM uses ERDs to represent the conceptual database as viewed by the end user. The ERM’s main components are entities, relationships, and attributes. The ERD includes connectivity and cardinality notations, and can also show relationship strength, relationship participation (optional or mandatory), and degree of relation-ship (such as unary, binary, or ternary).\\n•\\n Connectivity describes the relationship classification (1:1, 1:M, or M:N). Cardinality expresses the specific number of entity occurrences associated with an occurrence of a related entity. Connectivities and cardinalities are usually based on business rules.\\n•\\n In the ERM, an M:N relationship is valid at the conceptual level. However, when imple-menting the ERM in a relational database, the M:N relationship must be mapped to a set of 1:M relationships through a composite entity.\\n•\\n ERDs may be based on many different ERMs. However, regardless of which model is selected, the modeling logic remains the same. Because no ERM can accurately por -\\ntray all real-world data and action constraints, application software must be used to augment the implementation of at least some of the business rules.\\n•\\n Unified Modeling Language (UML) class diagrams are used to represent the static data structures in a data model. The symbols used in the UML class and ER diagrams are very similar. The UML class diagrams can be used to depict data models at the conceptual or implementation abstraction levels.\\n•\\n Database designers, no matter how well they can produce designs that conform to all applicable modeling conventions, are often forced to make design compromises. Those compromises are required when end users have vital transaction-speed and information requirements that prevent the use of “perfect” modeling logic and adher -\\nence to all modeling conventions. Therefore, database designers must use their pro-fessional judgment to determine how and to what extent the modeling conventions are subject to modification. To ensure that their professional judgments are sound, database designers must have detailed and in-depth knowledge of data-modeling conventions. It is also important to document the design process from beginning to end, which helps keep the design process on track and allows for easy modifications in the future.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7c9f875f-206c-4ddc-8962-a6f16bc46b31', embedding=None, metadata={'page_label': '153', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    153\\n1. What two conditions must be met before an entity can be classified as a weak entity? \\nGive an example of a weak entity.\\n2. What is a strong (or identifying) relationship, and how is it depicted in a Crow’s Foot \\nERD?\\n3. Given the business rule “an employee may have many degrees, ” discuss its effect on \\nattributes, entities, and relationships. ( Hint:  Remember what a multivalued attribute \\nis and how it might be implemented.)\\n4. What is a composite entity, and when is it used?\\n5. Suppose you are working within the framework of the conceptual model in  \\nFigure Q4.5.\\nbinary relationship\\ncardinality\\ncomposite attribute\\ncomposite identifier\\nconnectivity\\nderived attribute\\nexistence-dependent\\nexistence-independent\\nidentifier\\niterative processmandatory participation\\nmultivalued attribute\\noptional attribute\\noptional participation\\nparticipants\\nrecursive relationship\\nregular entity\\nrelational schema\\nrelationship degree\\nrequired attributesimple attribute\\nsingle-valued attribute\\nstrong entity\\nstrong (identifying) \\nrelationship\\nternary relationship\\nunary relationship\\nweak entity\\nweak (non-identifying) \\nrelationshipKey Terms\\nReview Questions\\nFlashcards and crossword \\npuzzles for key term practice \\nare available at  \\nwww.cengagebrain.com .Online \\nContent\\nFIGURE Q4.5  THE CONCEPTUAL MODEL FOR QUESTION 5  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fcbb91e5-4837-4b5e-959c-49cb2a00784f', embedding=None, metadata={'page_label': '154', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='154   Part 2     Design Concepts\\nGiven the conceptual model in Figure Q4.5:\\n  a. Write the business rules that are reflected in it.\\n  b. Identify all of the cardinalities.\\n6. What is a recursive relationship? Give an example.\\n7. How would you (graphically) identify each of the following ERM components in \\na Crow’s Foot notation?\\n  a. an entity\\n  b. the cardinality (0,N)\\n  c. a weak relationship\\n  d. a strong relationship\\n8. Discuss the difference between a composite key and a composite attribute. How \\nwould each be indicated in an ERD?\\n9. What two courses of action are available to a designer who encounters a multivalued \\nattribute?\\n10. What is a derived attribute? Give an example.\\n11. How is a relationship between entities indicated in an ERD? Give an example using \\nthe Crow’s Foot notation.\\n12. Discuss two ways in which the 1:M relationship between COURSE and CLASS can \\nbe implemented. ( Hint:  Think about relationship strength.)\\n13. How is a composite entity represented in an ERD, and what is its function? Illustrate \\nthe Crow’s Foot notation.\\n14. What three (often conflicting) database requirements must be addressed in database \\ndesign?\\n15. Briefly, but precisely, explain the difference between single-valued attributes and \\nsimple attributes. Give an example of each.\\n16. What are multivalued attributes, and how can they be handled within the database \\ndesign?\\nQuestions 17–20 are based on the ERD in Figure Q4.17.\\nFIGURE Q4.17  THE ERD FOR QUESTIONS 17-20  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='52f35c9f-939a-4121-84ad-c530ba8b0a77', embedding=None, metadata={'page_label': '155', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    155\\n17. Write the 10 cardinalities that are appropriate for this ERD.\\n18. Write the business rules reflected in this ERD.\\n19. What two attributes must be contained in the composite entity between STORE and \\nPRODUCT? Use proper terminology in your answer.\\n20. Describe precisely the composition of the DEPENDENT weak entity’s primary key. Use proper terminology in your answer.\\n21.\\n The local city youth league needs a database system to help track children who sign up to play soccer. Data needs to be kept on each team, the children who will play on each team, and their parents. Also, data needs to be kept on the coaches for each team.\\n Draw a data model with the entities and attributes described here.\\n Entities required: Team, Player, Coach, and Parent\\n Attributes required:\\n Team: Team ID number, Team name, and Team colors\\n Player: Player ID number, Player first name, Player last name, and Player age\\n Coach: Coach ID number, Coach first name, Coach last name, and Coach home phone number\\n Parent: Parent ID number, Parent last name, Parent first name, Home phone num-ber, and Home address (Street, City, State, and Zip code)\\n The following relationships must be defined:\\n•  Team is related to Player.\\n• Team is related to Coach.\\n• Player is related to Parent.\\n Connectivities and participations are defined as follows:\\n• A Team may or may not have a Player.\\n• A Player must have a Team.\\n• A Team may have many Players.\\n• A Player has only one Team.\\n• A Team may or may not have a Coach.\\n• A Coach must have a Team.\\n• A Team may have many Coaches.\\n• A Coach has only one Team.\\n• A Player must have a Parent.\\n• A Parent must have a Player.\\n• A Player may have many Parents.\\n• A Parent may have many Players.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9cf40fb7-2a31-47a7-9c01-9437ee1b0c99', embedding=None, metadata={'page_label': '156', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='156   Part 2    Design Concepts\\n1. Use the following business rules to create a Crow’s Foot ERD. Write all appropriate \\nconnectivities and cardinalities in the ERD.\\n• A department employs many employees, but each employee is employed by only one department.\\n•\\n Some employees, known as “rovers, ” are not assigned to any department.\\n• A division operates many departments, but each department is operated by only one division.\\n•\\n An employee may be assigned many projects, and a project may have many employees assigned to it.\\n•\\n A project must have at least one employee assigned to it.\\n• One of the employees manages each department, and each department is man-aged by only one employee.\\n•\\n One of the employees runs each division, and each division is run by only one employee.\\n2.\\n Create a complete ERD in Crow’s Foot notation that can be implemented in the relational model using the following description of operations. Hot Water (HW) is a small start-up company that sells spas. HW does not carry any stock. A few spas are set up in a simple warehouse so customers can see some of the models available, but any products sold must be ordered at the time of the sale.\\n•\\n HW can get spas from several different manufacturers.\\n• Each manufacturer produces one or more different brands of spas.\\n• Each and every brand is produced by only one manufacturer.\\n• Every brand has one or more models.\\n• Every model is produced as part of a brand. For example, Iguana Bay Spas is a manufacturer that produces Big Blue Iguana spas, a premium-level brand, and Lazy Lizard spas, an entry-level brand. The Big Blue Iguana brand offers several models, including the BBI-6, an 81-jet spa with two 6-hp motors, and the BBI-10, a 102-jet spa with three 6-hp motors.\\n•\\n Every manufacturer is identified by a manufacturer code. The company name, address, area code, phone number, and account number are kept in the system for every manufacturer.\\n•\\n For each brand, the brand name and brand level (premium, mid-level, or entry-level) are kept in the system.\\n•\\n For each model, the model number, number of jets, number of motors, number of horsepower per motor, suggested retail price, HW retail price, dry weight, water capacity, and seating capacity must be kept in the system.\\n3.\\n The Jonesburgh County Basketball Conference (JCBC) is an amateur basketball association. Each city in the county has one team as its representative. Each team has a maximum of 12 players and a minimum of 9 players. Each team also has up to 3 coaches (offensive, defensive, and physical training coaches). During the season, Problems\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58575187-a93b-4fc2-bbe8-e82d85053794', embedding=None, metadata={'page_label': '157', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    157\\neach team plays 2 games (home and visitor) against each of the other teams. Given \\nthose conditions, do the following:\\n• Identify the connectivity of each relationship.\\n• Identify the type of dependency that exists between CITY and TEAM.\\n• Identify the cardinality between teams and players and between teams and city.\\n• Identify the dependency between COACH and TEAM and between TEAM and PLAYER.\\n•\\n Draw the Chen and Crow’s Foot ERDs to represent the JCBC database.\\n• Draw the UML class diagram to depict the JCBC database.\\n4. Create an ERD based on the Crow’s Foot notation using the following requirements:\\n• An INVOICE is written by a SALESREP . Each sales representative can write many invoices, but each invoice is written by a single sales representative.\\n•\\n The INVOICE is written for a single CUSTOMER. However, each customer can have many invoices.\\n•\\n An INVOICE can include many detail lines (LINE), each of which describes one product bought by the customer.\\n•\\n The product information is stored in a PRODUCT entity.\\n• The product’s vendor information is found in a VENDOR entity.\\n5. The Hudson Engineering Group (HEG) has contacted you to create a conceptual model whose application will meet the expected database requirements for the com-pany’s training program. The HEG administrator gives you the following description of the training group’s operating environment. (Hint:  Some of the following sentences \\nidentify the volume of data rather than cardinalities. Can you tell which ones?)\\n The HEG has 12 instructors and can handle up to 30 trainees per class. HEG offers 5 Advanced Technology courses, each of which may generate several classes. If a class has fewer than 10 trainees, it will be canceled. Therefore, it is possible for a course not to generate any classes. Each class is taught by one instructor. Each instructor may teach up to 2 classes or may be assigned to do research only. Each trainee may take up to 2 classes per year.\\n Given that information, do the following:\\n  a. Define all of the entities and relationships. (Use Table 4.4 as your guide.)\\n  b.  Describe the relationship between instructor and class in terms of connectivity, cardinality, and existence dependence.\\n6.\\n Automata, Inc., produces specialty vehicles by contract. The company operates sev-eral departments, each of which builds a particular vehicle, such as a limousine, truck, van, or RV .\\n•\\n Before a new vehicle is built, the department places an order with the purchasing department to request specific components. Automata’s purchasing department is interested in creating a database to keep track of orders and to accelerate the process of delivering materials.\\n•\\n The order received by the purchasing department may contain several different items. An inventory is maintained so the most frequently requested items are delivered almost immediately. When an order comes in, it is checked to deter -\\nmine whether the requested item is in inventory. If an item is not in inventory, it must be ordered from a supplier. Each item may have several suppliers.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7191d161-0009-44ab-aed2-fc803fe91e15', embedding=None, metadata={'page_label': '158', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='158   Part 2    Design Concepts\\n Given that functional description of the processes at Automata’s purchasing depart-\\nment, do the following:\\n  a. Identify all of the main entities.\\n  b. Identify all of the relations and connectivities among entities.\\n  c. Identify the type of existence dependence in all the relationships.\\n  d.  Give at least two examples of the types of reports that can be obtained from the database.\\n7.\\n United Helpers is a nonprofit organization that provides aid to people after natural disasters. Based on the following brief description of operations, create the appropri-ate fully labeled Crow’s Foot ERD.\\n•\\n Volunteers carry out the tasks of the organization. The name, address, and tele-phone number are tracked for each volunteer. Each volunteer may be assigned to several tasks, and some tasks require many volunteers. A volunteer might be in the system without having been assigned a task yet. It is possible to have tasks that no one has been assigned. When a volunteer is assigned to a task, the system should track the start time and end time of that assignment.\\n•\\n Each task has a task code, task description, task type, and task status. For example, there may be a task with task code “101, ” a description of “answer the telephone, ” a type of “recurring, ” and a status of “ongoing. ” Another task might have a code of “102, ” a description of “prepare 5,000 packages of basic medical supplies, ” a type of “packing, ” and a status of “open. ”\\n•\\n For all tasks of type “packing, ” there is a packing list that specifies the contents of the packages. There are many packing lists to produce different packages, such as basic medical packages, child-care packages, and food packages. Each packing list has an ID number, a packing list name, and a packing list description, which describes the items that should make up the package. Every packing task is associated with only one pack-ing list. A packing list may not be associated with any tasks, or it may be associated with many tasks. Tasks that are not packing tasks are not associated with any packing list.\\n•\\n Packing tasks result in the creation of packages. Each individual package of sup-plies produced by the organization is tracked, and each package is assigned an ID number. The date the package was created and its total weight are recorded. A given package is associated with only one task. Some tasks (such as “answer the phones”) will not produce any packages, while other tasks (such as “prepare 5,000 packages of basic medical supplies”) will be associated with many packages.\\n•\\n The packing list describes the ideal  contents of each package, but it is not always \\npossible to include the ideal number of each item. Therefore, the actual items included in each package should be tracked. A package can contain many differ -\\nent items, and a given item can be used in many different packages.\\n•\\n Each item that the organization provides has an item ID number, item descrip-tion, item value, and item quantity on hand stored in the system. Along with tracking the actual items that are placed in each package, the quantity of each item placed in the package must be tracked as well. For example, a packing list may state that basic medical packages should include 100 bandages, 4 bottles of iodine, and 4 bottles of hydrogen peroxide. However, because of the limited sup-ply of items, a given package may include only 10 bandages, 1 bottle of iodine, and no hydrogen peroxide. The fact that the package includes bandages and iodine needs to be recorded along with the quantity of each item included. It is possible \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='972b66d1-fd64-42e5-a985-6acebf7f3658', embedding=None, metadata={'page_label': '159', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    159\\nfor the organization to have items that have not been included in any package yet, \\nbut every package will contain at least one item.\\n8. Using the Crow’s Foot notation, create an ERD that can be implemented for a med-ical clinic using the following business rules:\\n•\\n A patient can make many appointments with one or more doctors in the clinic, and a doctor can accept appointments with many patients. However, each appointment is made with only one doctor and one patient.\\n•\\n Emergency cases do not require an appointment. However, for appointment management purposes, an emergency is entered in the appointment book as “unscheduled. ”\\n•\\n If kept, an appointment yields a visit with the doctor specified in the appoint-ment. The visit yields a diagnosis and, when appropriate, treatment.\\n•\\n With each visit, the patient’s records are updated to provide a medical history.\\n• Each patient visit creates a bill. Each patient visit is billed by one doctor, and each doctor can bill many patients.\\n•\\n Each bill must be paid. However, a bill may be paid in many installments, and a payment may cover more than one bill.\\n•\\n A patient may pay the bill directly, or the bill may be the basis for a claim submit-ted to an insurance company.\\n•\\n If the bill is paid by an insurance company, the deductible is submitted to the patient for payment.\\n9.\\n Create a Crow’s Foot notation ERD to support the following business operations:\\n• A friend of yours has opened Professional Electronics and Repairs (PEAR) to repair smartphones, laptops, tablets, and MP3 players. She wants you to create a database to help her run her business.\\n•\\n When a customer brings a device to PEAR for repair, data must be recorded about the customer, the device, and the repair. The customer’s name, address, and a con-tact phone number must be recorded (if the customer has used the shop before, the information already in the system for the customer is verified as being cur -\\nrent). For the device to be repaired, the type of device, model, and serial number are recorded (or verified if the device is already in the system). Only customers who have brought devices into PEAR for repair will be included in this system.\\n•\\n Since a customer might sell an older device to someone else who then brings the device to PEAR for repair, it is possible for a device to be brought in for repair by more than one customer. However, each repair is associated with only one cus-tomer. When a customer brings in a device to be fixed, it is referred to as a repair request, or just “repair, ” for short. Each repair request is given a reference number, which is recorded in the system along with the date of the request, and a descrip-tion of the problem(s) that the customer wants fixed. It is possible for a device to be brought to the shop for repair many different times, and only devices that are brought in for repair are recorded in the system. Each repair request is for the repair of one and only one device. If a customer needs multiple devices fixed, then each device will require its own repair request.\\n•\\n There are a limited number of repair services that PEAR can perform. For each repair service, there is a service ID number, description, and charge. “Charge” is how much the customer is charged for the shop to perform the service, including \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='73a67cf2-aeaa-45a5-871f-6c174fb562d1', embedding=None, metadata={'page_label': '160', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='160   Part 2    Design Concepts\\nany parts used. The actual repair of a device is the performance of the services \\nnecessary to address the problems described by the customer. Completing a repair request may require the performance of many services. Each service can be performed many different times during the repair of different devices, but each service will be performed only once during a given repair request.\\n•\\n All repairs eventually require the performance of at least one service, but which services will be required may not be known at the time the repair request is made. It is possible for services to be available at PEAR but that have never been required in performing any repair.\\n•\\n Some services involve only labor activities and no parts are required, but most services require the replacement of one or more parts. The quantity of each part required in the performance of each service should also be recorded. For each part, the part number, part description, quantity in stock, and cost is recorded in the system. The cost indicated is the amount that PEAR pays for the part. Some parts may be used in more than one service, but each part is required for at least one service.\\n10.\\n Luxury-Oriented Scenic Tours (LOST) provides guided tours to groups of visitors to the Washington D.C. area. In recent years, LOST has grown quickly and is having difficulty keeping up with all of the various information needs of the company. The company’s operations are as follows:\\n•\\n LOST offers many different tours. For each tour, the tour name, approxi-mate length (in hours), and fee charged is needed. Guides are identified by an employee ID, but the system should also record a guide’s name, home address, and date of hire. Guides take a test to be qualified to lead specific tours. It is important to know which guides are qualified to lead which tours and the date that they completed the qualification test for each tour. A guide may be qualified to lead many different tours. A tour can have many different qualified guides. New guides may or may not be qualified to lead any tours, just as a new tour may or may not have any qualified guides.\\n•\\n Every tour must be designed to visit at least three locations. For each location, a name, type, and official description are kept. Some locations (such as the White House) are visited by more than one tour, while others (such as Arlington Ceme-tery) are visited by a single tour. All locations are visited by at least one tour. The order in which the tour visits each location should be tracked as well.\\n•\\n When a tour is actually given, that is referred to as an “outing. ” LOST sched-ules outings well in advance so they can be advertised and so employees can understand their upcoming work schedules. A tour can have many scheduled outings, although newly designed tours may not have any outings scheduled. Each outing is for a single tour and is scheduled for a particular date and time. All outings must be associated with a tour. All tours at LOST are guided tours, so a guide must be assigned to each outing. Each outing has one and only one guide. Guides are occasionally asked to lead an outing of a tour even if they are not officially qualified to lead that tour. Newly hired guides may not have ever been scheduled to lead any outings. Tourists, called “clients” by LOST, pay to join a scheduled outing. For each client, the name and telephone number are recorded. Clients may sign up to join many different outings, and each outing can have many clients. Information is kept only on clients who have signed up for at least one outing, although newly scheduled outings may not have any clients signed up yet.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dc6bf3fa-cf7f-436b-ba42-ed792a782980', embedding=None, metadata={'page_label': '161', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    161\\n  a. Create a Crow’s Foot notation ERD to support LOST operations.\\n  b.  The operations provided state that it is possible for a guide to lead an outing \\nof a tour even if the guide is not officially qualified to lead outings of that tour. Imagine that the business rules instead specified that a guide is never, under any circumstance, allowed to lead an outing unless he or she is qualified to lead outings of that tour. How could the data model in Part a. be modified to enforce this new constraint?\\n11.\\n The administrators of Tiny College are so pleased with your design and implemen-tation of their student registration and tracking system that they want you to expand the design to include the database for their motor vehicle pool. A brief description of operations follows:\\n•\\n Faculty members may use the vehicles owned by Tiny College for officially sanc-tioned travel. For example, the vehicles may be used by faculty members to travel to off-campus learning centers, to travel to locations at which research papers are presented, to transport students to officially sanctioned locations, and to travel for public service purposes. The vehicles used for such purposes are managed by Tiny College’s Travel Far But Slowly (TFBS) Center.\\n•\\n Using reservation forms, each department can reserve vehicles for its faculty, who are responsible for filling out the appropriate trip completion form at the end of a trip. The reservation form includes the expected departure date, vehicle type required, destination, and name of the authorized faculty member. The faculty member who picks up a vehicle must sign a checkout form to log out the vehicle and pick up a trip completion form. (The TFBS employee who releases the vehicle for use also signs the checkout form.) The faculty member’s trip completion form includes the faculty member’s identification code, the vehicle’s identification, the odometer readings at the start and end of the trip, maintenance complaints (if any), gallons of fuel purchased (if any), and the Tiny College credit card number used to pay for the fuel. If fuel is purchased, the credit card receipt must be stapled to the trip completion form. Upon receipt of the trip completion form, the faculty mem -\\nber’s department is billed at a mileage rate based on the vehicle type used: sedan, station wagon, panel truck, minivan, or minibus. (Hint:  Do not  use more entities \\nthan are necessary. Remember the difference between attributes and entities!)Cases\\nYou can use the following cases and additional problems from the Instructor Online Com-panion as the basis for class projects. These problems illustrate the challenge of translating a description of operations into a set of business rules that will define the components for an ERD you can implement successfully. These problems can also be used as the basis for discussions about the components and contents of a proper description of operations. If you want to create databases that can be successfully implemented, you must learn to separate the generic background material from the details that directly affect database design. You must also keep in mind that many constraints cannot be incorporated into the database design; instead, such constraints are handled by the application software.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e2902aa3-d86b-4327-8287-41ef64f54a92', embedding=None, metadata={'page_label': '162', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='162   Part 2    Design Concepts\\n• All vehicle maintenance is performed by TFBS. Each time a vehicle requires \\nmaintenance, a maintenance log entry is completed on a prenumbered mainte-nance log form. The maintenance log form includes the vehicle identification, brief description of the type of maintenance required, initial log entry date, date the maintenance was completed, and name of the mechanic who released the vehicle back into service. (Only mechanics who have an inspection authorization may release a vehicle back into service.)\\n•\\n As soon as the log form has been initiated, the log form’s number is transferred to a maintenance detail form; the log form’s number is also forwarded to the parts department manager, who fills out a parts usage form on which the maintenance log number is recorded. The maintenance detail form contains separate lines for each maintenance item performed, for the parts used, and for identification of the mechanic who performed the maintenance. When all maintenance items have been completed, the maintenance detail form is stapled to the maintenance log form, the maintenance log form’s completion date is filled out, and the mechanic who releases the vehicle back into service signs the form. The stapled forms are then filed, to be used later as the source for various maintenance reports.\\n•\\n TFBS maintains a parts inventory, including oil, oil filters, air filters, and belts of various types. The parts inventory is checked daily to monitor parts usage and to reorder parts that reach the “minimum quantity on hand” level. To track parts usage, the parts manager requires each mechanic to sign out the parts that are used to perform each vehicle’s maintenance; the parts manager records the main-tenance log number under which the part is used.\\n•\\n Each month TFBS issues a set of reports. The reports include the mileage driven by vehicle, by department, and by faculty members within a department. In addi-tion, various revenue reports are generated by vehicle and department. A detailed parts usage report is also filed each month. Finally, a vehicle maintenance sum-mary is created each month.\\n Given that brief summary of operations, draw the appropriate (and fully labeled) ERD. Use the Crow’s foot methodology to indicate entities, relationships, connectiv-ities, and participations.\\n12.\\n During peak periods, Temporary Employment Corporation (TEC) places temporary workers in companies. TEC’s manager gives you the following description of the business:\\n•\\n TEC has a file of candidates who are willing to work.\\n• Any candidate who has worked before has a specific job history. (Naturally, no job history exists if the candidate has never worked.) Each time the candidate works, one additional job history record is created.\\n•\\n Each candidate has earned several qualifications. Each qualification may be earned by more than one candidate. (For example, more than one candidate may have earned a Bachelor of Business Administration degree or a Microsoft Net-work Certification, and clearly a candidate may have earned both a BBA and a Microsoft Network Certification.)\\n•\\n TEC offers courses to help candidates improve their qualifications.\\n• Every course develops one specific qualification; however, TEC does not offer a course for every qualification. Some qualifications are developed through multi-ple courses.\\n•\\n Some courses cover advanced topics that require specific qualifications as pre-requisites. Some courses cover basic topics that do not require any prerequisite \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2060b433-2184-4e88-af15-6c9e4649aafb', embedding=None, metadata={'page_label': '163', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    163\\nqualifications. A course can have several prerequisites. A qualification can be a \\nprerequisite for more than one course.\\n• Courses are taught during training sessions. A training session is the presentation of a single course. Over time, TEC will offer many training sessions for each course; however, new courses may not have any training sessions scheduled right away.\\n•\\n Candidates can pay a fee to attend a training session. A training session can accommodate several candidates, although new training sessions will not have any candidates registered at first.\\n•\\n TEC also has a list of companies that request temporaries.\\n• Each time a company requests a temporary employee, TEC makes an entry in the Openings folder. That folder contains an opening number, a company name, required qualifications, a starting date, an anticipated ending date, and hourly pay.\\n•\\n Each opening requires only one specific or main qualification.\\n• When a candidate matches the qualification, the job is assigned, and an entry is made in the Placement Record folder. The folder contains such information as an opening number, candidate number, and total hours worked. In addition, an entry is made in the job history for the candidate.\\n•\\n An opening can be filled by many candidates, and a candidate can fill many openings.\\n• TEC uses special codes to describe a candidate’s qualifications for an opening. The list of codes is shown in Table P4.12.\\n TEC’s management wants to keep track of the following entities:\\n COMPANY , OPENING, QUALIFICATION, CANDIDATE, JOB_HISTORY , PLACEMENT, COURSE, and SESSION. Given that information, do the following:\\n  a. Draw the Crow’s Foot ERDs for this enterprise.\\n  b. Identify all necessary relationships.\\n  c. Identify the connectivity for each relationship.\\n  d. Identify the mandatory and optional dependencies for the relationships.\\n  e. Resolve all M:N relationships.TABLE P4.12\\nCODE DESCRIPTION\\nSEC-45 Secretarial work; candidate must type at least 45 words per minute\\nSEC-60 Secretarial work; candidate must type at least 60 words per minute\\nCLERK General clerking work\\nPRG-VB Programmer, Visual Basic\\nPRG-C++ Programmer, C++\\nDBA-ORA Database Administrator, Oracle\\nDBA-DB2 Database Administrator, IBM DB2\\nDBA-SQLSERV Database Administrator, MS SQL Server\\nSYS-1 Systems Analyst, level 1\\nSYS-2 Systems Analyst, level 2\\nNW-NOV Network Administrator, Novell experience\\nWD-CF Web Developer, ColdFusion\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b6adafb3-31d1-4d9f-9a6a-1843ee56da20', embedding=None, metadata={'page_label': '164', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='164   Part 2     Design Concepts\\n13. Use the following description of the operations of the RC_Charter2 Company to \\ncomplete this exercise.\\n• The RC_Charter2 Company operates a fleet of aircraft under the Federal Air Regula -\\ntions (FAR) Part 135 (air taxi or charter) certificate, enforced by the FAA. The aircraft \\nare available for air taxi (charter) operations within the United States and Canada.\\n• Charter companies provide so-called unscheduled operations—that is, charter \\nflights take place only after a customer reserves the use of an aircraft at a des -\\nignated date and time to fly to one or more designated destinations; the aircraft  \\ntransports passengers, cargo, or some combination of passengers and cargo. Of \\ncourse, a customer can reserve many different charter trips during any time \\nframe. However, for billing purposes, each charter trip is reserved by one and \\nonly one customer. Some of RC_Charter2’s customers do not use the compa -\\nny’s charter operations; instead, they purchase fuel, use maintenance services, or \\nuse other RC_Charter2 services. However, this database design will focus on the \\ncharter operations only.\\n• Each charter trip yields revenue for the RC_Charter2 Company. This revenue is \\ngenerated by the charges a customer pays upon the completion of a flight. The \\ncharter flight charges are a function of aircraft model used, distance flown, wait -\\ning time, special customer requirements, and crew expenses. The distance flown \\ncharges are computed by multiplying the round-trip miles by the model’s charge \\nper mile. Round-trip miles are based on the actual navigational path flown. The \\nsample route traced in Figure P4.13 illustrates the procedure. Note that the num -\\nber of round-trip miles is calculated to be 130 + 200 + 180 + 390 = 900.\\nFIGURE P4.13  ROUND-TRIP MILE DETERMINATION  \\nIntermediate Stop\\n200 miles\\nPax Pickup\\n130 miles\\nHome Base390 milesDestination180 miles\\n• Depending on whether a customer has RC_Charter2 credit authorization, the \\ncustomer may do the following:\\na. Pay the entire charter bill upon the completion of the charter flight.\\nb. Pay a part of the charter bill and charge the remainder to the account. The \\ncharge amount may not exceed the available credit.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bf5adeae-b90c-4cb6-b9e6-3525741f0a1b', embedding=None, metadata={'page_label': '165', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    165\\nc. Charge the entire charter bill to the account. The charge amount may not \\nexceed the available credit.\\nd. Customers may pay all or part of the existing balance for previous charter trips. Such payments may be made at any time and are not necessarily tied to a specific charter trip. The charter mileage charge includes the expense of the pilot(s) and other crew required by FAR 135. However, if customers request additional  crew not  required by FAR 135, those customers are charged for \\nthe crew members on an hourly basis. The hourly crew-member charge is based on each crew member’s qualifications.\\ne.\\n The database must be able to handle crew assignments. Each charter trip requires the use of an aircraft, and a crew flies each aircraft. The smaller, pis-ton-engine charter aircraft require a crew consisting of only a single pilot. All jets and other aircraft that have a gross takeoff weight of at least 12,500 pounds require a pilot and a copilot, while some of the larger aircraft used to transport passengers may require flight attendants as part of the crew. Some of the older aircraft require the assignment of a flight engineer, and larger cargo-carrying aircraft require the assignment of a loadmaster. In short, a crew can consist of more than one person, and not all crew members are pilots.\\nf.\\n The charter flight’s aircraft waiting charges are computed by multiplying the hours waited by the model’s hourly waiting charge. Crew expenses are limited to meals, lodging, and ground transportation.\\nThe RC_Charter2 database must be designed to generate a monthly summary of all charter trips, expenses, and revenues derived from the charter records. Such records are based on the data that each pilot in command is required to record for each char -\\nter trip: trip date(s) and time(s), destination(s), aircraft number, pilot data and other crew data, distance flown, fuel usage, and other data pertinent to the charter flight. Such charter data is then used to generate monthly reports that detail revenue and operating cost information for customers, aircraft, and pilots. All pilots and other crew members are RC_Charter2 Company employees; that is, the company does not use contract pilots and crew.\\nFAR Part 135 operations are conducted under a strict set of requirements that \\ngovern the licensing and training of crew members. For example, pilots must have earned either a commercial license or an Airline Transport Pilot (ATP) license. Both licenses require appropriate ratings, which are specific competency requirements. For example, consider the following:\\n•\\n To operate a multiengine aircraft designed for takeoffs and landings on land only, the appropriate rating is MEL, or Multiengine Landplane. When a multiengine aircraft can take off and land on water, the appropriate rating is MES, or Mul-tiengine Seaplane.\\n•\\n The instrument rating is based on a demonstrated ability to conduct all flight operations with sole reference to cockpit instrumentation. The instrument rating is required to operate an aircraft under Instrument Meteorological Conditions (IMC), and all such operations are governed under FAR-specified Instrument Flight Rules (IFR). In contrast, operations conducted under “good weather” or visual  flight conditions are based on the FAR Visual Flight Rules (VFR).\\n•\\n The type rating is required for all aircraft with a takeoff weight of more than 12,500 pounds or for aircraft that are purely jet-powered. If an aircraft uses jet engines to drive propellers, that aircraft is said to be turboprop-powered. A turboprop—that \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='593a97a4-2fd1-41fb-982c-6af2d43a70e2', embedding=None, metadata={'page_label': '166', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='166   Part 2    Design Concepts\\nis, a turbo-propeller-powered aircraft—does not require a type rating unless it \\nmeets the 12,500-pound weight limitation.\\n• Although pilot licenses and ratings are not time limited, exercising the privilege of the license and ratings under Part 135 requires both a current medical certifi-cate and a current Part 135 checkride. The following distinctions are important:\\na.\\n The medical certificate may be Class I or Class II. The Class I medical is more \\nstringent than the Class II, and it must be renewed every six months. The Class II medical must be renewed yearly. If the Class I medical is not renewed during the six-month period, it automatically reverts to a Class II certificate. If the Class II medical is not renewed within the specified period, it automat-ically reverts to a Class III medical, which is not valid for commercial flight operations.\\nb.\\n A Part 135 checkride is a practical flight examination that must be successfully completed every six months. The checkride includes all flight maneuvers and procedures specified in Part 135.\\n Nonpilot crew members must also have the proper certificates to meet specific job requirements. For example, loadmasters need an appropriate certificate, as do flight attendants. Crew members such as loadmasters and flight attendants may be required in operations that involve large aircraft with a takeoff weight of more than 12,500 pounds and more than 19 passengers; these crew members are also required to pass a written and practical exam periodically. The RC_Charter2 Company is required to keep a complete record of all test types, dates, and results for each crew member, as well as examination dates for pilot medical certificates.\\nIn addition, all flight crew members are required to submit to periodic drug \\ntesting; the results must be tracked as well. Note that nonpilot crew members are not required to take pilot-specific tests such as Part 135 checkrides, nor are pilots required to take crew tests such as loadmaster and flight attendant practical exams. However, many crew members have licenses and certifications in several areas. For example, a pilot may have an ATP and a loadmaster certificate. If that pilot is assigned to be a loadmaster on a given charter flight, the loadmaster certificate is required. Similarly, a flight attendant may have earned a commercial pilot’s license. Sample data formats are shown in Table P4.13.\\nPilots and other crew members must receive recurrency training appropriate to \\ntheir work assignments. Recurrency training is based on an FAA-approved curricu-lum that is job specific. For example, pilot recurrency training includes a review of all applicable Part 135 flight rules and regulations, weather data interpretation, com-pany flight operations requirements, and specified flight procedures. The RC_Char -\\nter2 Company is required to keep a complete record of all recurrency training for each crew member subject to the training.\\nThe RC_Charter2 Company is required to maintain a detailed record of all crew \\ncredentials and all training mandated by Part 135. The company must keep a com-plete record of each requirement and of all compliance data.\\nTo conduct a charter flight, the company must have a properly maintained aircraft \\navailable. A pilot who meets all of the FAA ’s licensing and currency requirements must fly the aircraft as Pilot in Command (PIC). For aircraft that are powered by pis-ton engines or turboprops and have a gross takeoff weight under 12,500 pounds, sin-gle-pilot operations are permitted under Part 135 as long as a properly maintained autopilot is available. However, even if FAR Part 135 permits single-pilot operations, many customers require the presence of a copilot who is capable of conducting the flight operations under Part 135.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='22336a6f-33dc-46cb-bb71-6da32e7e94e5', embedding=None, metadata={'page_label': '167', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 4    Entity Relationship ( ER) Modeling    167\\nThe RC_Charter2 operations manager anticipates the lease of turbojet-powered \\naircraft, which are required to have a crew consisting of a pilot and copilot. Both \\nthe pilot and copilot must meet the same Part 135 licensing, ratings, and training requirements.TABLE P4.13\\nPART A TESTS\\nTEST CODE TEST DESCRIPTION TEST FREQUENCY\\n1 Part 135 Flight Check 6 months\\n2 Medical, Class I 6 months\\n3 Medical, Class II 12 months\\n4 Loadmaster Practical 12 months\\n5 Flight Attendant Practical 12 months\\n6 Drug test Random\\n7 Operations, written exam 6 months\\nPART B RESUL TS\\nEMPLOYEE TEST CODE TEST DATE TEST RESULT\\n101 1 12-Nov-15 Pass-1\\n103 6 23-Dec-15 Pass-1\\n112 4 23-Dec-15 Pass-2\\n103 7 11-Jan-16 Pass-1\\n112 7 16-Jan-16 Pass-1\\n101 7 16-Jan-16 Pass-1\\n101 6 11-Feb-16 Pass-2\\n125 2 15-Feb-16 Pass-1\\nPART C LICENSES AND CERTIFICATIONS\\nLICENSE OR CERTIFICATE LICENSE OR CERTIFICATE DESCRIPTION\\nATP Airline Transport Pilot\\nComm Commercial license\\nMed-1 Medical certificate, Class I\\nMed-2 Medical certificate, Class II\\nInstr Instrument rating\\nMEL Multiengine Land aircraft rating\\nLM Loadmaster\\nFA Flight Attendant\\nEMPLOYEE LICENSE OR CERTIFICATE DATE EARNED\\n101 Comm 12-Nov-93\\n101 Instr 28-Jun-94\\n101 MEL 9-Aug-94\\n103 Comm 21-Dec-95\\n112 FA 23-Jun-02\\n103 Instr 18-Jan-96\\n112 LM 27-Nov-05\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5dee6b1e-f890-46ac-9d73-1489f77c8651', embedding=None, metadata={'page_label': '168', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='168   Part 2    Design Concepts\\n The company also leases larger aircraft that exceed the 12,500-pound gross takeoff  \\nweight. Those aircraft might carry enough passengers to require the presence of one or more flight attendants. If those aircraft carry cargo that weighs more than 12,500 pounds, a loadmaster must be assigned as a crew member to supervise the loading and securing of the cargo. The database must be designed to meet the anticipated capability for additional charter crew assignments.\\na.\\n Given this incomplete description of operations, write all applicable business rules to establish entities, relationships, optionalities, connectivities, and cardinalities. (Hint:  Use the following five business rules as examples, and write the remaining \\nbusiness rules in the same format.) A customer may request many charter trips.\\n•\\n Each charter trip is requested by only one customer.\\n• Some customers have not yet requested a charter trip.\\n• An employee may be assigned to serve as a crew member on many charter \\ntrips.\\n• Each charter trip may have many employees assigned to serve as crew members.\\nb. Draw the fully labeled and implementable Crow’s Foot ERD based on the busi-ness rules you wrote in Part a. of this problem. Include all entities, relationships, \\noptionalities, connectivities, and cardinalities.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9ab7f86-b50b-41c8-b942-1c70840ded0a', embedding=None, metadata={'page_label': '169', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 5\\nAdvanced Data Modeling\\nIn this chapter, you will learn:\\n• About the extended entity relationship (EER) model\\n• How entity clusters are used to represent multiple entities and relationships\\n• The characteristics of good primary keys and how to select them\\n• How to use flexible solutions for special data-modeling cases\\nPreviewIn the previous two chapters, you learned how to use entity relationship diagrams (ERDs) \\nto properly create a data model. In this chapter, you will learn about the extended entity relationship (EER) model. The EER model builds on ER concepts and adds support for entity supertypes, subtypes, and entity clustering.\\nMost current database implementations are based on relational databases. Because the \\nrelational model uses keys to create associations among tables, it is essential to learn the characteristics of good primary keys and how to select them. Selecting a good primary key is too important to be left to chance, so this chapter covers the critical aspects of primary key identification and placement.\\nFocusing on practical database design, this chapter also illustrates some special design \\ncases that highlight the importance of flexible designs, which can be adapted to meet the demands of changing data and information requirements. Data modeling is a vital step in the development of databases that in turn provides a good foundation for successful application development. Remember that good database applications cannot be based on bad database designs, and no amount of outstanding coding can overcome the limitations of poor database design.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH05_AirCo  P\\t P\\t P\\t P\\nCH05_TinyCollege  P\\t P\\t P\\t PCH05_GCSdata  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4685626-d985-41ef-954e-3ddc95190c0e', embedding=None, metadata={'page_label': '170', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='170   Part 2    Design Concepts\\n5-1 The Extended Entity Relationship Model\\nAs the complexity of the data structures being modeled has increased and as application \\nsoftware requirements have become more stringent, the need to capture more infor -\\nmation in the data model has increased. The extended entity relationship model (EERM), sometimes referred to as the enhanced entity relationship model, is the result of adding more semantic constructs to the original entity relationship (ER) model. As you might expect, a diagram that uses the EERM is called an EER diagram (EERD). In the following sections, you will learn about the main EER model constructs—entity supertypes, entity subtypes, and entity clustering—and see how they are represented in ERDs/EERDs.\\n5-1a  Entity Supertypes and Subtypes\\nBecause most employees possess a wide range of skills and special qualifications, data modelers must find a variety of ways to group employees based on their characteristics. For instance, a retail company could group employees as salaried and hourly, while a university could group employees as faculty, staff, and administrators.\\nThe grouping of employees into various types  provides two important benefits:\\n•\\n It avoids unnecessary nulls in attributes when some employees have characteristics that are not shared by other employees.\\n•\\n It enables a particular employee type to participate in relationships that are unique to that employee type.\\nTo illustrate those benefits, you will explore the case of an aviation business that \\nemploys pilots, mechanics, secretaries, accountants, database managers, and many other types of employees. Figure 5.1 illustrates how pilots share certain charac-teristics with other employees, such as a last name (EMP_LNAME) and hire date (EMP_HIRE_DATE). On the other hand, many pilot characteristics are not shared by other employees. For example, unlike other employees, pilots must meet special requirements such as flight hour restrictions, flight checks, and periodic training. Therefore, if all employee characteristics and special qualifications were stored in a single EMPLOYEE entity, you would have a lot of nulls or you would have to cre-ate a lot of needless dummy entries. In this case, special pilot characteristics such as EMP_LICENSE, EMP_RATINGS, and EMP_MED_TYPE will generate nulls for employees who are not pilots. In addition, pilots participate in some relationships that are unique to their qualifications. For example, not all employees can fly air -\\nplanes; only employees who are pilots can participate in the “employee flies airplane” relationship.\\nBased on the preceding discussion, you would correctly deduce that the PILOT entity \\nstores only attributes that are unique to pilots, and that the EMPLOYEE entity stores attributes that are common to all employees. Based on that hierarchy, you can conclude extended entity relationship model (EERM)\\nSometimes referred to as the enhanced entity relationship model; the result of adding more semantic constructs, such as entity supertypes, entity subtypes, and entity clustering, to the original entity relationship (ER) model.\\nEER diagram (EERD)\\nThe entity relationship diagram resulting from the application of extended entity relationship concepts that provide additional semantic content in the  ER model.\\nThe extended entity relationship model discussed in this chapter includes advanced data modeling constructs such as specialization hierarchies. Although Microsoft Visio 2010 and earlier versions handled these constructs neatly, newer versions of Visio starting with  \\nMicrosoft Visio 2013 removed support for many database modeling activities, including specialization hierarchies.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc89cedb-a6c9-4726-a46f-30998f29938c', embedding=None, metadata={'page_label': '171', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    171\\nthat PILOT is a subtype  of EMPLOYEE, and that EMPLOYEE is the supertype  of PILOT. \\nIn modeling terms, an entity supertype  is a generic entity type that is related to one or \\nmore entity subtypes . The entity supertype contains common characteristics, and the \\nentity subtypes each contain their own unique characteristics.\\nTwo criteria help the designer determine when to use subtypes and supertypes:\\n• There must be different, identifiable kinds or types of the entity in the user’s \\nenvironment.\\n• The different kinds or types of instances should each have one or more attributes that \\nare unique to that kind or type of instance.\\nIn the preceding example, because pilots meet both criteria of being an identifiable \\nkind of employee and having unique attributes that other employees do not possess, \\nit is appropriate to create PILOT as a subtype of EMPLOYEE. Assume that mechan -\\nics and accountants also each have attributes that are unique to them, respectively, and \\nthat clerks do not. In that case, MECHANIC and ACCOUNTANT would also be legiti -\\nmate subtypes of EMPLOYEE because they are identifiable kinds of employees and have \\nunique attributes. CLERK would not be an acceptable subtype of EMPLOYEE because it \\nonly satisfies one of the criteria—it is an identifiable kind of employee—but none of the \\nattributes are unique to just clerks. In the next section, you will learn how entity super -\\ntypes and subtypes are related in a specialization hierarchy.\\n5-1b  Specialization Hierarchy\\nEntity supertypes and subtypes are organized in a specialization hierarchy , which \\ndepicts the arrangement of higher-level entity supertypes (parent entities) and  \\nlower-level entity subtypes (child entities). Figure 5.2 shows the specialization hierarchy \\nformed by an EMPLOYEE supertype and three entity subtypes—PILOT, MECHANIC, \\nand ACCOUNTANT. The specialization hierarchy reflects the 1:1 relationship between \\nEMPLOYEE and its subtypes. For example, a PILOT subtype occurrence is related to one \\ninstance of the EMPLOYEE supertype, and a MECHANIC subtype occurrence is related \\nto one instance of the EMPLOYEE supertype. The terminology and symbols in Figure \\n5.2 are explained throughout this chapter.\\nThe relationships depicted within the specialization hierarchy are sometimes described \\nin terms of “is-a” relationships. For example, a pilot is an  employee, a mechanic is an  \\nemployee, and an accountant is an  employee. It is important to understand that within a \\nspecialization hierarchy, a subtype can exist only within the context of a supertype, and \\nevery subtype can have only one supertype to which it is directly related. However, a FIGURE 5.1  NULLS CREATED BY UNIQUE ATTRIBUTES  \\nDatabase name: Ch05_AirCo\\nentity supertype\\nIn a generalization/\\nspecialization hierarchy, \\na generic entity type that \\ncontains the common \\ncharacteristics of entity \\nsubtypes.\\nentity subtype\\nIn a generalization/\\nspecialization hierarchy, \\na subset of an entity \\nsupertype. The entity \\nsupertype contains the \\ncommon characteristics \\nand the subtypes \\ncontain the unique \\ncharacteristics of each \\nentity.\\nspecialization \\nhierarchy\\nA hierarchy based on \\nthe top-down process \\nof identifying lower-\\nlevel, more specific \\nentity subtypes from \\na higher-level entity \\nsupertype. Specialization \\nis based on grouping \\nunique characteristics \\nand relationships of the \\nsubtypes.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4b7eafc-c976-4cb4-8df6-9d2d2df66786', embedding=None, metadata={'page_label': '172', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='172   Part 2     Design Concepts\\nspecialization hierarchy can have many levels of supertype/subtype relationships—that \\nis, you can have a specialization hierarchy in which a supertype has many subtypes. In \\nturn, one of the subtypes is the supertype to other lower-level subtypes.\\nAs you can see in Figure 5.2, the arrangement of entity supertypes and subtypes in a \\nspecialization hierarchy is more than a cosmetic convenience. Specialization hierarchies \\nenable the data model to capture additional semantic content (meaning) into the ERD.  \\nA specialization hierarchy provides the means to:\\n• Support attribute inheritance.\\n• Define a special supertype attribute known as the subtype discriminator.\\n• Define disjoint/overlapping constraints and complete/partial constraints.\\nThe following sections cover such characteristics and constraints in more detail.\\n5-1c  Inheritance\\nThe property of inheritance  enables an entity subtype to inherit the attributes and relation -\\nships of the supertype. As discussed earlier, a supertype contains attributes that are com -\\nmon to all of its subtypes. In contrast, subtypes contain only the attributes that are unique \\nto the subtype. For example, Figure 5.2 illustrates that pilots, mechanics, and accountants \\nall inherit the employee number, last name, first name, middle initial, and hire date from \\nthe EMPLOYEE entity. However, Figure 5.2 also illustrates that pilots have unique attri -\\nbutes; the same is true for mechanics and accountants. One important inheritance charac -\\nteristic is that all entity subtypes inherit their primary key attribute from their supertype . Note \\nin Figure 5.2 that the EMP_NUM attribute is the primary key for each of the subtypes.\\nAt the implementation level, the supertype and its subtype(s) depicted in the special -\\nization hierarchy maintain a 1:1 relationship. For example, the specialization hierarchy Online \\nContent\\nThis chapter covers only \\nspecialization hierar -\\nchies. The EER model \\nalso supports special -\\nization lattices , in which \\na subtype can have \\nmultiple parents (super -\\ntypes). However, those \\nconcepts are better cov -\\nered under the object-  \\noriented model in \\nAppendix G, Object-  \\nOriented Databases. The  \\nappendix is available at \\nwww.cengagebrain.com .\\ninheritance\\nIn the EERD, the property \\nthat enables an entity \\nsubtype to inherit the \\nattributes and relationships \\nof the entity supertype.FIGURE 5.2  A SPECIALIZATION HIERARCHY  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e03cf604-39e5-4285-b5c8-f06e6ac94cd7', embedding=None, metadata={'page_label': '173', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    173\\nlets you replace the undesirable EMPLOYEE table structure in Figure 5.1 with two \\ntables—one representing the supertype EMPLOYEE and the other representing the  \\nsubtype PILOT. (See Figure 5.3.)\\nEntity subtypes inherit all relationships in which the supertype entity participates. For exam -\\nple, Figure 5.2 shows the EMPLOYEE entity supertype participating in a 1:M relationship with \\na DEPENDENT entity. Through inheritance, all subtypes also participate in that relationship. In \\nspecialization hierarchies with multiple levels of supertype and subtypes, a lower-level subtype \\ninherits all of the attributes and relationships from all of its upper-level supertypes.\\nInheriting the relationships of their supertypes does not mean that subtypes cannot have \\nrelationships of their own. Figure 5.4 illustrates a 1:M relationship between EMPLOYEE, a \\nsubtype of PERSON, and OFFICE. Because only employees and no other type of person will \\never have an office within this system, the relationship is modeled with the subtype directly.FIGURE 5.3  THE EMPLOYEE-PILOT SUPERTYPE-SUBTYPE RELATIONSHIP  \\nTable name: EMPLOYEE Table name: PILOTDatabase name: Ch05_AirCo\\nFIGURE 5.4  SPECIALIZATION HIERARCHY WITH OVERLAPPING SUBTYPES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='95e398d4-1cd3-4f70-9501-88b34c11f44a', embedding=None, metadata={'page_label': '174', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='174   Part 2    Design Concepts\\n5-1d  Subtype Discriminator\\nA subtype discriminator is the attribute in the supertype entity that determines to \\nwhich subtype the supertype occurrence is related. In Figure 5.2, the subtype discrimi-\\nnator is the employee type (EMP_TYPE).\\nIt is common practice to show the subtype discriminator and its value for each subtype \\nin the ER diagram, as shown in Figure 5.2. However, not all ER modeling tools follow that practice. For example, Microsoft Visio shows the subtype discriminator but not its value. In Figure 5.2, a text tool was used to manually add the discriminator value above the entity subtype, close to the connector line. Using Figure 5.2 as your guide, note that the supertype is related to a PILOT subtype if the EMP_TYPE has a value of “P . ” If the  \\nEMP_TYPE value is “M, ” the supertype is related to a MECHANIC subtype. If the EMP_TYPE value is “ A, ” the supertype is related to the ACCOUNTANT subtype.\\nNote that the default comparison condition for the subtype discriminator attribute is the \\nequality comparison. However, in some situations the subtype discriminator is not necessarily based on an equality comparison. For example, based on business requirements, you might create two new pilot subtypes: pilot-in-command (PIC)-qualified and copilot-qualified only. A PIC-qualified pilot must have more than 1,500 PIC flight hours. In this case, the subtype dis-criminator would be “Flight_Hours, ” and the criteria would be > 1,500 or <= 1,500, respectively.\\nIn Visio 2010, you select the subtype discriminator when creating a category by using  \\nthe Category shape from the available shapes. The Category shape is a small circle with a horizontal line underneath that connects the supertype to its subtypes. Visio 2013 does not support specialization hierarchy.NoteOnline \\nContent\\nFor a tutorial on using \\nVisio 2010 to create a specialization hierar -\\nchy, see Appendix A, Designing Databases with Visio Professional: A Tutorial, at www.  \\ncengagebrain.com.\\nsubtype discriminator\\nThe attribute in the supertype entity that determines to which entity subtype each supertype occurrence is related. \\ndisjoint subtype\\nIn a specialization hierarchy, a unique and nonoverlapping subtype entity set.\\nnonoverlapping subtype\\nSee disjoint subtype.\\noverlapping subtype\\n In a specialization hierarchy, a condition in which each entity instance (row) of the supertype can appear in more than one subtype.5-1e  Disjoint and Overlapping Constraints\\nAn entity supertype can have disjoint or overlapping entity subtypes. In the aviation example, an employee can be a pilot, a mechanic, or an accountant. Assume that one of the business rules dictates that an employee cannot belong to more than one subtype at a time; that is, an employee cannot be a pilot and a mechanic at the same time. Disjoint \\nsubtypes, also known as nonoverlapping subtypes, are subtypes that contain a unique  \\nsubset of the supertype entity set; in other words, each entity instance of the supertype can appear in only one of the subtypes. For example, in Figure 5.2, an employee (super -\\ntype) who is a pilot (subtype) can appear only in the PILOT subtype, not in any of the other subtypes. In an ERD, such disjoint subtypes are indicated by the letter d inside the category shape.\\nOn the other hand, if the business rule specifies that employees can have multiple \\nclassifications, the EMPLOYEE supertype may contain overlapping  job classification sub-\\ntypes. Overlapping subtypes are subtypes that contain nonunique subsets of the super -\\ntype entity set; that is, each entity instance of the supertype may appear in more than one subtype. For example, in a university environment, a person may be an employee, a student, or both. In turn, an employee may be a professor as well as an administrator. Because an employee may also be a student, STUDENT and EMPLOYEE are overlap-ping subtypes of the supertype PERSON, just as PROFESSOR and ADMINISTRATOR are overlapping subtypes of the supertype EMPLOYEE. Figure 5.4 illustrates overlapping subtypes with the letter o inside the category shape.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='750ef392-6bca-4ee2-9782-dd46903e5155', embedding=None, metadata={'page_label': '175', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    175\\nIt is common practice to show disjoint and overlapping symbols in the ERD. \\n(See Figures 5.2 and 5.4.) However, not all ER modeling tools follow that practice. \\nFor example, by default, Visio shows only the subtype discriminator (using the Category shape), but not the disjoint and overlapping symbols. The Visio text tool was used to manually add the d  and o  symbols in Figures 5.2 and 5.4.\\nAs you learned earlier in this section, the implementation of disjoint subtypes is \\nbased on the value of the subtype discriminator attribute in the supertype. However, implementing  overlapping subtypes requires the use of one discriminator attribute for \\neach subtype. For example, in the case of the Tiny College database design in Chapter 4, Entity Relationship (ER) Modeling, a professor can also be an administrator. Therefore, the EMPLOYEE supertype would have the subtype discriminator attributes and values shown in Table 5.1.\\n5-1f  Completeness Constraint\\nThe completeness constraint specifies whether each entity supertype occurrence must also \\nbe a member of at least one subtype. The completeness constraint can be partial or total. Partial completeness means that not every supertype occurrence is a member of a sub-type; some supertype occurrences may not be members of any subtype. Total completeness  \\nmeans that every supertype occurrence must be a member of at least one subtype.\\nThe ERDs in Figures 5.2 and 5.4 represent the completeness constraint based on the \\nVisio Category shape. A single horizontal line under the circle represents a partial com-pleteness constraint; a double horizontal line under the circle represents a total com-pleteness constraint.\\nGiven the disjoint and overlapping subtypes and completeness constraints, it is possi-\\nble to have the specialization hierarchy constraint scenarios shown in Table 5.2.TABLE 5.1\\nDISCRIMINATOR ATTRIBUTES WITH OVERLAPPING SUBTYPES\\nDISCRIMINATOR ATTRIBUTES COMMENT\\nPROFESSOR ADMINISTRATOR\\nY N The Employee is a member of the Professor subtype.\\nN Y The Employee is a member of the Administrator subtype.\\nY Y The Employee is both a Professor and an Administrator.\\nAlternative notations exist for representing disjoint and overlapping subtypes. For exam-ple, Toby J. Teorey popularized the use of G and Gs to indicate disjoint and overlapping subtypes.Note\\nAlternative notations exist to represent the completeness constraint. For example, some notations use a single line (partial) or double line (total) to connect the supertype to the Category shape.Notecompleteness constraint\\nA constraint that specifies whether each entity supertype occurrence must also be a member of at least one subtype. The completeness constraint can be partial or total. \\npartial completeness\\nIn a generalization/specialization hierarchy, a condition in which some supertype occurrences might not be members of any subtype.\\ntotal completeness\\nIn a generalization/specialization hierarchy, a condition in which every supertype occurrence must be a member of at least one subtype.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fe69d345-7199-4628-b125-bdee9b16eb8b', embedding=None, metadata={'page_label': '176', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='176   Part 2    Design Concepts\\n5-1g  Specialization and Generalization\\nY ou can use various approaches to develop entity supertypes and subtypes. For example, \\nyou can first identify a regular entity, and then identify all entity subtypes based on their distinguishing characteristics. Y ou can also start by identifying multiple entity types and then later extract the common characteristics of those entities to create a higher-level supertype entity.\\nSpecialization is the top-down process of identifying lower-level, more specific \\nentity subtypes from a higher-level entity supertype. Specialization is based on grouping the unique characteristics and relationships of the subtypes. In the aviation example, you used specialization to identify multiple entity subtypes from the original employee supertype. Generalization is the bottom-up process of identifying a higher-level, more \\ngeneric entity supertype from lower-level entity subtypes. Generalization is based on grouping the common characteristics and relationships of the subtypes. For example, you might identify multiple types of musical instruments: piano, violin, and guitar. Using the generalization approach, you could identify a “string instrument” entity supertype to hold the common characteristics of the multiple subtypes.\\n5-2 Entity Clustering\\nDeveloping an ER diagram entails the discovery of possibly hundreds of entity types and their respective relationships. Generally, the data modeler will develop an initial ERD that contains a few entities. As the design approaches completion, the ERD will contain hundreds of entities and relationships that crowd the diagram to the point of making it unreadable and inefficient as a communication tool. In those cases, you can use entity clusters to minimize the number of entities shown in the ERD.\\nAn entity cluster is a “virtual” entity type used to represent multiple entities and \\nrelationships in the ERD. An entity cluster is formed by combining multiple interrelated entities into a single, abstract entity object. An entity cluster is considered “virtual” or “abstract” in the sense that it is not actually an entity in the final ERD. Instead, it is a temporary entity used to represent multiple entities and relationships, with the purpose of simplifying the ERD and thus enhancing its readability.\\nFigure 5.5 illustrates the use of entity clusters based on the Tiny College example in \\nChapter 4. Note that the ERD contains two entity clusters:\\n•\\n OFFERING, which groups the SEMESTER, COURSE, and CLASS entities and \\nrelationships\\n• LOCATION, which groups the ROOM and BUILDING entities and relationshipsTABLE 5.2\\nSPECIALIZATION HIERARCHY CONSTRAINT SCENARIOS\\nTYPE DISJOINT CONSTRAINT OVERLAPPING CONSTRAINT\\nPartial Supertype has optional subtypes.Subtype discriminator can be null.Subtype sets are unique.Supertype has optional subtypes.Subtype discriminators can be null.Subtype sets are not unique.\\nTotal \\nEvery supertype occurrence is a member of only one subtype.Subtype discriminator cannot be null.Subtype sets are unique.Every supertype occurrence is a member of  at least one subtype.Subtype discriminators cannot be null.Subtype sets are not unique.\\nspecialization\\nIn a specialization hierarchy, the grouping of unique attributes into a subtype entity. \\ngeneralization\\nIn a specialization hierarchy, the grouping of common attributes into a supertype entity. \\nentity cluster\\nA “virtual” entity type used to represent multiple entities and relationships in the ERD. An entity cluster is formed by combining multiple interrelated entities into a single abstract entity object. An entity cluster is considered “virtual” or “abstract” because it is not actually an entity in the final ERD.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aeee3f55-a4e9-40e3-b27e-adfa40808487', embedding=None, metadata={'page_label': '177', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    177\\nNote also that the ERD in Figure 5.5 does not show attributes for the entities. When \\nusing entity clusters, the key attributes of the combined entities are no longer available. \\nWithout the key attributes, primary key inheritance rules change. In turn, the change  \\nin the inheritance rules can have undesirable consequences, such as changes in  \\nrelationships—from identifying to nonidentifying or vice versa—and the loss of foreign \\nkey attributes from some entities. To eliminate those problems, the general rule is to \\navoid the display of attributes when entity clusters are used .\\n5-3 Entity Integrity: Selecting Primary Keys\\nArguably, the most important characteristic of an entity is its primary key (a single attri -\\nbute or some combination of attributes), which uniquely identifies each entity instance. FIGURE 5.5  TINY COLLEGE ERD USING ENTITY CLUSTERS  \\nis used for\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='143b5ac9-5a16-45fe-8c3e-c11a0cc5f25b', embedding=None, metadata={'page_label': '178', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='178   Part 2    Design Concepts\\nThe primary key’s function is to guarantee entity integrity. Furthermore, primary keys \\nand foreign keys work together to implement relationships in the relational model. Therefore, the importance of properly selecting the primary key has a direct bearing on the efficiency and effectiveness of database implementation.\\n5-3a  Natural Keys and Primary Keys\\nThe concept of a unique identifier is commonly encountered in the real world. For exam-ple, you use class or section numbers to register for classes, invoice numbers to identify specific invoices, and account numbers to identify credit cards. Those examples illustrate natural identifiers or keys. A natural key or  natural identifier is a real-world, generally \\naccepted identifier used to distinguish—that is, uniquely identify—real-world objects. As its name implies, a natural key is familiar to end users and forms part of their day-to-day business vocabulary.\\nUsually, if an entity has  a natural identifier, a data modeler uses it as the primary key \\nof the entity being modeled. Generally, most natural keys make acceptable primary key identifiers. The next section presents some basic guidelines for selecting primary keys.\\n5-3b  Primary Key Guidelines\\nA primary key is the attribute or combination of attributes that uniquely identifies entity instances in an entity set. However, can the primary key be based on, for example, 12 attributes? And just how long can a primary key be? In previous examples, why was EMP_NUM selected as a primary key of EMPLOYEE and not a combination of EMP_LNAME, EMP_FNAME, EMP_INITIAL, and EMP_DOB? Can a single, 256-byte text attribute be a good primary key? There is no single answer to those questions, but data-base experts have built a body of practice over the years. This section examines that body of documented practices.\\nFirst, you should understand the function of a primary key. Its main function is to \\nuniquely identify an entity instance or row within a table. In particular, given a primary key value—that is, the determinant—the relational model can determine the value of all dependent attributes that “describe” the entity. Note that identification and description are separate semantic constructs in the model. The function of the primary key is to guar -\\nantee entity integrity, not to “describe” the entity.\\nSecond, primary keys and foreign keys are used to implement relationships among \\nentities. However, the implementation of such relationships is done mostly behind the scenes, hidden from end users. In the real world, end users identify objects based on the characteristics they know about the objects. For example, when shopping at a grocery store, you select products by taking them from a display shelf and reading the labels, not by looking at the stock number. It is wise for database applications to mimic the human selection process as much as possible. Therefore, database applications should let the end user choose among multiple descriptive narratives of different objects, while using primary key values behind the scenes. Keeping those concepts in mind, look at Table 5.3, which summarizes desirable primary key characteristics.\\n5-3c  When To Use Composite Primary Keys\\nIn the previous section, you learned about the desirable characteristics of primary keys. For example, you learned that the primary key should use the minimum number of attributes possible. However, that does not  mean that composite primary keys are \\nnot permitted in a model. In fact, composite primary keys are particularly useful in two cases:natural key (natural identifier)\\nA generally accepted identifier for real-world objects. As its name implies, a natural key is familiar to end users and forms part of their day-to-day business vocabulary.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e80bf3b-01d7-49c0-9315-ae8b9db0e06f', embedding=None, metadata={'page_label': '179', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    179\\n• As identifiers of composite entities, in which each primary key combination is allowed \\nonly once in the M:N relationship\\n• As identifiers of weak entities, in which the weak entity has a strong identifying rela-tionship with the parent entity\\nTo illustrate the first case, assume that you have a STUDENT entity set and a CLASS \\nentity set. In addition, assume that those two sets are related in an M:N relationship via an ENROLL entity set, in which each student/class combination may appear only once in the composite entity. Figure 5.6 shows the ERD to represent such a relationship.\\nAs shown in Figure 5.6, the composite primary key automatically provides the benefit \\nof ensuring that there cannot be duplicate values—that is, it ensures that the same stu-dent cannot enroll more than once in the same class.\\nIn the second case, a weak entity in a strong identifying relationship with a parent \\nentity is normally used to represent one of two situations:1.\\n A real-world object that is existence-dependent on another real-world object. Such objects are distinguishable in the real world. A dependent and an employee are two separate people who exist independently of each other. However, such objects can exist in the model only when they relate to each other in a strong identifying rela-tionship. For example, the relationship between EMPLOYEE and DEPENDENT is one of existence dependency, in which the primary key of the dependent entity is a composite key that contains the key of the parent entity.TABLE 5.3\\nDESIRABLE PRIMARY KEY CHARACTERISTICS\\nPK CHARACTERISTIC RATIONALE\\nUnique values The PK must uniquely identify each entity instance. A primary key must be able to guarantee unique values. It cannot contain nulls.\\nNonintelligent The PK should not have embedded semantic meaning other than to uniquely identify each entity instance. An attribute with embedded semantic meaning is probably better used as a descriptive characteristic of the entity than as an identifier. For example, a student ID of 650973 would be preferred over Smith, Martha L. as a primary key identifier.\\nNo change over time If an attribute has semantic meaning, it might be subject to updates, which is why \\nnames do not make good primary keys. If Vickie Smith is the primary key, what happens if she changes her name when she gets married? If a primary key is subject to change, the foreign key values must be updated, thus adding to the database work load. Furthermore, changing a primary key value means that you are basically changing the identity of an entity. In short, the PK should be permanent and unchangeable.\\nPreferably single-attribute A primary key should have the minimum number of attributes possible (irreducible). Single-attribute primary keys are desirable but not required. Single-attribute primary keys simplify the implementation of foreign keys. Having multiple-attribute primary keys can cause primary keys of related entities to grow through the possible addition of many attributes, thus adding to the database workload and making (application) coding more cumbersome.\\nPreferably numeric Unique values can be better managed when they are numeric, because the database can use internal routines to implement a counter-style attribute that automatically increments values with the addition of each new row. In fact, most database systems include the ability to use special constructs, such as Autonumber in Microsoft Access, sequence in Oracle, or uniqueidentifier in MS SQL Server to support self-incrementing primary key attributes.\\nSecurity-compliant The selected primary key must not be composed of any attribute(s) that might be \\nconsidered a security risk or violation. For example, using a Social Security number as a PK in an EMPLOYEE table is not a good idea.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='08968e33-301e-4e85-95c8-a049e75fbc2b', embedding=None, metadata={'page_label': '180', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='180   Part 2     Design Concepts\\n2. A real-world object that is represented in the data model as two separate entities in \\na strong identifying relationship . For example, the real-world invoice object is repre -\\nsented by two entities in a data model: INVOICE and LINE. Clearly, the LINE entity \\ndoes not exist in the real world as an independent object, but as part of an INVOICE.\\nIn both situations, having a strong identifying relationship ensures that the dependent \\nentity can exist only when it is related to the parent entity. In summary, the selection \\nof a composite primary key for composite and weak entity types provides benefits that \\nenhance the integrity and consistency of the model.\\n5-3d  When To Use Surrogate Primary Keys\\nIn some instances a primary key doesn’t exist in the real world or the existing natural \\nkey might not be a suitable primary key. In these cases, it is standard practice to create \\na surrogate key. A surrogate key  is a primary key created by the database designer to \\nsimplify the identification of entity instances. The surrogate key has no meaning in the \\nuser’s environment—it exists only to distinguish one entity instance from another (just \\nlike any other primary key). One practical advantage of a surrogate key is that because \\nit has no intrinsic meaning, values for it can be generated by the DBMS to ensure that \\nunique values are always provided.\\nFor example, consider the case of a park recreation facility that rents rooms for small \\nparties. The manager of the facility keeps track of all events, using a folder with the for -\\nmat shown in Table 5.4.\\nGiven the data shown in Table 5.4, you would model the EVENT entity as follows:\\nEVENT (DATE, TIME_START, TIME_END, ROOM, EVENT_NAME, PARTY_OF)\\nWhat primary key would you suggest? In this case, there is no simple natural key that \\ncould be used as a primary key in the model. Based on the primary key concepts you \\nlearned in previous chapters, you might suggest one of these options:FIGURE 5.6  THE M:N RELATIONSHIP BETWEEN STUDENT AND CLASS  \\nDatabase name: Ch05_Tinycollege\\nTable name: STUDENT\\n(ﬁrst four ﬁelds)Table name: CLASS\\n(ﬁrst three ﬁelds) Table name: ENROLL\\nsurrogate key\\nA system-assigned \\nprimary key, generally \\nnumeric and auto-\\nincremented.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='39ebbaf3-c174-49d2-9a6a-751836b0e494', embedding=None, metadata={'page_label': '181', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    181\\n(DATE , TIME_START, ROOM ) or (DATE , TIME_END, ROOM )\\nAssume that you select the composite primary key (DATE , TIME_START, ROOM ) for \\nthe EVENT entity. Next, you determine that one EVENT may use many RESOURCEs (such \\nas tables, projectors, PCs, and stands) and that the same RESOURCE may be used for many EVENTs. The RESOURCE entity would be represented by the following attributes:\\nRESOURCE (RSC_ID, RSC_DESCRIPTION, RSC_TYPE, RSC_QTY , RSC_PRICE)\\nGiven the business rules, the M:N relationship between RESOURCE and EVENT \\nwould be represented via the EVNTRSC composite entity with a composite primary key \\nas follows:\\nEVNTRSC (DATE , TIME_START, ROOM , RSC_ID, QTY_USED)\\nY ou now have a lengthy, four-attribute composite primary key. What would happen \\nif the EVNTRSC entity’s primary key were inherited by another existence-dependent \\nentity? At this point, you can see that the composite primary key could make the data-base implementation and program coding unnecessarily complex.\\nAs a data modeler, you probably noticed that the EVENT entity’s selected primary \\nkey might not fare well, given the primary key guidelines in Table 5.3. In this case, the EVENT entity’s selected primary key contains embedded semantic information and is formed by a combination of date, time, and text data columns. In addition, the selected primary key would cause lengthy primary keys for existence-dependent entities. The preferred alternative is to use a numeric, single-attribute surrogate primary key.\\nSurrogate primary keys are accepted practice in today’s complex data environments. \\nThey are especially helpful when there is no natural key, when the selected candidate key has embedded semantic contents, or when the selected candidate key is too long or cum-bersome. However, there is a trade-off: if you use a surrogate key, you must ensure that the candidate key of the entity in question performs properly through the use of “unique index” and “not null” constraints.TABLE 5.4\\nDATA USED TO KEEP TRACK OF EVENTS\\nDATE TIME_START TIME_END ROOM EVENT_NAME PARTY_OF\\n6/17/2016 11:00a.m. 2:00p.m. Allure Burton Wedding 60\\n6/17/2016 11:00a.m. 2:00p.m. Bonanza Adams Office 12\\n6/17/2016 3:00p.m. 5:30p.m. Allure Smith Family 15\\n6/17/2016 3:30p.m. 5:30p.m. Bonanza Adams Office 126/18/2016 1:00p.m. 3:00p.m. Bonanza Boy Scouts 336/18/2016 11:00a.m. 2:00p.m. Allure March of Dimes 25\\n6/18/2016 11:00a.m. 12:30p.m. Bonanza Smith Family 12\\nThis example shows a case in which entity integrity is maintained but semantic correctness \\nof business rules is not. For example, you could have two events that overlap and whose primary keys are perfectly compliant. The only way to ensure adherence to this type of business rule (two events cannot overlap—occur on the same room at the same time) would be via application programming code.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f8910dd5-dff0-4417-8dd5-5b36a96cd944', embedding=None, metadata={'page_label': '182', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='182   Part 2    Design Concepts\\n5-4  Design Cases: Learning Flexible  \\nDatabase Design\\nData modeling and database design require skills that are acquired through experience. In turn, experience is acquired through practice—regular and frequent repetition, apply-ing the concepts learned to specific and different design problems. This section presents four special design cases that highlight the importance of flexible designs, proper identi-fication of primary keys, and placement of foreign keys.\\nIn describing the various modeling concepts throughout this book, the focus is on rela-tional models. Also, given the focus on the practical nature of database design, all design issues are addressed with the implementation goal in mind. Therefore, there is no sharp line of demarcation between design and implementation.\\nAt the pure conceptual stage of the design, foreign keys are not part of an ER diagram. \\nThe ERD displays only entities and relationships. Entity instances are distinguished by iden-tifiers that may become primary keys. During design, the modeler attempts to understand and define the entities and relationships. Foreign keys are the mechanism through which the relationship designed in an ERD is implemented in a relational model.Note\\n5-4a  Design Case 1: Implementing 1:1 Relationships\\nForeign keys work with primary keys to properly implement relationships in the rela-tional model. The basic rule is very simple: put the primary key of the “one” side (the par -\\nent entity) on the “many” side (the dependent entity) as a foreign key. However, where do you place the foreign key when you are working with a 1:1 relationship? For exam-ple, take the case of a 1:1 relationship between EMPLOYEE and DEPARTMENT based on the business rule “one EMPLOYEE is the manager of one DEPARTMENT, and one DEPARTMENT is managed by one EMPLOYEE. ” In that case, there are two options for selecting and placing the foreign key:\\n1.\\n Place a foreign key in both entities. This option is derived from the basic rule you \\nlearned in Chapter 4. Place EMP_NUM as a foreign key in DEPARTMENT, and place DEPT_ID as a foreign key in EMPLOYEE. However, this solution is not recom-mended because it duplicates work, and it could conflict with other existing relation-ships. (Remember that DEPARTMENT and EMPLOYEE also participate in a 1:M relationship—one department employs many employees.)\\n2.\\n Place a foreign key in one of the entities. In that case, the primary key of one of the two entities appears as a foreign key in the other entity. That is the preferred solution, but a question remains: which  primary key should be used as a foreign key? The answer \\nis found in Table 5.5, which shows the rationale for selecting the foreign key in a 1:1 relationship based on the relationship properties in the ERD.\\nFigure 5.7 illustrates the “EMPLOYEE manages DEPARTMENT” relationship. Note \\nthat in this case, EMPLOYEE is mandatory to DEPARTMENT. Therefore, EMP_NUM is placed as the foreign key in DEPARTMENT. Alternatively, you might also argue that the “manager” role is played by the EMPLOYEE in the DEPARTMENT.\\nAs a designer, you must recognize that 1:1 relationships exist in the real world; there-\\nfore, they should be supported in the data model. In fact, a 1:1 relationship is used to \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6fc92a0c-3a7d-426e-b764-3f26bd2bedce', embedding=None, metadata={'page_label': '183', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    183\\nensure that two entity sets are not placed in the same table. In other words, EMPLOYEE \\nand DEPARTMENT are clearly separate and unique entity types that do not belong \\ntogether in a single entity. If you grouped them together in one entity, what would you \\nname that entity?\\n5-4b   Design Case 2: Maintaining History of  \\nTime-Variant Data\\nCompany managers generally realize that good decision making is based on the infor -\\nmation generated through the data stored in databases. Such data reflects both current \\nand past events. Company managers use the data stored in databases to answer questions \\nsuch as “How do the current company profits compare to those of previous years?” and \\n“What are XYZ product’s sales trends?” In other words, the data stored in databases \\nreflects not only current data, but historic data.\\nNormally, data changes are managed by replacing the existing attribute value with \\nthe new value, without regard to the previous value. However, in some situations \\nthe history of values for a given attribute must be preserved. From a data-modeling \\npoint of view, time-variant data  refer to data whose values change over time and \\nfor which you must  keep a history of the data changes. Y ou could argue that all data \\nin a database is subject to change over time and is therefore time variant. However, \\nsome attribute values, such as your date of birth or your Social Security number, are \\nnot time variant. On the other hand, attributes such as your student GPA or your \\nbank account balance are subject to change over time. Sometimes the data changes \\nare externally originated and event driven, such as a product price change. On other \\noccasions, changes are based on well-defined schedules, such as the daily stock quote \\n“open” and “close” values.TABLE 5.5\\nSELECTION OF FOREIGN KEY IN A 1:1 RELATIONSHIP\\nCASE ER RELATIONSHIP CONSTRAINTS ACTION\\nI One side is mandatory and the other side \\nis optional.Place the PK of the entity on the mandatory side in the entity \\non the optional side as a FK, and make the FK mandatory.\\nII Both sides are optional. Select the FK that causes the fewest nulls, or place the FK in the \\nentity in which the (relationship) role is played.\\nIII Both sides are mandatory. See Case II, or consider revising your model to ensure that the \\ntwo entities do not belong together in a single entity.\\nFIGURE 5.7  THE 1:1 RELATIONSHIP BETWEEN DEPARTMENT AND EMPLOYEE  \\ntime-variant data\\nData whose values \\nare a function of time. \\nFor example, time-\\nvariant data can be \\nseen at work when \\na company’s history \\nof all administrative \\nappointments is tracked.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8845a671-e107-444d-9f5e-c2a4e6faa334', embedding=None, metadata={'page_label': '184', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='184   Part 2     Design Concepts\\nThe storage of time-variant data requires changes in the data model; the type of change \\ndepends on the nature of the data. Some time-variant data is equivalent to having a mul -\\ntivalued attribute in your entity. To model this type of time-variant data, you must create \\na new entity in a 1:M relationship with the original entity. This new entity will contain the \\nnew value, the date of the change, and any other attribute that is pertinent to the event \\nbeing modeled. For example, if you want to track salary histories for each employee, then \\nthe EMP_SALARY attribute becomes multivalued, as shown in Figure 5.8. In this case, \\nfor each employee, there will be one or more records in the SALARY_HIST entity, which \\nstores the salary amount and the date when the new salary goes into effect.\\nOther time-variant data can turn a 1:M relationship into an M:N relationship. \\nAssume that in addition to employee data, your data model includes data about the \\ndifferent departments in the organization and which employee manages each depart -\\nment. Assuming that each department is managed by only one employee and each \\nemployee can manage one department at most, then a 1:1 relationship would exist \\nbetween EMPLOYEE and DEPARTMENT. This relationship would record the current \\nmanager of each department. However, if you want to keep track of the history of all \\ndepartment managers as well as the current manager, you can create the model shown \\nin Figure 5.9.\\nNote that in Figure 5.9, the MGR_HIST entity has a 1:M relationship with \\nEMPLOYEE and a 1:M relationship with DEPARTMENT to reflect the fact that \\nan employee could be the manager of many different departments over time, and a \\ndepartment could have many different employee managers. Because you are record -\\ning time-variant data, you must store the DATE_ASSIGN attribute in the MGR_HIST \\nentity to provide the date that the employee (EMP_NUM) became the department \\nmanager. The primary key of MGR_HIST permits the same employee to be the man -\\nager of the same department, but on different dates. If that scenario is not the case in \\nyour environment—if, for example, an employee is the manager of a department only \\nonce—you could make DATE_ASSIGN a nonprime attribute in the MGR_HIST entity.FIGURE 5.8  MAINTAINING SALARY HISTORY  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ff569923-5299-4f46-977a-9ac839d6ad3e', embedding=None, metadata={'page_label': '185', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    185\\nNote in Figure 5.9 that the “manages” relationship is optional in theory and redun -\\ndant in practice. At any time, you could identify the manager of a department by \\nretrieving the most recent DATE_ASSIGN date from MGR_HIST for a given depart -\\nment. On the other hand, the ERD in Figure 5.9 differentiates between current data \\nand historic data. The current  manager relationship is implemented by the “manages” \\nrelationship between EMPLOYEE and DEPARTMENT. Additionally, the historic data \\nis managed through EMP_MGR_HIST and DEPT_MGR_HIST. The trade-off with \\nthat model is that each time a new manager is assigned to a department, there will be \\ntwo data modifications: one update in the DEPARTMENT entity and one insert in the \\nMGR_HIST entity.\\nThe flexibility of the model proposed in Figure 5.9 becomes more apparent when you \\nadd the 1:M “one department employs many employees” relationship. In that case, the \\nPK of the “1” side (DEPT_ID) appears in the “many” side (EMPLOYEE) as a foreign \\nkey. Now suppose you would like to keep track of the job history for each of the com -\\npany’s employees—you’ d probably want to store the department, the job code, the date \\nassigned, and the salary. To accomplish that task, you could modify the model in Figure \\n5.9 by adding a JOB_HIST entity. Figure 5.10 shows the use of the new JOB_HIST entity \\nto maintain the employee’s history.\\nAgain, it is worth emphasizing that the “manages” and “employs” relationships \\nare theoretically optional and redundant in practice. Y ou can always find out where \\neach employee works by looking at the job history and selecting only the most \\ncurrent data row for each employee. However, as you will discover in Chapter 7, \\nIntroduction to Structured Query Language (SQL), and in Chapter 8, Advanced \\nSQL, finding where each employee works is not a trivial task. Therefore, the model \\nrepresented in Figure 5.10 includes the admittedly redundant but unquestionably \\nuseful “manages” and “employs” relationships to separate current data from his -\\ntoric data.FIGURE 5.9  MAINTAINING MANAGER HISTORY  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='510db88b-e8db-4ce3-a40d-f45595fdfe61', embedding=None, metadata={'page_label': '186', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='186   Part 2     Design Concepts\\n5-4c  Design Case 3: Fan Traps\\nCreating a data model requires proper identification of the data relationships among \\nentities. However, due to miscommunication or incomplete understanding of the busi -\\nness rules or processes, it is not uncommon to misidentify relationships among entities. \\nUnder those circumstances, the ERD may contain a design trap. A design trap  occurs \\nwhen a relationship is improperly or incompletely identified and is therefore represented \\nin a way that is not consistent with the real world. The most common design trap is \\nknown as a fan trap .\\nA fan trap  occurs when you have one entity in two 1:M relationships to other enti -\\nties, thus producing an association among the other entities that is not expressed in the \\nmodel. For example, assume that the JCB basketball league has many divisions. Each \\ndivision has many players, and each division has many teams. Given those “incomplete” \\nbusiness rules, you might create an ERD that looks like the one in Figure 5.11.\\nAs you can see in Figure 5.11, DIVISION is in a 1:M relationship with TEAM and in a \\n1:M relationship with PLAYER. Although that representation is semantically correct, the \\nrelationships are not properly identified. For example, there is no way to identify which \\nplayers belong to which team. Figure 5.11 also shows a sample instance relationship rep -\\nresentation for the ERD. Note that the relationship lines for the DIVISION instances fan \\nout to the TEAM and PLAYER entity instances—thus the “fan trap” label.\\nFigure 5.12 shows the correct ERD after the fan trap has been eliminated. Note that, \\nin this case, DIVISION is in a 1:M relationship with TEAM. In turn, TEAM is in a 1:M \\nrelationship with PLAYER. Figure 5.12 also shows the instance relationship representa -\\ntion after eliminating the fan trap.\\nGiven the design in Figure 5.12, note how easy it is to see which players play for which \\nteam. However, to find out which players play in which division, you first need to see \\nwhat teams belong to each division; then you need to find out which players play on each \\nteam. In other words, there is a transitive relationship between DIVISION and PLAYER \\nvia the TEAM entity.FIGURE 5.10  MAINTAINING JOB HISTORY  \\ndesign trap\\nA problem that occurs \\nwhen a relationship \\nis improperly or \\nincompletely identified \\nand therefore is \\nrepresented in a way \\nthat is not consistent \\nwith the real world. The \\nmost common design \\ntrap is known as a fan \\ntrap.\\nfan trap\\nA design trap that occurs \\nwhen one entity is in \\ntwo 1:M relationships \\nwith other entities, thus \\nproducing an association \\namong the other entities \\nthat is not expressed in \\nthe model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f396cfe7-9355-43aa-8a92-ca0583b91394', embedding=None, metadata={'page_label': '187', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    187\\n5-4d  Design Case 4: Redundant Relationships\\nAlthough redundancy is often good to have in computer environments (multiple \\nbackups in multiple places, for example), redundancy is seldom good in the database \\nenvironment. (As you learned in Chapter 3, The Relational Database Model, redun -\\ndancies can cause data anomalies in a database.) Redundant relationships occur \\nwhen there are multiple relationship paths between related entities. The main con -\\ncern with redundant relationships is that they remain consistent across the model. \\nHowever, it is important to note that some designs use redundant relationships as a \\nway to simplify the design.FIGURE 5.11  INCORRECT ERD WITH FAN TRAP PROBLEM  \\nFIGURE 5.12  CORRECTED ERD AFTER REMOVAL OF THE FAN TRAP  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5de953fb-f643-46ae-9f00-ca655586da71', embedding=None, metadata={'page_label': '188', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='188   Part 2     Design Concepts\\nAn example of redundant relationships was first introduced in Figure 5.9 during the \\ndiscussion of maintaining a history of time-variant data. However, the use of the redun -\\ndant “manages” and “employs” relationships was justified by the fact that such relation -\\nships dealt with current data rather than historic data. Another more specific example of \\na redundant relationship is represented in Figure 5.13.\\nIn Figure 5.13, note the transitive 1:M relationship between DIVISION and PLAYER \\nthrough the TEAM entity set. Therefore, the relationship that connects DIVISION and \\nPLAYER is redundant, for all practical purposes. In that case, the relationship could be \\nsafely deleted without losing any information-generation capabilities in the model.FIGURE 5.13  A REDUNDANT RELATIONSHIP  \\nSummary\\n• The extended entity relationship (EER) model adds semantics to the ER model via \\nentity supertypes, subtypes, and clusters. An entity supertype is a generic entity type \\nthat is related to one or more entity subtypes.\\n• A specialization hierarchy depicts the arrangement and relationships between entity \\nsupertypes and entity subtypes. Inheritance means that an entity subtype inherits the \\nattributes and relationships of the supertype. Subtypes can be disjoint or overlapping. \\nA subtype discriminator is used to determine to which entity subtype the supertype \\noccurrence is related. The subtypes can exhibit partial or total completeness. There are \\nbasically two approaches to developing a specialization hierarchy of entity supertypes \\nand subtypes: specialization and generalization.\\n• An entity cluster is a “virtual” entity type used to represent multiple entities and rela -\\ntionships in the ERD. An entity cluster is formed by combining multiple interrelated \\nentities and relationships into a single, abstract entity object.\\n• Natural keys are identifiers that exist in the real world. Natural keys sometimes make \\ngood primary keys, but not always. Primary keys must have unique values, they \\nshould be nonintelligent, they must not change over time, and they are preferably \\nnumeric and composed of a single attribute.\\n• Composite keys are useful to represent M:N relationships and weak (strong identify -\\ning) entities.\\n• Surrogate primary keys are useful when there is no natural key that makes a suitable \\nprimary key, when the primary key is a composite primary key with multiple data \\ntypes, or when the primary key is too long to be usable.\\n• In a 1:1 relationship, place the PK of the mandatory entity as a foreign key in the \\noptional entity, as an FK in the entity that causes the fewest nulls, or as an FK where \\nthe role is played.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc890774-953d-4ef3-80c7-4884e481d8f3', embedding=None, metadata={'page_label': '189', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    189\\n• Time-variant data refers to data whose values change over time and require that you \\nkeep a history of data changes. To maintain the history of time-variant data, you must create an entity that contains the new value, the date of change, and any other time-relevant data. This entity maintains a 1:M relationship with the entity for which the history is to be maintained.\\n•\\n A fan trap occurs when you have one entity in two 1:M relationships to other entities, and there is an association among the other entities that is not expressed in the model. Redundant relationships occur when there are multiple relationship paths between related entities. The main concern with redundant relationships is that they remain consistent across the model.\\ncompleteness constraint\\ndesign trapdisjoint subtype EER diagram (EERD)entity clusterentity subtypeentity supertypeextended entity relationship \\nmodel (EERM)\\nfan trapgeneralizationinheritancenatural key (natural identifier)nonoverlapping subtypeoverlapping subtypepartial completenessspecializationspecialization hierarchysubtype discriminatorsurrogate keytime-variant datatotal completeness\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. What is an entity supertype, and why is it used?\\n2. What kinds of data would you store in an entity subtype?\\n3. What is a specialization hierarchy?\\n4. What is a subtype discriminator? Give an example of its use.\\n5. What is an overlapping subtype? Give an example.\\n6. What is the difference between partial completeness and total completeness?\\nFor Questions 7–9, refer to Figure Q5.7.\\n7. List all of the attributes of a movie.\\n8. According to the data model, is it required that every entity instance in the PROD-\\nUCT table be associated with an entity instance in the CD table? Why, or why not?\\n9. Is it possible for a book to appear in the BOOK table without appearing in the PRODUCT table? Why, or why not?\\n10.\\n What is an entity cluster, and what advantages are derived from its use?\\n11. What primary key characteristics are considered desirable? Explain why  each char -\\nacteristic is considered desirable.\\n12. Under what circumstances are composite primary keys appropriate?\\n13. What is a surrogate primary key, and when would you use one?Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='30641945-cc74-413d-aedc-3bd1387f3aa2', embedding=None, metadata={'page_label': '190', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='190   Part 2     Design Concepts\\n14. When implementing a 1:1 relationship, where should you place the foreign key if \\none side is mandatory and one side is optional? Should the foreign key be mandatory \\nor optional?\\n15. What is time-variant data, and how would you deal with such data from a database \\ndesign point of view?\\n16. What is the most common design trap, and how does it occur?\\n1. Given the following business scenario, create a Crow’s Foot ERD using a special -\\nization hierarchy if appropriate. Two-Bit Drilling Company keeps information on \\nemployees and their insurance dependents. Each employee has an employee num -\\nber, name, date of hire, and title. If an employee is an inspector, then the date of cer -\\ntification and certification renewal date should also be recorded in the system. For \\nall employees, the Social Security number and dependent names should be kept. All \\ndependents must be associated with one and only one employee. Some employees \\nwill not have dependents, while others will have many dependents.\\n2. Given the following business scenario, create a Crow’s Foot ERD using a special -\\nization hierarchy if appropriate. Tiny Hospital keeps information on patients and \\nhospital rooms. The system assigns each patient a patient ID number. In addition, \\nthe patient’s name and date of birth are recorded. Some patients are resident patients \\nwho spend at least one night in the hospital, and others are outpatients who are \\ntreated and released. Resident patients are assigned to a room. Each room is iden -\\ntified by a room number. The system also stores the room type (private or semipri -\\nvate) and room fee. Over time, each room will have many patients. Each resident \\npatient will stay in only one room. Every room must have had a patient, and every \\nresident patient must have a room.\\n3. Given the following business scenario, create a Crow’s Foot ERD using a special -\\nization hierarchy if appropriate. Granite Sales Company keeps information on FIGURE Q5.7  THE PRODUCT DATA MODEL  \\nProblems\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d62990c8-de04-4917-8bf0-32b131e4b113', embedding=None, metadata={'page_label': '191', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    191\\nemployees and the departments in which they work. For each department, the \\ndepartment name, internal mail box number, and office phone extension are kept. A department can have many assigned employees, and each employee is assigned to only one department. Employees can be salaried, hourly, or work on contract. All employees are assigned an employee number, which is kept along with the employee’s name and address. For hourly employees, hourly wages and target weekly work hours are stored; for example, the company may target 40 hours/week for some employees, 32 for others, and 20 for others. Some salaried employ-ees are salespeople who can earn a commission in addition to their base salary. For all salaried employees, the yearly salary amount is recorded in the system. For salespeople, their commission percentage on sales and commission percentage on profit are stored in the system. For example, John is a salesperson with a base sal-ary of $50,000 per year plus a 2 percent commission on the sales price for all sales he makes, plus another 5 percent of the profit on each of those sales. For contract employees, the beginning date and end date of their contracts are stored along with the billing rate for their hours.\\n4.\\n In Chapter 4, you saw the creation of the Tiny College database design, which reflected such business rules as “a professor may advise many students” and “a professor may chair one department. ” Modify the design shown in Figure 4.36 to include these business rules:\\n•\\n An employee could be staff, a professor, or an administrator.\\n• A professor may also be an administrator.\\n• Staff employees have a work-level classification, such as Level I or Level II.\\n• Only professors can chair a department. A department is chaired by only one professor.\\n•\\n Only professors can serve as the dean of a college. Each of the university’s colleges is served by one dean.\\n•\\n A professor can teach many classes.\\n• Administrators have a position title.\\n Given that information, create the complete ERD that contains all primary keys, foreign keys, and main attributes.\\n5.\\n Tiny College wants to keep track of the history of all its administrative appoint-ments, including dates of appointment and dates of termination. (Hint:  \\nTime-variant data is at work.) The Tiny College chancellor may want to know how many deans worked in the College of Business between January 1, 1960, and January 1, 2016, or who the dean of the College of Education was in 1990. Given that information, create the complete ERD that contains all primary keys, foreign keys, and main attributes.\\n6.\\n Some Tiny College staff employees are information technology (IT) personnel. Some IT personnel provide technology support for academic programs, some pro-vide technology infrastructure support, and some provide support for both. IT per -\\nsonnel are not professors; they are required to take periodic training to retain their technical expertise. Tiny College tracks all IT personnel training by date, type, and results (completed versus not completed). Given that information, create the com-plete ERD that contains all primary keys, foreign keys, and main attributes.\\n7.\\n The FlyRight Aircraft Maintenance (FRAM) division of the FlyRight Company (FRC) performs all maintenance for FRC’s aircraft. Produce a data model segment that reflects the following business rules:\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd259c14-b085-4810-a7d7-77cb0cdf4f16', embedding=None, metadata={'page_label': '192', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='192   Part 2    Design Concepts\\n• All mechanics are FRC employees. Not all employees are mechanics.\\n• Some mechanics are specialized in engine (EN) maintenance. Others are spe-\\ncialized in airframe (AF) maintenance or avionics (AV) maintenance. (Avionics are the electronic components of an aircraft that are used in communication and navigation.) All mechanics take periodic refresher courses to stay current in their areas of expertise. FRC tracks all courses taken by each mechanic—date, course type, certification (Y/N), and performance.\\n•\\n FRC keeps an employment history of all mechanics. The history includes the date hired, date promoted, and date terminated.\\nGiven those requirements, create the Crow’s Foot ERD segment.\\n8.\\n “Martial Arts R Us” (MARU) needs a database. MARU is a martial arts school with hundreds of students. The database must keep track of all the classes that are offered, who is assigned to teach each class, and which students attend each class. Also, it is important to track the progress of each student as they advance. Create a complete Crow’s Foot ERD for these requirements:\\n•\\n Students are given a student number when they join the school. The number is stored along with their name, date of birth, and the date they joined the school.\\n•\\n All instructors are also students, but clearly not all students are instructors. In addition to the normal student information, for all instructors, the date that they start working as an instructor must be recorded along with their instructor status (compensated or volunteer).\\n•\\n An instructor may be assigned to teach any number of classes, but each class has one and only one assigned instructor. Some instructors, especially volunteer instructors, may not be assigned to any class.\\n•\\n A class is offered for a specific level at a specific time, day of the week, and  \\nlocation. For example, one class taught on Mondays at 5:00 p.m. in Room 1 is an intermediate-level class. Another class taught on Mondays at 6:00 p.m. in Room 1 is a beginner-level class. A third class taught on Tuesdays at 5:00 p.m. in Room 2 is an advanced-level class.\\n•\\n Students may attend any class of the appropriate level during each week, so there is no expectation that any particular student will attend any particular class ses-sion. Therefore, the attendance of students at each individual class meeting must be tracked.\\n•\\n A student will attend many different class meetings, and each class meeting is normally attended by many students. Some class meetings may not be attended by any students. New students may not have attended any class meetings yet.\\n•\\n At any given meeting of a class, instructors other than the assigned instruc-tor may show up to help. Therefore, a given class meeting may have a head  \\ninstructor and many assistant instructors, but it will always have at least the one instructor who is assigned to that class. For each class meeting, the date of the class and the instructors’ roles (head instructor or assistant instructor) need to be recorded. For example, Mr. Jones is assigned to teach the Monday,  \\n5:00 p.m., intermediate class in Room 1. During a particular meeting of that class,  \\nMr. Jones was the head instructor and Ms. Chen served as an assistant instructor.Cases\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c663b1a8-adec-4ec4-b78c-c593d0200b9f', embedding=None, metadata={'page_label': '193', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    193\\n• Each student holds a rank in the martial arts. The rank name, belt color, and rank \\nrequirements are stored. Most ranks have numerous rank requirements, but each requirement is associated with only one particular rank. All ranks except white belt have at least one requirement.\\n•\\n A given rank may be held by many students. While it is customary to think of a student as having a single rank, it is necessary to track each student’s progress through the ranks. Therefore, every rank that a student attains is kept in the sys-tem. New students joining the school are automatically given the rank of white belt. The date that a student is awarded each rank should be kept in the system. All ranks have at least one student who has achieved that rank at some time.\\n9.\\n The Journal of E-commerce Research Knowledge is a prestigious information systems \\nresearch journal. It uses a peer-review process to select manuscripts for publication. Only about 10 percent of the manuscripts submitted to the journal are accepted for publication. A new issue of the journal is published each quarter. Create a complete ERD to support the business needs described below. \\n•\\n Unsolicited manuscripts are submitted by authors. When a manuscript is received, the editor assigns it a number and records some basic information about it in the system, including the title of the manuscript, the date it was received, and a manu -\\nscript status of “received. ” Information about the author(s) is also recorded, includ-ing each author’s name, mailing address, email address, and affiliation (the author’s school or company). Every manuscript must have an author. Only authors who have submitted manuscripts are kept in the system. It is typical for a manuscript to have several authors. A single author may have submitted many different manuscripts to the journal. Additionally, when a manuscript has multiple authors, it is important to record the order in which the authors are listed in the manuscript credits.\\n•\\n At his or her earliest convenience, the editor will briefly review the topic of the manuscript to ensure that its contents fall within the scope of the journal. If the content is not appropriate for the journal, the manuscript’s status is changed to “rejected, ” and the author is notified via email. If the content is within the scope of the journal, then the editor selects three or more reviewers to review the manu-script. Reviewers work for other companies or universities and read manuscripts to ensure their scientific validity. For each reviewer, the system records a reviewer number, name, email address, affiliation, and areas of interest. Areas of interest are predefined areas of expertise that the reviewer has specified. An area of inter -\\nest is identified by an IS code and includes a description (for example, IS2003 is the code for “database modeling”). A reviewer can have many areas of interest, and an area of interest can be associated with many reviewers. All reviewers must specify at least one area of interest. It is unusual, but possible, to have an area of interest for which the journal has no reviewers. The editor will change the status of the manuscript to “under review” and record which reviewers received the manuscript and the date it was sent to each reviewer. A reviewer will typically receive several manuscripts to review each year, although new reviewers may not have received any manuscripts yet.\\n•\\n The reviewers will read the manuscript at their earliest convenience and pro-vide feedback to the editor. The feedback from each reviewer includes rating the manuscript on a 10-point scale for appropriateness, clarity, methodology, and contribution to the field, as well as a recommendation for publication (accept or reject). The editor will record all of this information in the system for each review received, along with the date the feedback was received. Once all of the reviewers \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fc78cabe-1c5d-4292-821d-27bc8aa2b0ca', embedding=None, metadata={'page_label': '194', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='194   Part 2    Design Concepts\\nhave provided their evaluations, the editor will decide whether to publish the \\nmanuscript and change its status to “accepted” or “rejected. ” If the manuscript will be published, the date of acceptance is recorded.\\n•\\n Once a manuscript has been accepted for publication, it must be scheduled. For each issue of the journal, the publication period (fall, winter, spring, or summer), publication year, volume, and number are recorded. An issue will contain many manuscripts, although the issue may be created in the system before it is known which manuscripts will be published in that issue. An accepted manuscript appears in only one issue of the journal. Each manuscript goes through a typesetting pro -\\ncess that formats the content, including fonts, font size, line spacing, justification, and so on. Once the manuscript has been typeset, its number of pages is recorded in the system. The editor will then decide which issue each accepted manuscript will appear in and the order of manuscripts within each issue. The order and the beginning page number for each manuscript must be stored in the system. Once the manuscript has been scheduled for an issue, the status of the manuscript is changed to “scheduled. ” Once an issue is published, the print date for the issue is recorded, and the status of each manuscript in that issue is changed to “published. ”\\n10.\\n Global Unified Technology Sales (GUTS) is moving toward a “bring your own device” (BYOD) model for employee computing. Employees can use traditional desktop computers in their offices. They can also use a variety of personal mobile computing devices such as tablets, smartphones, and laptops. The new computing  \\nmodel introduces some security risks that GUTS is attempting to address. The company wants to ensure that any devices connecting to their servers are properly  \\nregistered and approved by the Information Technology department. Create a com-plete ERD to support the business needs described below: \\n•\\n Every employee works for a department that has a department code, name, mail box number, and phone number. The smallest department currently has 5 employees, and the largest department has 40 employees. This system will only track in which depart-ment an employee is currently employed. Very rarely, a new department can be created within the company. At such times, the department may exist temporarily without any employees. For every employee, an employee number and name (first, last, and middle initial) are recorded in the system. It is also necessary to keep each employee’s title.\\n•\\n An employee can have many devices registered in the system. Each device is assigned an identification number when it is registered. Most employees have at least one device, but newly hired employees might not have any devices registered initially. For each device, the brand and model need to be recorded. Only devices that are registered to an employee will be in the system. While unlikely, it is possible that a device could transfer from one employee to another. However, if that happens, only the employee who currently owns the device is tracked in the system. When a device is registered in the system, the date of that registration needs to be recorded.\\n•\\n Devices can be either desktop systems that reside in a company office or mobile devices. Desktop devices are typically provided by the company and are intended to be a permanent part of the company network. As such, each desktop device is assigned a static IP address, and the MAC address for the computer hardware is kept in the system. A desktop device is kept in a static location (building name and office number). This location should also be kept in the system so that, if the device becomes compromised, the IT department can dispatch someone to remediate the problem.\\n•\\n For mobile devices, it is important to also capture the device’s serial number, which operating system (OS) it is using, and the version of the OS. The IT depart-ment is also verifying that each mobile device has a screen lock enabled and has \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c53f9b39-d9af-43e3-a7dd-1d35cdb3521e', embedding=None, metadata={'page_label': '195', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    195\\nencryption enabled for data. The system should support storing information on \\nwhether or not each mobile device has these capabilities enabled.\\n• Once a device is registered in the system, and the appropriate capabilities are enabled if it is a mobile device, the device may be approved for connections to one or more servers. Not all devices meet the requirements to be approved at first so the device might be in the system for a period of time before it is approved to connect to any server. GUTS has a number of servers, and a device must be approved for each server individually. Therefore, it is possible for a single device to be approved for several servers but not for all servers.\\n•\\n Each server has a name, brand, and IP address. Within the IT department’s facilities are a number of climate-controlled server rooms where the physical servers can be located. Which room each server is in should also be recorded. Further, it is necessary to track which operating system is being used on each server. Some servers are virtual servers and some are physical servers. If a server is a virtual server, then the system should track which physical server it is running on. A single physical server can host many virtual servers, but each virtual server is hosted on only one physical server. Only physical servers can host a virtual server. In other words, one virtual server can-not host another virtual server. Not all physical servers host a virtual server.\\n•\\n A server will normally have many devices that are approved to access the server, but it is possible for new servers to be created that do not yet have any approved devices. When a device is approved for connection to a server, the date of that approval should be recorded. It is also possible for a device that was approved for a server to lose its approval. If that happens, the date that the approval was removed should be recorded. If a device loses its approval, it may regain that approval at a later date if whatever circumstance that lead to the removal is resolved.\\n•\\n A server can provide many user services, such as email, chat, homework manag-ers, and others. Each service on a server has a unique identification number and name. The date that GUTS began offering that service should be recorded. Each service runs on only one server although new servers might not offer any services initially. Client-side services are not tracked in this system so every service must be associated with a server.\\n•\\n Employees must get permission to access a service before they can use it. Most employees have permissions to use a wide array of services, but new employees might not have permission on any service. Each service can support multiple approved employees as users, but new services might not have any approved users at first. The date on which the employee is approved to use a service is tracked by the system. The first time an employee is approved to access a service, the employee must create a username and password. This will be the same username and password that the employee will use for every service for which the employee is eventually approved.\\n11.\\n Global Computer Solutions (GCS) is an information technology consulting company with many offices throughout the United States. The company’s success is based on its ability to maximize its resources—that is, its ability to match highly skilled employees with projects according to region. To better manage its projects, GCS has contacted you to design a database so GCS managers can keep track of their customers, employees, projects, project schedules, assignments, and invoices.\\nThe GCS database must support all of GCS’s operations and information require-\\nments. A basic description of the main entities follows:\\n•\\n  The employees  of GCS must have an employee ID, a last name, a middle initial, a \\nfirst name, a region, and a date of hire recorded in the system.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cebe4570-b94b-44f3-9cdf-fb592d75705f', embedding=None, metadata={'page_label': '196', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='196   Part 2    Design Concepts\\n• Valid regions  are as follows: Northwest (NW), Southwest (SW), Midwest North \\n(MN), Midwest South (MS), Northeast (NE), and Southeast (SE).\\n• Each employee has many skills, and many employees have the same skill.\\n• Each skill has a skill ID, description, and rate of pay. Valid skills are as follows: \\nData Entry I, Data Entry II, Systems Analyst I, Systems Analyst II, Database \\nDesigner I, Database Designer II, Cobol I, Cobol II, C++ I, C++ II, VB I, VB II, ColdFusion I, ColdFusion II, ASP I, ASP II, Oracle DBA, MS SQL Server DBA, Network Engineer I, Network Engineer II, Web Administrator, Technical Writer, and Project Manager. Table P5.11a shows an example of the Skills Inventory.\\nTABLE P5.11A\\nSKILL EMPLOYEE\\nData Entry I Seaton Amy; Williams Josh; Underwood Trish\\nData Entry II Williams Josh; Seaton Amy\\nSystems Analyst I Craig Brett; Sewell Beth; Robbins Erin; Bush Emily; Zebras Steve\\nSystems Analyst II Chandler Joseph; Burklow Shane; Robbins Erin\\nDB Designer I Yarbrough Peter; Smith Mary\\nDB Designer II Yarbrough Peter; Pascoe Jonathan\\nCobol I Kattan Chris; Ephanor Victor; Summers Anna; Ellis Maria\\nCobol II Kattan Chris; Ephanor Victor; Batts Melissa\\nC++ I Smith Jose; Rogers Adam; Cope Leslie\\nC++ II Rogers Adam; Bible Hanah\\nVB I Zebras Steve; Ellis Maria\\nVB II Zebras Steve; Newton Christopher\\nColdFusion I Duarte Miriam; Bush Emily\\nColdFusion II Bush Emily; Newton Christopher\\nASP I Duarte Miriam; Bush Emily\\nASP II Duarte Miriam; Newton Christopher\\nOracle DBA Smith Jose; Pascoe Jonathan\\nSQL Server DBA Yarbrough Peter; Smith Jose\\nNetwork Engineer I Bush Emily; Smith Mary\\nNetwork Engineer II Bush Emily; Smith Mary\\nWeb Administrator Bush Emily; Smith Mary; Newton Christopher\\nTechnical Writer Kilby Surgena; Bender Larry\\nProject Manager Paine Brad; Mudd Roger; Kenyon Tiffany; Connor Sean\\n• GCS has many customers . Each customer has a customer ID, name, phone \\nnumber, and region.\\n• GCS works by projects . A project is based on a contract between the cus-\\ntomer and GCS to design, develop, and implement a computerized solution. Each project has specific characteristics such as the project ID, the customer to which the project belongs, a brief description, a project date (the date the contract was signed), an estimated project start date and end date, an esti-mated project budget, an actual start date, an actual end date, an actual cost, and one employee assigned as the manager of the project.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='914431bb-7b13-44a5-a2c5-6ac4555a1df3', embedding=None, metadata={'page_label': '197', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    197\\n• The actual cost of the project is updated each Friday by adding that week’s cost \\nto the actual cost. The week’s cost is computed by multiplying the hours each employee worked by the rate of pay for that skill.\\n•\\n The employee who is the manager of the project must complete a project schedule , \\nwhich effectively is a design and development plan. In the project schedule (or plan), the manager must determine the tasks that will be performed to take the project from beginning to end. Each task has a task ID, a brief task description, starting and ending dates, the types of skills needed, and the number of employees (with the required skills) needed to complete the task. General tasks are the initial interview, database and system design, implementation, coding, testing, and final evaluation and sign-off. For example, GCS might have the project schedule shown in Table P5.11b.\\nTABLE P5.11B\\nPROJECT ID: 1 DESCRIPTION: SALES MANAGEMENT SYSTEM\\nCOMPANY: SEE ROCKS CONTRACT DATE: 2/12/2016 REGION: NW\\nSTART DATE: 3/1/2016 END DATE: 7/1/2016 BUDGET: $15,500\\nSTART DATE END DATE TASK DESCRIPTION SKILL(S) REQUIRED QUANTITY  REQUIRED\\n3/1/16 3/6/16 Initial interview Project ManagerSystems Analyst IIDB Designer I111\\n3/11/16 3/15/16 Database design DB Designer I 1\\n3/11/16 4/12/16 System design Systems Analyst IISystems Analyst I12\\n3/18/16 3/22/16 Database implementation Oracle DBA 1\\n3/25/16 5/20/16 System coding and testing Cobol ICobol IIOracle DBA211\\n3/25/16 6/7/16 System documentation Technical Writer 1\\n6/10/16 6/14/16 Final evaluation Project ManagerSystems Analyst IIDB Designer ICobol II1111\\n6/17/16 6/21/16 On-site system online and data loading Project Manager\\nSystems Analyst IIDB Designer ICobol II1111\\n7/1/16 7/1/16 Sign-off Project Manager 1\\n• GCS pools all of its employees by region; from this pool, employees are assigned to a specific task scheduled by the project manager. For example, in the first project’s schedule, you know that a Systems Analyst II, Database Designer I, and Project Manager are needed for the period from 3/1/16 to 3/6/16. The project manager is assigned when the project is created and remains for the duration of the project. Using that information, GCS searches the employees who are located in the same region as the customer, matches the skills required, and assigns the employees to the project task.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='176a1361-51a8-4047-bb28-0fe83a07f20c', embedding=None, metadata={'page_label': '198', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='198   Part 2    Design Concepts\\n• Each project schedule task can have many employees assigned to it, and a given \\nemployee can work on multiple project tasks. However, an employee can work on only one project task at a time. For example, if an employee is already assigned to work on a project task from 2/20/16 to 3/3/16, the employee cannot work on another task until the current assignment is closed (ends). The date that an assign-ment is closed does not necessarily match the ending date of the project schedule task because a task can be completed ahead of or behind schedule.\\n•\\n Given all of the preceding information, you can see that the assignment associates an employee with a project task, using the project schedule. Therefore, to keep track of the assignment , you require at least the following information: assign-\\nment ID, employee, project schedule task, assignment start date, and assignment end date. The end date could be any date, as some projects run ahead of or behind schedule. Table P5.11c shows a sample assignment form.\\nTABLE P5.11C\\nPROJECT ID: 1 DESCRIPTION: SALES MANAGEMENT SYSTEM\\nCOMPANY: SEE ROCKS CONTRACT DATE: 2/12/2016 AS OF: 03/29/16\\nSCHEDULED ACTUAL ASSIGNMENTS\\nPROJECT TASK START DATE END DATE SKILL EMPLOYEE START DATE END DATE\\nInitial interview 3/1/16 3/6/16 Project Mgr.\\nSys. Analyst IIDB Designer I101-Connor S.102-Burklow S.103-Smith M.3/1/163/1/163/1/163/6/163/6/163/6/16\\nDatabase design 3/11/16 3/15/16 DB Designer I 104-Smith M. 3/11/16 3/14/16\\nSystem design 3/11/16 4/12/16 Sys. Analyst II\\nSys. Analyst I\\nSys. Analyst I105-Burklow S.106-Bush E.107-Zebras S.3/11/163/11/163/11/16\\nDatabase implementation3/18/16 3/22/16 Oracle DBA 108-Smith J. 3/15/16 3/19/16\\nSystem coding and testing3/25/16 5/20/16 Cobol I\\nCobol ICobol IIOracle DBA109-Summers A.110-Ellis M.111-Ephanor V.112-Smith J.3/21/163/21/163/21/163/21/16\\nSystem documentation3/25/16 6/7/16 Tech. Writer 113-Kilby S. 3/25/16\\nFinal evaluation 6/10/16 6/14/16 Project Mgr.\\nSys. Analyst IIDB Designer ICobol II\\nOn-site system online and data loading6/17/16 6/21/16 Project Mgr.\\nSys. Analyst IIDB Designer ICobol II\\nSign-off 7/1/16 7/1/16 Project Mgr.\\n(Note:  The assignment number is shown as a prefix of the employee name—for \\nexample, 101 or 102.) Assume that the assignments shown previously are the only ones as of the date of this design. The assignment number can be any number that matches your database design.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c7783665-681a-4de4-adf9-e01a08fb7e4c', embedding=None, metadata={'page_label': '199', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 5    Advanced Data Modeling    199\\n• Employee work hours are kept in a work log , which contains a record of the \\nactual hours worked by employees on a given assignment. The work log is a \\nform that the employee fills out at the end of each week (Friday) or at the end of each month. The form contains the date, which is either the current Friday of the month or the last workday of the month if it does not fall on a Friday. The form also contains the assignment ID, the total hours worked either that week or up to the end of the month, and the bill number to which the work-log entry is charged. Obviously, each work-log entry can be related to only one bill. A sample list of the current work-log entries for the first sample project is shown in Table P5.11d.\\nTABLE P5.11D\\nEMPLOYEE NAME WEEK ENDING ASSIGNMENT NUMBER HOURS WORKED BILL NUMBER\\nBurklow S. 3/1/16 1-102 4 xxx\\nConnor S. 3/1/16 1-101 4 xxx\\nSmith M. 3/1/16 1-103 4 xxx\\nBurklow S. 3/8/16 1-102 24 xxx\\nConnor S. 3/8/16 1-101 24 xxx\\nSmith M. 3/8/16 1-103 24 xxx\\nBurklow S. 3/15/16 1-105 40 xxx\\nBush E. 3/15/16 1-106 40 xxx\\nSmith J. 3/15/16 1-108 6 xxx\\nSmith M. 3/15/16 1-104 32 xxx\\nZebras S. 3/15/16 1-107 35 xxx\\nBurklow S. 3/22/16 1-105 40\\nBush E. 3/22/16 1-106 40\\nEllis M. 3/22/16 1-110 12\\nEphanor V. 3/22/16 1-111 12\\nSmith J. 3/22/16 1-108 12\\nSmith J. 3/22/16 1-112 12\\nSummers A. 3/22/16 1-109 12\\nZebras S. 3/22/16 1-107 35\\nBurklow S. 3/29/16 1-105 40\\nBush E. 3/29/16 1-106 40\\nEllis M. 3/29/16 1-110 35\\nEphanor V. 3/29/16 1-111 35\\nKilby S. 3/29/16 1-113 40\\nSmith J. 3/29/16 1-112 35\\nSummers A. 3/29/16 1-109 35\\nZebras S. 3/29/16 1-107 35\\nNote: xxx represents the bill ID. Use the one that matches the bill number in your database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc2ae9ab-a688-479c-8939-f4e61ca34533', embedding=None, metadata={'page_label': '200', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='200   Part 2    Design Concepts\\n• Finally, every 15 days, a bill  is written and sent to the customer for the total \\nhours worked on the project during that period. When GCS generates a bill, \\nit uses the bill number to update the work-log entries that are part of the bill. In summary, a bill can refer to many work-log entries, and each work-log entry can be related to only one bill. GCS sent one bill on 3/15/16 for the first project (SEE ROCKS), totaling the hours worked between 3/1/16 and 3/15/16. Therefore, you can safely assume that there is only one bill in this table and that the bill covers the work-log entries shown in the preceding form.\\nY our assignment is to create a database that fulfills the operations described in this problem. The minimum required entities are employee, skill, customer, region, project, project schedule, assignment, work log, and bill. (There are additional required entities that are not listed.) \\n•\\n Create all of the required tables and required relationships.\\n• Create the required indexes to maintain entity integrity when using surrogate primary keys.\\n•\\n Populate the tables as needed, as indicated in the sample data and forms.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13d3eea3-fe7c-437a-9639-43ce0806c2a6', embedding=None, metadata={'page_label': '201', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 6\\nNormalization of Database Tables\\nIn this chapter, you will learn:\\n• What normalization is and what role it plays in the database design process\\n• About the normal forms 1NF, 2NF, 3NF, BCNF, and 4NF\\n• How normal forms can be transformed from lower normal forms to higher normal forms\\n• That normalization and ER modeling are used concurrently to produce a good database design\\n• That some situations require denormalization to generate information efficiently\\nPreviewGood database design must be matched to good table structures. In this chapter, you \\nwill learn to evaluate and design good table structures to control data redundancies, thereby avoiding data anomalies. The process that yields such desirable results is known as normalization.\\nTo recognize and appreciate the characteristics of a good table structure, it is useful to \\nexamine a poor one. Therefore, the chapter begins by examining the characteristics of a poor table structure and the problems it creates. Y ou then learn how to correct the table structure. This methodology will yield important dividends: you will know how to design a good table structure and how to repair a poor one.\\nY ou will discover not only that data anomalies can be eliminated through normaliza-\\ntion, but that a properly normalized set of table structures is actually less complicated to use than an unnormalized set. In addition, you will learn that the normalized set of table structures more faithfully reflects an organization’s real operations.\\nData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH06_ConstructCo  P\\t P\\t P\\t P\\nCH06_Eval  P\\t P\\t P\\t PCH06_Service  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nData Files Available on cengagebrain.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3276e246-e9bb-475d-afe0-c1aef5dada3f', embedding=None, metadata={'page_label': '202', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='202   Part 2    Design Concepts\\n6-1 Database Tables and Normalization\\nHaving good relational database software is not enough to avoid the data redundancy \\ndiscussed in Chapter 1, Database Systems. If the database tables are treated as though they are files in a file system, the relational database management system (RDBMS) never has a chance to demonstrate its superior data-handling capabilities.\\nThe table is the basic building block of database design. Consequently, the table’s \\nstructure is of great interest. Ideally, the database design process explored in Chapter 4, Entity Relationship (ER) Modeling, yields good table structures. Y et, it is possible to create poor table structures even in a good database design. How do you recognize a poor table structure, and how do you produce a good table? The answer to both ques-tions involves normalization. Normalization is a process for evaluating and correcting table structures to minimize data redundancies, thereby reducing the likelihood of data anomalies. The normalization process involves assigning attributes to tables based on the concept of determination you learned in Chapter 3, The Relational Database Model.\\nNormalization works through a series of stages called normal forms. The first three \\nstages are described as first normal form (1NF), second normal form (2NF), and third normal form (3NF). From a structural point of view, 2NF is better than 1NF, and 3NF is better than 2NF. For most purposes in business database design, 3NF is as high as you need to go in the normalization process. However, you will discover that properly designed 3NF structures also meet the requirements of fourth normal form (4NF).\\nAlthough normalization is a very important ingredient in database design, you should \\nnot assume that the highest level of normalization is always the most desirable. Gener -\\nally, the higher the normal form, the more relational join operations you need to produce a specified output. Also, more resources are required by the database system to respond to end-user queries. A successful design must also consider end-user demand for fast performance. Therefore, you will occasionally need to denormalize  some portions of a \\ndatabase design to meet performance requirements. Denormalization produces a lower normal form; that is, a 3NF will be converted to a 2NF through denormalization. How-ever, the price you pay for increased performance through denormalization is greater data redundancy.\\nAlthough the word table is used throughout this chapter, formally, normalization is con-cerned with relations. In Chapter 3 you learned that the terms table and relation are fre -\\nquently used interchangeably. In fact, you can say that a table is the implementation view of a logical relation that meets some specific conditions. (See Table 3.1.) However, being more rigorous, the mathematical relation does not allow duplicate tuples; whereas they could exist in tables (see Section 6-5). Also, in normalization terminology, any attribute that is at least part of a key is known as a \\nprime attribute  instead of the more common \\nterm key attribute , which was introduced earlier. Conversely, a nonprime attribute , or \\na nonkey attribute , is not part of any candidate key.Notenormalization\\nA process that assigns attributes to entities so that data redundancies are reduced or eliminated.\\ndenormalization\\nA process by which a table is changed from a higher-level normal form to a lower-level normal form, usually to increase processing speed. Denormalization potentially yields data anomalies.\\nprime attribute\\nA key attribute; that is, an attribute that is part of a key or is the whole key. See also key attributes.\\nkey attributes\\nThe attributes that form a primary key. See also prime attribute.\\nnonprime attribute\\nAn attribute that is not part of a key.\\nnonkey attribute\\nSee nonprime attribute.\\n6-2 The Need For Normalization\\nNormalization is typically used in conjunction with the entity relationship modeling that you learned in the previous chapters. Database designers commonly use normaliza-tion in two situations. When designing a new database structure based on the business requirements of the end users, the database designer will construct a data model using a technique such as Crow’s Foot notation ERDs. After the initial design is complete, \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b6604548-d639-4b49-b213-c2917d88be59', embedding=None, metadata={'page_label': '203', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    203\\nthe designer can use normalization to analyze the relationships among the attributes \\nwithin each entity and determine if the structure can be improved through normaliza -\\ntion. Alternatively, database designers are often asked to modify existing data structures \\nthat can be in the form of flat files, spreadsheets, or older database structures. Again, by \\nanalyzing relationships among the attributes or fields in the data structure, the database \\ndesigner can use the normalization process to improve the existing data structure and \\ncreate an appropriate database design. Whether you are designing a new database struc -\\nture or modifying an existing one, the normalization process is the same.\\nTo get a better idea of the normalization process, consider the simplified database \\nactivities of a construction company that manages several building projects. Each project \\nhas its own project number, name, assigned employees, and so on. Each employee has an \\nemployee number, name, and job classification, such as engineer or computer technician.\\nThe company charges its clients by billing the hours spent on each contract. The hourly \\nbilling rate is dependent on the employee’s position. For example, one hour of computer \\ntechnician time is billed at a different rate than one hour of engineer time. Periodically, a \\nreport is generated that contains the information displayed in Table 6.1.\\nThe total charge in Table 6.1 is a derived attribute and is not stored in the table at this \\npoint.\\nThe easiest short-term way to generate the required report might seem to be a table \\nwhose contents correspond to the reporting requirements. (See Figure 6.1.)\\nFIGURE 6.1  TABULAR REPRESENTATION OF THE REPORT FORMAT  \\nTable name: RPT_FORMAT Database name: Ch06_ConstructCo\\nNote that the data in Figure 6.1 reflects the assignment of employees to projects. \\nApparently, an employee can be assigned to more than one project. For example, Dar -\\nlene Smithson (EMP_NUM = 112) has been assigned to two projects: Amber Wave and \\nStarflight. Given the structure of the dataset, each project includes only a single occur -\\nrence of any one employee. Therefore, knowing the PROJ_NUM and EMP_NUM values \\nwill let you find the job classification and its hourly charge. In addition, you will know \\nthe total number of hours each employee worked on each project. (The total charge—a \\nderived attribute whose value can be computed by multiplying the hours billed and the \\ncharge per hour—has not been included in Figure 6.1. No structural harm is done if this \\nderived attribute is included.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1a59e356-3698-4810-857c-81f16d2f6e55', embedding=None, metadata={'page_label': '204', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='204   Part 2    Design Concepts\\nTABLE 6.1\\nA SAMPLE REPORT LAYOUT\\nPROJECT \\nNUMBERPROJECT NAMEEMPLOYEE NUMBEREMPLOYEE NAME JOB CLASS CHARGE/ HOURHOURS BILLEDTOTAL CHARGE\\n15 Evergreen 103 June E. Arbough Elec. Engineer $ 84.50 23.8 $    2,011.10\\n101 John G. News Database Designer $105.00 19.4 $    2,037.00\\n105 Alice K. Johnson * Database Designer $105.00 35.7 $    3,748.50\\n106 William Smithfield Programmer $ 35.75 12.6 $   450.45\\n102 David H. Senior Systems Analyst $ 96.75 23.8 $    2,302.65\\nSubtotal $10,549.70\\n18 Amber Wave 114 Annelise Jones Applications Designer $ 48.10 24.6 $    1,183.26\\n118 James J. Frommer General Support $ 18.36 45.3 $   831.71\\n104 Anne K. Ramoras * Systems Analyst $ 96.75 32.4 $    3,134.70\\n112 Darlene M. Smithson DSS Analyst $ 45.95 44.0 $    2,021.80\\nSubtotal $ 7,171.47\\n22 Rolling Tide 105 Alice K. Johnson Database Designer $105.00 64.7 $    6,793.50\\n104 Anne K. Ramoras Systems Analyst $96.75 48.4 $    4,682.70\\n113 Delbert K. Joenbrood * Applications Designer $48.10 23.6 $    1,135.16\\n111 Geoff B. Wabash Clerical Support $26.87 22.0 $   591.14\\n106 William Smithfield Programmer $35.75 12.8 $   457.60\\nSubtotal $13,660.10\\n25 Starflight 107 Maria D. Alonzo Programmer $ 35.75 24.6 $   879.45\\n115 Travis B. Bawangi Systems Analyst $ 96.75 45.8 $    4,431.15\\n101 John G. News * Database Designer $105.00 56.3 $    5,911.50\\n114 Annelise Jones Applications Designer $ 48.10 33.1 $    1,592.11\\n108 Ralph B. Washington Systems Analyst $ 96.75 23.6 $    2,283.30\\n118 James J. Frommer General Support $ 18.36 30.5 $   559.98\\n112 Darlene M. Smithson DSS Analyst $ 45.95 41.4 $    1,902.33\\nSubtotal $17,559.82\\nTotal $48,941.09\\nNote: A * indicates the project leader.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cb888479-a333-43fb-a3ac-b43e66ff4e42', embedding=None, metadata={'page_label': '205', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    205\\nUnfortunately, the structure of the dataset in Figure 6.1 does not conform to the \\nrequirements discussed in Chapter 3, nor does it handle data very well. Consider the \\nfollowing deficiencies:\\n1. The project number (PROJ_NUM) is apparently intended to be a primary key (PK) or \\nat least a part of a PK, but it contains nulls. Given the preceding discussion, you know that PROJ_NUM + EMP_NUM will define each row.\\n2.\\n The table entries invite data inconsistencies. For example, the JOB_CLASS value “Elect. Engineer” might be entered as “Elect.Eng. ” in some cases, “El. Eng. ” in others, and “EE” in still others.\\n3.\\n The table displays data redundancies that yield the following anomalies:\\na. Update anomalies . Modifying the JOB_CLASS for employee number 105 requires \\nmany potential alterations, one for each EMP_NUM = 105.\\nb. Insertion anomalies. Just to complete a row definition, a new employee must be \\nassigned to a project. If the employee is not yet assigned, a phantom project must be created to complete the employee data entry.\\nc.\\n Deletion anomalies . Suppose that only one employee is associated with a given \\nproject. If that employee leaves the company and the employee data is deleted, the project information will also be deleted. To prevent the loss of the project informa-tion, a fictitious employee must be created.\\nIn spite of those structural deficiencies, the table structure appears  to work; the report \\nis generated with ease. Unfortunately, the report might yield varying results depending on what data anomaly has occurred. For example, if you want to print a report to show the total “hours worked” value by the job classification “Database Designer, ” that report will not include data for “DB Design” and “Database Design” data entries. Such reporting anomalies cause a multitude of problems for managers—and cannot be fixed through application programming.\\nEven if careful data-entry auditing can eliminate most of the reporting problems (at \\na high cost), it is easy to demonstrate that even a simple data entry becomes inefficient. Given the existence of update anomalies, suppose Darlene M. Smithson is assigned to work on the Evergreen project. The data-entry clerk must update the PROJECT file with the following entry:\\n15\\n  Evergreen   112  Darlene M. Smithson   DSS Analyst   $45.95   0.0\\nto match the attributes PROJ_NUM, PROJ_NAME, EMP_NUM, EMP_NAME, JOB_\\nCLASS, CHG_HOUR, and HOURS. (If Smithson has just been assigned to the project, the total number of hours worked is 0.0.)\\nRemember that the naming convention makes it easy to see what each attribute stands for and its likely origin. For example, PROJ_NAME uses the prefix PROJ to indicate that the attri -\\nbute is associated with the PROJECT table, while the NAME component is self-documenting as well. However, keep in mind that name length is also an issue, especially in the prefix des -\\nignation. For that reason, the prefix CHG was used rather than CHARGE. (Given the database’s context, it is not likely that the prefix will be misunderstood.)Note\\nEach time another employee is assigned to a project, some data entries (such as \\nPROJ_NAME, EMP_NAME, and CHG_HOUR) are unnecessarily repeated. Imagine \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b103ebb5-e801-4199-b3ea-ff19fbe2a208', embedding=None, metadata={'page_label': '206', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='206   Part 2    Design Concepts\\nthe data-entry chore when 200 or 300 table entries must be made! The entry of the \\nemployee number should be sufficient to identify Darlene M. Smithson, her job descrip-tion, and her hourly charge. Because only one person is identified by the number 112, that person’s characteristics (name, job classification, and so on) should not have to be entered each time the main file is updated. Unfortunately, the structure displayed in Figure 6.1 does not make allowances for that possibility.\\nThe data redundancy evident in Figure 6.1 leads to wasted data storage space. Even \\nworse, data redundancy produces data anomalies. For example, suppose the data-entry clerk had entered the data as:\\n15\\n  Evergeen   112  Darla Smithson   DCS Analyst   $45.95   0.0\\nAt first glance, the data entry appears to be correct. But is Evergeen the same project as \\nEvergreen? And is DCS Analyst supposed to be DSS Analyst? Is Darla Smithson the same \\nperson as Darlene M. Smithson? Such confusion is a data integrity problem because the data entry failed to conform to the rule that all copies of redundant data must be identical.\\nThe possibility of introducing data integrity problems caused by data redundancy \\nmust be considered during database design. The relational database environment is  \\nespecially well suited to help the designer overcome those problems.\\n6-3 The Normalization Process\\nIn this section, you will learn how to use normalization to produce a set of normalized tables to store the data that will be used to generate the required information. The objec-tive of normalization is to ensure that each table conforms to the concept of well-formed relations—in other words, tables that have the following characteristics:\\n•\\n  Each table represents a single subject. For example, a COURSE table will contain only \\ndata that directly pertain to courses. Similarly, a STUDENT table will contain only student data.\\n•\\n No data item will be unnecessarily  stored in more than one table (in short, tables have \\nminimum controlled redundancy). The reason for this requirement is to ensure that the data is updated in only one place.\\n•\\n All nonprime attributes in a table are dependent on the primary key—the entire primary key and nothing but the primary key. The reason for this requirement is to ensure that the data is uniquely identifiable by a primary key value.\\n•\\n Each table is void of insertion, update, or deletion anomalies, which ensures the integ-rity and consistency of the data.\\nTo accomplish the objective, the normalization process takes you through the steps \\nthat lead to successively higher normal forms. The most common normal forms and their basic characteristic are listed in Table 6.2. Y ou will learn the details of these normal forms in the indicated sections.\\nThe concept of keys is central to the discussion of normalization. Recall from Chap-\\nter 3 that a candidate key is a minimal (irreducible) superkey. The primary key is the candidate key selected to be the primary means used to identify the rows in the table. Although normalization is typically presented from the perspective of candidate keys, this initial discussion assumes for the sake of simplicity that each table has only one can-didate key; therefore, that candidate key is the primary key.\\nFrom the data modeler’s point of view, the objective of normalization is to ensure that \\nall tables are at least in third normal form (3NF). Even higher-level normal forms exist. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e1ff2ed-ca28-44a0-a88a-e50e07c5b8a3', embedding=None, metadata={'page_label': '207', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    207\\nHowever, normal forms such as the fifth normal form (5NF) and domain-key normal \\nform (DKNF) are not likely to be encountered in a business environment and are mainly of theoretical interest. Such higher normal forms usually increase joins, which slows performance without adding any value in the elimination of data redundancy. Some very specialized applications, such as statistical research, might require normalization beyond the 4NF, but those applications fall outside the scope of most business opera-tions. Because this book focuses on practical applications of database techniques, the higher-level normal forms are not covered.\\nFunctional Dependence  Before outlining the normalization process, it is a good idea \\nto review the concepts of determination and functional dependence that were covered in detail in Chapter 3. Table 6.3 summarizes the main concepts.\\nIt is crucial to understand these concepts because they are used to derive the set \\nof functional dependencies for a given relation. The normalization process works one relation at a time, identifying the dependencies on that relation and normalizing the relation. As you will see in the following sections, normalization starts by identifying the dependencies of a given relation and progressively breaking up the relation (table) into a set of new relations (tables) based on the identified dependencies.\\nTwo types of functional dependencies that are of special interest in normalization \\nare partial dependencies and transitive dependencies. A partial dependency exists when there is a functional dependence in which the determinant is only part of the primary key (remember the assumption that there is only one candidate key). For example, if (A, B) →  (C, D), B →  C, and (A, B) is the primary key, then the functional TABLE 6.2\\nNORMAL FORMS\\nNORMAL FORM CHARACTERISTIC SECTION\\nFirst normal form (1NF) Table format, no repeating groups, and PK identified 6-3a\\nSecond normal form (2NF) 1NF and no partial dependencies 6-3b\\nThird normal form (3NF) 2NF and no transitive dependencies 6-3c\\nBoyce-Codd normal form (BCNF) Every determinant is a candidate key (special case of 3NF) 6-6a\\nFourth normal form (4NF) 3NF and no independent multivalued dependencies 6-6b\\nTABLE 6.3\\nFUNCTIONAL DEPENDENCE CONCEPTS\\nCONCEPT DEFINITION\\nFunctional dependence The attribute B is fully functionally dependent on the attribute A if each value of A \\ndetermines one and only one value of B.\\nExample: PROJ_NUM → PROJ_NAME  (read as PROJ_NUM functionally determines PROJ_NAME)In this case, the attribute PROJ_NUM is known as the determinant attribute, and the attribute PROJ_NAME is known as the dependent attribute.\\nFunctional dependence(generalized definition)Attribute A determines attribute B (that is, B is functionally dependent on A) if all (generalized definition) of the rows in the table that agree in value for attribute A also agree in value for attribute B.\\nFully functional dependence (composite key)If attribute B is functionally dependent on a composite key A but not on any subset of that composite key, the attribute B is fully functionally dependent on A.\\npartial dependency\\nA condition in which an attribute is dependent on only a portion (subset) of the primary key.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c76bbf2c-f270-42b4-b9e3-b4e33aa4aa6b', embedding=None, metadata={'page_label': '208', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='208   Part 2    Design Concepts\\ndependence B →  C is a partial dependency because only part of the primary key (B) \\nis needed to determine the value of C. Partial dependencies tend to be straightforward \\nand easy to identify.\\nA transitive dependency exists when there are functional dependencies such that  \\nX → Y , Y → Z, and X is the primary key. In that case, the dependency X → Z is a transi-\\ntive dependency because X determines the value of Z via Y . Unlike partial dependencies, transitive dependencies are more difficult to identify among a set of data. Fortunately, there is an effective way to identify transitive dependencies: they occur only when a functional dependence exists among nonprime attributes. In the previous example, the actual transitive dependency is X → Z. However, the dependency Y → Z signals that \\na transitive dependency exists. Hence, throughout the discussion of the normalization process, the existence of a functional dependence among nonprime attributes will be considered a sign of a transitive dependency. To address the problems related to tran-sitive dependencies, changes to the table structure are made based on the functional dependence that signals the transitive dependency’s existence. Therefore, to simplify the description of normalization, from this point forward the signaling dependency will be called the transitive dependency .\\n6-3a  Conversion To First Normal Form\\nBecause the relational model views data as part of a table or a collection of tables in which all key values must be identified, the data depicted in Figure 6.1 might not be stored as shown. Note that Figure 6.1 contains what is known as repeating groups. A repeating group derives its name from the fact that a group of multiple entries of the same type can exist for any single  key attribute occurrence. In Figure 6.1, note that each \\nsingle project number (PROJ_NUM) occurrence can reference a group of related data entries. For example, the Evergreen project (PROJ_NUM = 15) shows five entries at this point—and those entries are related because they each share the PROJ_NUM = 15 char -\\nacteristic. Each time a new record is entered for the Evergreen project, the number of entries in the group grows by one.\\nA relational table must not contain repeating groups. The existence of repeating \\ngroups provides evidence that the RPT_FORMAT table in Figure 6.1 fails to meet even the lowest normal form requirements, thus reflecting data redundancies.\\nNormalizing the table structure will reduce the data redundancies. If repeating groups \\ndo exist, they must be eliminated by making sure that each row defines a single entity. In addition, the dependencies must be identified to diagnose the normal form. Identi-fication of the normal form lets you know where you are in the normalization process. Normalization starts with a simple three-step procedure.\\nStep 1: Eliminate the Repeating Groups  Start by presenting the data in a tabular \\nformat, where each cell has a single value and there are no repeating groups. To elimi-nate the repeating groups, eliminate the nulls by making sure that each repeating group attribute contains an appropriate data value. That change converts the table in Figure 6.1 to 1NF in Figure 6.2.\\nStep 2: Identify the Primary Key  The layout in Figure 6.2 represents more than \\na mere cosmetic change. Even a casual observer will note that PROJ_NUM is not an adequate primary key because the project number does not uniquely identify all of the remaining entity (row) attributes. For example, the PROJ_NUM value 15 can identify any one of five employees. To maintain a proper primary key that will uniquely  identify \\nany attribute value, the new key must be composed of a combination  of PROJ_NUM \\nand EMP_NUM. For example, using the data shown in Figure 6.2, if you know that transitive  dependency\\nA condition in which an attribute is dependent on another attribute that is not part of the primary key.\\nrepeating group\\nIn a relation, a characteristic describing a group of multiple entries of the same type for a single key attribute occurrence. For example, a car can have multiple colors for its top, interior, bottom, trim, and so on.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eca8aa42-b2e4-4432-a6b6-fd18a390e080', embedding=None, metadata={'page_label': '209', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    209\\nPROJ_NUM = 15 and EMP_NUM = 103, the entries for the attributes PROJ_NAME, \\nEMP_NAME, JOB_CLASS, CHG_HOUR, and HOURS must be Evergreen, June E. \\nArbough, Elect. Engineer, $84.50, and 23.8, respectively.\\nStep 3: Identify All Dependencies  The identification of the PK in Step 2 means that \\nyou have already identified the following dependency:\\nPROJ_NUM, EMP_NUM → PROJ_NAME, EMP_NAME, JOB_CLASS, CHG_HOUR, \\nHOURS\\nThat is, the PROJ_NAME, EMP_NAME, JOB_CLASS, CHG_HOUR, and HOURS \\nvalues are all dependent on—they are determined by—the combination of PROJ_NUM \\nand EMP_NUM. There are additional dependencies. For example, the project number \\nidentifies (determines) the project name. In other words, the project name is dependent \\non the project number. Y ou can write that dependency as:\\nPROJ_NUM → PROJ_NAME\\nAlso, if you know an employee number, you also know that employee’s name, job \\nclassification, and charge per hour. Therefore, you can identify the dependency shown \\nnext:\\nEMP_NUM → EMP_NAME, JOB_CLASS, CHG_HOUR\\nIn simpler terms, an employee has the following attributes: a number, a name, a job \\nclassification, and a charge per hour. However, by further studying the data in Figure \\n6.2, you can see that knowing the job classification means knowing the charge per hour \\nfor that job classification. (Notice that all “System Analyst” or “Programmer” positions \\nhave the same charge per hour regardless of the project or employee.) In other words, the \\ncharge per hour depends on the job classification, not the employee. Therefore, you can \\nidentify one last dependency:\\nJOB_CLASS → CHG_HOURFIGURE 6.2  A TABLE IN FIRST NORMAL FORM  \\nTable name: DATA_ORG_1NF Database name: Ch06_ConstructCo\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ce78be9b-7dad-42ba-8509-dfc0918490c2', embedding=None, metadata={'page_label': '210', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='210   Part 2     Design Concepts\\nThis dependency exists between two nonprime attributes; therefore, it is a signal \\nthat a transitive dependency exists, and we will refer to it as a transitive dependency. \\nThe dependencies you have just examined can also be depicted with the help of the \\ndiagram shown in Figure 6.3. Because such a diagram depicts all dependencies found \\nwithin a given table structure, it is known as a dependency diagram . Dependency \\ndiagrams are very helpful in getting a bird’s-eye view of all the relationships among a \\ntable’s attributes, and their use makes it less likely that you will overlook an important \\ndependency.\\nFIGURE 6.3  FIRST NORMAL FORM (1NF) DEPENDENCY DIAGRAM  \\nTRANSITIVE DEPENDENCY:\\n (JOB_CLASS CHG_HOUR)PARTIAL DEPENDENCIES:\\n (PROJ_NUM PROJ_NAME)\\n (EMP_NUM EMP_NAME, JOB_CLASS, CHG_HOUR)EMP_NUM EMP_NAME PROJ_NUM PROJ_NAME CHG_HOUR JOB_CLASS HOURS\\nTransitive\\ndependencyPartial dependency\\nPartial dependencies\\n1NF (PROJ_NUM, EMP_NUM, PROJ_NAME, EMP_NAME, JOB_CLASS, CHG_HOURS, HOURS)\\nAs you examine Figure 6.3, note the following features of a dependency diagram:\\n1. The primary key attributes are bold, underlined, and in a different color.\\n2. The arrows above the attributes indicate all desirable dependencies—that is, depen -\\ndencies based on the primary key. In this case, note that the entity’s attributes are \\ndependent on the combination  of PROJ_NUM  and EMP_NUM .\\n3. The arrows below the dependency diagram indicate less desirable dependencies. Two \\ntypes of such dependencies exist:\\na. Partial dependencies . Y ou need to know only the PROJ_NUM to determine the \\nPROJ_NAME; that is, the PROJ_NAME is dependent on only part of the primary \\nkey. Also, you need to know only the EMP_NUM to find the EMP_NAME, the \\nJOB_CLASS, and the CHG_HOUR. A dependency based on only a part of a com -\\nposite primary key is a partial dependency.\\nb. Transitive dependencies . Note that CHG_HOUR is dependent on JOB_CLASS. \\nBecause neither CHG_HOUR nor JOB_CLASS is a prime attribute—that is, nei -\\nther attribute is at least part of a key—the condition is a transitive dependency. In \\nother words, a transitive dependency is a dependency of one nonprime attribute \\non another nonprime attribute. The problem with transitive dependencies is that \\nthey still yield data anomalies.\\nFigure 6.3 includes the relational schema for the table in 1NF and a textual notation \\nfor each identified dependency.dependency \\ndiagram\\nA representation of all \\ndata dependencies \\n(primary key, partial, or \\ntransitive) within a table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e4bc7e6a-2f3e-4a17-8836-fe00bb7facf1', embedding=None, metadata={'page_label': '211', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    211\\nAll relational tables satisfy the 1NF requirements. The problem with the 1NF table \\nstructure shown in Figure 6.3 is that it contains partial dependencies—dependencies \\nbased on only a part of the primary key.\\nWhile partial dependencies are sometimes used for performance reasons, they \\nshould be used with caution. Such caution is warranted because a table that contains partial dependencies is still subject to data redundancies, and therefore to various anomalies. The data redundancies occur because every row entry requires duplica-tion of data. For example, if Alice K. Johnson submits her work log, then the user would have to make multiple entries during the course of a day. For each entry, the EMP_NAME, JOB_CLASS, and CHG_HOUR must be entered each time, even though the attribute values are identical for each row entered. Such duplication of effort is very inefficient, and it helps create data anomalies; nothing prevents the user from typing slightly different versions of the employee name, the position, or the hourly pay. For instance, the employee name for EMP_NUM = 102 might be entered as Dave Senior or D. Senior. The project name might also be entered correctly as Evergreen or misspelled as Evergeen. Such data anomalies violate the relational database’s integrity and consis-\\ntency rules.\\n6-3b  Conversion To Second Normal Form\\nConversion to 2NF occurs only when the 1NF has a composite primary key. If the 1NF has a single-attribute primary key, then the table is automatically in 2NF. The 1NF-to-2NF conversion is simple. Starting with the 1NF format displayed in Figure 6.3, you take the following steps:\\nStep 1: Make New Tables to Eliminate Partial Dependencies  For each component \\nof the primary key that acts as a determinant in a partial dependency, create a new table with a copy of that component as the primary key. While these components are placed in the new tables, it is important that they also remain in the original table as well. The determinants must remain in the original table because they will be the foreign keys for the relationships needed to relate these new tables to the original table. To construct the revised dependency diagram, write each key component on a separate line and then write the original (composite) key on the last line. For example:\\nPROJ_NUMEMP_NUMPROJ_NUM EMP_NUM\\nEach component will become the key in a new table. In other words, the original table \\nis now divided into three tables (PROJECT, EMPLOYEE, and ASSIGNMENT).\\nThe term first normal form (1NF)  describes the tabular format in which:\\n• All of the key attributes are defined.\\n• There are no repeating groups in the table. In other words, each row/column inter -\\nsection contains one and only one value, not a set of values.\\n• All attributes are dependent on the primary key.Note\\nfirst normal form \\n(1NF)\\nThe first stage in the normalization process. It describes a relation depicted in tabular format, with no repeating groups and a primary key identified. All nonkey attributes in the relation are dependent on the primary key.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='88493e9e-d164-4bb5-adeb-d18f872078aa', embedding=None, metadata={'page_label': '212', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='212   Part 2    Design Concepts\\nStep 2: Reassign Corresponding Dependent Attributes  Use Figure 6.3 to deter -\\nmine attributes that are dependent in the partial dependencies. The dependencies for \\nthe original key components are found by examining the arrows below the dependency diagram shown in Figure 6.3. The attributes that are dependent in a partial dependency are removed from the original table and placed in the new table with the dependency’s determinant. Any attributes that are not dependent in a partial dependency will remain in the original table. In other words, the three tables that result from the conversion to 2NF are given appropriate names (PROJECT, EMPLOYEE, and ASSIGNMENT) and are described by the following relational schemas:\\nPROJECT (PROJ_NUM, PROJ_NAME)EMPLOYEE (EMP_NUM, EMP_NAME, JOB_CLASS, CHG_HOUR)ASSIGNMENT (PROJ_NUM, EMP_NUM, ASSIGN_HOURS)\\nBecause the number of hours spent on each project by each employee is dependent \\non both PROJ_NUM and EMP_NUM in the ASSIGNMENT table, you leave those \\nhours in the ASSIGNMENT table as ASSIGN_HOURS. Notice that the ASSIGNMENT table contains a composite primary key composed of the attributes PROJ_NUM and EMP_NUM. Notice that by leaving the determinants in the original table as well as making them the primary keys of the new tables, primary key/foreign key relation-ships have been created. For example, in the EMPLOYEE table, EMP_NUM is the primary key. In the ASSIGNMENT table, EMP_NUM is part of the composite primary key (PROJ_NUM, EMP_NUM) and is a foreign key relating the EMPLOYEE table to the ASSIGNMENT table.\\nThe results of Steps 1 and 2 are displayed in Figure 6.4. At this point, most of the \\nanomalies discussed earlier have been eliminated. For example, if you now want to add, change, or delete a PROJECT record, you need to go only to the PROJECT table and make the change to only one row.\\nBecause a partial dependency can exist only when a table’s primary key is composed \\nof several attributes, a table whose primary key consists of only a single attribute is auto-matically in 2NF once it is in 1NF.\\nFigure 6.4 still shows a transitive dependency, which can generate anomalies. For \\nexample, if the charge per hour changes for a job classification held by many employees, that change must be made for each  of those employees. If you forget to update some of \\nthe employee records that are affected by the charge per hour change, different employ-ees with the same job description will generate different hourly charges.\\nsecond normal form (2NF)\\nThe second stage in the normalization process, in which a relation is in 1NF and there are no partial dependencies (dependencies in only part of the primary key).\\nA table is in second normal form (2NF)  when:\\n• It is in 1NF.\\nand\\n• It includes no partial dependencies; that is, no attribute is dependent on only a portion \\nof the primary key.\\nIt is still possible for a table in 2NF to exhibit transitive dependency. That is, the primary key \\nmay rely on one or more nonprime attributes to functionally determine other nonprime attributes, as indicated by a functional dependence among the nonprime attributes.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5fa59c1d-0cb0-47ca-bbb8-9ce382bfdc05', embedding=None, metadata={'page_label': '213', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    213\\n6-3c  Conversion To Third Normal Form\\nThe data anomalies created by the database organization shown in Figure 6.4 are easily \\neliminated by completing the following two steps:\\nStep 1: Make New Tables to Eliminate Transitive Dependencies  For every \\ntransitive dependency, write a copy of its determinant as a primary key for a new table. \\nA determinant  is any attribute whose value determines other values within a row. If \\nyou have three different transitive dependencies, you will have three different deter -\\nminants. As with the conversion to 2NF, it is important that the determinant remain \\nin the original table to serve as a foreign key. Figure 6.4 shows only one table that \\ncontains a transitive dependency. Therefore, write the determinant for this transitive \\ndependency as:\\nJOB_CLASS\\nStep 2: Reassign Corresponding Dependent Attributes  Using Figure 6.4, \\nidentify the attributes that are dependent on each determinant identified in Step 1. \\nPlace the dependent attributes in the new tables with their determinants and remove \\nthem from their original tables. In this example, eliminate CHG_HOUR from the \\nEMPLOYEE table shown in Figure 6.4 to leave the EMPLOYEE table dependency \\ndefinition as:\\nEMP_NUM → EMP_NAME, JOB_CLASSFIGURE 6.4  SECOND NORMAL FORM (2NF) CONVERSION RESULTS  \\n  \\nTRANSITIVE DEPENDENCY  \\n(JOB_CLASS          CHG_HOUR)EMPLOYEE (EMP_NUM, EMP_NAME, JOB_CLASS, CHG_HOUR)PROJECT (PROJ_NUM, PROJ_NAME)\\nASSIGNMENT (PROJ_NUM, EMP_NUM, ASSIGN_HOURS) Table name: ASSIGNMENTTable name: EMPLOYEEPROJ_NUM PROJ_NAMETable name: PROJECT\\nPROJ_NUM EMP_NUM ASSIGN_HOURSEMP_NUM EMP_NAME CHG_HOUR JOB_CLASS\\nTransitive\\ndependency\\ndeterminant\\nAny attribute in a specific \\nrow whose value directly \\ndetermines other values \\nin that row. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='19a444f4-4fb6-4c5a-b80d-33e20bf1070a', embedding=None, metadata={'page_label': '214', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='214   Part 2     Design Concepts\\nDraw a new dependency diagram to show all of the tables you have defined in Steps 1 \\nand 2. Name the table to reflect its contents and function. In this case, JOB seems appro -\\npriate. Check all of the tables to make sure that each table has a determinant and that no \\ntable contains inappropriate dependencies. When you have completed these steps, you \\nwill see the results in Figure 6.5.\\nIn other words, after the 3NF conversion has been completed, your database will \\ncontain four tables:\\nPROJECT ( PROJ_NUM , PROJ_NAME)\\nEMPLOYEE ( EMP_NUM , EMP_NAME, JOB_CLASS)\\nJOB ( JOB_CLASS , CHG_HOUR)\\nASSIGNMENT ( PROJ_NUM, EMP_NUM , ASSIGN_HOURS)\\nNote that this conversion has eliminated the original EMPLOYEE table’s transitive \\ndependency. The tables are now said to be in third normal form (3NF).\\nIt is interesting to note the similarities between resolving 2NF and 3NF problems. To \\nconvert a table from 1NF to 2NF, it is necessary to remove the partial dependencies. To con -\\nvert a table from 2NF to 3NF, it is necessary to remove the transitive dependencies. No mat -\\nter whether the “problem” dependency is a partial dependency or a transitive dependency, \\nA table is in third normal form (3NF)  when:\\n• It is in 2NF.\\nand\\n• It contains no transitive dependencies.Notethird normal form \\n(3NF)\\nA table is in 3NF when it \\nis in 2NF and no nonkey \\nattribute is functionally \\ndependent on another \\nnonkey attribute; that \\nis, it cannot include \\ntransitive dependencies.FIGURE 6.5  THIRD NORMAL FORM (3NF) CONVERSION RESULTS  \\nTable name: JOB\\nJOB  (JOB_CLASS, CHG_HOUR)JOB_CLASS CHG_HOURTable name: PROJECT\\nPROJECT  (PROJ_NUM, PROJ_NAME)PROJ_NUM PROJ_NAME EMP_NUM EMP_NAME JOB_CLASS\\nTable name: EMPLOYEE\\nEMPLOYEE  (EMP_NUM, EMP_NAME, JOB_CLASS)\\nPROJ_NUM EMP_NUM ASSIGN_HOURS\\nTable name: ASSIGNMENT\\nASSIGNMENT  (PROJ_NUM, EMP_NUM, ASSIGN_HOURS)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9bd82eee-ab9c-4afd-b9c5-46629d8ea3bf', embedding=None, metadata={'page_label': '215', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    215\\nthe solution is the same: create a new table for each problem dependency. The determinant \\nof the problem dependency remains in the original table and is placed as the primary key of the new table. The dependents of the problem dependency are removed from the original table and placed as nonprime attributes in the new table.\\nBe aware, however, that while the technique is the same, it is imperative that 2NF be \\nachieved before moving on to 3NF; be certain to resolve the partial dependencies before resolving the transitive dependencies. Also, recall the assumption that was made at the beginning of the normalization discussion—that each table has only one candidate key, which is the primary key. If a table has multiple candidate keys, then the overall process remains the same, but there are additional considerations.\\nFor example, if a table has multiple candidate keys and one of them is a composite \\nkey, the table can have partial dependencies based on this composite candidate key, even when the primary key chosen is a single attribute. In those cases, following the process described above, those dependencies would be perceived as transitive dependencies and would not be resolved until 3NF. The simplified process described above will allow the designer to achieve the correct result, but through practice, you should recognize all candidate keys and their dependencies as such, and resolve them appropriately. The existence of multiple candidate keys can also influence the identi-fication of transitive dependencies. Previously, a transitive dependency was defined to exist when one nonprime attribute determined another nonprime attribute. In the presence of multiple candidate keys, the definition of a nonprime attribute as an attribute that is not a part of any candidate key is critical. If the determinant of a functional dependence is not the primary key but is a part of another candidate key, then it is not a nonprime attribute and does not signal the presence of a transitive dependency.\\n6-4 Improving the Design\\nNow that the table structures have been cleaned up to eliminate the troublesome par -\\ntial and transitive dependencies, you can focus on improving the database’s ability to provide information and on enhancing its operational characteristics. In the next few paragraphs, you will learn about the various types of issues you need to address to produce a good normalized set of tables. Note that for space issues, each section pres-ents just one example—the designer must apply the principle to all remaining tables in the design. Remember that normalization cannot, by itself, be relied on to make good designs. Instead, normalization is valuable because its use helps eliminate data redundancies.\\nEvaluate PK Assignments  Each time a new employee is entered into the EMPLOYEE \\ntable, a JOB_CLASS value must be entered. Unfortunately, it is too easy to make data-entry errors that lead to referential integrity violations. For example, entering DB Designer  instead of Database Designer  for the JOB_CLASS attribute in the EMPLOYEE \\ntable will trigger such a violation. Therefore, it would be better to add a JOB_CODE attribute to create a unique identifier. The addition of a JOB_CODE attribute produces the following dependency:\\nJOB_CODE → JOB_CLASS, CHG_HOUR\\nIf you assume that the JOB_CODE is a proper primary key, this new attribute does \\nproduce the following dependency:JOB_CLASS → CHG_HOUR\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='26799cb0-481b-4311-8ede-b3f0535361ce', embedding=None, metadata={'page_label': '216', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='216   Part 2    Design Concepts\\nHowever, this dependency is not a transitive dependency because the determinant \\nis a candidate key. Further, the presence of JOB_CODE greatly decreases the likelihood \\nof referential integrity violations. Note that the new JOB table now has two candidate keys—JOB_CODE and JOB_CLASS. In this case, JOB_CODE is the chosen primary key as well as a surrogate key. A surrogate key, as you should recall, is an artificial PK intro-duced by the designer with the purpose of simplifying the assignment of primary keys to tables. Surrogate keys are usually numeric, they are often generated automatically by the DBMS, they are free of semantic content (they have no special meaning), and they are usually hidden from the end users.\\nEvaluate Naming Conventions  It is best to adhere to the naming conventions out-\\nlined in Chapter 2, Data Models. Therefore, CHG_HOUR will be changed to JOB_CHG_HOUR to indicate its association with the JOB table. In addition, the attribute name JOB_CLASS does not quite describe entries such as Systems Analyst, Database Designer , \\nand so on; the label JOB_DESCRIPTION fits the entries better. Also, you might have noticed that HOURS was changed to ASSIGN_HOURS in the conversion from 1NF to 2NF. That change lets you associate the hours worked with the ASSIGNMENT table.\\nRefine Attribute Atomicity  It is generally good practice to pay attention to the ato -\\nmicity requirement. An atomic attribute is one that cannot be further subdivided. Such an attribute is said to display atomicity. Clearly, the use of the EMP_NAME in the EMPLOYEE table is not atomic because EMP_NAME can be decomposed into a last name, a first name, and an initial. By improving the degree of atomicity, you also gain querying flexibility. For example, if you use EMP_LNAME, EMP_FNAME, and EMP_INITIAL, you can easily generate phone lists by sorting last names, first names, and initials. Such a task would be very difficult if the name components were within a single attribute. In general, designers prefer to use simple, single-valued attributes, as indicated by the business rules and processing requirements.\\nIdentify New Attributes  If the EMPLOYEE table were used in a real-world environ-\\nment, several other attributes would have to be added. For example, year-to-date gross salary payments, Social Security payments, and Medicare payments would be desirable. An employee hire date attribute (EMP_HIREDATE) could be used to track an employee’s job longevity, and it could serve as a basis for awarding bonuses to long-term employees and for other morale-enhancing measures. The same principle must be applied to all other tables in your design.\\nIdentify New Relationships  According to the original report, the users need to track \\nwhich employee is acting as the manager of each project. This can be implemented as a relationship between EMPLOYEE and PROJECT. From the original report, it is clear that each project has only one manager. Therefore, the system’s ability to supply detailed information about each project’s manager is ensured by using the EMP_NUM as a for -\\neign key in PROJECT. That action ensures that you can access the details of each PROJ-ECT’s manager data without producing unnecessary and undesirable data duplication. The designer must take care to place the right attributes in the right tables by using normalization principles.\\nRefine Primary Keys as Required for Data Granularity  Granularity refers to the \\nlevel of detail represented by the values stored in a table’s row. Data stored at its low-est level of granularity is said to be atomic data , as explained earlier. In Figure 6.5, the \\nASSIGNMENT table in 3NF uses the ASSIGN_HOURS attribute to represent the hours worked by a given employee on a given project. However, are those values recorded at atomic attribute\\nAn attribute that cannot be further subdivided to produce meaningful components. For example, a person’s last name attribute cannot be meaningfully subdivided.\\natomicity\\nNot being able to be divided into smaller units.\\ngranularity\\nThe level of detail represented by the values stored in a table’s row. Data stored at its lowest level of granularity is said to be atomic data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c2aee26f-f619-41cb-91f2-d92ad95b0ef4', embedding=None, metadata={'page_label': '217', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    217\\ntheir lowest level of granularity? In other words, does ASSIGN_HOURS represent the \\nhourly  total, daily  total, weekly  total, monthly  total, or yearly  total? Clearly, ASSIGN_\\nHOURS requires more careful definition. In this case, the relevant question would be as follows: for what time frame—hour, day, week, month, and so on—do you want to record the ASSIGN_HOURS data?\\nFor example, assume that the combination of EMP_NUM and PROJ_NUM is an \\nacceptable (composite) primary key in the ASSIGNMENT table. That primary key is useful in representing only the total number of hours an employee worked on a project since its start. Using a surrogate primary key such as ASSIGN_NUM pro-vides lower granularity and yields greater flexibility. For example, assume that the EMP_NUM and PROJ_NUM combination is used as the primary key, and then an employee makes two “hours worked” entries in the ASSIGNMENT table. That action violates the entity integrity requirement. Even if you add the ASSIGN_DATE as part of a composite PK, an entity integrity violation is still generated if any employee makes two or more entries for the same project on the same day. (The employee might have worked on the project for a few hours in the morning and then worked on it again later in the day.) The same data entry yields no problems when ASSIGN_NUM is used as the primary key.\\nMaintain Historical Accuracy  Writing the job charge per hour into the ASSIGN-\\nMENT table is crucial to maintaining the historical accuracy of the table’s data. It would be appropriate to name this attribute ASSIGN_CHG_HOUR. Although this attribute would appear to have the same value as JOB_CHG_HOUR, this is true only  if the JOB_\\nCHG_HOUR value remains the same forever. It is reasonable to assume that the job charge per hour will change over time. However, suppose that the charges to each project were calculated and billed by multiplying the hours worked from the ASSIGNMENT table by the charge per hour from the JOB table. Those charges would always show the current charge per hour stored in the JOB table rather than the charge per hour that was in effect at the time of the assignment.\\nEvaluate Using Derived Attributes  Finally, you can use a derived attribute in the \\nASSIGNMENT table to store the actual charge made to a project. That derived attribute, named ASSIGN_CHARGE, is the result of multiplying ASSIGN_HOURS by ASSIGN_CHG_HOUR. This creates a transitive dependency such that:\\n(ASSIGN_CHARGE + ASSIGN_HOURS) → ASSIGN_CHG_HOUR\\nFrom a system functionality point of view, such derived attribute values can be cal-\\nculated when they are needed to write reports or invoices. However, storing the derived \\nattribute in the table makes it easy to write the application software to produce the desired results. Also, if many transactions must be reported and/or summarized, the availability \\nIn an ideal database design, the level of desired granularity would be determined during the conceptual design or while the requirements were being gathered. However, as you have already seen in this chapter, many database designs involve the refinement of exist -\\ning data requirements, thus triggering design modifications. In a real-world environment, changing granularity requirements might dictate changes in primary key selection, and those changes might ultimately require the use of surrogate keys.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a109750e-af39-46a9-a4bc-d473b428e224', embedding=None, metadata={'page_label': '218', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='218   Part 2     Design Concepts\\nof the derived attribute will save reporting time. (If the calculation is done at the time of \\ndata entry, it will be completed when the end user presses the Enter key, thus speeding \\nup the process.) Review Chapter 4 for a discussion of the implications of storing derived \\nattributes in a database table.\\nThe enhancements described in the preceding sections are illustrated in the tables and \\ndependency diagrams shown in Figure 6.6.\\nFIGURE 6.6  THE COMPLETED DATABASE  \\nTable name: PROJECT Table name: JOBDatabase name: Ch06_ConstructCo\\n Table name: JOB\\nTable name: ASSIGNMENT\\nASSIGN_NUM ASSIGN_DATE PROJ_NUM EMP_NUM ASSIGN_HOURS ASSIGN_CHG_HOUR ASSIGN_CHARGE\\nTable name: ASSIGNMENTTable name: PROJECT\\nPROJ_NUM PROJ_NAME EMP_NUM JOB_CODE JOB_DESCRIPTION JOB_CHG_HOUR\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d7471814-f293-4400-aef9-0f8f27e0986d', embedding=None, metadata={'page_label': '219', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    219\\nFigure 6.6 is a vast improvement over the original database design. If the application soft -\\nware is designed properly, the most active table (ASSIGNMENT) requires the entry of only \\nthe PROJ_NUM, EMP_NUM, and ASSIGN_HOURS values. The values for the attributes \\nASSIGN_NUM and ASSIGN_DATE can be generated by the application. For example, the \\nASSIGN_NUM can be created by using a counter, and the ASSIGN_DATE can be the system \\ndate read by the application and automatically entered into the ASSIGNMENT table. In addi -\\ntion, the application software can automatically insert the correct ASSIGN_CHG_HOUR \\nvalue by writing the appropriate JOB table’s JOB_CHG_HOUR value into the ASSIGN -\\nMENT table. (The JOB and ASSIGNMENT tables are related through the JOB_CODE attri -\\nbute.) If the JOB table’s JOB_CHG_HOUR value changes, the next insertion of that value \\ninto the ASSIGNMENT table will reflect the change automatically. The table structure thus \\nminimizes the need for human intervention. In fact, if the system requires the employees to \\nenter their own work hours, they can scan their EMP_NUM into the ASSIGNMENT table \\nby using a magnetic card reader that enters their identity. Thus, the ASSIGNMENT table’s \\nstructure can set the stage for maintaining some desired level of security.\\n6-5 Surrogate Key Considerations\\nAlthough this design meets the vital entity and referential integrity requirements, the \\ndesigner must still address some concerns. For example, a composite primary key might \\nbecome too cumbersome to use as the number of attributes grows. (It becomes difficult \\nto create a suitable foreign key when the related table uses a composite primary key. In \\naddition, a composite primary key makes it more difficult to write search routines.) Or, \\na primary key attribute might simply have too much descriptive content to be usable—\\nwhich is why the JOB_CODE attribute was added to the JOB table to serve as its primary \\nkey. When the primary key is considered to be unsuitable for some reason, designers use \\nsurrogate keys, as discussed in the previous chapter.FIGURE 6.6  THE COMPLETED DATABASE (CONTINUED)  \\nTable name: EMPLOYEE\\nEMP_NUM EMP_LNAME EMP_FNAME EMP_INITIAL EMP_HIREDATE JOB_CODE\\nTable name: EMPLOYEEDatabase name: Ch06_ConstructCo\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76e14967-f0c1-4e9e-956e-3460cc7e461c', embedding=None, metadata={'page_label': '220', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='220   Part 2    Design Concepts\\nAt the implementation level, a surrogate key is a system-defined attribute generally \\ncreated and managed via the DBMS. Usually, a system-defined surrogate key is numeric, \\nand its value is automatically incremented for each new row. For example, Microsoft  Access uses an AutoNumber data type, Microsoft SQL Server uses an identity column, and Oracle uses a sequence object.\\nRecall from Section 6-4 that the JOB_CODE attribute was designated to be the JOB \\ntable’s primary key. However, remember that the JOB_CODE attribute does not prevent duplicate entries, as shown in the JOB table in Table 6.4.\\nClearly, the data entries in Table 6.4 are inappropriate because they duplicate existing \\nrecords—yet there has been no violation of either entity integrity or referential integrity. This problem of multiple duplicate records was created when the JOB_CODE attribute was added as the PK. (When the JOB_DESCRIPTION was initially designated to be the PK, the DBMS would ensure unique values for all job description entries when it was asked to enforce entity integrity. However, that option created the problems that caused the use of the JOB_CODE attribute in the first place!) In any case, if JOB_CODE is to be the surrogate PK, you still must ensure the existence of unique values in the JOB_DESCRIPTION through the use of a unique index.\\nNote that all of the remaining tables (PROJECT, ASSIGNMENT, and EMPLOYEE) \\nare subject to the same limitations. For example, if you use the EMP_NUM attribute in the EMPLOYEE table as the PK, you can make multiple entries for the same employee. To avoid that problem, you might create a unique index for EMP_LNAME, EMP_FNAME, and EMP_INITIAL, but how would you then deal with two employees named Joe B. Smith? In that case, you might use another (preferably externally defined) attribute to serve as the basis for a unique index.\\nIt is worth repeating that database design often involves trade-offs and the exercise of \\nprofessional judgment. In a real-world environment, you must strike a balance between design integrity and flexibility. For example, you might design the ASSIGNMENT table to use a unique index on PROJ_NUM, EMP_NUM, and ASSIGN_DATE if you want to limit an employee to only one ASSIGN_HOURS entry per date. That limitation would ensure that employees could not enter the same hours multiple times for any given date. Unfortunately, that limitation is likely to be undesirable from a managerial point of view. After all, if an employee works several different times on a project during any given day, it must be possible to make multiple entries for that same employee and the same project during that day. In that case, the best solution might be to add a new externally defined attribute—such as a stub, voucher, or ticket number—to ensure uniqueness. In any case, frequent data audits would be appropriate.\\n6-6 Higher-Level Normal Forms\\nTables in 3NF will perform suitably in business transactional databases. However, higher normal forms are sometimes useful. In this section, you will learn about a special case of 3NF, known as Boyce-Codd normal form, and about fourth normal form (4NF).TABLE 6.4\\nDUPLICATE ENTRIES IN THE JOB TABLE\\nJOB_CODE JOB_DESCRIPTION JOB_CHG_HOUR\\n511 Programmer $35.75\\n512 Programmer $35.75\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5eee7eb4-0e2b-4350-b728-1ee4262e8e22', embedding=None, metadata={'page_label': '221', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    221\\n6-6a  The Boyce-Codd Normal Form\\nA table is in Boyce-Codd normal form (BCNF) when every determinant in the table is a \\ncandidate key. (Recall from Chapter 3 that a candidate key has the same characteristics as a primary key, but for some reason, it was not chosen to be the primary key.) Clearly, when a table contains only one candidate key, the 3NF and the BCNF are equivalent. In other words, BCNF can be violated only when the table contains more than one candi-date key. In the previous normal form examples, tables with only one candidate key were used to simplify the explanations. Remember, however, that multiple candidate keys are always possible, and normalization rules focus on candidate keys, not just the primary key. Consider the table structure shown in Figure 6.7.\\nThe CLASS table has two candidate keys:\\n•\\n CLASS_CODE\\n• CRS_CODE + CLASS_SECTION\\nThe table is in 1NF because the key attributes are defined and all nonkey attributes \\nare determined by the key. This is true for both candidate keys. Both candidate keys have been identified, and all of the other attributes can be determined by either candidate key. The table is in 2NF because it is in 1NF and there are no partial dependencies on either candidate key. Since CLASS_CODE is a single attribute candidate key, the issue of par -\\ntial dependencies doesn’t apply. However, the composite candidate key of CRS_CODE + CLASS_SECTION could potentially have a partial dependency so 2NF must be evalu-ated for that candidate key. In this case, there are no partial dependencies involving the composite key. Finally, the table is in 3NF because there are no transitive dependencies. Remember, because CRS_CODE + CLASS_SECTION is a candidate key, the fact that this composite can determine the CLASS_TIME and ROOM_CODE is not a transitive dependency. A transitive dependency exists when a nonkey  attribute can determine \\nanother nonkey attribute, and CRS_CODE + CLASS_SECTION is a key.FIGURE 6.7  TABLES WITH MULTIPLE CANDIDATE KEYS  \\nCLASS_CODE CRS_CODE CLASS_SECTION CLASS_TIME ROOM_CODETable name: CLASS\\nBoyce-Codd normal form (BCNF)\\nA special type of third normal form (3NF) in which every determinant is a candidate key. A table in BCNF must be in 3NF. See also determinant.Most designers consider the BCNF to be a special case of the 3NF. In fact, if the tech-\\nniques shown in this chapter are used, most tables conform to the BCNF requirements once the 3NF is reached. So, how can a table be in 3NF and not be in BCNF? To answer that question, you must keep in mind that a transitive dependency exists when one non-prime attribute is dependent on another nonprime attribute.\\nA table is in Boyce-Codd normal form (BCNF)  when every determinant in the table is \\na candidate key.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58f85960-d57b-4ad8-8d12-72c3eba18059', embedding=None, metadata={'page_label': '222', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='222   Part 2     Design Concepts\\nIn other words, a table is in 3NF when it is in 2NF and there are no transitive depen -\\ndencies, but what about a case in which one key attribute is the determinant of another key \\nattribute? That condition does not violate 3NF, yet it fails to meet the BCNF requirements (see \\nFigure 6.8) because BCNF requires that every determinant in the table be a candidate key.\\nNote these functional dependencies in Figure 6.8:\\nA + B → C, D\\nA + C → B, D\\nC → B\\nNotice that this structure has two candidate keys: (A + B) and (A + C). The table \\nstructure shown in Figure 6.8 has no partial dependencies, nor does it contain transitive \\ndependencies. (The condition C → B indicates that one key attribute determines part of \\nthe primary key —and that dependency is not  transitive or partial because the dependent \\nis a prime attribute!) Thus, the table structure in Figure 6.8 meets the 3NF requirements, \\nalthough the condition C → B causes the table to fail to meet the BCNF requirements.\\nTo convert the table structure in Figure 6.8 into table structures that are in 3NF and \\nin BCNF, first change the primary key to A + C. This change is appropriate because the \\ndependency C → B means that C is effectively a superset of B. At this point, the table \\nis in 1NF because it contains a partial dependency, C → B. Next, follow the standard \\ndecomposition procedures to produce the results shown in Figure 6.9.\\nTo see how this procedure can be applied to an actual problem, examine the sample \\ndata in Table 6.5.\\nTable 6.5 reflects the following conditions:\\n• Each CLASS_CODE identifies a class uniquely. This condition illustrates the case in \\nwhich a course might generate many classes. For example, a course labeled INFS 420 \\nmight be taught in two classes (sections), each identified by a unique code to facilitate \\nregistration. Thus, the CLASS_CODE 32456 might identify INFS 420, class section \\n1, while the CLASS_CODE 32457 might identify INFS 420, class section 2. Or, the \\nCLASS_CODE 28458 might identify QM 362, class section 5.\\n• A student can take many classes. Note, for example, that student 125 has taken both \\n21334 and 32456, earning the grades A and C, respectively.\\n• A staff member can teach many classes, but each class is taught by only one staff  \\nmember. Note that staff member 20 teaches the classes identified as 32456 and 28458.\\nThe structure shown in Table 6.5 is reflected in Panel A of Figure 6.10:\\nSTU_ID + STAFF_ID → CLASS_CODE, ENROLL_GRADE\\nCLASS_CODE → STAFF_IDFIGURE 6.8  A TABLE THAT IS IN 3NF BUT NOT IN BCNF  \\nA B C D\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0c30fb64-cb08-487d-a85b-7b939c455650', embedding=None, metadata={'page_label': '223', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    223\\nPanel A of Figure 6.10 shows a structure that is clearly in 3NF, but the table repre -\\nsented by this structure has a major problem because it is trying to describe two things: \\nstaff assignments to classes and student enrollment information. Such a dual-purpose \\ntable structure will cause anomalies. For example, if a different staff member is assigned \\nto teach class 32456, two rows will require updates, thus producing an update anomaly. \\nAlso, if student 135 drops class 28458, information about who taught that class is lost, \\nthus producing a deletion anomaly. The solution to the problem is to decompose the \\ntable structure, following the procedure outlined earlier. The decomposition of Panel B \\nshown in Figure 6.10 yields two table structures that conform to both 3NF and BCNF \\nrequirements.TABLE 6.5\\nSAMPLE DATA FOR A BCNF CONVERSION\\nSTU_ID STAFF_ID CLASS_CODE ENROLL_GRADE\\n125 25 21334 A\\n125 20 32456 C\\n135 20 28458 B\\n144 25 27563 C\\n144 20 32456 BFIGURE 6.9  DECOMPOSITION TO BCNF  \\nA B C D\\nA C B D\\nA C D C B3NF, but not BCNF\\n1NF\\nPartial dependency\\n3NF and BCNF 3NF and BCNF\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ae11025b-8b3e-4691-b50d-2f60e5ca1f2c', embedding=None, metadata={'page_label': '224', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='224   Part 2     Design Concepts\\nRemember that a table is in BCNF when every determinant in that table is a candi -\\ndate key. Therefore, when a table contains only one candidate key, 3NF and BCNF are \\nequivalent.\\n6-6b  Fourth Normal Form (4NF)\\nY ou might encounter poorly designed databases, or you might be asked to convert \\nspreadsheets into a database format in which multiple multivalued attributes exist. For \\nexample, consider the possibility that an employee can have multiple assignments and \\ncan also be involved in multiple service organizations. Suppose employee 10123 vol -\\nunteers for the Red Cross and United Way. In addition, the same employee might be \\nassigned to work on three projects: 1, 3, and 4. Figure 6.11 illustrates how that set of facts \\ncan be recorded in very different ways.FIGURE 6.10  ANOTHER BCNF DECOMPOSITION  \\nCLASS_CODE STAFF_ID STU_ID CLASS_CODE ENROLL_GRADESTU_ID STAFF_ID CLASS_CODE ENROLL_GRADEPanel A: 3N F, but not BCNF\\nPanel B: 3NF and BCNF\\nFIGURE 6.11  TABLES WITH MULTIVALUED DEPENDENCIES  \\nTable name: VO LUNTEER_V1Database name: Ch06_Service\\nTable name: VO LUNTEER_V3Table name: VO LUNTEER_V2\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1f2a0cb5-c2ab-4b2d-a4d5-12feacb67485', embedding=None, metadata={'page_label': '225', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    225\\nThere is a problem with the tables in Figure 6.11. The attributes ORG_CODE \\nand ASSIGN_NUM each may have many different values. In normalization ter -\\nminology, this situation is referred to as a multivalued dependency, which occurs \\nwhen one key determines multiple values of two other attributes and those attributes \\nare independent of each other. (One employee can have many service entries and \\nmany assignment entries. Therefore, one EMP_NUM can determine multiple val -\\nues of ORG_CODE and multiple values of ASSIGN_NUM; however, ORG_CODE \\nand ASSIGN_NUM are independent of each other.) The presence of a multivalued \\ndependency means that if table versions 1 and 2 are implemented, the tables are \\nlikely to contain quite a few null values; in fact, the tables do not even have a via -\\nble candidate key. (The EMP_NUM values are not unique, so they cannot be PKs. \\nNo combination of the attributes in table versions 1 and 2 can be used to create a \\nPK because some of them contain nulls.) Such a condition is not desirable, espe -\\ncially when there are thousands of employees, many of whom may have multiple job \\nassignments and many service activities. Version 3 at least has a PK, but it is com -\\nposed of all the attributes in the table. In fact, version 3 meets 3NF requirements, yet \\nit contains many redundancies that are clearly undesirable.\\nThe solution is to eliminate the problems caused by the multivalued dependency. Y ou \\ndo this by creating new tables for the components of the multivalued dependency. In \\nthis example, the multivalued dependency is resolved and eliminated by creating the \\nASSIGNMENT and SERVICE_V1 tables depicted in Figure 6.12. Those tables are said \\nto be in 4NF.\\nFIGURE 6.12  A SET OF TABLES IN 4NF  \\nThe relational diagram\\nTable name: EMPLOYEEDatabase name: CH06_Service\\nTable name: PROJECT\\nTable name: ORGANIZATION\\nTable name: ASSIGNMENT\\nTable name: SERVICE_V1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e839f216-75d9-4227-9a53-eea7b7cb4815', embedding=None, metadata={'page_label': '226', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='226   Part 2    Design Concepts\\nIf you follow the proper design procedures illustrated in this book, you should not \\nencounter the problem shown in Figure 6.11. Specifically, the discussion of 4NF is largely \\nacademic if you make sure that your tables conform to the following two rules:\\n1. All attributes must be dependent on the primary key, but they must be independent \\nof each other.\\n2. No row may contain two or more multivalued facts about an entity.\\n6-7 Normalization and Database Design\\nThe tables shown in Figure 6.6 illustrate how normalization procedures can be used to produce good tables from poor ones. Y ou will likely have ample opportunity to put this skill into practice when you begin to work with real-world databases. Normalization \\nshould be part of the design process. Therefore, make sure that proposed entities meet the required normal form before  the table structures are created. Keep in mind that if \\nyou follow the design procedures discussed in Chapters 3 and 4, the likelihood of data anomalies will be small. However, even the best database designers are known to make occasional mistakes that come to light during normalization checks. Also, many of the real-world databases you encounter will have been improperly designed or burdened with anomalies if they were improperly modified over the course of time. That means you might be asked to redesign and modify existing databases that are, in effect, anomaly traps. Therefore, you should be aware of good design principles and procedures as well as normalization procedures.\\nFirst, an ERD is created through an iterative process. Y ou begin by identifying rele-\\nvant entities, their attributes, and their relationships. Then you use the results to identify additional entities and attributes. The ERD provides the big picture, or macro view, of an organization’s data requirements and operations.\\nSecond, normalization focuses on the characteristics of specific entities; that is, nor -\\nmalization represents a micro view of the entities within the ERD. Also, as you learned in the previous sections of this chapter, the normalization process might yield additional entities and attributes to be incorporated into the ERD. Therefore, it is difficult to sep-arate normalization from ER modeling; the two techniques are used in an iterative and incremental process.\\nTo understand the proper role of normalization in the design process, you should \\nreexamine the operations of the contracting company whose tables were normalized in the preceding sections. Those operations can be summarized by using the following business rules:\\n•\\n The company manages many projects.\\n• Each project requires the services of many employees.\\n• An employee may be assigned to several different projects.\\n• Some employees are not assigned to a project and perform duties not specifically \\nrelated to a project. Some employees are part of a labor pool, to be shared by all proj-ect teams. For example, the company’s executive secretary would not be assigned to any one particular project.\\nA table is in fourth normal form (4NF)  when it is in 3NF and has no multivalued \\ndependencies.Note\\nfourth normal form (4NF)\\nA table is in 4NF if it is in 3NF and contains no multiple independent sets of multivalued dependencies.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='743e2ca6-c1f3-4fe7-912d-550c1beb3480', embedding=None, metadata={'page_label': '227', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    227\\n• Each employee has a single primary job classification, which determines the hourly \\nbilling rate.\\n• Many employees can have the same job classification. For example, the company \\nemploys more than one electrical engineer.\\nGiven that simple description of the company’s operations, two entities and their \\nattributes are initially defined:\\n• PROJECT ( PROJ_NUM , PROJ_NAME)\\n• EMPLOYEE ( EMP_NUM , EMP_LNAME, EMP_FNAME, EMP_INITIAL, JOB_\\nDESCRIPTION, JOB_CHG_HOUR)\\nThose two entities constitute the initial ERD shown in Figure 6.13.\\nAfter creating the initial ERD shown in Figure 6.13, the normal forms are defined:\\n• PROJECT is in 3NF and needs no modification at this point.\\n• EMPLOYEE requires additional scrutiny. The JOB_DESCRIPTION attribute defines \\njob classifications such as Systems Analyst, Database Designer, and Programmer. In \\nturn, those classifications determine the billing rate, JOB_CHG_HOUR. Therefore, \\nEMPLOYEE contains a transitive dependency.\\nThe removal of EMPLOYEE’s transitive dependency yields three entities:\\n• PROJECT ( PROJ_NUM , PROJ_NAME)\\n• EMPLOYEE ( EMP_NUM , EMP_LNAME, EMP_FNAME, EMP_INITIAL, \\nJOB_CODE)\\n• JOB ( JOB_CODE , JOB_DESCRIPTION, JOB_CHG_HOUR)\\nBecause the normalization process yields an additional entity (JOB), the initial ERD \\nis modified as shown in Figure 6.14.\\nTo represent the M:N relationship between EMPLOYEE and PROJECT, you might \\nthink that two 1:M relationships could be used—an employee can be assigned to many \\nprojects, and each project can have many employees assigned to it. (See Figure 6.15.) \\nUnfortunately, that representation yields a design that cannot be correctly implemented.\\nBecause the M:N relationship between EMPLOYEE and PROJECT cannot be imple -\\nmented, the ERD in Figure 6.15 must be modified to include the ASSIGNMENT entity \\nto track the assignment of employees to projects, thus yielding the ERD shown in Fig -\\nure 6.16. The ASSIGNMENT entity in Figure 6.16 uses the primary keys from the enti -\\nties PROJECT and EMPLOYEE to serve as its foreign keys. However, note that in this \\nimplementation, the ASSIGNMENT entity’s surrogate primary key is ASSIGN_NUM, \\nto avoid the use of a composite primary key. Therefore, the “enters” relationship between \\nEMPLOYEE and ASSIGNMENT and the “requires” relationship between PROJECT and \\nASSIGNMENT are shown as weak or nonidentifying.FIGURE 6.13  INITIAL CONTRACTING COMPANY ERD  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94d4fa8f-e929-4422-8fba-36baa3d7f4af', embedding=None, metadata={'page_label': '228', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='228   Part 2     Design Concepts\\nIn Figure 6.16, the ASSIGN_HOURS attribute is assigned to the composite entity \\nnamed ASSIGNMENT. Because you will likely need detailed information about each \\nproject’s manager, the creation of a “manages” relationship is useful. The “manages” \\nrelationship is implemented through the foreign key in PROJECT. Finally, some addi -\\ntional attributes may be created to improve the system’s ability to generate additional \\ninformation. For example, you may want to include the date the employee was hired \\n(EMP_HIREDATE) to keep track of worker longevity. Based on this last modification, \\nthe model should include four entities and their attributes:\\nPROJECT ( PROJ_NUM , PROJ_NAME, EMP_NUM)\\n EMPLOYEE ( EMP_NUM , EMP_LNAME, EMP_FNAME, EMP_INITIAL,  \\nEMP_HIREDATE, JOB_CODE)\\nJOB ( JOB_CODE , JOB_DESCRIPTION, JOB_CHG_HOUR)\\nASSIGNMENT ( ASSIGN_NUM , ASSIGN_DATE, PROJ_NUM, EMP_NUM,  \\nASSIGN_HOURS, ASSIGN_CHG_HOUR, ASSIGN_CHARGE)FIGURE 6.14  MODIFIED CONTRACTING COMPANY ERD  \\nFIGURE 6.15  INCORRECT M:N RELATIONSHIP REPRESENTATION  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cb8037f5-54c4-4b08-9e50-a7e47d8e73b4', embedding=None, metadata={'page_label': '229', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    229\\nThe design process is now on the right track. The ERD represents the operations \\naccurately, and the entities now reflect their conformance to 3NF. The combination of \\nnormalization and ER modeling yields a useful ERD, whose entities may now be trans -\\nlated into appropriate table structures. In Figure 6.15, note that PROJECT is optional \\nto EMPLOYEE in the “manages” relationship. This optionality exists because not all \\nemployees manage projects. The final database contents are shown in Figure 6.17.\\n6-8 Denormalization\\nIt is important to remember that the optimal relational database implementation requires that \\nall tables be at least in third normal form (3NF). A good relational DBMS excels at manag -\\ning normalized relations—that is, relations void of any unnecessary redundancies that might \\ncause data anomalies. Although the creation of normalized relations is an important database \\ndesign goal, it is only one of many such goals. Good database design also considers processing \\n(or reporting) requirements and processing speed. The problem with normalization is that as \\ntables are decomposed to conform to normalization requirements, the number of database \\ntables expands. Therefore, in order to generate information, data must be put together from \\nvarious tables. Joining a large number of tables takes additional input/output (I/O) operations \\nand processing logic, thereby reducing system speed. Most relational database systems are \\nable to handle joins very efficiently. However, rare and occasional circumstances may allow \\nsome degree of denormalization so processing speed can be increased.\\nKeep in mind that the advantage of higher processing speed must be carefully weighed \\nagainst the disadvantage of data anomalies. On the other hand, some anomalies are of \\nonly theoretical interest. For example, should people in a real-world database environ -\\nment worry that a ZIP_CODE determines CITY in a CUSTOMER table whose primary \\nkey is the customer number? Is it really practical to produce a separate table for\\nZIP ( ZIP_CODE , CITY)\\nto eliminate a transitive dependency from the CUSTOMER table? (Perhaps your \\nanswer to that question changes if you are in the business of producing mailing lists.) \\nAs explained earlier, the problem with denormalized relations and redundant data is \\nthat data integrity could be compromised due to the possibility of insert, update, and FIGURE 6.16  FINAL CONTRACTING COMPANY ERD  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8bb70552-067e-4352-b32b-4e7c2e39f2b0', embedding=None, metadata={'page_label': '230', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='230   Part 2     Design Concepts\\ndeletion anomalies. The advice is simple: use common sense during the normalization \\nprocess.\\nFurthermore, the database design process could, in some cases, introduce some \\nsmall degree of redundant data in the model, as seen in the previous example. This, in \\neffect, creates “denormalized” relations. Table 6.6 shows some common examples of data \\nredundancy that are generally found in database implementations.\\nA more comprehensive example of the need for denormalization due to reporting \\nrequirements is the case of a faculty evaluation report in which each row lists the scores \\nobtained during the last four semesters taught. (See Figure 6.18.)\\nAlthough this report seems simple enough, the problem is that the data is stored in \\na normalized table in which each row represents a different score for a given faculty \\nmember in a given semester. (See Figure 6.19.)\\nThe difficulty of transposing multirow data to multicolumn data is compounded by \\nthe fact that the last four semesters taught are not necessarily the same for all faculty \\nmembers. Some might have taken sabbaticals, some might have had research appoint -\\nments, some might be new faculty with only two semesters on the job, and so on. To \\ngenerate this report, the two tables in Figure 6.18 were used. The EV ALDATA table is FIGURE 6.17  THE IMPLEMENTED DATABASE  \\nTable name: EMPLOYEE\\nTable name: JOB\\nTable name: ASSIGNMENTDatabase name: Ch06_ConstructCo\\nTable name: PROJECT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2a3ac000-7da5-4a22-97f8-1f976f710dd0', embedding=None, metadata={'page_label': '231', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    231\\nthe master data table containing the evaluation scores for each faculty member for each \\nsemester taught; this table is normalized. The FACHIST table contains the last four data \\npoints—that is, evaluation score and semester—for each faculty member. The FACHIST \\ntable is a temporary denormalized table created from the EV ALDATA table via a series of \\nqueries. (The FACHIST table is the basis for the report shown in Figure 6.18.)\\nAs shown in the faculty evaluation report, the conflicts between design efficiency, \\ninformation requirements, and performance are often resolved through compromises \\nthat may include denormalization. In this case, and assuming there is enough storage \\nspace, the designer’s choices could be narrowed down to:\\n•  Store the data in a permanent denormalized table. This is not the recommended solu -\\ntion because the denormalized table is subject to data anomalies (insert, update, and \\ndelete). This solution is viable only if performance is an issue.\\n• Create a temporary denormalized table from the permanent normalized table(s). The \\ndenormalized table exists only as long as it takes to generate the report; it disappears after \\nthe report is produced. Therefore, there are no data anomaly problems. This solution is \\npractical only if performance is not an issue and there are no other viable processing options.\\nAs shown, normalization purity is often difficult to sustain in the modern database environ -\\nment . Y ou will learn in Chapter 13, Business Intelligence and Data Warehouses, that lower TABLE 6.6\\nCOMMON DENORMALIZATION EXAMPLES\\nCASE EXAMPLE RATIONALE AND CONTROLS\\nRedundant data Storing ZIP and CITY attributes in the \\nAGENT table when ZIP determines CITY \\n(see Figure 2.2)Avoid extra join operations\\nProgram can validate city (drop-down box) \\nbased on the zip code\\nDerived data Storing STU_HRS and STU_CLASS (student \\nclassification) when STU_HRS determines \\nSTU_CLASS (see Figure 3.28)Avoid extra join operations\\nProgram can validate classification (lookup) \\nbased on the student hours\\nPreaggregated data \\n(also derived data)Storing the student grade point \\naverage (STU_GPA) aggregate value in \\nthe STUDENT table when this can be \\ncalculated from the ENROLL and COURSE \\ntables (see Figure 3.28)Avoid extra join operations\\nProgram computes the GPA every time a \\ngrade is entered or updated\\nSTU_GPA can be updated only via \\nadministrative routine\\nInformation \\nrequirementsUsing a temporary denormalized table \\nto hold report data; this is required when \\ncreating a tabular report in which the \\ncolumns represent data that are stored in \\nthe table as rows (see Figures 6.17 and 6.18)Impossible to generate the data required \\nby the report using plain SQL\\nNo need to maintain table\\nTemporary table is deleted once report is done\\nProcessing speed is not an issue\\nFIGURE 6.18  THE FACULTY EVALUATION REPORT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8a7d77ac-4605-4519-a514-d13478733d76', embedding=None, metadata={'page_label': '232', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='232   Part 2     Design Concepts\\nnormalization forms occur (and are even required) in specialized databases known as data \\nwarehouses. Such specialized databases reflect the ever-growing demand for greater scope \\nand depth in the data on which decision support systems increasingly rely. Y ou will discover \\nthat the data warehouse routinely uses 2NF structures in its complex, multilevel, multisource \\ndata environment. In short, although normalization is very important, especially in the \\nso-called production database environment, 2NF is no longer disregarded as it once was.\\nAlthough 2NF tables cannot always be avoided, the problem of working with tables \\nthat contain partial and/or transitive dependencies in a production database environment \\nshould not be minimized. Aside from the possibility of troublesome data anomalies being \\ncreated, unnormalized tables in a production database tend to suffer from these defects:\\n• Data updates are less efficient because programs that read and update tables must deal \\nwith larger tables.\\n• Indexing is more cumbersome. It is simply not practical to build all of the indexes \\nrequired for the many attributes that might be located in a single unnormalized table.\\n• Unnormalized tables yield no simple strategies for creating virtual tables known as \\nviews . Y ou will learn how to create and use views in Chapter 8, Advanced SQL.\\nRemember that good design cannot be created in the application programs that use a \\ndatabase. Also keep in mind that unnormalized database tables often lead to various data \\nredundancy disasters in production databases, such as the problems examined thus far. \\nIn other words, use denormalization cautiously and make sure that you can explain why \\nthe unnormalized tables are a better choice in certain situations than their normalized \\ncounterparts.\\n6-9 Data-Modeling Checklist\\nIn the chapters of Part 2, you have learned how data modeling translates a specific real-world \\nenvironment into a data model that represents the real-world data, users, processes, and \\ninteractions. The modeling techniques you have learned thus far give you the tools needed \\nto produce successful database designs. However, just as any good pilot uses a checklist to \\nensure that all is in order for a successful flight, the data-modeling checklist shown in Table \\n6.7 will help ensure that you perform data-modeling tasks successfully based on the concepts \\nand tools you have learned in this text.FIGURE 6.19  THE EVALDATA AND FACHIST TABLES  \\nTable name: FACHIST       Database name: Ch06_EVAL Table name: EVALDATA\\nDenormalized\\nNormalizedRepeating Group\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b831267d-c195-48c0-9e57-15a3305b7e10', embedding=None, metadata={'page_label': '233', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    233\\nYou can also find this data-modeling checklist on the inside front cover of this book for \\neasy reference.Note\\nTABLE 6.7\\nDATA-MODELING CHECKLIST\\nBUSINESS RULES\\n• Properly document and verify all business rules with the end users.\\n• Ensure that all business rules are written precisely, clearly, and simply. The business rules must help identify entities, attributes, relationships, and constraints.\\n• Identify the source of all business rules, and ensure that each business rule is justified, dated, and signed off by an approving authority.\\nDATA MODELING\\nNaming conventions: All names should be limited in length (database-dependent size). \\n• Entity names:\\n• Should be nouns that are familiar to business and should be short and meaningful\\n• Should document abbreviations, synonyms, and aliases for each entity\\n• Should be unique within the model\\n• For composite entities, may include a combination of abbreviated names of the entities linked through the composite entity\\n• Attribute names:\\n• Should be unique within the entity\\n• Should use the entity abbreviation as a prefix\\n• Should be descriptive of the characteristic\\n• Should use suffixes such as _ID, _NUM, or _CODE for the PK attribute\\n• Should not be a reserved word\\n• Should not contain spaces or special characters such as @, !, or &\\n• Relationship names:\\n• Should be active or passive verbs that clearly indicate the nature of the relationship\\nEntities:\\n• Each entity should represent a single subject.\\n• Each entity should represent a set of distinguishable entity instances.\\n• All entities should be in 3NF or higher. Any entities below 3NF should be justified.\\n• The granularity of the entity instance should be clearly defined.\\n• The PK should be clearly defined and support the selected data granularity.\\nAttributes: \\n• Should be simple and single-valued (atomic data)\\n• Should document default values, constraints, synonyms, and aliases\\n• Derived attributes should be clearly identified and include source(s)\\n• Should not be redundant unless this is required for transaction accuracy, performance, or maintaining a history\\n• Nonkey attributes must be fully dependent on the PK attribute\\nRelationships:\\n• Should clearly identify relationship participants\\n• Should clearly define participation, connectivity, and document cardinality\\nER model:\\n• Should be validated against expected processes: inserts, updates, and deletions\\n• Should evaluate where, when, and how to maintain a history\\n• Should not contain redundant relationships except as required (see attributes)\\n• Should minimize data redundancy to ensure single-place updates\\n• Should conform to the minimal data rule: All that is needed is there, and all that is there is needed.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dbabe5e3-edbf-4324-afac-45b1935483d7', embedding=None, metadata={'page_label': '234', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='234   Part 2    Design Concepts\\nSummary\\n• Normalization is a technique used to design tables in which data redundancies are \\nminimized. The first three normal forms (1NF, 2NF, and 3NF) are the most com-mon. From a structural point of view, higher normal forms are better than lower normal forms because higher normal forms yield relatively fewer data redundancies in the database. Almost all business designs use 3NF as the ideal normal form. A special, more restricted 3NF known as Boyce-Codd normal form, or BCNF, is also used.\\n•\\n A table is in 1NF when all key attributes are defined and all remaining attributes are dependent on the primary key. However, a table in 1NF can still contain both par -\\ntial and transitive dependencies. A partial dependency is one in which an attribute is functionally dependent on only a part of a multiattribute primary key. A transi-tive dependency is one in which an attribute is functionally dependent on another nonkey attribute. A table with a single-attribute primary key cannot exhibit partial dependencies.\\n•\\n A table is in 2NF when it is in 1NF and contains no partial dependencies. Therefore, a 1NF table is automatically in 2NF when its primary key is based on only a single attribute. A table in 2NF may still contain transitive dependencies.\\n•\\n A table is in 3NF when it is in 2NF and contains no transitive dependencies. Given that definition, the Boyce-Codd normal form (BCNF) is merely a special 3NF case in which all determinant keys are candidate keys. When a table has only a single candi-date key, a 3NF table is automatically in BCNF.\\n•\\n A table that is not in 3NF may be split into new tables until all of the tables meet the 3NF requirements.\\n•\\n Normalization is an important part—but only a part—of the design process. As entities and attributes are defined during the ER modeling process, subject each entity (set) to normalization checks and form new entities (sets) as required. Incorporate the normalized entities into the ERD and continue the iterative ER process until all entities and their attributes are defined and all equivalent tables are in 3NF.\\n•\\n A table in 3NF might contain multivalued dependencies that produce either numer -\\nous null values or redundant data. Therefore, it might be necessary to convert a 3NF table to the fourth normal form (4NF) by splitting the table to remove the multivalued dependencies. Thus, a table is in 4NF when it is in 3NF and contains no multivalued dependencies.\\n•\\n The larger the number of tables, the more additional I/O operations and processing logic you need to join them. Therefore, tables are sometimes denormalized to yield less I/O in order to increase processing speed. Unfortunately, with larger tables, you pay for the increased processing speed by making the data updates less efficient, by making indexing more cumbersome, and by introducing data redundancies that are likely to yield data anomalies. In the design of production databases, use denormal-ization sparingly and cautiously.\\n•\\n The data-modeling checklist provides a way for the designer to check that the ERD meets a set of minimum requirements.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b452ccc7-6bec-4917-9df6-8d2e852ac6aa', embedding=None, metadata={'page_label': '235', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    235\\n1. What is normalization?\\n2. When is a table in 1NF?\\n3. When is a table in 2NF?\\n4. When is a table in 3NF?\\n5. When is a table in BCNF?\\n6. Given the dependency diagram shown in Figure Q6.6, answer Items 6a−6c.\\na. Identify and discuss each of the indicated dependencies.\\nb. Create a database whose tables are at least in 2NF, showing the dependency dia -\\ngrams for each table.\\nc. Create a database whose tables are at least in 3NF, showing the dependency dia -\\ngrams for each table.\\n7. The dependency diagram in Figure Q6.7 indicates that authors are paid royalties for \\neach book they write for a publisher. The amount of the royalty can vary by author, \\nby book, and by edition of the book.\\natomic attribute\\natomicity\\nBoyce-Codd normal form \\n(BCNF)\\ndenormalization\\ndependency diagram\\ndeterminantfirst normal form (1NF)\\nfourth normal form (4NF)\\ngranularity\\nkey attribute\\nnonkey attribute\\nnonprime attribute\\nnormalizationpartial dependency\\nprime attribute\\nrepeating group\\nsecond normal form (2NF)\\nthird normal form (3NF)\\ntransitive dependencyKey Term  \\nReview Questions\\nFlashcards and crossword \\npuzzles for key term practice \\nare available at  \\nwww.cengagebrain.com .Online \\nContent\\nFIGURE Q6.6  DEPENDENCY DIAGRAM FOR QUESTION 6  \\nC1 C2 C3 C4 C5\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4890fa5d-c5c6-41b0-8fb5-ae5fd979b505', embedding=None, metadata={'page_label': '236', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='236   Part 2     Design Concepts\\na. Based on the dependency diagram, create a database whose tables are at least in \\n2NF, showing the dependency diagram for each table.\\nb. Create a database whose tables are at least in 3NF, showing the dependency \\ndiagram for each table.\\n8. The dependency diagram in Figure Q6.8 indicates that a patient can receive many \\nprescriptions for one or more medicines over time. Based on the dependency dia -\\ngram, create a database whose tables are in at least 2NF, showing the dependency \\ndiagram for each table.FIGURE Q6.7  BOOK ROYALTY DEPENDENCY DIAGRAM  \\nFIGURE Q6.8  PRESCRIPTION DEPENDENCY DIAGRAM  \\nISBN BookTitle LastName Author _Num Publisher Royalty Edition\\nMedName PatientID ReﬁllsAllowed Date PatientName Dosage ShelfLife\\n9. What is a partial dependency? With what normal form is it associated?\\n10. What three data anomalies are likely to be the result of data redundancy? How can \\nsuch anomalies be eliminated?\\n11. Define and discuss the concept of transitive dependency.\\n12. What is a surrogate key, and when should you use one?\\n13. Why is a table whose primary key consists of a single attribute automatically in 2NF \\nwhen it is in 1NF?\\n14. How would you describe a condition in which one attribute is dependent on another \\nattribute when neither attribute is part of the primary key?\\n15. Suppose someone tells you that an attribute that is part of a composite primary key \\nis also a candidate key. How would you respond to that statement?\\n16. A table is in  normal form when it is in  and there are no \\ntransitive dependencies.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b8cac76b-a58b-42c7-abfa-2e7f4af0fad2', embedding=None, metadata={'page_label': '237', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    237\\n1. Using the descriptions of the attributes given in the figure, convert the ERD shown \\nin Figure P6.1 into a dependency diagram that is in at least 3NF.\\n2. Using the descriptions of the attributes given in the figure, convert the ERD shown \\nin Figure P6.2 into a dependency diagram that is in at least 3NF.Problems\\nFIGURE P6.1  APPOINTMENT ERD FOR PROBLEM 1  \\nFIGURE P6.2  PRESENTATION ERD FOR PROBLEM 2  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3e512bb3-e89a-4bf4-95c8-30f1d23fbb43', embedding=None, metadata={'page_label': '238', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='238   Part 2    Design Concepts\\n3. Using the INVOICE table structure shown in Table P6.3, do the following:\\nTABLE P6.3\\nATTRIBUTE \\nNAMESAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nINV_NUM 211347 211347 211347 211348 211349\\nPROD_NUM AA-E3422QW QD-300932X RU-995748G AA-E3422QW GH-778345P\\nSALE_DATE 15-Jan-2016 15-Jan-2016 15-Jan-2016 15-Jan-2016 16-Jan-2016PROD_LABEL Rotary sander 0.25-in. drill bit Band saw Rotary sander Power drillVEND_CODE 211 211 309 211 157\\nVEND_NAME NeverFail, Inc. NeverFail, Inc. BeGood, Inc. NeverFail, Inc. ToughGo, Inc.QUANT_SOLD 1 8 1 2 1\\nPROD_PRICE $49.95 $3.45 $39.99 $49.95 $87.75\\na. Write the relational schema, draw its dependency diagram, and identify all \\ndependencies, including all partial and transitive dependencies. Y ou can assume that the table does not contain repeating groups and that an invoice number ref-erences more than one product. (Hint:  This table uses a composite primary key.)\\nb.\\n Remove all partial dependencies, write the relational schema, and draw the new dependency diagrams. Identify the normal forms for each table structure you created.\\nc.\\n Remove all transitive dependencies, write the relational schema, and draw the new dependency diagrams. Also identify the normal forms for each table struc-ture you created.\\nd.\\n Draw the Crow’s Foot ERD.\\n4. Using the STUDENT table structure shown in Table P6.4, do the following:\\na. Write the relational schema and draw its dependency diagram. Identify all dependencies, including all transitive dependencies.\\nb.\\n Write the relational schema and draw the dependency diagram to meet the 3NF requirements to the greatest practical extent possible. If you believe that practical considerations dictate using a 2NF structure, explain why your decision to retain 2NF is appropriate. If necessary, add or modify attributes to create appropriate determinants and to adhere to the naming conventions.\\nc.\\n Using the results of Problem 4, draw the Crow’s Foot ERD.\\nYou can assume that any given product is supplied by a single vendor, but a vendor can supply many products. Therefore, it is proper to conclude that the following dependency exists:\\nPROD_NUM → PROD_LABEL, PROD_PRICE, VEND_CODE, VEND_NAME\\n(Hint: Your actions should produce three dependency diagrams.)Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7b786420-0583-4a7b-89b6-95b3c1c79126', embedding=None, metadata={'page_label': '239', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    239\\n5. To keep track of office furniture, computers, printers, and other office equipment, \\nthe FOUNDIT Company uses the table structure shown in Table P6.5.\\na. Given that information, write the relational schema and draw the dependency diagram. Make sure that you label the transitive and/or partial dependencies.\\nb.\\n Write the relational schema and create a set of dependency diagrams that meet 3NF requirements. Rename attributes to meet the naming conventions, and cre-ate new entities and attributes as necessary.\\nc.\\n Draw the Crow’s Foot ERD.\\nAlthough the completed student hours (STU_HOURS) do determine the student classifi-cation (STU_CLASS), this dependency is not as obvious as you might initially assume it to be. For example, a student is considered a junior if the student has completed between 61 and 90 credit hours.NoteTABLE P6.4\\nATTRIBUTE NAMESAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nSTU_NUM 211343 200128 199876 198648 223456\\nSTU_LNAME Stephanos Smith Jones Ortiz McKulski\\nSTU_MAJOR Accounting Accounting Marketing Marketing Statistics\\nDEPT_CODE ACCT ACCT MKTG MKTG MATH\\nDEPT_NAME Accounting Accounting Marketing Marketing MathematicsDEPT_PHONE 4356 4356 4378 4378 3420\\nCOLLEGE_NAME Business Admin Business Admin Business Admin Business Admin Arts & SciencesADVISOR_LNAME Grastrand Grastrand Gentry Tillery Chen\\nADVISOR_OFFICE T201 T201 T228 T356 J331\\nADVISOR_BLDG Torre Building Torre Building Torre Building Torre Building Jones BuildingADVISOR_PHONE 2115 2115 2123 2159 3209\\nSTU_GPA 3.87 2.78 2.31 3.45 3.58\\nSTU_HOURS 75 45 117 113 87\\nSTU_CLASS Junior Sophomore Senior Senior Junior\\nTABLE P6.5\\nATTRIBUTE NAME SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nITEM_ID 231134-678 342245-225 254668-449\\nITEM_LABEL HP DeskJet 895Cse HP Toner DT Scanner\\nROOM_NUMBER 325 325 123\\nBLDG_CODE NTC NTC CSF\\nBLDG_NAME Nottooclear Nottooclear Canseefar\\nBLDG_MANAGER I. B. Rightonit I. B. Rightonit May B. Next\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2411e234-25ed-4a65-8621-d635a8be8b87', embedding=None, metadata={'page_label': '240', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='240   Part 2    Design Concepts\\n6. The table structure shown in Table P6.6 contains many unsatisfactory components \\nand characteristics. For example, there are several multivalued attributes, naming conventions are violated, and some attributes are not atomic.\\na.\\n Given the structure shown in Table P6.6, write the relational schema and draw its dependency diagram. Label all transitive and/or partial dependencies.\\nb.\\n Draw the dependency diagrams that are in 3NF. (Hint:  Y ou might have to create \\na few new attributes. Also make sure that the new dependency diagrams contain attributes that meet proper design criteria; i.e., make sure there are no multival-ued attributes, that the naming conventions are met, and so on.)\\nc.\\n Draw the relational diagram.\\nd. Draw the Crow’s Foot ERD.\\n7. Suppose you are given the following business rules to form the basis for a database design. The database must enable the manager of a company dinner club to mail invitations to the club’s members, to plan the meals, to keep track of who attends the dinners, and so on.\\n•\\n Each dinner serves many members, and each member may attend many dinners.\\n• A member receives many invitations, and each invitation is mailed to many members.\\n• A dinner is based on a single entree, but an entree may be used as the basis for many \\ndinners. For example, a dinner may be composed of a fish entree, rice, and corn, or the dinner may be composed of a fish entree, a baked potato, and string beans.\\n Because the manager is not a database expert, the first attempt at creating the data-base uses the structure shown in Table P6.7.\\na.\\n Given the table structure illustrated in Table P6.7, write the relational schema and draw its dependency diagram. Label all transitive and/or partial dependen-cies. (Hint:  This structure uses a composite primary key.)TABLE P6.6\\nEMP_NUM 1003 1018 1019 1023\\nEMP_LNAME Willaker Smith McGuire McGuire\\nEMP_EDUCATION BBA, MBA BBA BS, MS, Ph.D.\\nJOB_CLASS SLS SLS JNT DBA\\nEMP_DEPENDENTS Gerald (spouse),  Mary (daughter),  John (son)JoAnne (spouse) George (spouse)  \\nJill (daughter)\\nDEPT_CODE MKTG MKTG SVC INFS\\nDEPT_NAME Marketing Marketing General Service Info. Systems\\nDEPT_MANAGER Jill H. Martin Jill H. Martin Hank B. Jones Carlos G. Ortez\\nEMP_TITLE Sales Agent Sales Agent Janitor DB Admin\\nEMP_DOB 23-Dec-1968 28-Mar-1979 18-May-1982 20-Jul-1959\\nEMP_HIRE_DATE 14-Oct-1997 15-Jan-2006 21-Apr-2003 15-Jul-1999\\nEMP_TRAINING L1, L2 L1 L1 L1, L3, L8, L15\\nEMP_BASE_SALARY $38,255.00 $30,500.00 $19,750.00 $127,900.00\\nEMP_COMMISSION_RATE 0.015 0.010\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5d0cf90-dcd8-4877-af3f-0dd0769d9a6d', embedding=None, metadata={'page_label': '241', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    241\\nb. Break up the dependency diagram you drew in Problem 7a to produce depen -\\ndency diagrams that are in 3NF, and write the relational schema. ( Hint:  Y ou might \\nhave to create a few new attributes. Also, make sure that the new dependency \\ndiagrams contain attributes that meet proper design criteria; i.e., make sure there \\nare no multivalued attributes, that the naming conventions are met, and so on.)\\nc. Using the results of Problem 7b, draw the Crow’s Foot ERD.\\n8. Use the dependency diagram shown in Figure P6.8 to work the following problems.\\na. Break up the dependency diagram shown in Figure P6.8 to create two new \\ndependency diagrams: one in 3NF and one in 2NF.\\nb. Modify the dependency diagrams you created in Problem 8a to produce a set of \\ndependency diagrams that are in 3NF. ( Hint:  One of your dependency diagrams \\nshould be in 3NF but not in BCNF.)\\nc. Modify the dependency diagrams you created in Problem 8b to produce a collec -\\ntion of dependency diagrams that are in 3NF and BCNF.TABLE P6.7\\nATTRIBUTE NAME SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nMEMBER_NUM 214 235 214\\nMEMBER_NAME Alice B. VanderVoort Gerald M. Gallega Alice B. VanderVoort\\nMEMBER_ADDRESS 325 Meadow Park 123 Rose Court 325 Meadow Park\\nMEMBER_CITY Murkywater Highlight Murkywater\\nMEMBER_ZIPCODE 12345 12349 12345\\nINVITE_NUM 8 9 10\\nINVITE_DATE 23-Feb-2016 12-Mar-2016 23-Feb-2016\\nACCEPT_DATE 27-Feb-2016 15-Mar-2016 27-Feb-2016\\nDINNER_DATE 15-Mar-2016 17-Mar-2016 15-Mar-2016\\nDINNER_ATTENDED Yes Yes No\\nDINNER_CODE DI5 DI5 DI2\\nDINNER_DESCRIPTION Glowing Sea Delight Glowing Sea Delight Ranch Superb\\nENTREE_CODE EN3 EN3 EN5\\nENTREE_DESCRIPTION Stuffed crab Stuffed crab Marinated steak\\nDESSERT_CODE DE8 DE5 DE2\\nDESSERT_DESCRIPTION Chocolate mousse with raspberry sauce Cherries jubilee Apple pie with honey crust\\nFIGURE P6.8  INITIAL DEPENDENCY DIAGRAM FOR PROBLEM 8  \\nA B C D E F G\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='597906a1-42ee-43ce-9ce1-6d2ea88a61d6', embedding=None, metadata={'page_label': '242', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='242   Part 2    Design Concepts\\n9. Suppose you have been given the table structure and data shown in Table P6.9, \\nwhich was imported from an Excel spreadsheet. The data reflects that a professor can have multiple advisees, can serve on multiple committees, and can edit more than one journal.\\n Given the information in Table P6.9:\\na. Draw the dependency diagram.\\nb. Identify the multivalued dependencies.\\nc. Create the dependency diagrams to yield a set of table structures in 3NF.\\nd. Eliminate the multivalued dependencies by converting the affected table struc-tures to 4NF.\\ne.\\n Draw the Crow’s Foot ERD to reflect the dependency diagrams you drew in Problem 9c. (Note:  Y ou might have to create additional attributes to define the \\nproper PKs and FKs. Make sure that all of your attributes conform to the naming conventions.)\\n10.\\n The manager of a consulting firm has asked you to evaluate a database that contains the table structure shown in Table P6.10.\\nTable P6.10 was created to enable the manager to match clients with consultants. \\nThe objective is to match a client within a given region with a consultant in that region and to make sure that the client’s need for specific consulting services is prop-erly matched to the consultant’s expertise. For example, if the client needs help with database design and is located in the Southeast, the objective is to make a match with a consultant who is located in the Southeast and whose expertise is in database design. (Although the consulting company manager tries to match consultant and client locations to minimize travel expense, it is not always possible to do so.) The following basic business rules are maintained:\\n•\\n Each client is located in one region.\\n• A region can contain many clients.TABLE P6.9\\nATTRIBUTE NAME SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nEMP_NUM 123 104 118\\nPROF_RANK Professor Asst. Professor Assoc. Professor Assoc. Professor\\nEMP_NAME Ghee Rankin Ortega Smith\\nDEPT_CODE CIS CHEM CIS ENG\\nDEPT_NAME Computer Info.\\nSystemsChemistry Computer Info.\\nSystemsEnglish\\nPROF_OFFICE KDD-567 BLF-119 KDD-562 PRT-345\\nADVISEE 1215, 2312, 3233,2218, 20983102, 2782, 3311,2008, 2876, 2222,3745, 1783, 23782134, 2789, 3456,2002, 2046, 2018,27642873, 2765, 2238,2901, 2308\\nCOMMITTEE_CODE PROMO, TRAF,APPL, DEVDEV SPR, TRAF PROMO, SPR, DEV\\nJOURNAL_CODE JMIS, QED, JMGT JCIS, JMGT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0ce60900-13a0-4cce-8e23-69970d962bcf', embedding=None, metadata={'page_label': '243', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 6    Normalization of Database Tables    243\\n• Each consultant can work on many contracts.\\n• Each contract might require the services of many consultants.\\n• A client can sign more than one contract, but each contract is signed by only one \\nclient.\\n• Each contract might cover multiple consulting classifications. (For example, a contract may list consulting services in database design and networking.)\\nTABLE P6.10\\nATTRIBUTE NAME SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nCLIENT_NUM 298 289 289\\nCLIENT_NAME Marianne R. Brown James D. Smith James D. Smith\\nCLIENT_REGION Midwest Southeast Southeast\\nCONTRACT_DATE 10-Feb-2016 15-Feb-2016 12-Mar-2016\\nCONTRACT_NUMBER 5841 5842 5843\\nCONTRACT_AMOUNT $2,985,000.00 $670,300.00 $1,250,000.00\\nCONSULT_CLASS_1 Database Administration Internet Services Database Design\\nCONSULT_CLASS_2 Web Applications Database Administration\\nCONSULT_CLASS_3 Network Installation\\nCONSULT_CLASS_4CONSULTANT_NUM_1 29 34 25\\nCONSULTANT_NAME_1 Rachel G. Carson Gerald K. Ricardo Angela M. Jamison\\nCONSULTANT_REGION_1 Midwest Southeast Southeast\\nCONSULTANT_NUM_2 56 38 34\\nCONSULTANT_NAME_2 Karl M. Spenser Anne T. Dimarco Gerald K. Ricardo\\nCONSULTANT_REGION_2 Midwest Southeast Southeast\\nCONSULTANT_NUM_3 22 45\\nCONSULTANT_NAME_3 Julian H. Donatello Geraldo J. Rivera\\nCONSULTANT_REGION_3 Midwest Southeast\\nCONSULTANT_NUM_4 18\\nCONSULTANT_NAME_4 Donald Chen\\nCONSULTANT_REGION_4 West\\n• Each consultant is located in one region.\\n• A region can contain many consultants.\\n• Each consultant has one or more areas of expertise (class). For example, a con-\\nsultant might be classified as an expert in both database design and networking.\\n• Each area of expertise (class) can have many consultants. For example, the con-sulting company might employ many consultants who are networking experts.\\na.\\n Given this brief description of the requirements and the business rules, write the relational schema and draw the dependency diagram for the preceding (and very poor) table structure. Label all transitive and/or partial dependencies.\\nb.\\n Break up the dependency diagram you drew in Problem 10a to produce depen-dency diagrams that are in 3NF and write the relational schema. (Hint:  Y ou might \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='40e79df8-4d2a-44cd-ae00-dfd297c35a3c', embedding=None, metadata={'page_label': '244', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='244   Part 2    Design Concepts\\nhave to create a few new attributes. Also make sure that the new dependency dia-\\ngrams contain attributes that meet proper design criteria; that is, make sure there are no multivalued attributes, that the naming conventions are met, and so on.)\\nc.\\n Using the results of Problem 10b, draw the Crow’s Foot ERD.\\n11. Given the sample records in the CHARTER table shown in Table P6.11, do the following:\\na.\\n Write the relational schema and draw the dependency diagram for the table structure. Make sure that you label all dependencies. CHAR_PAX indicates the number of passengers carried. The CHAR_MILES entry is based on round-trip miles, including pickup points. (Hint:  Look at the data values to determine the \\nnature of the relationships. For example, note that employee Melton has flown two charter trips as pilot and one trip as copilot.)\\nb.\\n Decompose the dependency diagram you drew to solve Problem 11a to create table structures that are in 3NF and write the relational schema.\\nc.\\n Draw the Crow’s Foot ERD to reflect the properly decomposed dependency dia-grams you created in Problem 11b. Make sure the ERD yields a database that can track all of the data shown in Problem 11. Show all entities, relationships, connectivities, optionalities, and cardinalities.\\nTABLE P6.11\\nATTRIBUTE NAME SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE SAMPLE VALUE\\nCHAR_TRIP 10232 10233 10234 10235\\nCHAR_DATE 15-Jan-2016 15-Jan-2016 16-Jan-2016 17-Jan-2016\\nCHAR_CITY STL MIA TYS ATL\\nCHAR_MILES 580 1,290 524 768\\nCUST_NUM 784 231 544 784\\nCUST_LNAME Brown Hanson Bryana Brown\\nCHAR_PAX 5 12 2 5\\nCHAR_CARGO 235 lbs. 18,940 lbs. 348 lbs. 155 lbs.\\nPILOT Melton Chen Henderson Melton\\nCOPILOT Henderson Melton\\nFLT_ENGINEER O’Shaski\\nLOAD_MASTER Benkasi\\nAC_NUMBER 1234Q 3456Y 1234Q 2256W\\nMODEL_CODE PA31-350 CV-580 PA31-350 PA31-350\\nMODEL_SEATS 10 38 10 10\\nMODEL_CHG_MILE $2.79 $23.36 $2.79 $2.79\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc204640-823d-412e-ac10-92a4b4ef6a4d', embedding=None, metadata={'page_label': '245', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 3\\nAdvanced Design and Implementation\\n7Introduction to Structured Query Language (SQL)\\n8\\n9Advanced SQL\\nDatabase Design\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='49fdc9e9-1881-4e8b-8ad9-7267bf2d9ecd', embedding=None, metadata={'page_label': '246', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 7\\nIntroduction to Structured Query Language (SQL)\\nIn this chapter, you will learn:\\n• The basic commands and functions of SQL\\n• How to use SQL for data administration (to create tables and indexes)\\n• How to use SQL for data manipulation (to add, modify, delete, and retrieve data)\\n• How to use SQL to query a database for useful information\\nPreviewIn this chapter, you will learn the basics of Structured Query Language (SQL). SQL, \\nwhich is pronounced S-Q-L or sequel , is composed of commands that enable users to \\ncreate database and table structures, perform various types of data manipulation and data administration, and query the database to extract useful information. All relational DBMS software supports SQL, and many software vendors have developed extensions to the basic SQL command set.\\nAlthough it is quite useful and powerful, SQL is not meant to stand alone in the appli-\\ncations arena. Data entry with SQL is possible but awkward, as are data corrections and additions. SQL itself does not create menus, special report forms, overlays, pop-ups, or other features that end users usually expect. Instead, those features are available as \\n vendor-supplied enhancements. SQL focuses on data definition (creating tables and indexes) and data manipulation (adding, modifying, deleting, and retrieving data). This chapter covers these basic functions. In spite of its limitations, SQL is a powerful tool for extracting information and managing data.\\nData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH07_SaleCo  P\\t P\\t P\\t P CH07_ConstructCo  P\\t P\\t P\\t P\\nCH07_LargeCo  P\\t P\\t P\\t P\\nCh07_Fact  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nData Files Available on cengagebrain.com\\nAlthough you can use the MS Access  databases and SQL script files for creating the tables and loading the data supplied online, it is strongly suggested that you create your own database structures so you can practice the SQL commands illustrated in this chapter.\\nHow you connect to your database depends on how the software was installed on your \\ncomputer. Follow the instructions provided by your instructor or school.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2ba68cb5-99d2-4fda-8df5-ff62aaead66a', embedding=None, metadata={'page_label': '247', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    247\\n7-1 Introduction to SQL\\nIdeally, a database language allows you to create database and table structures, perform \\nbasic data management chores (add, delete, and modify), and perform complex que-ries designed to transform the raw data into useful information. Moreover, a database language must perform such basic functions with minimal user effort, and its com-mand structure and syntax must be easy to learn. Finally, it must be portable; that is, it must conform to some basic standard so a person does not have to relearn the basics when moving from one RDBMS to another. SQL meets those ideal database language requirements well.\\nSQL functions fit into two broad categories:\\n•\\n It is a data definition language (DDL). SQL includes commands to create database objects such as tables, indexes, and views, as well as commands to define access rights to those database objects. Some common data definition commands you will learn are listed in Table 7.1.\\n•\\n It is a data manipulation language (DML). SQL includes commands to insert, update, delete, and retrieve data within the database tables. The data manipulation commands you will learn in this chapter are listed in Table 7.2.\\nTABLE 7.1\\nSQL DATA DEFINITION COMMANDS\\nCOMMAND OR OPTION DESCRIPTION\\nCREATE SCHEMA AUTHORIZATION Creates a database schema\\nCREATE TABLE Creates a new table in the user’s database schema\\nNOT NULL Ensures that a column will not have null values\\nUNIQUE Ensures that a column will not have duplicate values\\nPRIMARY KEY Defines a primary key for a table\\nFOREIGN KEY Defines a foreign key for a table\\nDEFAULT Defines a default value for a column (when no value is given)\\nCHECK Validates data in an attribute\\nCREATE INDEX Creates an index for a table\\nCREATE VIEW Creates a dynamic subset of rows and columns from one or more tables  \\n(see Chapter 8, Advanced SQL)\\nALTER TABLE Modifies a table’s definition (adds, modifies, or deletes attributes or constraints)\\nCREATE TABLE AS Creates a new table based on a query in the user’s database schema\\nDROP TABLE Permanently deletes a table (and its data)\\nDROP INDEX Permanently deletes an index\\nDROP VIEW Permanently deletes a view\\nSQL is relatively easy to learn. Its basic command set has a vocabulary of fewer than \\n100 words. Better yet, SQL is a nonprocedural language: you merely command what  is to \\nbe done; you do not have to worry about how . For example, a single command creates the \\ncomplex table structures required to store and manipulate data successfully; end users and programmers do not need to know the physical data storage format or the complex activities that take place when a SQL command is executed.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='24f1692b-e9c3-4a32-ad95-09277b8575cd', embedding=None, metadata={'page_label': '248', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='248   Part 3    Advanced Design and Implementation\\nThe American National Standards Institute (ANSI) prescribes a standard SQL. The \\nANSI SQL standards are also accepted by the International Organization for Standard-\\nization (ISO), a consortium composed of national standards bodies of more than 150 countries. Although adherence to the ANSI/ISO SQL standard is usually required in commercial and government contract database specifications, many RDBMS vendors add their own special enhancements. Consequently, it is seldom possible to move a SQL-based application from one RDBMS to another without making some changes.\\nHowever, even though there are several different SQL “dialects, ” their differences are \\nminor. Whether you use Oracle, Microsoft SQL Server, MySQL, IBM’s DB2, Microsoft  Access, or any other well-established RDBMS, a software manual should be sufficient to get you up to speed if you know the material presented in this chapter.\\nAt the heart of SQL is the query. In Chapter 1, Database Systems, you learned that a \\nquery is a spur-of-the-moment question. Actually, in the SQL environment, the word query  covers both questions and actions. Most SQL queries are used to answer questions TABLE 7.2\\nSQL DATA MANIPULATION COMMANDS\\nCOMMAND OR OPTION DESCRIPTION\\nINSERT Inserts row(s) into a table\\nSELECT Selects attributes from rows in one or more tables or views\\nWHERE Restricts the selection of rows based on a conditional expression\\nGROUP BY Groups the selected rows based on one or more attributes\\nHAVING Restricts the selection of grouped rows based on a condition\\nORDER BY Orders the selected rows based on one or more attributes\\nUPDATE Modifies an attribute’s values in one or more table’s rows\\nDELETE Deletes one or more rows from a table\\nCOMMIT Permanently saves data changes\\nROLLBACK Restores data to its original values\\nComparison operators\\n=, <, >, <=, >=, <>, != Used in conditional expressions\\nLogical operatorsAND/OR/NOT Used in conditional expressions\\nSpecial operators Used in conditional expressions\\nBETWEEN Checks whether an attribute value is within a range\\nIS NULL Checks whether an attribute value is null\\nLIKE Checks whether an attribute value matches a given string pattern\\nIN Checks whether an attribute value matches any value within a value list\\nEXISTS Checks whether a subquery returns any rows\\nDISTINCT Limits values to unique values\\nAggregate functions Used with SELECT to return mathematical summaries on columns\\nCOUNT Returns the number of rows with non-null values for a given column\\nMIN Returns the minimum attribute value found in a given column\\nMAX Returns the maximum attribute value found in a given column\\nSUM Returns the sum of all values for a given column\\nAVG Returns the average of all values for a given column\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b343e64f-0b71-4c05-93ad-123bc495401e', embedding=None, metadata={'page_label': '249', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    249\\nsuch as these: “What products currently held in inventory are priced over $100, and what \\nis the quantity on hand for each of those products?” or “How many employees have been \\nhired since January 1, 2016, by each of the company’s departments?” However, many \\nSQL queries are used to perform actions such as adding or deleting table rows or chang -\\ning attribute values within tables. Still other SQL queries create new tables or indexes. In \\nshort, for a DBMS, a query is simply a SQL statement that must be executed. However, \\nbefore you can use SQL to query a database, you must define the database environment \\nfor SQL with its data definition commands.\\n7-2 Data Definition Commands\\nBefore you examine the SQL syntax for creating and defining tables and other elements, \\nfirst examine a simple database model and the database tables that form the basis for the \\nmany SQL examples you will explore in this chapter.\\n7-2a  The Database Model\\nA simple database composed of the following tables is used to illustrate the SQL \\n commands in this chapter: CUSTOMER, INVOICE, LINE, PRODUCT, and VENDOR. \\nThis database model is shown in Figure 7.1.\\nThe database model in Figure 7.1 reflects the following business rules:\\n• A customer may generate many invoices. Each invoice is generated by one customer.\\n• An invoice contains one or more invoice lines. Each invoice line is associated with \\none invoice.\\n• Each invoice line references one product. A product may be found in many invoice \\nlines. (Y ou can sell more than one hammer to more than one customer.)The database model in \\nFigure 7.1 is implemented \\nin the Microsoft Access \\nCh07_SaleCo database, \\nwhich is available at \\nwww.cengagebrain.com . \\n(This database contains a \\nfew additional tables that \\nare not reflected in Figure \\n7.1. These tables are used \\nfor discussion purposes \\nonly.) Online \\nContent\\nFIGURE 7.1  THE DATABASE MODEL  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a843cf36-f3aa-4fc3-8765-bb8446f0b6e9', embedding=None, metadata={'page_label': '250', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='250   Part 3     Advanced Design and Implementation\\nFIGURE 7.2  THE VENDOR AND PRODUCT TABLES  \\nTable name: VENDOR\\nTable name: PRODUCTDatabase name: Ch07_SaleCo\\n• A vendor may supply many products. Some vendors do not yet supply products. For \\nexample, a vendor list may include potential  vendors.\\n• If a product is vendor-supplied, it is supplied by only a single vendor.\\n• Some products are not supplied by a vendor. For example, some products may be \\nproduced in-house or bought on the open market.\\nAs you can see in Figure 7.1, the database model contains many tables. However, to \\nillustrate the initial set of data definition commands, the focus of attention will be the \\nPRODUCT and VENDOR tables. Y ou will have the opportunity to use the remaining \\ntables later in this chapter and in the Problems section.\\nTo give you a point of reference for understanding the effect of the SQL queries, the con -\\ntents of the PRODUCT and VENDOR tables are listed in Figure 7.2. In the tables, note the \\nfollowing features, which correspond to the business rules reflected in the ERD shown in \\nFigure 7.1:\\n• The VENDOR table contains vendors who are not referenced in the PRODUCT \\ntable. Database designers note that possibility by saying that PRODUCT is optional \\nto VENDOR; a vendor may exist without a reference to a product. Y ou examined such \\noptional relationships in detail in Chapter 4, Entity Relationship (ER) Modeling.\\n• Existing V_CODE values in the PRODUCT table must (and do) have a match in the \\nVENDOR table to ensure referential integrity.\\n• A few products are supplied factory-direct, a few are made in-house, and a few may \\nhave been bought in a warehouse sale. In other words, a product is not necessarily \\nsupplied by a vendor. Therefore, VENDOR is optional to PRODUCT.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b26c9f6-fb28-456c-9fef-c994b5fc40d8', embedding=None, metadata={'page_label': '251', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    251\\nA few of the conditions just described were made for the sake of illustrating specific \\nSQL features. For example, null V_CODE values were used in the PRODUCT table to \\nillustrate how you can track such nulls using SQL.\\n7-2b  Creating The Database\\nBefore you can use a new RDBMS, you must complete two tasks: create the database structure and create the tables that will hold the end-user data. To complete the first task, the RDBMS creates the physical files that will hold the database. When you create a new database, the RDBMS automatically creates the data dictionary tables in which to store the metadata and creates a default database administrator. Creating the physical files that will hold the database means interacting with the operating system and the file systems supported by the operating system. Therefore, creating the database structure is the one feature that tends to differ substantially from one RDBMS to another. However, it is \\n relatively easy to create a database structure, regardless of which RDBMS you use.\\nIf you use Microsoft Access, creating the database is simple: start Access, click the \\nFILE tab, click New in the left pane, and then click Blank desktop database in the right pane. Specify the folder in which you want to store the database, and then name the database. However, if you work in a database environment typically used by larger orga-nizations, you will probably use an enterprise RDBMS such as Oracle, MS SQL Server, MySQL, or DB2. Given their security requirements and greater complexity, creating a\\xa0database with these products is a more elaborate process. (See Appendix N, Creating a New Database Using Oracle 11g, for specific instructions to create a database structure in Oracle.)\\nWith the exception of creating the database, most RDBMS vendors use SQL that devi-\\nates little from the ANSI standard SQL. For example, most RDBMSs require each SQL command to end with a semicolon. However, some SQL implementations do not use a\\xa0semicolon. Important syntax differences among implementations will be highlighted in the Note boxes in this chapter.\\nIf you are using an enterprise RDBMS, you must be authenticated by the RDBMS \\nbefore you can start creating tables. Authentication is the process the DBMS uses to verify that only registered users access the database. To be authenticated, you must log on to the RDBMS using a user ID and a password created by the database administrator. In an enterprise RDBMS, every user ID is associated with a database schema.\\n7-2c  The Database Schema\\nIn the SQL environment, a schema is a logical group of database objects—such as tables and indexes—that are related to each other. Usually, the schema belongs to a single user or application. A single database can hold multiple schemas that belong to different users or applications. Schemas are useful in that they group tables by owner (or function) and enforce a first level of security by allowing each user to see only the tables that belong to that user.\\nANSI SQL standards define a command to create a database schema:\\nCREATE SCHEMA AUTHORIZATION {creator};\\nTherefore, if the creator is JONES, the following command is used:\\nCREATE SCHEMA AUTHORIZATION JONES;\\nMost enterprise RDBMSs support that command. However, the command is \\nseldom used directly—that is, from the command line. (When a user is created, authentication\\nThe process through which a DBMS verifies that only registered users can access the database.\\nschema\\nA logical grouping of database objects, such as tables, indexes, views, and queries, that are related to each other. Usually, a schema belongs to a single user or application.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc32dad8-c242-4748-b0df-51c83cfc293e', embedding=None, metadata={'page_label': '252', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='252   Part 3    Advanced Design and Implementation\\nthe DBMS automatically assigns a schema to that user.) When the DBMS is  used, \\nthe CREATE SCHEMA AUTHORIZATION command must be issued by the user \\nwho owns the schema. That is, if you log on as JONES, you can only use CREATE SCHEMA AUTHORIZATION JONES.\\nFor most RDBMSs, the CREATE SCHEMA AUTHORIZATION command is \\noptional, which is why this chapter focuses on the ANSI SQL commands required to create and manipulate tables.\\n7-2d  Data Types\\nIn the data dictionary in Table 7.3, note the data types selected. Keep in mind that data-type selection is usually dictated by the nature and intended use of the data. For example:\\n•\\n P_PRICE clearly requires some kind of numeric data type; defining it as a character \\nfield is not acceptable.\\n• Just as clearly, a vendor name is an obvious candidate for a character data type. For example, V ARCHAR(35) fits well because vendor names are variable-length character strings, and in this case, such strings may be up to 35 characters long.\\n•\\n At first glance, it might seem logical to select a numeric data type for V_AREACODE because it contains only digits. However, adding and subtracting area codes does not yield meaningful results. Therefore, selecting a character data type is more appro-priate. This is true for many common attributes found in business data models. For example, even though zip codes contain all digits, they must be defined as character data because some zip codes begin with the digit zero (0), and a numeric data type would cause the leading zero to be dropped.\\n•\\n U.S. state abbreviations are always two characters, so CHAR(2) is a logical choice.\\n• Selecting P_INDATE to be a (Julian) DATE field rather than a character field is desir -\\nable because Julian dates allow you to make simple date comparisons and perform date arithmetic. For instance, if you have used DATE fields, you can determine the number of days between dates.\\nIf you use DATE fields, you can also determine a future date using a simple command. \\nFor example, you can determine the date that is 60 days from a given P_INDATE by using P_INDATE + 60 in most DBMSs. MySQL requires a function for adding dates. For example, the AddDate() function used in “ AddDate(P_INDATE, 60)” determines the date that is 60 days from the P_INDATE. Or, you can use the RDBMS’s system date—SYSDATE in Oracle, SYSDATE() or NOW() in MySQL, GETDATE() in MS SQL Server, and Date() in Access—to answer questions such as “What will be the date 60 days from today?” For example, you might use SYSDATE + 60 in Oracle, AddDate(SYSDATE(), 60) in MySQL, GETDATE() + 60 in MS SQL Server, or Date() + 60 in Access.\\nOracle uses DATE data types to store complete dates, that is, a date and time. Access uses Date/Time as the data type to store these types of values. MySQL and MS SQL Server use the DATE data type to store only dates without a time component. Stor -\\ning a complete date with time component in MySQL or MS SQL Server requires the  \\nDATETIME data type.Note\\nDate arithmetic capability is particularly useful in billing. Perhaps you want your sys-\\ntem to start charging interest on a customer balance 60 days after the invoice is gener -\\nated. Such simple date arithmetic would be impossible if you used a character data type.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='11d7f927-d38b-46c3-97d2-10db44f60677', embedding=None, metadata={'page_label': '253', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    253TABLE 7.3\\nDATA DICTIONARY FOR THE CH07_SALECO DATABASE\\nTABLE NAME ATTRIBUTE \\nNAMECONTENTS TYPE FORMAT RANGE REQUIRED PK OR FK FK REFERENCED \\nTABLE\\nPRODUCT P_CODE Product code VARCHAR(10) XXXXXXXXXX NA Y PK\\nP_DESCRIPT Product \\ndescriptionVARCHAR(35) Xxxxxxxxxxxx NA Y\\nP_INDATE Stocking date DATE DD-MON-YYYY NA Y\\nP_QOH Units available SMALLINT #### 0–9999 Y\\nP_MIN Minimum units SMALLINT #### 0–9999 Y\\nP_PRICE Product price NUMBER(8,2) ####.## 0.00–9999.00 Y\\nP_DISCOUNT Discount rate NUMBER(5,2) 0.## 0.00–0.20 Y\\nV_CODE Vendor code INTEGER ### 100–999 FK VENDOR\\nVENDOR V_CODE Vendor code INTEGER ##### 1000–9999 Y PK\\nV_NAME Vendor name VARCHAR(35) Xxxxxxxxxxxxxx NA Y\\nV_CONTACT Contact person VARCHAR(25) Xxxxxxxxxxxxxx NA Y\\nV_AREACODE Area code CHAR(3) 999 NA Y\\nV_PHONE Phone number CHAR(8) 999–9999 NA Y\\nV_STATE State CHAR(2) XX NA Y\\nV_ORDER Previous order CHAR(1) X Y or N Y\\nFK = Foreign key\\nPK = Primary key\\nCHAR  = Fixed-length character data, 1 to 255 characters\\nVARCHAR  = Variable-length character data, 1 to 2,000 characters. VARCHAR is automatically converted to VARCHAR2 in Oracle.\\nNUMBER  =  Numeric data. NUMBER(9,2) is used to specify numbers that have two decimal places and are up to nine digits long, including the decimal places. Some RDBMSs permit the use of a MONEY or a CURRENCY data type.\\nNUMERIC\\n = Numeric data. DBMSs that do not support the NUMBER data type typically use NUMERIC instead.\\nINT = Integer values only. INT is automatically converted to NUMBER in Oracle.\\nSMALLINT  = Small integer values only. SMALLINT is automatically converted to NUMBER in Oracle.\\nDATE formats vary. Commonly accepted formats are DD-MON-YYYY, DD-MON-YY, MM/DD/YYYY, and MM/DD/YY.\\n*Not all the ranges shown here will be illustrated in this chapter. However, you can use these constraints to practice writing your own.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='605a5ce7-62b3-48c2-8be8-7344bfe4405e', embedding=None, metadata={'page_label': '254', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"254   Part 3    Advanced Design and Implementation\\nData-type selection sometimes requires professional judgment. For example, you \\nmust make a decision about the V_CODE’s data type as follows:\\n• If you want the computer to generate new vendor codes by adding 1 to the largest \\nrecorded vendor code, you must classify V_CODE as a numeric attribute. (Y ou can-not perform mathematical procedures on character data.) The designation INTEGER will ensure that only the counting numbers (integers) can be used. Most SQL imple-mentations also permit the use of SMALLINT for integer values up to six digits.\\n•\\n If you do not want to perform mathematical procedures based on V_CODE, you should classify it as a character attribute, even though it is composed entirely of num-bers. When there is no need to perform mathematical procedures on the attribute, store it as a character attribute.\\nThe first option is used to demonstrate the SQL procedures in this chapter.When you define the attribute’s data type, you must pay close attention to the expected use \\nof the attributes for sorting and data-retrieval purposes. For example, in a real estate application, an attribute that represents the numbers of bathrooms in a home (H_BATH_NUM) could be assigned the CHAR(3) data type because the application will probably not do any addition, multiplication, or division with the number of bathrooms. Based on the CHAR(3) data-type definition, valid H_BATH_NUM values would be '2','1','2.5','10'. However, this data-type deci-sion creates potential problems. For example, if an application sorts the homes by number of bathrooms, a query would “see” the value '10' as less than '2', which is clearly incorrect. So, you must consider the expected use of the data to properly define the attribute data type.\\nThe data dictionary in Table 7.3 contains only a few of the data types supported by \\nSQL. For teaching purposes, the selection of data types is limited to ensure that almost any RDBMS can be used to implement the examples. If your RDBMS is fully compliant with ANSI SQL, it will support many more data types than those shown in Table 7.4. Also, many RDBMSs support data types beyond the ones specified in ANSI SQL.\\nTABLE 7.4\\nSOME COMMON SQL DATA TYPES\\nDATA TYPE FORMAT COMMENTS\\nNumeric NUMBER(L,D)  or  NUMERIC(L,D)The declaration NUMBER(7,2) or NUMERIC(7,2) indicates that numbers will be stored with two decimal places and may be up to seven digits long, including the sign and the decimal place (for example, 12.32 or −134.99).\\nINTEGER May be abbreviated as INT. Integers are (whole) counting numbers, so they cannot \\nbe used if you want to store numbers that require decimal places.\\nSMALLINT Like INTEGER but limited to integer values up to six digits. If your integer values are \\nrelatively small, use SMALLINT instead of INT.\\nDECIMAL(L,D) Like the NUMBER specification, but the storage length is a minimum specification. \\nThat is, greater lengths are acceptable, but smaller ones are not. DECIMAL(9,2), DECIMAL(9), and DECIMAL are all acceptable.\\nCharacter CHAR(L) Fixed-length character data for up to 255 characters. If you store strings that are \\nnot as long as the CHAR parameter value, the remaining spaces are left unused. Therefore, if you specify CHAR(25), strings such as Smith and Katzenjammer are each stored as 25 characters. However, a U.S. area code is always three digits long, so CHAR(3) would be appropriate if you wanted to store such codes.\\nVARCHAR(L) or VARCHAR2(L)Variable-length character data. The designation VARCHAR2(25) or VARCHAR(25) will let you store characters up to 25 characters long. However, unlike CHAR, VARCHAR will not leave unused spaces. Oracle automatically converts VARCHAR to VARCHAR2.\\nDate DATE Stores dates in the Julian date format.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='adc8d6f9-9202-43ab-ab66-03266389aa96', embedding=None, metadata={'page_label': '255', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    255\\nIn addition to the data types shown in Table 7.4, SQL supports several other data \\ntypes, including TIME, TIMESTAMP , REAL, DOUBLE, and FLOAT, and intervals, such \\nas INTERV AL DAY TO HOUR. Many RDBMSs have also expanded the list to include other types of data, such as LOGICAL, CURRENCY , and AutoNumber (Access). How-ever, because this chapter is designed to introduce the basics of SQL, the discussion is limited to the data types summarized in Table 7.4.\\n7-2e  Creating Table Structures\\nNow you are ready to implement the PRODUCT and VENDOR table structures with the help of SQL, using the CREATE TABLE syntax shown next.\\nCREATE TABLE tablename  (\\n   column1 data type [constraint ] [,\\n   column2 data type [constraint ] ] [,\\n   PRIMARY KEY (column1 [, column2 ]) ] [,\\n   FOREIGN KEY (column1 [, column2 ]) REFERENCES tablename ] [,\\n   CONSTRAINT constraint  ] );\\nTo make the SQL code more readable, most SQL programmers use one line per col-\\numn (attribute) definition. In addition, spaces are used to line up the attribute character -\\nistics and constraints. Finally, both table and attribute names are fully capitalized. Those conventions are used in the following examples that create VENDOR and PRODUCT tables and subsequent tables throughout the book.All the SQL commands used in this chapter are located in script files at www.cengagebrain.com. You can copy and paste the SQL commands into your SQL program. Script files are provided for Oracle, MS SQL Server, and MySQL users.Online \\nContent\\nSQL Syntax\\nSyntax notation for SQL commands used in this book:\\nCAPITALS Required SQL command keywordsitalics A parameter provided by the end user (generally required)\\n{a | b | ..} A mandatory parameter; use one option from the list separated by |[……] An optional parameter—anything inside square brackets is optionalTablename The name of a table\\nColumn The name of an attribute in a table\\ndata type A valid data-type definition\\nconstraint A valid constraint definition\\ncondition A valid conditional expression (evaluates to true or false)\\ncolumnlist One or more column names or expressions separated by commas\\ntablelist One or more table names separated by commas\\nconditionlist One or more conditional expressions separated by logical operators\\nexpression A simple value (such as 76 or Married) or a formula (such as P_PRICE − 10)Note\\nCREATE TABLE\\nA SQL command \\nthat creates a table’s structures using the characteristics and attributes given.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c80e0e0-9d89-4f18-9a0b-f3d79b02d08b', embedding=None, metadata={'page_label': '256', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='256   Part 3    Advanced Design and Implementation\\nCREATE TABLE VENDOR (\\nV_CODE INTEGER NOT NULL UNIQUE,\\nV_NAME V ARCHAR(35) NOT NULL,\\nV_CONTACT V ARCHAR(25) NOT NULL,\\nV_AREACODE CHAR(3) NOT NULL,\\nV_PHONE CHAR(8) NOT NULL,\\nV_STATE CHAR(2) NOT NULL,\\nV_ORDER CHAR(1) NOT NULL,\\nPRIMARY KEY (V_CODE));\\nCREATE TABLE PRODUCT (\\nP_CODE V ARCHAR(10) NOT NULL UNIQUE,\\nP_DESCRIPT V ARCHAR(35) NOT NULL,P_INDATE DATE NOT NULL,\\nP_QOH SMALLINT NOT NULL,P_MIN SMALLINT NOT NULL,P_PRICE NUMBER(8,2) NOT NULL,P_DISCOUNT NUMBER(5,2) NOT NULL,V_CODE INTEGER,\\nPRIMARY KEY (P_CODE),FOREIGN KEY (V_CODE) REFERENCES VENDOR ON UPDATE CASCADE);\\n• Because the PRODUCT table contains a foreign key that references the VENDOR table, \\ncreate the VENDOR table first. (In fact, the “M” side of a relationship always references the “1” side. Therefore, in a 1:M relationship, you must always create the table for the “1” side first.)\\n• If your RDBMS does not support the VARCHAR2 and FCHAR format, use CHAR.\\n• Oracle accepts the VARCHAR data type and automatically converts it to VARCHAR2.\\n• If your RDBMS does not support SINT or SMALLINT, use INTEGER or INT. If INTEGER is not supported, use NUMBER (Oracle or Access) or NUMERIC (MS SQL Server or MySQL).\\n• If you use Access, you can use the NUMBER data type, but you cannot use the number delimiters at the SQL level. For example, using NUMBER(8,2) to indicate numbers with up to eight digits with two digits to the right of the decimal place is fine in Oracle, but you cannot use it in Access—you must use NUMBER without the delimiters.\\n• If your RDBMS does not support primary and foreign key designations or the UNIQUE specification, delete them from the SQL code shown here.\\n• If you use the PRIMARY KEY designation in Oracle, you do not need the NOT NULL and UNIQUE specifications.\\n• The ON UPDATE CASCADE clause is part of the ANSI standard, but it may not be \\n supported by your RDBMS. In that case, delete the ON UPDATE CASCADE clause.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c7231163-db1b-4555-9768-05c79bddf15e', embedding=None, metadata={'page_label': '257', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    257\\nAs you examine the preceding SQL table-creating command sequences, note the \\n following features:\\n• The NOT NULL specifications for the attributes ensure that a data entry will be made. \\nWhen it is crucial to have the data available, the NOT NULL specification will not allow the end user to leave the attribute empty (with no data entry at all). Because this specification is made at the table level and stored in the data dictionary, appli-cation programs can use this information to create the data dictionary validation automatically.\\n•\\n The UNIQUE specification creates a unique index in the respective attribute. Use it to avoid having duplicated values in a column.\\n•\\n The primary key attributes contain both a NOT NULL and UNIQUE specification, which enforce the entity integrity requirements. If the NOT NULL and UNIQUE specifications are not supported, use PRIMARY KEY without the specifications. (For\\xa0example, if you designate the PK in MS Access, the NOT NULL and UNIQUE specifications are automatically assumed and are not spelled out.)\\n•\\n The entire table definition is enclosed in parentheses. A comma is used to separate each table element definition (attributes, primary key, and foreign key).\\nNote to MySQL Users\\nMySQL was originally designed to handle very rapid retrieval of data. To improve retrieval speed, the developers sacrificed many features that ensure data integrity. As MySQL has become more robust, many of those features, such as referential integrity, have been added. To provide developers with options for database behavior, MySQL still supports “\\n nontransaction-safe” tables that do not enable some of the features for data integrity, as \\nwell as “transaction-safe” tables that do. MySQL storage engines allow the developer to specify which type of tables to use. MySQL defaults to the MyISAM storage engine, which produces nontransaction-safe tables. The InnoDB storage engine produces \\n transaction-safe \\ntables. The storage engine is specified at the end of the CREATE TABLE command as shown below:\\nCREATE TABLE PRODUCT (\\nP_CODE VARCHAR(10) NOT NULL UNIQUE,\\nP_DESCRIPT VARCHAR(35) NOT NULL,P_INDATE DATE NOT NULL,\\nP_QOH SMALLINT NOT NULL,\\nP_MIN SMALLINT NOT NULL,\\nP_PRICE NUMBER(8,2) NOT NULL,\\nP_DISCOUNT NUMBER(5,2) NOT NULL,V_CODE INTEGER,\\nPRIMARY KEY (P_CODE),FOREIGN KEY (V_CODE) REFERENCES VENDOR (V_CODE) ON UPDATE CASCADE);;\\nTransaction-safe tables provide improved support for data integrity, implementation \\nof\\xa0 database transactions and transaction logs (as discussed in Chapter 10, Transaction \\nManagement and Concurrency Control), and improved backup and recovery options.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7b6b5c63-7c40-457b-a355-acc41374576d', embedding=None, metadata={'page_label': '258', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='258   Part 3    Advanced Design and Implementation\\n• The ON UPDATE CASCADE specification ensures that if you make a change in any \\nVENDOR’s V_CODE that change is automatically applied to all foreign key references throughout the system to ensure that referential integrity is maintained. (Although the ON UPDATE CASCADE clause is part of the ANSI standard, some RDBMSs, such as Oracle, do not support it. If your RDBMS does not support the clause, delete it from the code shown here.)\\n•\\n An RDBMS automatically enforces referential integrity for foreign keys. That is, you cannot have an invalid entry in the foreign key column; at the same time, you cannot delete a vendor row as long as a product row references that vendor.\\n•\\n The command sequence ends with a semicolon. (Remember that your RDBMS may require you to omit the semicolon.)\\nIf you are working with a composite primary key, all of the primary key’s attributes are contained within the parentheses and are separated with commas. For example, the LINE table in Figure 7.1 has a primary key that consists of the two attributes INV_NUMBER and LINE_NUMBER. Therefore, you would define the primary key by typing the following:\\nPRIMARY KEY (INV_NUMBER, LINE_NUMBER),\\nThe order of the primary key components is important because the indexing starts with \\nthe first mentioned attribute, then proceeds with the next attribute, and so on. In this \\nexample, the line numbers would be ordered within each of the invoice numbers:\\nINV_NUMBER LINE_NUMBER\\n1001 1\\n1001 2\\n1002 1\\n1003 1\\n1003 2Note\\nNote About Column Names\\nDo not use mathematical symbols such as +, −, and / in your column names; instead, use an \\nunderscore to separate words, if necessary. For example, PER-NUM might generate an error message, but PER_NUM is acceptable. Also, do not use reserved words. \\nReserved words  \\nare words used by SQL to perform specific functions. For example, in some RDBMSs, the column name INITIAL will generate the message “invalid column name. ”Notereserved words\\nWords used by a system that cannot be used for any other purpose. For example, in Oracle SQL, the word INITIAL cannot be used to name tables or columns.\\nNote to Oracle Users\\nWhen you press Enter after typing each line, a line number is automatically generated as long as you do not type a semicolon before pressing Enter. For example, Oracle’s execution of the CREATE TABLE command will look like the following:Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0cba8b05-e4cd-4aa3-9f09-a3dbd5ab1ba8', embedding=None, metadata={'page_label': '259', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    259\\n7-2f  SQL Constraints\\nIn Chapter 3, The Relational Database Model, you learned that adherence to rules for \\nentity integrity and referential integrity is crucial in a relational database environment. Fortunately, most SQL implementations support both integrity rules. Entity integrity is enforced automatically when the primary key is specified in the CREATE TABLE com-mand sequence. For example, you can create the VENDOR table structure and set the stage for the enforcement of entity integrity rules by using the following:\\nPRIMARY KEY (V_CODE)\\nIn the PRODUCT table’s CREATE TABLE sequence, note that referential integrity \\nhas been enforced by specifying the following in the PRODUCT table:FOREIGN KEY (V_CODE) REFERENCES VENDOR ON UPDATE CASCADE\\nCREATE TABLE PRODUCT (\\n2 P_CODE VARCHAR2(10)\\n3 CONSTRAINT PRODUCT_P_CODE_PK PRIMARY KEY,4 P_DESCRIPT VARCHAR2(35) NOT NULL,\\n5 P_INDATE DATE NOT NULL,\\n6 P_QOH NUMBER NOT NULL,\\n7 P_MIN NUMBER NOT NULL,\\n8 P_PRICE NUMBER(8,2) NOT NULL,\\n9 P_DISCOUNT NUMBER(5,2) NOT NULL,\\n10 V_CODE NUMBER,\\n11 CONSTRAINT PRODUCT_V_CODE_FK12 FOREIGN KEY V_CODE REFERENCES VENDOR\\n13 ;\\nIn the preceding SQL command sequence, note the following:\\n• The attribute definition for P_CODE starts in line 2 and ends with a comma at the end \\nof line 3.\\n• The CONSTRAINT clause (line 3) allows you to define and name a constraint in Oracle. You can name the constraint to meet your own naming conventions. In this case, the constraint was named PRODUCT_P_CODE_PK.\\n• Examples of constraints are NOT NULL, UNIQUE, PRIMARY KEY, FOREIGN KEY, and CHECK. Additional details about constraints are explained as follows.\\n• To define a PRIMARY KEY constraint, you could also use the following syntax: P_CODE VARCHAR2(10) PRIMARY KEY.\\n• In this case, Oracle would automatically name the constraint.\\n• Lines 11 and 12 define a FOREIGN KEY constraint named PRODUCT_V_CODE_FK for the attribute V_CODE. The CONSTRAINT clause is generally used at the end of the CREATE TABLE command sequence.\\n• If you do not name the constraints yourself, Oracle will automatically assign a name. Unfor -\\ntunately, the Oracle-assigned name makes sense only to Oracle, so you will have a difficult time deciphering it later. You should assign a name that makes sense to human beings!\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='de5ad8fa-f3e0-4c37-bcdb-67e6bc110083', embedding=None, metadata={'page_label': '260', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='260   Part 3    Advanced Design and Implementation\\nThe foreign key constraint definition ensures that:\\n• Y ou cannot delete a vendor from the VENDOR table if at least one product row \\nreferences that vendor. This is the default behavior for the treatment of foreign keys.\\n•\\n On the other hand, if a change is made in an existing VENDOR table’s V_CODE, that change must be reflected automatically in any PRODUCT table V_CODE reference (ON UPDATE CASCADE). That restriction makes it impossible for a V_CODE value to exist in the PRODUCT table if it points to a nonexistent \\n VENDOR table V_CODE value. In other words, the ON UPDATE CASCADE specification ensures the preservation of referential integrity. (Oracle does not support ON UPDATE CASCADE.)\\nIn general, ANSI SQL permits the use of ON DELETE and ON UPDATE clauses to \\ncover CASCADE, SET NULL, or SET DEFAULT.\\nBesides the PRIMARY KEY and FOREIGN KEY constraints, the ANSI SQL standard \\nalso defines the following constraints:\\n•\\n The NOT NULL constraint ensures that a column does not accept nulls.\\n• The UNIQUE constraint ensures that all values in a column are unique.\\n• The DEFAULT constraint assigns a value to an attribute when a new row is added to \\na\\xa0table. The end user may, of course, enter a value other than the default value.\\n• The CHECK constraint is used to validate data when an attribute value is entered. The\\xa0CHECK constraint does precisely what its name suggests: it checks to see that a\\xa0specified condition exists. Examples of such constraints include the following:\\n –The minimum order value must be at least 10.\\n –The date must be after April 15, 2016.\\nIf the CHECK constraint is met for the specified attribute (that is, the condition is true), the data is accepted for that attribute. If the condition is found to be false, an error message is generated and the data is not accepted.Online \\nContent\\nFor a more detailed dis-\\ncussion of the options for using the ON DELETE and ON UPDATE clauses, see Appendix D, Con-verting the ER Model into a \\n Database Structure, \\n Section D.2, General Rules Governing Relation\\n ships \\nAmong Tables. Appendix D is available at www.\\n \\ncengagebrain.com.\\nNote about Referential Constraint Actions\\nThe support for the referential constraint’s actions varies from product to product. For\\xa0example:\\n• MySQL requires the InnoDB storage engine to enforce referential integrity.\\n• MS Access, SQL Server, MySQL, and Oracle support ON DELETE CASCADE.\\n• MS Access, MySQL, and SQL Server support ON UPDATE CASCADE.\\n• Oracle does not support ON UPDATE CASCADE.\\n• Oracle and MySQL support SET NULL.\\n• MS Access and SQL Server do not support SET NULL.\\n• Refer to your product manuals for additional information on referential constraints.\\nWhile MS Access does not support ON DELETE CASCADE or ON UPDATE CASCADE at \\nthe SQL command-line level, it does support them through the relationship window inter -\\nface. In fact, whenever you try to establish a relationship between two tables in Access, the \\nrelationship window interface will automatically pop up.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ad595bb-a210-4bd0-889d-56d6de908d63', embedding=None, metadata={'page_label': '261', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    261\\nNote that the CREATE TABLE command lets you define constraints in two different \\nplaces:\\n• When you create the column definition (known as a column constraint )\\n• When you use the CONSTRAINT keyword (known as a table constraint )\\nA column constraint applies to just one column; a table constraint may apply to many col-\\numns. Those constraints are supported at varying levels of compliance by enterprise RDBMSs.\\nIn this chapter, Oracle is used to illustrate SQL constraints. For example, note that the \\nfollowing SQL command sequence uses the DEFAULT and CHECK constraints to define \\nthe table named CUSTOMER.\\nCREATE TABLE CUSTOMER (\\nCUS_CODE NUMBER PRIMARY KEY ,CUS_LNAME V ARCHAR(15) NOT NULL,CUS_FNAME V ARCHAR(15) NOT NULL,CUS_INITIAL CHAR(1),CUS_AREACODE CHAR(3) DEFAULT '615' NOT NULL\\nCHECK(CUS_AREACODE IN \\n('615','713','931')),\\nCUS_PHONE CHAR(8) NOT NULL,\\nCUS_BALANCE NUMBER(9,2) DEFAULT 0.00,CONSTRAINT CUS_UI1 UNIQUE (CUS_LNAME, CUS_FNAME));\\nIn this case, the CUS_AREACODE attribute is assigned a default value of '615'. There-\\nfore, if a new CUSTOMER table row is added and the end user makes no entry for the \\narea code, the '615' value will be recorded. Also, the CHECK condition restricts the val-ues for the customer’s area code to 615, 713, and 931; any other values will be rejected.\\nIt is important to note that the DEFAULT value applies only when new rows are added \\nto a table, and then only when no value is entered for the customer’s area code. (The default value is not used when the table is modified.) In contrast, the CHECK condition is vali-dated whether a customer row is added or modified . However, while the CHECK condition \\nmay include any valid expression, it applies only to the attributes in the table being checked. If you want to check for conditions that include attributes in other tables, you must use triggers. (See Chapter 8, Advanced SQL.) Finally, the last line of the CREATE TABLE com -\\nmand sequence creates a unique index constraint (named CUS_UI1) on the customer’s last\\xa0name and first name. The index will prevent the entry of two customers with the same last name and first name. (This index merely illustrates the process. Clearly, it should be possible to have more than one person named John Smith in the CUSTOMER table.)\\nNote to MS Access and MySQL Users\\nMS Access does not accept the DEFAULT or CHECK constraints. However, MS Access will accept the CONSTRAINT CUS_UI1 UNIQUE (CUS_LNAME, CUS_FNAME) line and create the unique index.\\nMySQL will allow CHECK constraints in the table definition for compatibility, but it does \\nnot enforce them. MySQL does allow DEFAULT constraints, but the DEFAULT value cannot be a function. Therefore, it is not possible to set the default value for a date field to be the current date using SYSDATE() or NOW() because they are both functions.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='133cf5f0-9eb4-43a8-8a24-76a465bdd500', embedding=None, metadata={'page_label': '262', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"262   Part 3    Advanced Design and Implementation\\nIn the following SQL command to create the INVOICE table, the DEFAULT con-\\nstraint assigns a default date to a new invoice, and the CHECK constraint validates that \\nthe invoice date is greater than January 1, 2016.\\nCREATE TABLE INVOICE (\\nINV_NUMBER NUMBER PRIMARY KEY ,CUS_CODE NUMBER NOT NULL REFERENCES CUSTOMER(CUS_CODE),\\nINV_DATE DATE DEFAULT SYSDATE NOT NULL,\\nCONSTRAINT INV_CK1 CHECK (INV_DATE > TO_DATE('01-JAN-2016', \\n'DD-MON-YYYY')));\\nIn this case, notice the following:\\n•\\n The CUS_CODE attribute definition contains REFERENCES CUSTOMER (CUS_CODE) to indicate that the CUS_CODE is a foreign key. This is another way to define a foreign key.\\n•\\n The DEFAULT constraint uses the SYSDATE special function. This function always returns today’s date.\\n•\\n The invoice date (INV_DATE) attribute is automatically given today’s date (returned by SYSDATE) when a new row is added and no value is given for the attribute.\\n•\\n A CHECK constraint is used to validate that the invoice date is greater than 'January 1, 2016'. When comparing a date to a manually entered date in a CHECK clause, Oracle requires the use of the TO_DATE function. The TO_DATE function takes two parameters: the literal date and the date format used.\\nThe final SQL command sequence creates the LINE table. The LINE table has a com-\\nposite primary key (INV_NUMBER, LINE_NUMBER) and uses a UNIQUE constraint in INV_NUMBER and P_CODE to ensure that the same product is not ordered twice in the same invoice.\\nCREATE TABLE LINE (\\nINV_NUMBER NUMBER NOT NULL,LINE_NUMBER NUMBER(2,0) NOT NULL,P_CODE V ARCHAR(10) NOT NULL,\\nLINE_UNITS NUMBER(9,2) DEFAULT 0.00 NOT NULL,LINE_PRICE NUMBER(9,2) DEFAULT 0.00 NOT NULL,PRIMARY KEY (INV_NUMBER, LINE_NUMBER),FOREIGN KEY (INV_NUMBER) REFERENCES INVOICE ON DELETE CASCADE,FOREIGN KEY (P_CODE) REFERENCES PRODUCT(P_CODE),CONSTRAINT LINE_UI1 UNIQUE(INV_NUMBER, P_CODE));\\nIn the creation of the LINE table, note that a UNIQUE constraint is added to prevent the \\nduplication of an invoice line. A UNIQUE constraint is enforced through the creation of a \\nunique index. Also note that the ON DELETE CASCADE foreign key enforces referential integrity. The use of ON DELETE CASCADE is recommended for weak entities to ensure that the deletion of a row in the strong entity automatically triggers the deletion of the cor -\\nresponding rows in the dependent weak entity. In that case, the deletion of an INVOICE row will automatically delete all of the LINE rows related to the invoice. In the following section, you will learn more about indexes and how to use SQL commands to create them.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a590b9d1-fe4a-4214-9925-2af00fe9ca7f', embedding=None, metadata={'page_label': '263', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    263\\n7-2g  SQL Indexes\\nY ou learned in Chapter 3 that indexes can be used to improve the efficiency of searches \\nand to avoid duplicate column values. In the previous section, you saw how to declare unique indexes on selected attributes when the table is created. In fact, when you declare a primary key, the DBMS automatically creates a unique index. Even with this feature, you often need additional indexes. The ability to create indexes quickly and efficiently is important. Using the CREATE INDEX command, SQL indexes can be created on the basis of any selected attribute. The syntax is:\\nCREATE [UNIQUE]INDEX indexname  ON tablename (column1  [, column2 ])\\nFor example, based on the attribute P_INDATE stored in the PRODUCT table, the \\nfollowing command creates an index named P_INDATEX:CREATE INDEX P_INDATEX ON PRODUCT(P_INDATE);\\nSQL does not let you write over an existing index without warning you first, thus pre-\\nserving the index structure within the data dictionary. Using the UNIQUE index qual-\\nifier, you can even create an index that prevents you from using a value that has been used before. Such a feature is especially useful when the index attribute is a candidate key whose values must not be duplicated:\\nCREATE UNIQUE INDEX P_CODEX ON PRODUCT(P_CODE);\\nIf you now try to enter a duplicate P_CODE value, SQL produces the error mes-\\nsage “duplicate value in index. ” Many RDBMSs, including Access, automatically create \\na\\xa0unique index on the PK attribute(s) when you declare the PK.\\nA common practice is to create an index on any field that is used as a search key, in \\ncomparison operations in a conditional expression, or when you want to list rows in a specific order. For example, if you want to create a report of all products by vendor, it would be useful to create an index on the V_CODE attribute in the PRODUCT table. Remember that a vendor can supply many products. Therefore, you should not create a UNIQUE index in this case. Better yet, to make the search as efficient as possible, using a composite index is recommended.\\nUnique composite indexes are often used to prevent data duplication. For example, \\nconsider the case illustrated in Table 7.5, in which required employee test scores are stored. (An employee can take a test only once on a given date.) Given the structure of Table 7.5, the PK is EMP_NUM + TEST_NUM. The third test entry for employee 111 meets entity integrity requirements—the combination 111,3 is unique—yet the WEA test entry is clearly duplicated.\\nCREATE INDEX\\nA SQL command that creates indexes on the basis of a selected attribute or attributes.\\nTABLE 7.5\\nA DUPLICATED TEST RECORD\\nEMP_NUM TEST_NUM TEST_CODE TEST_DATE TEST_SCORE\\n110 1 WEA 15-Jan-2016 93\\n110 2 WEA 12-Jan-2016 87\\n111 1 HAZ 14-Dec-2015 91\\n111 2 WEA 18-Feb-2016 95\\n111 3 WEA 18-Feb-2016 95\\n112 1 CHEM 17-Aug-2015 91\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f0245d9-01a8-44f3-9aff-b837a1350d5e', embedding=None, metadata={'page_label': '264', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"264   Part 3    Advanced Design and Implementation\\nSuch duplication could have been avoided through the use of a unique composite \\nindex, using the attributes EMP_NUM, TEST_CODE, and TEST_DATE:\\nCREATE UNIQUE INDEX EMP_TESTDEX ON TEST(EMP_NUM, TEST_CODE, \\nTEST_DATE);\\nBy default, all indexes produce results that are listed in ascending order, but you can \\ncreate an index that yields output in descending order. For example, if you routinely print a report that lists all products ordered by price from highest to lowest, you could create an index named PROD_PRICEX by typing:\\nCREATE INDEX PROD_PRICEX ON PRODUCT(P_PRICE DESC);\\nTo delete an index, use the DROP INDEX command:\\nDROP INDEX indexname\\nFor example, if you want to eliminate the PROD_PRICEX index, type:\\nDROP INDEX PROD_PRICEX;\\nAfter creating the tables and some indexes, you are ready to start entering data. The \\nfollowing sections use two tables (VENDOR and PRODUCT) to demonstrate most of \\nthe data manipulation commands.\\n7-3 Data Manipulation Commands\\nIn this section, you will learn how to use the basic SQL data manipulation commands INSERT, SELECT, COMMIT, UPDATE, ROLLBACK, and DELETE.\\n7-3a  Adding Table Rows\\nSQL requires the use of the INSERT command to enter data into a table. The INSERT command’s basic syntax looks like this:\\nINSERT INTO tablename  V ALUES (value1 , value2 , …, valuen )\\nBecause the PRODUCT table uses its V_CODE to reference the VENDOR table’s \\nV_CODE, an integrity violation will occur if the VENDOR table V_CODE values do \\nnot yet exist. Therefore, you need to enter the VENDOR rows before the PRODUCT rows. Given the VENDOR table structure defined earlier and the sample VENDOR data shown in Figure 7.2, you would enter the first two data rows as follows:\\nINSERT INTO VENDOR\\n  V ALUES (21225,'Bryson, Inc.','Smithson','615','223-3234','TN','Y');\\nINSERT INTO VENDOR\\n  V ALUES (21226,'Superloo, Inc.','Flushing','904','215-8995','FL','N');\\nand so on, until all of the VENDOR table records have been entered.\\n(To see the contents of the VENDOR table, use the SELECT * FROM VENDOR; \\ncommand.)\\nThe PRODUCT table rows would be entered in the same fashion, using the PROD-\\nUCT data shown in Figure 7.2. For example, the first two data rows would be entered as \\nfollows, pressing Enter at the end of each line:DROP INDEX\\nA SQL command used to delete database objects such as tables, views, indexes, and users.\\nINSERT\\nA SQL command that allows the insertion of one or more data rows into a table using a subquery.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0d0d740a-0218-41cc-994a-bb64cf3e9d20', embedding=None, metadata={'page_label': '265', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    265\\nINSERT INTO PRODUCT\\n  V ALUES ('11QER/31','Power painter, 15 psi., 3-nozzle','03-Nov-15',8,5,109.99,0.00,25595);\\nINSERT INTO PRODUCT\\n   V ALUES ('13-Q2/P2','7.25-in. pwr. saw blade','13-Dec-15',32,15,14.99, 0.05, \\n21344);\\n(To see the contents of the PRODUCT table, use the SELECT * FROM PRODUCT; \\ncommand.)\\nIn the preceding data-entry lines, observe that:\\n• The row contents are entered between parentheses. Note that the first character after V ALUES \\nis a parenthesis and that the last character in the command sequence is also a parenthesis.\\n• Character (string) and date values must be entered between apostrophes ( ’ ).\\n• Numerical entries are not  enclosed in apostrophes.\\n• Attribute entries are separated by commas.\\n• A value is required for each column in the table.\\nThis version of the INSERT command adds one table row at a time.\\nInserting Rows with Null Attributes  Thus far, you have entered rows in which all of \\nthe attribute values are specified. But what do you do if a product does not have a vendor or if you do not yet know the vendor code? In those cases, you would want to leave the vendor code null. To enter a null, use the following syntax:\\nINSERT INTO PRODUCT\\n  V ALUES ('BRT-345','Titanium drill bit','18-Oct-15', 75, 10, 4.50, 0.06, NULL);\\nIncidentally, note that the NULL entry is accepted only because the V_CODE  attribute \\nis optional—the NOT NULL declaration was not used in the CREATE TABLE statement \\nfor this attribute.\\nInserting Rows with Optional Attributes  Sometimes, more than one attribute \\nis optional. Rather than declaring each attribute as NULL in the INSERT command, you can indicate just the attributes that have required values. Y ou do that by listing the attribute names inside parentheses after the table name. For the purpose of this exam-ple, assume that the only required attributes for the PRODUCT table are P_CODE and P_DESCRIPT:\\nINSERT INTO PRODUCT(P_CODE, P_DESCRIPT) V ALUES ('BRT-345','Titanium \\ndrill bit');\\nDate entry is a function of the date format expected by the DBMS. For example, March 25, 2016, might be shown as 25-Mar-2016 in Access and Oracle, 2016-03-25 in MySQL, or it might be displayed in other presentation formats in another RDBMS. MS Access requires the use of # delimiters when performing any computations or comparisons based on date attributes, as in P_INDATE >= #25-Mar-16#. Date data and the functions for manipulating it in various DBMS products is discussed in more detail in Chapter 8.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd2b9d74-1836-4b3e-8a40-f94141cb33bd', embedding=None, metadata={'page_label': '266', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='266   Part 3    Advanced Design and Implementation\\n7-3b  Saving Table Changes\\nAny changes made to the table contents are not saved on disk until you close the data-\\nbase, close the program you are using, or use the COMMIT command. If the database is open and a power outage or some other interruption occurs before you issue the \\n COMMIT command, your changes will be lost and only the original table contents will\\xa0be retained. The syntax for the COMMIT command is:\\nCOMMIT [WORK]\\nThe COMMIT command permanently saves all changes—such as rows added, attri-\\nbutes modified, and rows deleted—made to any table in the database. Therefore, if you \\nintend to make your changes to the PRODUCT table permanent, it is a good idea to save those changes by using the following command:\\nCOMMIT;\\nHowever, the COMMIT command’s purpose is not just to save changes. In fact, the \\nultimate purpose of the COMMIT and ROLLBACK commands (see Section 7-3e) is to \\nensure database update integrity in transaction management. (Y ou will see how such issues are addressed in Chapter 10, Transaction Management and Concurrency Control.)\\n7-3c  Listing Table Rows\\nThe SELECT command is used to list the contents of a table. The syntax of the SELECT \\ncommand is as follows:\\nSELECT   columnlist   FROM   tablename\\nThe SELECT clause of the query specifies the columns to be retrieved as a column \\nlist. The columnlist  represents one or more attributes, separated by commas. Y ou could \\nuse the asterisk ( * ) as a wildcard character to list all attributes. A wildcard character SELECT\\nA SQL command that \\nyields the values of all rows or a subset of rows in a table. The SELECT statement is used to retrieve data from tables.\\nwildcard character\\nA symbol that can be used as a general substitute for:  \\n(1) all columns in a table (*)  \\nwhen used in an attribute list of a SELECT statement or,  \\n(2) zero or more characters in a SQL LIKE clause condition ( % and _ ).COMMIT\\nThe SQL command that permanently saves data changes to a database.\\nNote to MS Access and MySQL Users\\nMS Access does not support the COMMIT command because it automatically saves changes after the execution of each SQL command. By default, MySQL also automatically commits changes with each command. However, if START TRANSACTION or BEGIN is placed at the beginning of a series of commands, MySQL will delay committing the commands until the COMMIT or ROLLBACK command is issued.Note\\nWhen inserting rows interactively, omitting the attribute list in the INSERT command is accept -\\nable if the programmer intends to provide a value for each attribute. However, if an INSERT com -\\nmand is embedded inside a program for later use, the attribute list should always be used, even \\nif the programmer provides a value for every attribute. The reason is that the structure of the database table may change over time. The programs that are created today become the leg -\\nacy systems of tomorrow. These applications may be expected to have a very long, useful life. If the structure of the table changes over time as new business requirements develop, an INSERT without an attribute list may inadvertently insert data into the wrong columns if the order of the columns in the table changes, or the INSERT command may generate an error because the command does not provide enough values if new columns are subsequently added to the table.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b652f7e0-f66d-45b2-a4de-909bd0c5440e', embedding=None, metadata={'page_label': '267', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    267\\nis a symbol that can be used as a general substitute for other characters or commands. \\nFor example, to list all attributes and all rows of the PRODUCT table, use the following:\\nSELECT * FROM PRODUCT;\\nThe FROM  clause of the query specifies the table or tables from which the data is to be \\nretrieved. Figure 7.3 shows the output generated by that command. (Figure 7.3 shows all of \\nthe rows in the PRODUCT table that serve as the basis for subsequent discussions. If you \\nentered only the PRODUCT table’s first two records, as shown in the preceding section, the \\noutput of the preceding SELECT command would show only the rows you entered. Don’t \\nworry about the difference between your SELECT output and the output shown in Figure \\n7.3. When you complete the work in this section, you will have created and populated your \\nVENDOR and PRODUCT tables with the correct rows for use in future sections.)\\nFROM\\nA SQL clause that \\nspecifies the table or \\ntables from which data is \\nto be retrieved.\\nYour listing might not be in the order shown in Figure 7.3. The listings shown in the figure \\nare the result of system-controlled primary-key-based index operations. You will learn later \\nhow to control the output so that it conforms to the order you have specified.Note\\nNote to Oracle Users\\nSome SQL implementations (such as Oracle’s) cut the attribute labels to fit the width of \\nthe column. However, Oracle lets you set the width of the display column to show the \\ncomplete attribute name. You can also change the display format, regardless of how the \\ndata is stored in the table. For example, if you want to display dollar symbols and commas \\nin the P_PRICE output, you can declare:\\nCOLUMN P_PRICE FORMAT $99,999.99\\nto change the output 12347.67 to $12,347.67.\\nIn the same manner, to display only the first 12 characters of the P_DESCRIPT attribute, \\nuse the following:\\nCOLUMN P_DESCRIPT FORMAT A12 TRUNCATENoteFIGURE 7.3  THE CONTENTS OF THE PRODUCT TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='16891aea-97f1-45d3-9fd8-a3c893df87f2', embedding=None, metadata={'page_label': '268', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"268   Part 3    Advanced Design and Implementation\\nAlthough SQL commands can be grouped together on a single line, complex com-\\nmand sequences are best shown on separate lines, with space between the SQL command \\nand the command’s components. Using that formatting convention makes it much easier to see the components of the SQL statements, which in turn makes it easy to trace the SQL logic and make corrections if necessary. The number of spaces used in the indention is up to you. For example, note the following format for a more complex statement:\\nSELECT P_CODE, P_DESCRIPT, P_INDATE, P_QOH, P_MIN, P_PRICE,  \\nP_DISCOUNT, V_CODE\\nFROM PRODUCT;\\nWhen you run a SELECT command on a table, the RDBMS returns a set of one or \\nmore rows that have the same characteristics as a relational table. In addition, the SELECT \\ncommand lists all rows from the table you specified in the FROM clause. This is a very important characteristic of SQL commands. By default, most SQL data manipulation com -\\nmands operate over an entire table (or relation), which is why SQL commands are said to be set-oriented commands. A SQL set-oriented command works over a set of rows. The set \\nmay include one or more columns and zero or more rows from one or more tables.\\nJust as with INSERT commands, omitting the column list by specifying “ * ” for all columns is acceptable when querying the database interactively. However, if the SELECT query is embedded in a program for later use, the column list should always be included even if every column in the table is being included in the result because the structure of the table might change over time. In real-world business applications, SELECT * commands embed-ded in programs are often considered bugs waiting to happen.Note\\n7-3d  Updating Table Rows\\nUse the UPDATE command to modify data in a table. The syntax for this command is as follows:\\nUPDATE tablename\\nSET columnname  = expression  [, columnname  = expression ]\\n[WHERE conditionlist  ];\\nFor example, if you want to change P_INDATE from December 13, 2015, to January \\n18, 2016, in the second row of the PRODUCT table (see Figure 7.3), use the primary key \\n(13-Q2/P2) to locate the correct row. Therefore, type:\\nUPDATE PRODUCT\\nSET P_INDATE = '18-JAN-2016'\\nWHERE P_CODE = '13-Q2/P2';\\nIf more than one attribute is to be updated in the row, separate the corrections with \\ncommas:\\nUPDATE PRODUCT\\nSET P_INDATE = '18-JAN-2016', P_PRICE = 17.99, P_MIN = 10\\nWHERE P_CODE = '13-Q2/P2';UPDATE\\nA SQL command that \\nallows attribute values to be changed in one or more rows of a table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f6445de7-364f-496f-b91a-54f09066899a', embedding=None, metadata={'page_label': '269', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    269\\nWhat would have happened if the previous UPDATE command had not included the \\nWHERE condition? The P_INDATE, P_PRICE, and P_MIN values would have been \\nchanged in all  rows of the PRODUCT table. Remember, the UPDATE command is a \\nset-oriented operator. Therefore, if you do not specify a WHERE condition, the UPDATE command will apply the changes to all  rows in the specified table.\\nConfirm the correction(s) by using the following SELECT command to check the \\nPRODUCT table’s listing:\\nSELECT * FROM PRODUCT;\\n7-3e  Restoring Table Contents\\nIf you have not yet used the COMMIT command to store the changes permanently in \\nthe database, you can restore the database to its previous condition with the ROLLBACK command. ROLLBACK undoes any changes since the last COMMIT command and brings all of the data back to the values that existed before the changes were made. To restore the data to its “prechange” condition, type:\\nROLLBACK;and then press Enter. Use the SELECT statement again to verify that the ROLLBACK \\nrestored the data to its original values.\\nCOMMIT and ROLLBACK work only with data manipulation commands that add, \\nmodify, or delete table rows. For example, assume that you perform these actions:\\n1.\\n CREATE a table called SALES.\\n2. INSERT 10 rows in the SALES table.\\n3. UPDATE two rows in the SALES table.\\n4. Execute the ROLLBACK command.\\nWill the SALES table be removed by the ROLLBACK command? No, the  ROLLBACK \\ncommand will undo only  the results of the INSERT and UPDATE commands. All \\ndata\\xa0definition commands (CREATE TABLE) are automatically committed to the data \\ndictionary and cannot be rolled back. The COMMIT and ROLLBACK commands are examined in greater detail in Chapter 10.\\nROLLBACK\\nA SQL command that restores the database table contents to the condition that existed after the last COMMIT statement.\\nDELETE\\nA SQL command that allows data rows to be deleted from a table.\\nNote to MS Access Users\\nMS Access does not support the ROLLBACK command.Note\\nSome RDBMSs, such as Oracle, automatically COMMIT data changes when issuing \\ndata definition commands. For example, if you had used the CREATE INDEX command after updating the two rows in the previous example, all previous changes would have been committed automatically; doing a ROLLBACK afterward would not have undone anything. Check your RDBMS manual to understand these subtle differences.\\n7-3f  Deleting Table Rows\\nIt is easy to delete a table row using the DELETE statement. The syntax is:\\nDELETE FROM tablename\\n[WHERE conditionlist  ];\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e0c81ad-9db5-4335-a54a-1dd7bbc00b9e', embedding=None, metadata={'page_label': '270', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"270   Part 3    Advanced Design and Implementation\\nFor example, if you want to delete the product you added earlier whose code \\n(P_CODE) is 'BRT-345', use the following command:\\nDELETE FROM PRODUCT\\nWHERE P_CODE = 'BRT-345';\\nIn this example, the primary key value lets SQL find the exact record to be deleted \\nfrom the PRODUCT table. However, deletions are not limited to a primary key match; \\nany attribute may be used. For example, in your PRODUCT table, you will see several products for which the P_MIN attribute is equal to 5. Use the following command to delete all rows from the PRODUCT table for which the P_MIN is equal to 5:\\nDELETE FROM PRODUCT\\nWHERE P_MIN = 5;\\nCheck the PRODUCT table’s contents again to verify that all products with P_MIN \\nequal to 5 have been deleted.\\nFinally, remember that DELETE is a set-oriented command, and that the WHERE \\ncondition is optional. Therefore, if you do not specify a WHERE condition, all  rows from \\nthe specified table will be deleted!\\nNote to MySQL Users\\nBy default MySQL is set for “safe mode” for updates and deletes. This means that users can-\\nnot update or delete rows from a table unless the UPDATE or DELETE command includes a WHERE clause that provides a value for the primary key. To disable safe mode temporarily, set the sql_safe_updates variable to 0. Safe mode can be re-enabled by setting the variable back to 1. For example, to complete the DELETE command shown above, the following sequence could be used:\\nSET SQL_SAFE_UPDATES = 0;DELETE FROM PRODUCT WHERE P_MIN = 5;SET SQL_SAFE_UPDATES = 1;\\nTo permanently disable safe mode, uncheck the safe mode option in MySQL \\n Workbench \\nunder the Edit → Preferences window.Note\\n7-3g  Inserting Table Rows with a Select Subquery\\nY ou learned in Section 7-3a how to use the INSERT statement to add rows to a table. \\nIn that section, you added rows one at a time. In this section, you will learn how to add multiple rows to a table, using another table as the source of the data. The syntax for the INSERT statement is:\\nINSERT INTO tablename\\n SELECT columnlist  FROM tablename ;\\nIn this case, the INSERT statement uses a SELECT subquery. A subquery, also \\nknown as a nested query or an inner query, is a query that is embedded (or nested) \\ninside another query. The inner query is always executed first by the RDBMS. Given subquery\\nA query that is embedded (or nested) inside another query. Also known as a nested query or an inner query.\\nnested query\\nIn SQL, a query that is embedded in another query. See subquery.\\ninner query\\nA query that is embedded or nested inside another query. Also known as a nested query or a subquery.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='023406ef-250e-463c-ac49-79014daebb40', embedding=None, metadata={'page_label': '271', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    271\\nthe previous SQL statement, the INSERT portion represents the outer query, and the \\nSELECT portion represents the subquery. Y ou can nest queries (place queries inside que-ries) many levels deep. In every case, the output of the inner query is used as the input for the outer (higher-level) query. In Chapter 8 you will learn more about the various types of subqueries.\\nThe values returned by the SELECT subquery should match the attributes and data \\ntypes of the table in the INSERT statement. If the table into which you are inserting rows has one date attribute, one number attribute, and one character attribute, the SELECT subquery should return one or more rows in which the first column has date values, the second column has number values, and the third column has character values.\\n7-4 SELECT  Queries\\nIn this section, you will learn how to fine-tune the SELECT command by adding restric-tions to the search criteria. When coupled with appropriate search conditions, SELECT is an incredibly powerful tool that enables you to transform data into information. For example, in the following sections, you will learn how to create queries that can answer questions such as these: “What products were supplied by a particular vendor?” , “Which products are priced below $10?” , and “How many products supplied by a given vendor were sold between January 5, 2016, and March 20, 2016?”\\n7-4a  Selecting Rows with Conditional Restrictions\\nY ou can select partial table contents by placing restrictions on the rows to be included in the output. Use the WHERE clause to add conditional restrictions to the SELECT state-ment that limit the rows returned by the query. The following syntax enables you to specify which rows to select:\\nSELECT columnlist\\nFROM tablelist\\n[WHERE conditionlist  ];\\nThe SELECT statement retrieves all rows that match the specified condition(s)—\\nalso known as the conditional criteria—you specified in the WHERE clause. The con-\\nditionlist  in the WHERE clause of the SELECT statement is represented by one or \\nmore conditional expressions, separated by logical operators. The WHERE clause is optional. If no rows match the specified criteria in the WHERE clause, you see a blank screen or a message that tells you no rows were retrieved. For example, consider the following query:\\nSELECT P_DESCRIPT, P_INDATE, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE V_CODE = 21344;\\nThis query returns the description, date, and price of products with a vendor code of \\n21344, as shown in Figure 7.4.\\nMS Access users can use the Access QBE (query by example) query generator. \\nAlthough the Access QBE generates its own “native” version of SQL, you can also elect \\nto type standard SQL in the Access SQL window, as shown at the bottom of Figure 7.5. The figure shows the Access QBE screen, the SQL window’s QBE-generated SQL, and the listing of the modified SQL.Before you execute the commands in the follow -\\ning sections, you must do the following:\\n• If you are using \\n Oracle, MySQL, or MS SQL Server, run the respective sqlintrod-binit.sql script file at www.cengagebrain.com  to create all \\ntables and load the data in the database.\\n• If you are using Access, copy the \\n original Ch07_SaleCo. mdb file from www.cengagebrain.com.Online \\nContent\\nWHERE\\n A SQL clause that adds \\nconditional restrictions to a SELECT statement that limit the rows returned by the query.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ebd123dc-3590-4fef-a869-4df8b794f3a1', embedding=None, metadata={'page_label': '272', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='272   Part 3     Advanced Design and Implementation\\nNumerous conditional restrictions can be placed on the selected table contents. For \\nexample, the comparison operators shown in Table 7.6 can be used to restrict output.\\nThe following example uses the “not equal to” operator:\\nSELECT P_DESCRIPT, P_QOH, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE V_CODE <> 21344;\\nThe output, shown in Figure 7.6, lists all of the rows for which the vendor code is not 21344.\\nNote to MS Access Users\\nThe MS Access QBE interface automatically designates the data source by using the table \\nname as a prefix. You will discover later that the table name prefix is used to avoid ambi -\\nguity when the same column name appears in multiple tables. For example, both the \\nVENDOR and PRODUCT tables contain the V_CODE attribute. Therefore, if both tables are \\nused (as they would be in a join), the source of the V_CODE attribute must be specified.NoteFIGURE 7.4   SELECTED PRODUCT TABLE ATTRIBUTES FOR  \\nVENDOR CODE 21344  \\nFIGURE 7.5  THE MICROSOFT ACCESS QBE AND ITS SQL  \\nMicrosoft Access-generated SQL User-entered SQLQuery view\\noptions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3e122054-35a0-4a1a-9062-334a25fb887f', embedding=None, metadata={'page_label': '273', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    273\\nNote that, in Figure 7.6, rows with nulls in the V_CODE column (see Figure 7.3) are \\nnot included in the SELECT command’s output.\\nFIGURE 7.6   PRODUCT TABLE ATTRIBUTES FOR VENDOR CODES OTHER \\nTHAN 21344  \\nTABLE 7.6\\nCOMPARISON OPERATORS\\nSYMBOL MEANING\\n= Equal to\\n< Less than\\n<= Less than or equal to\\n> Greater than\\n>= Greater than or equal to\\n<> or != Not equal to\\nThe following command sequence:\\nSELECT P_DESCRIPT, P_QOH, P_MIN, P_PRICE\\nFROM PRODUCT\\nWHERE P_PRICE <= 10;\\nyields the output shown in Figure 7.7.\\nFIGURE 7.7   SELECTED PRODUCT TABLE ATTRIBUTES WITH A P_PRICE \\nRESTRICTION  \\nUsing Comparison Operators on Character Attributes  Because computers \\n identify all characters by their numeric American Standard Code for Information \\n Interchange (ASCII) codes, comparison operators may even be used to place restrictions \\non  character-based attributes. Therefore, the command:\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27acf6e8-040e-4cd4-bbac-966f95822139', embedding=None, metadata={'page_label': '274', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"274   Part 3     Advanced Design and Implementation\\nString (character) comparisons are made from left to right. This left-to-right compari -\\nson is especially useful when attributes such as names are to be compared. For example, the \\nstring “ Ardmore” would be judged greater than  the string “ Aarenson” but less than  the string \\n“Brown”; such results may be used to generate alphabetical listings like those in a phone direc -\\ntory. If the characters 0−9 are stored as strings, the same left-to-right string comparisons can \\nlead to apparent anomalies. For example, the ASCII code for the character “5” is greater than  \\nthe ASCII code for the character “4, ” as expected. Y et, the same “5” will also be judged greater \\nthan  the string “44” because the first character in the string “44” is less than the string “5. ” For \\nthat reason, you may get some unexpected results from comparisons when dates or other \\nnumbers are stored in character format. For example, the left-to-right ASCII character com -\\nparison would force the conclusion that the date “01/01/2016” occurred before  “12/31/2015. ” \\nBecause the leftmost character “0” in “01/01/2016” is less than  the leftmost character “1” in \\n“12/31/2015, ” “01/01/2016” is less than  “12/31/2015. ” Naturally, if date strings are stored in a \\nyyyy/mm/dd format, the comparisons will yield appropriate results, but this is a nonstandard \\ndate presentation. Therefore, all current RDBMSs support date data types; you should use \\nthem. In addition, using date data types gives you the benefit of date arithmetic.\\nUsing Comparison Operators on Dates  Date procedures are often more soft -\\nware-specific than other SQL procedures. For example, the query to list all of the rows in \\nwhich the inventory stock dates occur on or after January 20, 2016, looks like this:\\nSELECT P_DESCRIPT, P_QOH, P_MIN, P_PRICE, P_INDATE\\nFROM PRODUCT\\nWHERE P_INDATE >= '20-Jan-2016';\\nRemember that MS Access users must use the # delimiters for dates. For example, \\nyou would use #20-Jan-16# in the preceding WHERE clause. The date-restricted out -\\nput is shown in Figure 7.9. In MySQL, the expected date format is yyyy-mm-dd, so the \\nWHERE clause would be written as:\\nWHERE P_INDATE >= '2016-01-20'\\nUsing Computed Columns and Column Aliases  Suppose that you want to deter -\\nmine the total value of each of the products currently held in inventory. Logically, that \\ndetermination requires the multiplication of each product’s quantity on hand by its \\n current price. Y ou can accomplish this task with the following command:FIGURE 7.8   SELECTED PRODUCT TABLE ATTRIBUTES: THE ASCII CODE \\nEFFECT  \\nSELECT P_CODE, P_DESCRIPT, P_QOH, P_MIN, P_PRICE\\nFROM PRODUCT\\nWHERE P_CODE < '1558-QW1';\\nwould be correct and would yield a list of all rows in which the P_CODE is alphabetically \\nless than 1558-QW1. (Because the ASCII code value for the letter B is greater than the \\nvalue of the letter A, it follows that A is less than B.) Therefore, the output will be gener -\\nated as shown in Figure 7.8.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0fcf0a56-8364-498d-aeaa-b0b02d815e91', embedding=None, metadata={'page_label': '275', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    275\\nSELECT P_DESCRIPT, P_QOH, P_PRICE, P_QOH * P_PRICE\\nFROM PRODUCT;\\nEntering the SQL command in Access generates the output shown in Figure 7.10.\\nSQL accepts any valid expressions (or formulas) in the computed columns. Such for -\\nmulas can contain any valid mathematical operators and functions that are applied to \\nattributes in any of the tables specified in the FROM clause of the SELECT statement. \\nNote also that Access automatically adds an Expr  label to all computed columns. (The \\nfirst computed column would be labeled Expr1; the second, Expr2; and so on.) Oracle \\nuses the actual formula text as the label for the computed column.\\nTo make the output more readable, the SQL standard permits the use of aliases for any \\ncolumn in a SELECT statement. An alias  is an alternate name given to a column or\\xa0table \\nin any SQL statement.\\nFor example, you can rewrite the previous SQL statement as follows:\\nSELECT P_DESCRIPT, P_QOH, P_PRICE, P_QOH * P_PRICE AS \\nTOTV ALUE\\nFROM PRODUCT;\\nThe output of the command is shown in Figure 7.11.\\nY ou could also use a computed column, an alias, and date arithmetic in a single query. \\nFor example, assume that you want to get a list of out-of-warranty products that have \\nbeen stored more than 90 days. In that case, the P_INDATE is at least 90 days less than \\nthe current (system) date. The MS Access version of this query is:\\nSELECT P_CODE, P_INDATE, DATE() - 90 AS CUTDATE\\nFROM PRODUCT\\nWHERE P_INDATE <= DATE() - 90;FIGURE 7.9  SELECTED PRODUCT TABLE ATTRIBUTES: DATE RESTRICTION  \\nalias\\nAn alternative name for a \\ncolumn or table in a SQL \\nstatement.FIGURE 7.10  SELECT STATEMENT WITH A COMPUTED COLUMN  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d87c3d85-9441-41ad-abd1-46bc1f294ce6', embedding=None, metadata={'page_label': '276', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='276   Part 3     Advanced Design and Implementation\\nThe Oracle version of the same query is shown here:\\nSELECT P_CODE, P_INDATE, SYSDATE - 90 AS CUTDATE\\nFROM PRODUCT\\nWHERE P_INDATE <= SYSDATE - 90;\\nNote that DATE() and SYSDATE are special functions that return the current date in MS \\nAccess and Oracle, respectively. Y ou can use the DATE() and SYSDATE functions anywhere \\na date literal is expected, such as in the value list of an INSERT statement, in an UPDATE \\nstatement when changing the value of a date attribute, or in a SELECT statement, as shown \\nhere. Of course, the previous query output would change based on the current date.\\nSuppose that a manager wants a list of all products, the dates they were received, and the \\nwarranty expiration date (90 days from receiving the product). To generate that list, type:\\nSELECT P_CODE, P_INDATE, P_INDATE + 90 AS EXPDATE\\nFROM PRODUCT;\\nNote that you can use all arithmetic operators with date attributes as well as with \\nnumeric attributes.\\n7-4b  Arithmetic Operators: The Rule of Precedence\\nAs you saw in the previous example, you can use arithmetic operators with table  attributes \\nin a column list or in a conditional expression. In fact, SQL commands are often used in \\nconjunction with the arithmetic operators shown in Table 7.7.FIGURE 7.11   SELECT STATEMENT WITH A COMPUTED COLUMN AND AN \\nALIAS  \\nTABLE 7.7\\nTHE ARITHMETIC OPERATORS\\nOPERATOR DESCRIPTION\\n+ Add\\n- Subtract\\n* Multiply\\n/ Divide\\n^ Raise to the power of (some applications use ** instead of ^)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8a17fd01-cc14-4db6-a22b-dee3bbd5343e', embedding=None, metadata={'page_label': '277', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    277\\nDo not confuse the multiplication symbol ( * ) with the wildcard symbol used by some SQL \\nimplementations, such as MS Access. The wildcard symbol is used only in string compari -\\nsons, while the multiplication symbol is used in conjunction with mathematical procedures.\\nAs you perform mathematical operations on attributes, remember the mathematical \\nrules of precedence. As the name suggests, the rules of precedence  are the rules that \\nestablish the order in which computations are completed. For example, note the order of \\nthe following computational sequence:\\n1. Perform operations within parentheses.\\n2. Perform power operations.\\n3. Perform multiplications and divisions.\\n4. Perform additions and subtractions.\\nThe application of the rules of precedence will tell you that 8 + 2 * 5 = 8 + 10 = 18, but (8 + 2) \\n* 5 = 10 * 5 = 50. Similarly, 4 + 5^2 * 3 = 4 + 25 * 3 = 79, but (4 + 5)^2 * 3 = 81 * 3 = 243, while \\nthe operation expressed by (4 + 5^2) * 3 yields the answer (4 + 25) * 3 = 29 * 3 = 87.\\n7-4c  Logical Operators: AND, OR, and NOT\\nIn the real world, a search of data normally involves multiple conditions. For exam -\\nple, when you are buying a new house, you look for a certain area, a certain number of \\nbedrooms, bathrooms, stories, and so on. In the same way, SQL allows you to include \\nmultiple conditions in a query through the use of logical operators. The logical operators \\nare AND, OR, and NOT. For example, if you want a list of the table contents for either \\nthe V_CODE = 21344 or the V_CODE = 24288, you can use the OR logical operator, as \\nin the following command sequence:\\nSELECT P_DESCRIPT, P_INDATE, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE V_CODE = 21344 OR V_CODE = 24288;\\nThis command generates the six rows shown in Figure 7.12 that match the logical \\nrestriction.rules of precedence\\nBasic algebraic rules \\nthat specify the order \\nin which operations \\nare performed. For \\nexample, operations \\nwithin parentheses are \\nexecuted first, so in the \\nequation 2 + (3 × 5), the \\nmultiplication portion is \\ncalculated first, making \\nthe correct answer 17.\\nOR\\nThe SQL logical operator \\nused to link multiple \\nconditional expressions \\nin a WHERE or HAVING \\nclause. It requires only \\none of the conditional \\nexpressions to be true.\\nAND\\nThe SQL logical operator \\nused to link multiple \\nconditional expressions \\nin a WHERE or HAVING \\nclause. It requires that all \\nconditional expressions \\nevaluate to true.FIGURE 7.12  SELECTED PRODUCT TABLE ATTRIBUTES: THE LOGICAL OR  \\nThe logical operator AND  has the same SQL syntax requirement as OR. The following \\ncommand generates a list of all rows for which P_PRICE is less than $50 and for which \\nP_INDATE is a date occurring after January 15, 2016:\\nSELECT P_DESCRIPT, P_INDATE, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE P_PRICE < 50\\nAND P_INDATE > '15-Jan-2016';\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6237755b-dc08-482e-84ff-eac670811b1f', embedding=None, metadata={'page_label': '278', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"278   Part 3     Advanced Design and Implementation\\nThis command produces the output shown in Figure 7.13.\\nFIGURE 7.13  SELECTED PRODUCT TABLE ATTRIBUTES: THE LOGICAL AND  \\nY ou can combine the logical OR with the logical AND to place further restrictions on \\nthe output. For example, suppose that you want a table listing for the following conditions:\\n• The P_INDATE is after January 15, 2016, and the P_PRICE is less than $50.\\n• Or the V_CODE is 24288.\\nThe required listing can be produced by using the following:\\nSELECT P_DESCRIPT, P_INDATE, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE (P_PRICE < 50 AND P_INDATE > '15-Jan-2016')\\nOR V_CODE = 24288;\\nNote the use of parentheses to combine logical restrictions. Where you place the \\nparentheses depends on how you want the logical restrictions to be executed. Conditions \\nlisted within parentheses are always executed first. The preceding query yields the output \\nshown in Figure 7.14.\\nNote that the three rows with the V_CODE = 24288 are included regardless of the \\nP_INDATE and P_PRICE entries for those rows.\\nThe use of the logical operators OR and AND can become quite complex when \\nnumerous restrictions are placed on the query. In fact, a specialty field in mathematics \\nknown as Boolean algebra  is dedicated to the use of logical operators.\\nThe logical operator NOT  is used to negate the result of a conditional expression. That \\nis, in SQL, all conditional expressions evaluate to true or false. If an expression is true, the \\nrow is selected; if an expression is false, the row is not selected. The NOT logical opera -\\ntor is typically used to find the rows that do not  match a certain condition. For example, \\nif\\xa0you want to see a listing of all rows for which the vendor code is not 21344, use the \\nfollowing command sequence:\\nSELECT *\\nFROM PRODUCT\\nWHERE NOT (V_CODE = 21344);FIGURE 7.14   SELECTED PRODUCT TABLE ATTRIBUTES: THE LOGICAL AND  \\nAND OR  \\nBoolean algebra\\nA branch of mathematics \\nthat uses the logical \\noperators OR, AND, and \\nNOT.\\nNOT\\nA SQL logical operator \\nthat negates a given \\npredicate.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4d7665c3-d571-4177-8b2e-889c3fc2bcdd', embedding=None, metadata={'page_label': '279', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    279\\nNote that the condition is enclosed in parentheses; that practice is optional, but it is \\nhighly recommended for clarity. The logical operator NOT can be combined with AND \\nand OR.\\n7-4d  Special Operators\\nANSI-standard SQL allows the use of special operators in conjunction with the WHERE clause. These special operators include:\\nBETWEEN: Used to check whether an attribute value is within a rangeIS NULL: Used to check whether an attribute value is nullLIKE: Used to check whether an attribute value matches a given string patternIN: Used to check whether an attribute value matches any value within a value listEXISTS: Used to check whether a subquery returns any rows\\nThe BETWEEN Special Operator  If you use software that implements a standard \\nSQL, the operator BETWEEN may be used to check whether an attribute value is within \\na range of values. For example, if you want to see a listing for all products whose prices are between  $50 and $100, use the following command sequence:\\nSELECT *\\nFROM PRODUCT\\nWHERE P_PRICE BETWEEN 50.00 AND 100.00;\\nIf your SQL version does not support the logical NOT, you can generate the required output \\nby using the following condition:\\nWHERE V_CODE <> 21344\\nIf your version of SQL does not support <>, use:\\nWHERE V_CODE != 21344Note\\nNote to Oracle Users\\nWhen using the BETWEEN special operator, always specify the lower-range value first. \\nThe\\xa0WHERE clause of the command above is interpreted as:\\nWHERE P_PRICE >= 50 AND P_PRICE <= 100\\nIf you list the higher-range value first, the DBMS will return an empty result set because \\nthe WHERE clause will be interpreted as:WHERE P_PRICE >= 100 and P_PRICE <= 50\\nClearly, no product can have a price that is both greater than 100 and simultaneously \\nless than 50, Therefore, no rows can possibly match the criteria.NoteBETWEEN\\nIn SQL, a special \\ncomparison operator used to check whether a value is within a range of specified values.\\nIS NULL\\nIn SQL, a comparison operator used to check whether an attribute has a value.\\nLIKE\\nIn SQL, a comparison operator used to check whether an attribute’s text value matches a specified string pattern.\\nIN\\nIn SQL, a comparison operator used to check whether a value is among a list of specified values.\\nEXISTS\\nIn SQL, a comparison operator that checks whether a subquery returns any rows.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f0f8b31c-4ca0-43f7-8e11-6210c28189a2', embedding=None, metadata={'page_label': '280', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"280   Part 3    Advanced Design and Implementation\\nIf your DBMS does not support BETWEEN, you can use:\\nSELECT *\\nFROM PRODUCT\\nWHERE P_PRICE => 50.00 AND P_PRICE <= 100.00;\\nThe IS NULL Special Operator  Standard SQL allows the use of IS NULL to check for \\na null attribute value. For example, suppose that you want to list all products that do not \\nhave a vendor assigned (V_CODE is null). Such a null entry could be found by using the following command sequence:\\nSELECT P_CODE, P_DESCRIPT, V_CODE\\nFROM PRODUCT\\nWHERE V_CODE IS NULL;\\nSimilarly, if you want to check a null date entry, the command sequence is:\\nSELECT P_CODE, P_DESCRIPT, P_INDATEFROM PRODUCT\\nWHERE P_INDATE IS NULL;\\nNote that SQL uses a special operator to test for nulls. Why? Couldn’t you just enter a \\ncondition such as “V_CODE = NULL ”? No. Technically, NULL is not a “value” the way \\nthe number 0 or the blank space is; instead, a NULL is a special property of an attribute that represents the absence of any value.\\nThe LIKE Special Operator  The LIKE special operator is used in conjunction with \\nwildcards to find patterns within string attributes. Standard SQL allows you to use the percent sign ( % ) and underscore ( _ ) wildcard characters to make matches when the entire string is not known:\\n•\\n % means any and all following  or preceding  characters are eligible. For example:\\n'J%' includes Johnson, Jones, Jernigan, July, and J-231Q.'Jo%' includes Johnson and Jones.'%n' includes Johnson and Jernigan.\\n•\\n _ means any one  character may be substituted for the underscore. For example:\\n'_23-456-6789' includes 123-456-6789, 223-456-6789, and 323-456-6789.\\n'_23-_56-678_' includes 123-156-6781, 123-256-6782, and 823-956-6788.'_o_es' includes Jones, Cones, Cokes, totes, and roles.\\nSome RDBMSs, such as Microsoft Access, use the wildcard characters * and ? instead of % \\nand _.Note\\nFor example, the following query would find all VENDOR rows for contacts whose \\nlast names begin with Smith .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='18f24b95-d647-422c-a105-e5b441818b0a', embedding=None, metadata={'page_label': '281', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    281\\nSELECT V_NAME, V_CONTACT, V_AREACODE, V_PHONE\\nFROM VENDOR\\nWHERE V_CONTACT LIKE 'Smith%';\\nIf you check the original VENDOR data in Figure 7.2 again, you’ll see that this SQL \\nquery yields three records: two Smiths and one Smithson.\\nKeep in mind that most SQL implementations yield case-sensitive searches. For exam-\\nple, Oracle will not yield a result that includes Jones  if you use the wildcard search delim-\\niter 'jo%' in a search for last names; Jones  begins with a capital J, and your wildcard search \\nstarts with a lowercase j. On the other hand, MS Access searches are not case sensitive.\\nFor example, suppose that you typed the following query in Oracle:\\nSELECT V_NAME, V_CONTACT, V_AREACODE, V_PHONEFROM VENDOR\\nWHERE V_CONTACT LIKE 'SMITH%';\\nNo rows will be returned because character-based queries may be case sensitive. That \\nis, an uppercase character has a different ASCII code than a lowercase character, causing \\nSMITH, Smith , and smith  to be evaluated as different (unequal) entries. Because the table \\ncontains no vendor whose last name begins with SMITH (all uppercase), the 'SMITH%' used in the query cannot be matched. Matches can be made only when the query entry is written exactly like the table entry.\\nSome RDBMSs, such as Microsoft Access, automatically make the necessary con-\\nversions to eliminate case sensitivity. Others, such as Oracle, provide a special UPPER function to convert both table and query character entries to uppercase. (The conversion is done in the computer’s memory only; the conversion has no effect on how the value is actually stored in the table.) So, if you want to avoid a no-match result based on case sensitivity, and if your RDBMS allows the use of the UPPER function, you can generate the same results by using the following query:\\nSELECT V_NAME, V_CONTACT, V_AREACODE, V_PHONE\\nFROM VENDOR\\nWHERE UPPER(V_CONTACT) LIKE 'SMITH%';\\nThe preceding query produces a list that includes all rows containing a last name \\nthat begins with Smith , regardless of uppercase or lowercase letter combinations such as \\nSmith , smith , and SMITH.\\nThe logical operators may be used in conjunction with the special operators. For \\ninstance, the following query:\\nSELECT V_NAME, V_CONTACT, V_AREACODE, V_PHONE\\nFROM VENDOR\\nWHERE V_CONTACT NOT LIKE 'Smith%';\\nwill yield an output of all vendors whose names do not start with Smith .\\nSuppose that you do not know whether a person’s name is spelled Johnson  or Johnsen. \\nThe wildcard character _ lets you find a match for either spelling. The proper search \\nwould be instituted by the following query:\\nSELECT *\\nFROM VENDOR\\nWHERE V_CONTACT LIKE 'Johns_n';\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7e2af0dd-6e82-44eb-bf3f-f5e60b971481', embedding=None, metadata={'page_label': '282', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"282   Part 3    Advanced Design and Implementation\\nThus, the wildcards allow you to make matches when only approximate spellings are \\nknown. Wildcard characters may be used in combinations. For example, the wildcard \\nsearch based on the string '_l%' can yield the strings “ Al” , “ Alton” , “Elgin” , “Blakeston” , “blank” , “bloated” , and “eligible” .\\nThe IN Special Operator  Many queries that would require the use of the logical OR \\ncan be more easily handled with the help of the special operator IN. For example, the following query:\\nSELECT *\\nFROM PRODUCT\\nWHERE V_CODE = 21344OR V_CODE = 24288;\\ncan be handled more efficiently with:\\nSELECT *\\nFROM PRODUCT\\nWHERE V_CODE IN (21344, 24288);\\nNote that the IN operator uses a value list. All of the values in the list must be of the \\nsame data type. Each of the values in the value list is compared to the attribute—in this \\ncase, V_CODE. If the V_CODE value matches any of the values in the list, the row is selected. In this example, the rows selected will be only those in which the V_CODE is\\xa0either 21344 or 24288.\\nIf the attribute used is of a character data type, the list values must be enclosed in \\nsingle quotation marks. For instance, if the V_CODE had been defined as CHAR(5) when\\xa0the table was created, the preceding query would have read:\\nSELECT *\\nFROM PRODUCT\\nWHERE V_CODE IN ('21344', '24288');\\nThe IN operator is especially valuable when it is used in conjunction with subqueries. \\nFor example, suppose that you want to list the V_CODE and V_NAME of only those \\nvendors who provide products. In that case, you could use a subquery within the IN operator to automatically generate the value list. The query would be:\\nSELECT V_CODE, V_NAME\\nFROM VENDOR\\nWHERE V_CODE IN (SELECT V_CODE FROM PRODUCT);\\nThe preceding query will be executed in two steps:\\n1.\\n The inner query or subquery will generate a list of V_CODE values from the PRODUCT \\ntables. Those V_CODE values represent the vendors who supply products.\\n2. The IN operator will compare the values generated by the subquery to the V_CODE values in the VENDOR table, and will select only the rows with matching values—that is, the vendors who provide products.\\nThe IN special operator will receive additional attention in Chapter 8, where you will \\nlearn more about subqueries.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='52011cb6-3e25-4c31-8d52-9ab0be266a7a', embedding=None, metadata={'page_label': '283', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    283\\nThe EXISTS Special Operator  The EXISTS special operator can be used whenever \\nthere is a requirement to execute a command based on the result of another query. That \\nis, if a subquery returns any rows, run the main query; otherwise, do not. For example, the following query will list all vendors, but only if there are products to order:\\nSELECT *\\nFROM VENDOR\\nWHERE EXISTS (SELECT * FROM PRODUCT WHERE P_QOH <= P_MIN);\\nThe EXISTS special operator is used in the following example to list all vendors, but \\nonly if there are products with the quantity on hand, and less than double the minimum \\nquantity:\\nSELECT *\\nFROM VENDOR\\nWHERE EXISTS (SELECT * FROM PRODUCT WHERE P_QOH < P_MIN * 2);\\nThe EXISTS special operator will receive additional attention in Chapter 8, where you \\nwill learn more about subqueries.\\n7-5 Additional Data Definition Commands\\nIn this section, you will learn how to change table structures by changing attribute char -\\nacteristics and by adding columns. Then you will learn how to make advanced data \\nupdates to the new columns. Finally, you will learn how to copy tables or parts of tables and how to delete tables.\\nAll changes in the table structure are made by using the ALTER TABLE command fol-\\nlowed by a keyword that produces the specific change you want to make. Three options are available: ADD, MODIFY , and DROP . Y ou use ADD to add a column, MODIFY to change column characteristics, and DROP to delete a column from a table. Most RDBMSs do not allow you to delete a column unless the column does not contain any values; otherwise, such an action might delete crucial data used by other tables. The basic syntax to add or modify columns is:\\nALTER TABLE tablename\\n   {ADD | MODIFY} ( columnname datatype  [ {ADD | MODIFY}  \\ncolumnname datatype ] );\\nThe ALTER TABLE command can also be used to add table constraints. In those \\ncases, the syntax would be:ALTER TABLE tablename\\n  ADD constraint  [ ADD constraint  ];\\nwhere constraint  refers to a constraint definition similar to those you learned in  \\nSection 7-2f.\\nY ou could also use the ALTER TABLE command to remove a column or table \\n constraint. The syntax would be as follows:ALTER TABLE tablename\\n   DROP {PRIMARY KEY | COLUMN columnname  | CONSTRAINT  \\nconstraintname  };ALTER TABLE\\nThe SQL command \\nused to make changes to table structure. When the command is followed by a keyword (ADD or MODIFY), it adds a column or changes column characteristics.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e377098-bee7-4f92-8838-5f27974d1675', embedding=None, metadata={'page_label': '284', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='284   Part 3    Advanced Design and Implementation\\nNotice that when removing a constraint, you need to specify it by name, which is one \\nreason you should always name constraints in your CREATE TABLE or ALTER TABLE \\nstatement.\\n7-5a  Changing a Column’s Data Type\\nUsing the ALTER syntax, the integer V_CODE in the PRODUCT table can be changed to a character V_CODE by using the following command:\\nALTER TABLE PRODUCT\\n  MODIFY (V_CODE CHAR(5));\\nSome RDBMSs, such as Oracle, do not let you change data types unless the column to be \\nchanged is empty. For example, if you want to change the V_CODE field from the cur -\\nrent number definition to a character definition, the preceding command will yield an \\nerror message because the V_CODE column already contains data. The error message is easily explained. Remember that the V_CODE in PRODUCT references the V_CODE in VENDOR. If you change the V_CODE data type, the data types do not match, and there is a referential integrity violation, which triggers the error message. If the V_CODE column does not contain data, the preceding command sequence will alter the table structure as expected (if the foreign key reference was not specified during the creation of the PRODUCT table).\\n7-5b  Changing a Column’s Data Characteristics\\nIf the column to be changed already contains data, you can make changes in the column’s characteristics if those changes do not alter the data type. For example, if you want to increase the width of the P_PRICE column to nine digits, use the following command:\\nALTER TABLE PRODUCT\\n  MODIFY (P_PRICE DECIMAL(9,2));\\nIf you now list the table contents, you can see that the column width of P_PRICE \\nhas\\xa0increased by one digit.\\nSome DBMSs impose limitations on when it is possible to change attribute charac -\\nteristics. For example, Oracle lets you increase (but not decrease) the size of a column \\nbecause an attribute modification will affect the integrity of the data in the database. In fact, some attribute changes can be made only when there is no data in any rows for the affected attribute.Note\\n7-5c  Adding a Column\\nY ou can alter an existing table by adding one or more columns. In the following example, you add the column named P_SALECODE to the PRODUCT table. (This column will be used later to determine whether goods that have been in inventory for a certain length of time should be placed on special sale.)\\nSuppose that you expect the P_SALECODE entries to be 1, 2, or 3. Because no arith-\\nmetic will be performed with the P_SALECODE, the P_SALECODE will be classified \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5e859f5e-6baf-4dec-9265-b4f6923a2db9', embedding=None, metadata={'page_label': '285', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    285\\nas a single-character attribute. Note the inclusion of all required information in the \\nfollowing ALTER command:\\nALTER TABLE PRODUCT\\n  ADD (P_SALECODE CHAR(1));\\nWhen adding a column, be careful not to include the NOT NULL clause for the new \\ncolumn. Doing so will cause an error message; if you add a new column to a table that \\nalready has rows, the existing rows will default to a value of null for the new column. Therefore, it is not possible to add the NOT NULL clause for this new column. (Of course, you can add the NOT NULL clause to the table structure after all the data for the new column has been entered and the column no longer contains nulls.)\\n7-5d  Dropping a Column\\nOccasionally, you might want to modify a table by deleting a column. Suppose that you want to delete the V_ORDER attribute from the VENDOR table. Y ou would use the following command:\\nALTER TABLE VENDOR\\n  DROP COLUMN V_ORDER;\\nAgain, some RDBMSs impose restrictions on attribute deletion. For example, you \\nmay not drop attributes that are involved in foreign key relationships, nor may you delete \\nan attribute if it is the only one in a table.\\n7-5e  Advanced Data Updates\\nTo make changes to data in the columns of existing rows, use the UPDATE command. Do not confuse the INSERT and UPDATE commands: INSERT creates new rows in the table, while UPDATE changes rows that already exist. For example, to enter the P_SALE-CODE value '2' in the fourth row, use the UPDATE command together with the primary key P_CODE '1546-QQ2'. Enter the value by using the following command sequence:\\nUPDATE PRODUCT\\nSET P_SALECODE = '2'\\nWHERE P_CODE = '1546-QQ2';\\nSubsequent data can be entered the same way, defining each entry location by its \\nprimary key (P_CODE) and its column location (P_SALECODE). For example, if you \\nwant to enter the P_SALECODE value '1' for the P_CODE values '2232/QWE' and '2232/QTY', you use:\\nUPDATE PRODUCT\\nSET P_SALECODE = '1'\\nWHERE P_CODE IN ('2232/QWE', '2232/QTY');\\nIf your RDBMS does not support IN, use the following command:\\nUPDATE PRODUCTSET P_SALECODE = '1'\\nWHERE P_CODE = '2232/QWE' OR P_CODE = '2232/QTY';If you are using the MS \\nAccess databases provided at www.cengagebrain.\\ncom , you can track each \\nof the updates in the following sections. For example, look at the cop -\\nies of the PRODUCT table in the Ch07_SaleCo data-base, one named PROD -\\nUCT_2 and one named PRODUCT_3. Each of the two copies includes the new P_SALECODE col-umn. If you want to see the cumulative effect of \\nall UPDATE commands, you can continue using the PRODUCT table with the P_SALECODE mod-ification and all of the changes you will make in the following sections. (You might even want to use both options, first to examine the individual effects of the update que -\\nries and then to examine the cumulative effects.)Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2cf65fe4-4dbb-4a78-9224-2297844e5d01', embedding=None, metadata={'page_label': '286', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"286   Part 3    Advanced Design and Implementation\\nY ou can check the results of your efforts by using the following commands:\\nSELECT P_CODE, P_DESCRIPT, P_INDATE, P_PRICE, P_SALECODE\\nFROM PRODUCT;\\nAlthough the UPDATE sequences just shown allow you to enter values into specified \\ntable cells, the process is very cumbersome. Fortunately, if a relationship can be estab-\\nlished between the entries and the existing columns, the relationship can be used to assign values to their appropriate slots. For example, suppose that you want to place sales codes into the table based on the P_INDATE using the following schedule:\\nP_INDATE P_SALECODE\\nbefore December 25, 2015 2\\nbetween January 16, 2016 and February 10, 2016 1\\nUsing the PRODUCT table, the following two command sequences make the \\n appropriate assignments:UPDATE PRODUCT\\nSET P_SALECODE = '2'\\nWHERE P_INDATE < '25-Dec-2015';UPDATE PRODUCTSET P_SALECODE = '1'\\nWHERE P_INDATE >= '16-Jan-2016' AND P_INDATE <='10-Feb-2016';\\nTo check the results of those two command sequences, use:\\nSELECT P_CODE, P_DESCRIPT, P_INDATE, P_PRICE, P_SALECODEFROM PRODUCT;\\nIf you have made all  of the updates shown in this section using Oracle, your PROD-\\nUCT table should look like Figure 7.15. Make sure that you issue a COMMIT statement \\nto save these changes.\\nThe arithmetic operators are particularly useful in data updates. For example, if the \\nquantity on hand in your PRODUCT table has dropped below the minimum desirable value, you will order more of the product. Suppose, for example, that you have ordered 20 units of product 2232/QWE. When the 20 units arrive, you will want to add them to inventory using the following commands:\\nUPDATE PRODUCT\\nSET P_QOH = P_QOH + 20\\nWHERE P_CODE = ’2232/QWE’;\\nIf you want to add 10 percent to the price for all products that have current prices \\nbelow $50, you can use:\\nUPDATE PRODUCT\\nSET P_PRICE = P_PRICE * 1.10\\nWHERE P_PRICE < 50.00;\\nIf you are using Oracle, issue a ROLLBACK command to undo the changes made by \\nthe last two UPDATE statements.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='17b01205-4c7f-4b33-bcc4-0ed8fab5b945', embedding=None, metadata={'page_label': '287', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    287\\n7-5f  Copying Parts of Tables\\nAs you will discover in later chapters on database design, sometimes it is necessary to \\nbreak up a table structure into several component parts (or smaller tables). Fortunately, SQL allows you to copy the contents of selected table columns so that the data need not be re-entered manually into the newly created table(s). For example, if you want to copy P_CODE, P_DESCRIPT, P_PRICE, and V_CODE from the PRODUCT table to a new table named PART, you create the PART table structure first, as follows:\\nCREATE TABLE PART(\\nPART_CODE CHAR(8),\\nPART_DESCRIPT CHAR(35),\\nPART_PRICE DECIMAL(8,2),\\nV_CODE INTEGER,\\nPRIMARY KEY (PART_CODE));\\nIf you fail to roll back the changes of the preceding UPDATE queries, the output of the \\n subsequent queries will not match the results shown in the figures. Therefore:\\n• If you are using Oracle, use the ROLLBACK command to restore the database to its \\n previous state.\\n• If you are using Access, copy the original Ch07_SaleCo.mdb file from www.cengage \\nbrain.com.NoteFIGURE 7.15   THE CUMULATIVE EFFECT OF THE MULTIPLE UPDATES IN THE PRODUCT TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e4b6832a-4344-46a1-ba14-c8212674d91c', embedding=None, metadata={'page_label': '288', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='288   Part 3     Advanced Design and Implementation\\nNote that the PART column names need not be identical to those of the original table and \\nthat the new table need not have the same number of columns as the original table. In this \\ncase, the first column in the PART table is PART_CODE, rather than the original P_CODE \\nin the PRODUCT table. Also, the PART table contains only four columns rather than the \\neight columns in the PRODUCT table. However, column characteristics must match; you \\ncannot copy a character-based attribute into a numeric structure, and vice versa.\\nNext, you need to add the rows to the new PART table, using the PRODUCT table \\nrows and the INSERT command you learned in Section 7–3g. The syntax is:\\nINSERT INTO target_tablename [(target_columnlist )]\\nSELECT source_columnlist\\nFROM source_tablename ;\\nNote that the target column list is required if the source column list does not match all \\nof the attribute names and characteristics of the target table (including the order of the \\ncolumns). Otherwise, you do not need to specify the target column list. In this example, \\nyou must specify the target column list in the following INSERT command because the \\ncolumn names of the target table are different:\\nINSERT INTO PART (PART_CODE, PART_DESCRIPT, PART_PRICE, V_CODE)\\nSELECT P_CODE, P_DESCRIPT, P_PRICE, V_CODE FROM \\nPRODUCT;\\nThe contents of the PART table can now be examined by using the following query \\nto\\xa0generate the new PART table’s contents, shown in Figure 7.16:\\nSELECT  * FROM PART;\\nFIGURE 7.16  PART TABLE ATTRIBUTES COPIED FROM THE PRODUCT TABLE  \\nSQL provides another way to rapidly create a new table based on selected columns and \\nrows of an existing table. In this case, the new table will copy the attribute names, data \\n characteristics, and rows of the original table. The Oracle version of the command is:\\nCREATE TABLE PART AS\\nSELECT     P_CODE AS PART_CODE, P_DESCRIPT AS PART_DESCRIPT,  \\nP_PRICE AS PART_PRICE, V_CODE\\nFROM      PRODUCT;\\nIf the PART table already exists, Oracle will not let you overwrite the existing table. \\nTo run this command, you must first delete the existing PART table. (See Section 7-5h.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9cffeada-dd35-467d-a923-c8ab222f0a71', embedding=None, metadata={'page_label': '289', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    289\\nThe MS Access version of this command is:\\nSELECT P_CODE AS PART_CODE, P_DESCRIPT AS PART_DESCRIPT, \\nP_PRICE AS PART_PRICE, V_CODE INTO PART\\nFROM PRODUCT;\\nIf the PART table already exists, MS Access will ask if you want to delete the existing \\ntable and continue with the creation of the new PART table.\\nThe SQL command just shown creates a new PART table with PART_CODE, PART_\\nDESCRIPT, PART_PRICE, and V_CODE columns. In addition, all of the data rows for \\nthe selected columns will be copied automatically. However, note that no entity integrity (primary key) or referential integrity (foreign key) rules are automatically applied to the new table . In the next section, you will learn how to define the PK to enforce entity integ-\\nrity and the FK to enforce referential integrity.\\n7-5g  Adding Primary and Foreign Key Designations\\nWhen you create a new table based on another table, the new table does not include integrity rules from the old table. In particular, there is no primary key. To define the primary key for the new PART table, use the following command:\\nALTER TABLE PART\\nADD PRIMARY KEY (PART_CODE);\\nSeveral other scenarios could leave you without entity and referential integrity. \\nFor example, you might have forgotten to define the primary and foreign keys when \\nyou created the original tables. Or, if you imported tables from a different database, you might have discovered that the importing procedure did not transfer the integrity rules. In any case, you can re-establish the integrity rules by using the ALTER com-mand. For example, if the PART table’s foreign key has not yet been designated, it can be designated by:\\nALTER TABLE PART\\nADD FOREIGN KEY (V_CODE) REFERENCES VENDOR;\\nAlternatively, if neither the PART table’s primary key nor its foreign key has been \\ndesignated, you can incorporate both changes at once:ALTER TABLE PART\\nADD PRIMARY KEY (PART_CODE)\\nADD FOREIGN KEY (V_CODE) REFERENCES VENDOR;\\nEven composite primary keys and multiple foreign keys can be designated in a single \\nSQL command. For example, if you want to enforce the integrity rules for the LINE table \\nshown in Figure 7.1, you can use:\\nALTER TABLE LINE\\nADD PRIMARY KEY (INV_NUMBER, LINE_NUMBER)\\nADD FOREIGN KEY (INV_NUMBER) REFERENCES INVOICE\\nADD FOREIGN KEY (P_CODE) REFERENCES PRODUCT;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3c3fce5-2fab-428d-b752-e8a42834aa4c', embedding=None, metadata={'page_label': '290', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='290   Part 3    Advanced Design and Implementation\\n7-5h  Deleting a Table from the Database\\nA table can be deleted from the database using the DROP TABLE command. For example, \\nyou can delete the PART table you just created with the following command:\\nDROP TABLE PART;\\nY ou can drop a table only if it is not the “one” side of any relationship. If you try \\nto\\xa0drop a table otherwise, the RDBMS will generate an error message indicating that a \\nforeign key integrity violation has occurred.\\n7-6 Additional SELECT  Query Keywords\\nOne of the most important advantages of SQL is its ability to produce complex free-form queries. The logical operators that were introduced earlier to update table contents work just as well in the query environment. In addition, SQL provides useful functions that count, find minimum and maximum values, calculate averages, and so on. Better yet, SQL allows the user to limit queries to only those entries that have no duplicates or entries whose duplicates can be grouped.\\n7-6a  Ordering a Listing\\nThe ORDER BY clause is especially useful when the listing order is important to you. The \\nsyntax is:\\nSELECT columnlist\\nFROM tablelist\\n[WHERE conditionlist  ]\\n[ORDER BY columnlist  [ASC | DESC] ];\\nAlthough you have the option of declaring the order type—ascending or descending—\\nthe default order is ascending. For example, if you want the contents of the PRODUCT \\ntable to be listed by P_PRICE in ascending order, use the following commands:\\nSELECT P_CODE, P_DESCRIPT, P_QOH, P_PRICE\\nFROM PRODUCT\\nORDER BY P_PRICE;\\nThe output is shown in Figure 7.17. Note that ORDER BY yields an ascending price \\nlisting.\\nComparing the listing in Figure 7.17 to the actual table contents shown earlier in \\nFigure 7.2, you will see that the lowest-priced product is listed first in Figure 7.17,  \\nfollowed by the next lowest-priced product, and so on. However, although ORDER BY \\nproduces a sorted output, the actual table contents are unaffected by the ORDER BY command.\\nTo produce the list in descending order, you would enter:\\nSELECT P_CODE, P_DESCRIPT, P_INDATE, P_PRICE\\nFROM PRODUCT\\nORDER BY P_PRICE DESC;DROP TABLE\\nA SQL command used to \\ndelete database objects such as tables, views, indexes, and users.\\nORDER BY\\nA SQL clause that is useful for ordering the output of a SELECT query (for example, in ascending or descending order).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f18f4521-52fe-45ff-8c9c-60501aef6655', embedding=None, metadata={'page_label': '291', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    291\\nOrdered listings are used frequently. For example, suppose that you want to create \\na phone directory. It would be helpful if you could produce an ordered sequence (last \\nname, first name, initial) in three stages:\\n1. ORDER BY last name.\\n2. Within the last names, ORDER BY first name.\\n3. Within the first and last names, ORDER BY middle initial.\\nSuch a multilevel ordered sequence is known as a cascading order sequence , and it \\ncan be created easily by listing several attributes, separated by commas, after the ORDER \\nBY clause.\\nThe cascading order sequence is the basis for any telephone directory. To illustrate \\na\\xa0cascading order sequence, use the following SQL command on the EMPLOYEE table:\\nSELECT EMP_LNAME, EMP_FNAME, EMP_INITIAL, EMP_AREACODE, \\nEMP_PHONE\\nFROM EMPLOYEE\\nORDER BY EMP_LNAME, EMP_FNAME, EMP_INITIAL;\\nThis command yields the results shown in Figure 7.18.\\nThe ORDER BY clause is useful in many applications, especially because the \\nDESC qualifier can be invoked. For example, listing the most recent items first is a \\nstandard procedure. Typically, invoice due dates are listed in descending order. Or, \\nif you want to examine budgets, it is probably useful to list the largest budget line \\nitems first.\\nY ou can use the ORDER BY clause in conjunction with other SQL commands, too. \\nFor example, note the use of restrictions on date and price in the following command \\nsequence:\\nSELECT P_DESCRIPT, V_CODE, P_INDATE, P_PRICE\\nFROM PRODUCT\\nWHERE P_INDATE < '21-Jan-2016'\\nAND P_PRICE <= 50.00\\nORDER BY V_CODE, P_PRICE DESC;cascading order \\nsequence\\nA nested ordering \\nsequence for a set of \\nrows, such as a list in \\nwhich all last names are \\nalphabetically ordered \\nand, within the last \\nnames, all first names are \\nordered.FIGURE 7.17   SELECTED PRODUCT TABLE ATTRIBUTES: ORDERED BY \\n(ASCENDING) P_PRICE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='19d60ca0-9b87-4d78-bbcc-9e22888dc098', embedding=None, metadata={'page_label': '292', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='292   Part 3     Advanced Design and Implementation\\nThe output is shown in Figure 7.19. Note that within each V_CODE, the P_PRICE \\nvalues are in descending order.FIGURE 7.18  TELEPHONE LIST QUERY RESULTS  \\nFIGURE 7.19  A QUERY BASED ON MULTIPLE RESTRICTIONS  \\n7-6b  Listing Unique Values\\nHow many different  vendors are currently represented in the PRODUCT table? A sim -\\nple listing (SELECT) is not very useful if the table contains several thousand rows and \\nyou have to sift through the vendor codes manually. Fortunately, SQL ’s DISTINCT  clause \\nproduces a list of only those values that are different from one another. For example, the \\ncommand\\nSELECT DISTINCT V_CODE\\nFROM PRODUCT;\\nyields only the different vendor codes (V_CODE) in the PRODUCT table, as shown in \\nFigure 7.20. Note that the first output row shows the null. The placement of nulls does \\nnot affect the list contents. In Oracle, you could use ORDER BY V_CODE NULLS FIRST \\nto place nulls at the top of the list.\\n7-6c  Aggregate Functions\\nSQL can perform various mathematical summaries for you, such as counting the num -\\nber of rows that contain a specified condition, finding the minimum or maximum values DISTINCT\\nA SQL clause that \\nproduces only a list of \\nvalues that are different \\nfrom one another.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3a118520-1480-4d63-86c1-96ea0e38b513', embedding=None, metadata={'page_label': '293', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    293\\nfor a specified attribute, summing the values in a specified column, and averaging the \\nvalues in a specified column. Those aggregate functions are shown in Table 7.8.\\nTo illustrate another standard SQL command format, most of the remaining input \\nand output sequences are presented using the Oracle RDBMS.\\nCOUNT  The COUNT  function is used to tally the number of non-null values of an \\n attribute. COUNT can be used in conjunction with the DISTINCT clause. For example, \\nsuppose that you want to find out how many different vendors are in the PRODUCT \\ntable. The answer, generated by the first SQL code set shown in Figure 7.21, is 6. Note \\nthat\\xa0the nulls are not counted as V_CODE values.\\nThe aggregate functions can be combined with the SQL commands explored earlier. \\nFor example, the second SQL command set in Figure 7.21 supplies the answer to the \\nquestion, “How many vendors referenced in the PRODUCT table have supplied prod -\\nucts with prices that are less than or equal to $10?” The answer is that three vendors’ \\nproducts meet the price specification.\\nThe COUNT aggregate function uses one parameter within parentheses, generally a col -\\numn name such as COUNT(V_CODE) or COUNT(P_CODE). The parameter may also \\nbe an expression such as COUNT(DISTINCT V_CODE) or COUNT(P_PRICE+10). Using \\nthat syntax, COUNT always returns the number of non-null values in the given column. \\n(Whether the column values are computed or show stored table row values is immaterial.) In \\ncontrast, the syntax COUNT(*) returns the number of total rows from the query, including FIGURE 7.20   A LISTING OF DISTINCT V_CODE VALUES IN THE PRODUCT \\nTABLE  \\nIf the ordering column has nulls, they are listed either first or last, depending on the RDBMS.\\nThe ORDER BY clause must always be listed last in the SELECT command sequence.Note\\nTABLE 7.8\\nSOME BASIC SQL AGGREGATE FUNCTIONS\\nFUNCTION OUTPUT\\nCOUNT The number of rows containing non-null values\\nMIN The minimum attribute value encountered in a given column\\nMAX The maximum attribute value encountered in a given column\\nSUM The sum of all values for a given column\\nAVG The arithmetic mean (average) for a specified column\\nCOUNT\\nA SQL aggregate \\nfunction that outputs \\nthe number of rows \\ncontaining not null \\nvalues for a given \\ncolumn or expression, \\nsometimes used in \\nconjunction with the \\nDISTINCT clause.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6b45f384-fa9d-4a80-9e3a-53b4496f5dc6', embedding=None, metadata={'page_label': '294', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='294   Part 3    Advanced Design and Implementation\\nthe rows that contain nulls. In the example in Figure 7.21, SELECT COUNT(P_CODE) \\nFROM PRODUCT and SELECT COUNT(*) FROM PRODUCT will yield the same answer because there are no null values in the P_CODE primary key column.\\nNote that the third SQL command set in Figure 7.21 uses the COUNT(*) command to \\nanswer the question, “How many rows in the PRODUCT table have a P_PRICE value less than or equal to $10?” The answer indicates that five products have a listed price that meets the specification. The COUNT(*) aggregate function is used to count rows in a query result set. In contrast, the COUNT(column ) aggregate function counts the number of non-null val-\\nues in a given column. For example, in Figure 7.20, the COUNT(*) function would return a value of 7 to indicate seven rows returned by the query. The COUNT(V_CODE) function would return a value of 6 to indicate the six non-null \\n vendor code values.FIGURE 7.21  COUNT FUNCTION OUTPUT EXAMPLES  \\nNote to MS Access Users\\nMS Access does not support the use of COUNT with the DISTINCT clause. If you want to use such queries in MS Access, you must create subqueries with DISTINCT and NOT NULL clauses. For example, the equivalent MS Access queries for the first two queries shown in Figure 7.21 are:\\nSELECT COUNT(*)\\nFROM (SELECT DISTINCT V_CODE FROM PRODUCT WHERE V_CODE IS NOT NULL)\\nand\\nSELECT COUNT(*)FROM (SELECT DISTINCT(V_CODE)\\n FROM (SELECT V_CODE, P_PRICE FROM PRODUCT\\n  WHERE V_CODE IS NOT NULL AND P_PRICE<10))Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b89836e5-3d4d-4e2f-8c20-be2aa4841f99', embedding=None, metadata={'page_label': '295', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    295\\nThe third SQL command set in Figure 7.22 demonstrates that the numeric functions \\ncan be used in conjunction with more complex queries. However, you must remember \\nthat the numeric functions yield only one value based on all the values found in the table: a \\nsingle maximum value, a single minimum value, a single count, or a single average value. It is easy to overlook this warning. For example, examine the question, “Which product has the highest price?”\\nAlthough that query seems simple enough, the SQL command sequence:\\nSELECT P_CODE, P_DESCRIPT, P_PRICE\\nFROM PRODUCT\\nWHERE P_PRICE = MAX(P_PRICE);\\ndoes not yield the expected results because the use of MAX(P_PRICE) on the right side \\nof a comparison operator is incorrect, thus producing an error message. The aggregate function MAX(columnname ) can be used only in the column list of a SELECT statement. \\nAlso, in a comparison that uses an equality symbol, you can use only a single value to the right of the equals sign.MAX\\nA SQL aggregate function that yields the maximum attribute value in a given column.\\nMIN\\nA SQL aggregate function that yields the minimum attribute value in a given column.FIGURE 7.22  MAX AND MIN OUTPUT EXAMPLES  \\nThe two queries are available at www.cengagebrain.com in the Ch07_SaleCo (Access) \\ndatabase. MS Access does add a trailer at the end of the query after you have executed it, but you can delete that trailer the next time you use the query. Subqueries are covered in detail in Chapter 8, Advanced SQL.\\nMAX and MIN  The MAX  and MIN functions help you find answers to problems such \\nas the highest and lowest (maximum and minimum) prices in the PRODUCT table. The highest price, $256.99, is supplied by the first SQL command set in Figure 7.22. The\\xa0\\n second SQL command set shown in Figure 7.22 yields the minimum price of $4.99.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f20751f0-c34d-4cf8-b910-a6d560d545da', embedding=None, metadata={'page_label': '296', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='296   Part 3    Advanced Design and Implementation\\nTo answer the question, therefore, you must compute the maximum price first, then \\ncompare it to each price returned by the query. To do that, you need a nested query. \\nIn\\xa0this case, the nested query is composed of two parts:\\n• The inner query, which is executed first.\\n• The outer query, which is executed last. (Remember that the outer query is always the \\nfirst SQL command you encounter—in this case, SELECT.)\\nUsing the following command sequence as an example, note that the inner query first \\nfinds the maximum price value, which is stored in memory. Because the outer query now \\nhas a value to which to compare each P_PRICE value, the query executes properly.\\nSELECT P_CODE, P_DESCRIPT, P_PRICE\\nFROM PRODUCT\\nWHERE P_PRICE = (SELECT MAX(P_PRICE) FROM PRODUCT);\\nThe execution of the nested query yields the correct answer, shown below the third \\n(nested) SQL command set in Figure 7.22.\\nThe MAX and MIN aggregate functions can also be used with date columns. For exam-\\nple, to find out which product has the oldest date, you would use MIN(P_INDATE). In \\nthe same manner, to find out the most recent product, you would use MAX(P_INDATE).\\nSUM  The SUM function computes the total sum for any specified attribute, using any \\ncondition(s) you have imposed. For example, if you want to compute the total amount owed by your customers, you could use the following command:\\nSELECT SUM(CUS_BALANCE) AS TOTBALANCE\\nFROM CUSTOMER;\\nY ou could also compute the sum total of an expression. For example, if you want to \\nfind the total value of all items carried in inventory, you could use the following:\\nSELECT SUM(P_QOH * P_PRICE) AS TOTV ALUE\\nFROM PRODUCT;\\nThe total value is the sum of the product of the quantity on hand and the price for \\nall\\xa0items. (See Figure 7.23.)\\nAVG  The AVG  function format is similar to those of MIN and MAX and is subject to \\nthe same operating restrictions. The first SQL command set in Figure 7.24 shows how a \\nsimple average P_PRICE value can be generated to yield the computed average price of 56.42125. The second SQL command set in Figure 7.24 produces five output lines that describe products whose prices exceed the average product price. Note that the second query uses nested SQL commands and the ORDER BY clause examined earlier.\\nYou can use expressions anywhere a column name is expected. Suppose that you want to know what product has the highest inventory value. To find the answer, you can write the following query:\\nSELECT *\\nFROM PRODUCTWHERE P_QOH*P_PRICE = (SELECT MAX(P_QOH*P_PRICE) FROM PRODUCT);Note\\nSUM\\nA SQL aggregate function that yields the sum of all values for a given column or expression.\\nAVG\\nA SQL aggregate function that outputs the mean average for a specified column or expression.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='75060b58-b11b-43f9-95b9-09b42ffa6af1', embedding=None, metadata={'page_label': '297', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    297\\n7-6d  Grouping Data\\nIn the previous examples, the aggregate functions summarized data across all rows in \\nthe given tables. Sometimes, however, you do not want to treat the entire table as a sin-gle collection of data for summarizing. Rows can be grouped into smaller collections quickly and easily using the GROUP BY clause within the SELECT statement. The aggre-\\ngate functions will then summarize the data within each smaller collection. The syntax is\\nSELECT columnlist\\nFROM tablelist\\n[WHERE conditionlist  ]\\n[GROUP BY columnlist  ]\\n[HAVING conditionlist  ]\\n[ORDER BY columnlist  [ASC | DESC] ];\\nThe GROUP BY clause is generally used when you have attribute columns combined \\nwith aggregate functions in the SELECT statement. For example, to determine the min-\\nimum price for each sales code, use the first SQL command set shown in Figure 7.25.FIGURE 7.23  THE TOTAL VALUE OF ALL ITEMS IN THE PRODUCT TABLE  \\nGROUP BY\\nA SQL clause used to create frequency distributions when combined with any of the aggregate functions in a SELECT statement.FIGURE 7.24  AVG FUNCTION OUTPUT EXAMPLES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='108bcb67-9822-450b-bbc7-1ca045617b0e', embedding=None, metadata={'page_label': '298', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='298   Part 3    Advanced Design and Implementation\\nThe second SQL command set in Figure 7.25 generates the average price within each \\nsales code. Note that the P_SALECODE nulls are included within the grouping.\\nThe GROUP BY clause is valid only when used in conjunction with one of the SQL \\naggregate functions, such as COUNT, MIN, MAX, AVG, and SUM. For example, as \\nshown in the first command set in Figure 7.26, if you try to group the output by using\\nSELECT V_CODE, P_CODE, P_DESCRIPT, P_PRICE\\nFROM PRODUCT\\nGROUP BY V_CODE;\\nyou generate a “not a GROUP BY expression” error. However, if you write the pre-\\nceding SQL command sequence in conjunction with an aggregate function, the GROUP \\nBY clause works properly. The second SQL command sequence in Figure 7.26 properly answers the question, “How many products are supplied by each vendor?” because it uses a COUNT aggregate function.\\nNote that the last output line in Figure 7.26 shows a null for the V_CODE, indicating \\nthat two products were not supplied by a vendor. Perhaps those products were produced in-house, or they might have been bought without the use of a vendor, or the person who entered the data might have merely forgotten to enter a vendor code. (Remember that nulls can be the result of many things.)FIGURE 7.25  GROUP BY CLAUSE OUTPUT EXAMPLES  \\nWhen using the GROUP BY clause with a SELECT statement:\\n• The SELECT’s columnlist must include a combination of column names and aggregate functions.\\n• The GROUP BY clause’s columnlist must include all nonaggregate function columns specified in the SELECT’s columnlist. If required, you could also group by any aggregate function columns that appear in the SELECT’s columnlist.\\n• The GROUP BY clause columnlist can include any columns from the tables in the FROM clause of the SELECT statement, even if they do not appear in the SELECT’s columnlist.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='198dad57-58bf-4e28-a534-3c9e21b12e95', embedding=None, metadata={'page_label': '299', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    299\\nThe GROUP BY Feature’s HAVING Clause  A particularly useful extension of the \\nGROUP BY feature is the HAVING clause. The HAVING clause operates very much like \\nthe WHERE clause in the SELECT statement. However the WHERE clause applies to col -\\numns and expressions for individual rows, while the HAVING clause is applied to the out -\\nput of a GROUP BY operation. For example, suppose that you want to generate a listing of the number of products in the inventory supplied by each vendor. However, this time you want to limit the listing to products whose prices average less than $10. The first part of that requirement is satisfied with the help of the GROUP BY clause, as illustrated in the first SQL command set in Figure 7.27. Note that the HAVING clause is used in conjunction with the GROUP BY clause in the second SQL command set in Figure 7.27 to generate the desired result.\\nIf you use the WHERE clause instead of the HAVING clause, the second SQL \\n command set in Figure 7.27 will produce an error message.\\nY ou can also combine multiple clauses and aggregate functions. For example,  consider \\nthe following SQL statement:\\nSELECT V_CODE, SUM(P_QOH * P_PRICE) AS TOTCOST\\nFROM PRODUCT\\nGROUP BY V_CODE\\nHAVING (SUM(P_QOH * P_PRICE) > 500)ORDER BY SUM(P_QOH * P_PRICE) DESC;FIGURE 7.26  INCORRECT AND CORRECT USE OF THE GROUP BY CLAUSE  \\nHAVING\\nA clause applied to the \\noutput of a GROUP BY operation to restrict selected rows.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7f99a875-3870-40ce-89c5-b0549d53882d', embedding=None, metadata={'page_label': '300', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='300   Part 3    Advanced Design and Implementation\\nThis statement will do the following:\\n• Aggregate the total cost of products grouped by V_CODE.\\n• Select only the rows with totals that exceed $500.\\n• List the results in descending order by the total cost.\\nNote the syntax used in the HAVING and ORDER BY clauses; in both cases, you \\nmust specify the column expression (formula) used in the SELECT statement’s column \\nlist, rather than the column alias (TOTCOST). Some RDBMSs allow you to replace the column expression with the column alias, while others do not.\\n7-7 Joining Database Tables\\nThe ability to combine, or join, tables on common attributes is perhaps the most import-ant distinction between a relational database and other databases. A join is performed when data is retrieved from more than one table at a time. If necessary, review the join definitions and examples in Chapter 3, The Relational Database Model.FIGURE 7.27  AN APPLICATION OF THE HAVING CLAUSE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='63c07a6f-6da9-4d74-b622-2a97d7b77bef', embedding=None, metadata={'page_label': '301', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    301\\nTo join tables, you simply list the tables in the FROM clause of the SELECT statement. \\nThe DBMS will create the Cartesian product of every table in the FROM clause. How -\\never, to get the correct result—that is, a natural join—you must select only the rows in \\nwhich the common attribute values match. To do this, use the WHERE clause to indicate \\nthe common attributes used to link the tables; this WHERE clause is sometimes referred \\nto as the join condition.\\nThe join condition is generally composed of an equality comparison between the \\n foreign key and the primary key of related tables. For example, suppose that you want \\nto\\xa0join the two tables VENDOR and PRODUCT. Because V_CODE is the foreign key in \\nthe PRODUCT table and the primary key in the VENDOR table, the link is established \\non V_CODE. (See Table 7.9.)\\nFIGURE 7.28  THE RESULTS OF A JOIN  \\nSELECT P_DESCRIPT, P_PRICE, V_NAME, V_CONTACT,  \\nV_AREACODE, V_PHONE\\nFROM PRODUCT, VENDOR\\nWHERE PRODUCT.V_CODE = VENDOR.V_CODE;\\nY our output might be presented in a different order because the SQL command pro -\\nduces a listing in which the order of the rows is not relevant. In fact, you are likely to get When the same attribute name appears in more than one of the joined tables, the \\nsource table of the attributes listed in the SELECT command sequence must be defined. \\nTo join the PRODUCT and VENDOR tables, you would use the following, which \\n produces the output shown in Figure 7.28:TABLE 7.9\\nCREATING LINKS THROUGH FOREIGN KEYS\\nTABLE ATTRIBUTES TO BE SHOWN LINKING ATTRIBUTE\\nPRODUCT P_DESCRIPT, P_PRICE V_CODE\\nVENDOR V_NAME, V_CONTACT, V_AREACODE, \\nV_PHONEV_CODE\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3946393f-ca6e-4237-82b1-e3efcd60750d', embedding=None, metadata={'page_label': '302', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"302   Part 3    Advanced Design and Implementation\\na different order of the same listing the next time you execute the command. However, \\nyou can generate a more predictable list by using an ORDER BY clause:\\nSELECT PRODUCT.P_DESCRIPT, PRODUCT.P_PRICE,  \\nVENDOR.V_NAME, VENDOR.V_CONTACT,  \\nVENDOR.V_AREACODE, VENDOR.V_PHONE\\nFROM PRODUCT, VENDOR\\nWHERE PRODUCT.V_CODE = VENDOR.V_CODE\\nORDER BY PRODUCT.P_PRICE;\\nIn this case, your listing will always be arranged from the lowest price to the highest \\nprice.\\nThe preceding SQL command sequence joins a row in the PRODUCT table with a \\nrow in the VENDOR table, in which the V_CODE values of these rows are the same, as \\nindicated in the WHERE clause’s condition. Because any vendor can deliver any number of ordered products, the PRODUCT table might contain multiple V_CODE entries for each V_CODE entry in the VENDOR table. In other words, each V_CODE in VENDOR can be matched with many V_CODE rows in PRODUCT.\\nIf you do not specify the WHERE clause, the result will be the Cartesian product \\nof PRODUCT and VENDOR. Because the PRODUCT table contains 16 rows and the VENDOR table contains 11 rows, the Cartesian product will yield a listing of (16 × 11) = 176 rows. (Each row in PRODUCT will be joined to each row in the VENDOR table.)\\nAll of the SQL commands can be used on the joined tables. For example, the following \\ncommand sequence is quite acceptable in SQL and produces the output shown in Figure 7.29.\\nSELECT P_DESCRIPT, P_PRICE, V_NAME, V_CONTACT,  \\nV_AREACODE, V_PHONE\\nFROM PRODUCT, VENDOR\\nWHERE PRODUCT.V_CODE = VENDOR.V_CODE\\nAND P_INDATE > '15-Jan-2016';\\nTable names were used as prefixes in the preceding SQL command sequence. For example, \\nPRODUCT.P_PRICE was used rather than P_PRICE. Most current-generation RDBMSs do not require table names to be used as prefixes unless the same attribute name occurs in several of the tables being joined. In the previous case, V_CODE is used as a foreign key in PROD -\\nUCT and as a primary key in VENDOR; therefore, you must use the table names as prefixes in the WHERE clause. In other words, you can write the previous query as:\\nSELECT P_DESCRIPT, P_PRICE, V_NAME, V_CONTACT, V_AREACODE,  \\nV_PHONE\\nFROM PRODUCT, VENDOR WHERE PRODUCT.V_CODE = VENDOR.V_CODE ORDER BY P_PRICE;\\nNaturally, if an attribute name occurs in several places, its origin (table) must be speci-\\nfied. If you fail to provide such a specification, SQL will generate an error message to indi-cate that you have been ambiguous about the attribute’s origin.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a65f34e3-04f3-47dc-96a5-07a2fe60640a', embedding=None, metadata={'page_label': '303', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    303\\nWhen joining three or more tables, you need to specify a join condition for each pair of \\ntables. The number of join conditions will always be n–1, where n represents the number \\nof tables listed in the FROM clause. For example, if you have three tables, you must have \\ntwo join conditions; if you have five tables, you must have four join conditions; and so on.\\nRemember, the join condition will match the foreign key of a table to the primary key \\nof the related table. For example, using Figure 7.1, if you want to list the customer last \\nname, invoice number, invoice date, and product descriptions for all invoices for cus -\\ntomer 10014, you must type the following:\\nSELECT CUS_LNAME, INVOICE.INV_NUMBER, INV_DATE, P_DESCRIPT\\nFROM CUSTOMER, INVOICE, LINE, PRODUCT\\nWHERE CUSTOMER.CUS_CODE = INVOICE.CUS_CODE\\nAND INVOICE.INV_NUMBER = LINE.INV_NUMBER\\nAND LINE.P_CODE = PRODUCT.P_CODE\\nAND CUSTOMER.CUS_CODE = 10014\\nORDER BY INV_NUMBER;\\nFinally, be careful not to create circular join conditions. For example, if Table A is \\nrelated to Table B, Table B is related to Table C, and Table C is also related to Table A, \\ncreate only two join conditions: join A with B and B with C. Do not join C with A!\\n7-7a  Joining Tables with an Alias\\nAn alias may be used to identify the source table from which the data is taken. The \\naliases P and V are used to label the PRODUCT and VENDOR tables in the next com -\\nmand sequence. Any legal table name may be used as an alias. (Also notice that there are \\nno table name prefixes because the attribute listing contains no duplicate names in the \\nSELECT statement.)\\nSELECT P_DESCRIPT, P_PRICE, V_NAME, V_CONTACT, V_AREACODE, \\nV_PHONE\\nFROM PRODUCT P , VENDOR V\\nWHERE P .V_CODE = V .V_CODE\\nORDER BY P_PRICE;\\n7-7b  Recursive Joins\\nAn alias is especially useful when a table must be joined to itself in a recursive query . For \\nexample, suppose that you are working with the EMP table shown in Figure 7.30. Using \\nthe data in the EMP table, you can generate a list of all employees with their managers’ FIGURE 7.29  AN ORDERED AND LIMITED LISTING AFTER A JOIN  \\nrecursive query\\nA nested query that joins \\na table to itself.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='048fd7d4-e793-451d-85ef-dcef00815dd5', embedding=None, metadata={'page_label': '304', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='304   Part 3     Advanced Design and Implementation\\nnames by joining the EMP table to itself. In that case, you would also use aliases to \\n differentiate the table from itself. The SQL command sequence would look like this:\\nSELECT E.EMP_NUM, E.EMP_LNAME, E.EMP_MGR, \\nM.EMP_LNAME\\nFROM EMP E, EMP M\\nWHERE E.EMP_MGR=M.EMP_NUM\\nORDER BY E.EMP_MGR;\\nThe output of the preceding command sequence is shown in Figure 7.31.\\nFIGURE 7.31  USING AN ALIAS TO JOIN A TABLE TO ITSELF  \\nFIGURE 7.30  THE CONTENTS OF THE EMP TABLE  \\nIn MS Access, you would add AS to the previous SQL command sequence. For example:\\nSELECT E.EMP_NUM,E.EMP_LNAME,E.EMP_MGR,M.EMP_LNAME\\nFROM EMP AS E, EMP AS M\\nWHERE E.EMP_MGR = M.EMP_NUM\\nORDER BY E.EMP_MGR;NoteOnline \\nContent\\nFor a complete walk-\\nthrough example of \\nconverting an ER model \\ninto a database struc -\\nture and using SQL \\ncommands to create \\ntables, see Appendix \\nD, Converting the ER \\nModel into a Data -\\nbase Structure at www.  \\ncengagebrain.com .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='14e8745f-a695-4ec2-b8eb-98709537359b', embedding=None, metadata={'page_label': '305', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    305\\n• SQL commands can be divided into two overall categories: data definition language \\n(DDL) commands and data manipulation language (DML) commands.\\n• The ANSI standard data types are supported by all RDBMS vendors in different ways. The basic data types are NUMBER, NUMERIC, INTEGER, CHAR, V ARCHAR, and DATE.\\n•\\n The basic data definition commands allow you to create tables and indexes. Many SQL constraints can be used with columns. The commands are CREATE TABLE, CREATE INDEX, ALTER TABLE, DROP TABLE, and DROP INDEX.\\n•\\n DML commands allow you to add, modify, and delete rows from tables. The basic DML commands are SELECT, INSERT, UPDATE, DELETE, COMMIT, and ROLLBACK.\\n•\\n The INSERT command is used to add new rows to tables. The UPDATE command is used to modify data values in existing rows of a table. The DELETE command is used to delete rows from tables. The COMMIT and ROLLBACK commands are used to permanently save or roll back changes made to the rows. Once you COMMIT the changes, you cannot undo them with a ROLLBACK command.\\n•\\n The SELECT statement is the main data retrieval command in SQL. A SELECT \\n statement has the following syntax:\\nSELECT columnlist\\nFROM tablelist\\n[WHERE conditionlist  ]\\n[GROUP BY columnlist  ]\\n[HAVING conditionlist  ]\\n[ORDER BY columnlist  [ASC | DESC] ];\\n• The column list represents one or more column names separated by commas. The \\ncolumn list may also include computed columns, aliases, and aggregate functions. A computed column is represented by an expression or formula (for example, P_PRICE * P_QOH). The FROM clause contains a list of table names.\\n•\\n The WHERE clause can be used with the SELECT, UPDATE, and DELETE state-ments to restrict the rows affected by the DDL command. The condition list rep-resents one or more conditional expressions separated by logical operators (AND, OR, and NOT). The conditional expression can contain any comparison operators (=,\\xa0>, <, >=, <=, and <>) as well as special operators (BETWEEN, IS NULL, LIKE, IN,\\xa0and EXISTS).\\n•\\n Aggregate functions (COUNT, MIN, MAX, and AVG) are special functions that per -\\nform arithmetic computations over a set of rows. The aggregate functions are usually used in conjunction with the GROUP BY clause to group the output of aggregate computations by one or more attributes. The HAVING clause is used to restrict the output of the GROUP BY clause by selecting only the aggregate rows that match a given condition.\\n•\\n The ORDER BY clause is used to sort the output of a SELECT statement. The ORDER BY clause can sort by one or more columns and can use either ascending or descend-ing order.Summary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6353fe87-426d-4cbf-a717-00033f4e1c38', embedding=None, metadata={'page_label': '306', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='306   Part 3    Advanced Design and Implementation\\n• Y ou can join the output of multiple tables with the SELECT statement. The join \\noperation is performed every time you specify two or more tables in the FROM clause and use a join condition in the WHERE clause to match the foreign key of one table to the primary key of the related table. If you do not specify a join con-dition, the DBMS will automatically perform a Cartesian product of the tables you specify in the FROM clause.\\n•\\n The natural join uses the join condition to match only rows with equal values in the specified columns.\\nalias\\nALTER TABLEANDauthenticationAVGBETWEENBoolean algebracascading order sequenceCOMMITCOUNTCREATE INDEXCREATE TABLEDELETEDISTINCTDROP INDEXDROP TABLEEXISTSFROMGROUP BYHAVINGINinner queryINSERTIS NULLLIKEMAXMINnested queryNOTORORDER BYrecursive queryreserved wordsROLLBACKrules of precedenceschemaSELECTsubquerySUMUPDATEWHEREwildcard character\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at www.cengagebrain.com.Online \\nContent\\n1. In a SELECT query, what is the difference between a WHERE clause and a HAVING \\nclause?\\n2. Explain why the following command would create an error and what changes could be made to fix the error:\\nSELECT V_CODE, SUM(P_QOH) FROM PRODUCT;\\n3.\\n What type of integrity is enforced when a primary key is declared?\\n4. Explain why it might be more appropriate to declare an attribute that contains only \\ndigits as a character data type instead of a numeric data type.\\n5. What is the difference between a column constraint and a table constraint?\\n6. What are “referential constraint actions”?Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6a5ffa85-f3be-4def-8358-e359abbed122', embedding=None, metadata={'page_label': '307', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 7    Introduction to Structured Query Language (SQL)    307\\n7. Rewrite the following WHERE clause without the use of the IN special operator:\\nWHERE V_STATE IN ('TN', 'FL', 'GA')\\n8. Explain the difference between an ORDER BY clause and a GROUP BY clause.\\n9. Explain why the following two commands produce different results:\\nSELECT DISTINCT COUNT (V_CODE) FROM PRODUCT;\\nSELECT COUNT (DISTINCT V_CODE) FROM PRODUCT;\\n10. What is the difference between the COUNT aggregate function and the SUM \\naggregate function?\\n11. Explain why it would be preferable to use a DATE data type to store date data \\ninstead of a character data type.\\n12. What is a recursive join?Problems 1−25 are based on \\nthe Ch07_ConstructCo data -\\nbase at www.cengagebrain.\\ncom . This database is stored \\nin Microsoft Access format. \\nOracle, MySQL, and MS SQL \\nServer script files are available \\nat www.cengagebrain.com .Online \\nContent\\nThe Ch07_ConstructCo database stores data for a consulting company that tracks all \\ncharges to projects. The charges are based on the hours each employee works on each \\nproject. The structure and contents of the Ch07_ConstructCo database are shown in \\nFigure P7.1.Problems\\nFIGURE P7.1  THE CH07_CONSTRUCTCO DATABASE  \\nRelational diagram Table name: EMPLOYEE\\nTable name: JOB\\nTable name: PROJECTTable name: ASSIGNMENT Database name: Ch07_ConstructCo\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f7ad763d-0ab1-4b01-8768-eaed8afd6a0c', embedding=None, metadata={'page_label': '308', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='308   Part 3     Advanced Design and Implementation\\nNote that the ASSIGNMENT table in Figure P7.1 stores the JOB_CHG_HOUR val -\\nues as an attribute (ASSIGN_CHG_HR) to maintain historical accuracy of the data. \\nThe JOB_CHG_HOUR values are likely to change over time. In fact, a JOB_CHG_\\nHOUR change will be reflected in the ASSIGNMENT table. Naturally, the employee \\nprimary job assignment might also change, so the ASSIGN_JOB is also stored. Because \\nthose attributes are required to maintain the historical accuracy of the data, they are \\nnot redundant.\\nGiven the structure and contents of the Ch07_ConstructCo database shown in \\nFigure P7.1, use SQL commands to answer Problems 1–25.\\n1. Write the SQL code that will create the table structure for a table named \\nEMP_1. This table is a subset of the EMPLOYEE table. The basic EMP_1 table \\nstructure is summarized in the following table. (Note that the JOB_CODE is \\nthe FK to JOB.)\\nATTRIBUTE (FIELD) NAME DATA DECLARATION\\nEMP_NUM CHAR(3)\\nEMP_LNAME VARCHAR(15)\\nEMP_FNAME VARCHAR(15)\\nEMP_INITIAL CHAR(1)\\nEMP_HIREDATE DATE\\nJOB_CODE CHAR(3)\\n2. Having created the table structure in Problem 1, write the SQL code to enter the first \\ntwo rows for the table shown in Figure P7.2.\\n3. Assuming that the data shown in the EMP_1 table have been entered, write the SQL \\ncode that will list all attributes for a job code of 502.\\n4. Write the SQL code that will save the changes made to the EMP_1 table.\\n5. Write the SQL code to change the job code to 501 for the person whose employee \\nnumber (EMP_NUM) is 107. After you have completed the task, examine the results \\nand then reset the job code to its original value.\\n6. Write the SQL code to delete the row for William Smithfield, who was hired on June \\n22, 2004, and whose job code is 500. ( Hint:  Use logical operators to include all of \\nthe information given in this problem. Remember, if you are using MySQL, you will \\nhave to first disable “safe mode. ”)FIGURE P7.2  THE CONTENTS OF THE EMP_1 TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8067ff17-c5c4-4b75-ab37-be1045531f9a', embedding=None, metadata={'page_label': '309', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    309\\n7. Write the SQL code that will restore the data to its original status; that is, the table \\nshould contain the data that existed before you made the changes in Problems 5 \\nand 6.\\n8. Write the SQL code to create a copy of EMP_1, naming the copy EMP_2. Then write \\nthe SQL code that will add the attributes EMP_PCT and PROJ_NUM to the struc -\\nture. The EMP_PCT is the bonus percentage to be paid to each employee. The new \\nattribute characteristics are:\\nEMP_PCT NUMBER(4,2)\\nPROJ_NUM CHAR(3)\\n [Note:  If your SQL implementation allows it, you may use DECIMAL(4,2) or \\nNUMERIC(4,2) rather than NUMBER(4,2).]\\n9. Write the SQL code to change the EMP_PCT value to 3.85 for the person whose \\nemployee number (EMP_NUM) is 103. Next, write the SQL command sequences to \\nchange the EMP_PCT values, as shown in Figure P7.9.\\n10. Using a single command sequence, write the SQL code that will change the proj -\\nect number (PROJ_NUM) to 18 for all employees whose job classification (JOB_\\nCODE) is 500.\\n11. Using a single command sequence, write the SQL code that will change the proj -\\nect number (PROJ_NUM) to 25 for all employees whose job classification (JOB_\\nCODE) is 502 or higher. When you finish Problems 10 and 11, the EMP_2 table will \\ncontain the data shown in Figure P7.11. (Y ou may assume that the table has been \\nsaved again at this point.)FIGURE P7.9  THE EMP_2 TABLE AFTER THE MODIFICATIONS  \\nFIGURE P7.11  THE EMP_2 TABLE CONTENTS AFTER THE MODIFICATIONS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6c59e4a4-6474-4a94-a3f6-613a1dc7aece', embedding=None, metadata={'page_label': '310', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='310   Part 3     Advanced Design and Implementation\\n12. Write the SQL code that will change the PROJ_NUM to 14 for employees who were \\nhired before January 1, 1994, and whose job code is at least 501. (Y ou may assume \\nthat the table will be restored to its condition preceding this question.)\\n13. Write the two SQL command sequences required to:\\na. Create a temporary table named TEMP_1 whose structure is composed of the \\nEMP_2 attributes EMP_NUM and EMP_PCT.\\nb. Copy the matching EMP_2 values into the TEMP_1 table.\\n14. Write the SQL command that will delete the newly created TEMP_1 table from the \\ndatabase.\\n15. Write the SQL code required to list all employees whose last names start with Smith . \\nIn other words, the rows for both Smith and Smithfield should be included in the \\nlisting. Assume case sensitivity.\\n16. Using the EMPLOYEE, JOB, and PROJECT tables in the Ch07_ConstructCo data -\\nbase (see Figure P7.1), write the SQL code that will produce the results shown in \\nFigure P7.16.\\nFIGURE P7.16  THE QUERY RESULTS FOR PROBLEM 16  \\n17. Write the SQL code that will produce the same information that was shown in Prob -\\nlem 16, but sorted by the employee’s last name.\\n18. Write the SQL code to find the average bonus percentage in the EMP_2 table you \\ncreated in Problem 8.\\n19. Write the SQL code that will produce a listing for the data in the EMP_2 table in \\nascending order by the bonus percentage.\\n20. Write the SQL code that will list only the distinct project numbers in the EMP_2 \\ntable.\\n21. Write the SQL code to calculate the ASSIGN_CHARGE values in the ASSIGNMENT \\ntable in the Ch07_ConstructCo database. (See Figure P7.1.) Note that ASSIGN_\\nCHARGE is a derived attribute that is calculated by multiplying ASSIGN_CHG_HR \\nby ASSIGN_HOURS.\\n22. Using the data in the ASSIGNMENT table, write the SQL code that will yield the \\ntotal number of hours worked for each employee and the total charges stemming \\nfrom those hours worked. The results of running that query are shown in Figure \\nP7.22.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d74ecfc0-fb59-4f87-ae03-ae0215c55290', embedding=None, metadata={'page_label': '311', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    311\\n23. Write a query to produce the total number of hours and charges for each of \\nthe projects represented in the ASSIGNMENT table. The output is shown in \\nFigure P7.23.\\n24. Write the SQL code to generate the total hours worked and the total charges made by \\nall employees. The results are shown in Figure P7.24. ( Hint:  This is a nested query. If \\nyou use Microsoft Access, you can use the output shown in Figure P7.22 as the basis \\nfor the query that will produce the output shown in Figure P7.24.)\\n25. Write the SQL code to generate the total hours worked and the total charges made \\nto all projects. The results should be the same as those shown in Figure P7.24. ( Hint:  \\nThis is a nested query. If you use Microsoft Access, you can use the output \\nshown in Figure P7.23 as the basis for this query.)\\nThe structure and contents of the Ch07_SaleCo database are shown in \\n Figure P7.26. Use this database to answer the following problems. Save each \\nquery as Q XX, where XX is the problem number.\\n26. Write a query to count the number of invoices.\\n27. Write a query to count the number of customers with a balance of more than \\n$500.\\n28. Generate a listing of all purchases made by the customers, using the output \\nshown in Figure P7.28 as your guide. ( Hint:  Use the ORDER BY clause to order \\nthe resulting rows shown in Figure P7.28.)FIGURE P7.22  TOTAL HOURS AND CHARGES BY EMPLOYEE  \\nFIGURE P7.23  TOTAL HOUR AND CHARGES BY PROJECT  \\nFIGURE P7.24  TOTAL HOURS AND CHARGES, ALL EMPLOYEES  \\nProblems 26−43 are based on \\nthe Ch07_SaleCo  database, \\nwhich is available at www.\\ncengagebrain.com . This data -\\nbase is stored in Microsoft \\nAccess format. Oracle, MySQL, \\nand MS SQL Server script files \\nare available at www.cengage \\nbrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e7153f52-4bf9-405c-a15f-950e27b00ecd', embedding=None, metadata={'page_label': '312', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='312   Part 3     Advanced Design and Implementation\\nFIGURE P7.26  THE CH07_SALECO DATABASE  \\nRelational diagram\\nTable name: VENDORTable name: CUSTOMER\\nTable name: PRODUCT Table name: INVOICE Table name: LINE\\nFIGURE P7.28  LIST OF CUSTOMER PURCHASES  \\n29. Using the output shown in Figure P7.29 as your guide, generate a list of cus -\\ntomer purchases, including the subtotals for each of the invoice line numbers. \\n(Hint:  Modify the query format used to produce the list of customer purchases in \\nProblem 28, delete the INV_DATE column, and add the derived attribute LINE_\\nUNITS * LINE_PRICE to calculate the subtotals.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8f6ae956-31f1-46ed-b841-cecd87c83984', embedding=None, metadata={'page_label': '313', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    313\\n30. Modify the query used in Problem 29 to produce the summary shown in Figure \\nP7.30.FIGURE P7.29  SUMMARY OF CUSTOMER PURCHASES WITH SUBTOTALS  \\nFIGURE P7.30  CUSTOMER PURCHASE SUMMARY  \\nFIGURE P7.32  AVERAGE PURCHASE AMOUNT BY CUSTOMER  \\nFIGURE P7.31   CUSTOMER TOTAL PURCHASE AMOUNTS AND NUMBER OF \\nPURCHASES  \\n31. Modify the query in Problem 30 to include the number of individual product pur -\\nchases made by each customer. (In other words, if the customer’s invoice is based on \\nthree products, one per LINE_NUMBER, you count three product purchases. Note \\nthat in the original invoice data, customer 10011 generated three invoices, which \\ncontained a total of six lines, each representing a product purchase.) Y our output \\nvalues must match those shown in Figure P7.31.\\n32. Use a query to compute the average purchase amount per product made by each cus -\\ntomer. ( Hint:  Use the results of Problem 31 as the basis for this query.) Y our output val -\\nues must match those shown in Figure P7.32. Note that the average purchase amount \\nis equal to the total purchases divided by the number of purchases per customer.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='752652a4-4420-40e4-a216-c00d16e2bd97', embedding=None, metadata={'page_label': '314', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='314   Part 3     Advanced Design and Implementation\\n33. Create a query to produce the total purchase per invoice, generating the results \\nshown in Figure P7.33. The invoice total is the sum of the product purchases in the \\nLINE that corresponds to the INVOICE.\\n34. Use a query to show the invoices and invoice totals in Figure P7.34. ( Hint:  Group by \\nthe CUS_CODE.)\\n35. Write a query to produce the number of invoices and the total purchase amounts \\nby customer, using the output shown in Figure P7.35 as your guide. (Compare this \\nsummary to the results shown in Problem 34.)\\n36. Using the query results in Problem 35 as your basis, write a query to generate the \\ntotal number of invoices, the invoice total for all of the invoices, the smallest of the \\ncustomer purchase amounts, the largest of the customer purchase amounts, and \\nthe average of all the customer purchase amounts. ( Hint:  Check the figure output \\nin Problem 35.) Y our output must match Figure P7.36.FIGURE P7.33  INVOICE TOTALS  \\nFIGURE P7.34  INVOICE TOTALS BY CUSTOMER  \\nFIGURE P7.35   NUMBER OF INVOICES AND TOTAL PURCHASE AMOUNTS \\nBY CUSTOMER  \\nFIGURE P7.36   NUMBER OF INVOICES, INVOICE TOTALS, MINIMUM,  \\nMAXIMUM, AND AVERAGE SALES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4213599b-5e85-41f2-9054-becdf6a38dc3', embedding=None, metadata={'page_label': '315', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    315\\n37. List the balances of customers who have made purchases during the current invoice \\ncycle—that is, for the customers who appear in the INVOICE table. The results of \\nthis query are shown in Figure P7.37.\\n38. Using the results of the query created in Problem 37, provide a summary of  customer \\nbalance characteristics, as shown in Figure P7.38.\\n39. Create a query to find the balance characteristics for all customers, including the \\ntotal of the outstanding balances. The results of this query are shown in Figure P7.39.\\n40. Find the listing of customers who did not make purchases during the invoicing \\nperiod. Y our output must match the output shown in Figure P7.40.\\n41. Find the customer balance summary for all customers who have not made purchases \\nduring the current invoicing period. The results are shown in Figure P7.41.FIGURE P7.37  BALANCES FOR CUSTOMERS WHO MADE PURCHASES  \\nFIGURE P7.38   BALANCE SUMMARY OF CUSTOMERS WHO MADE \\nPURCHASES  \\nFIGURE P7.39  BALANCE SUMMARY FOR ALL CUSTOMERS  \\nFIGURE P7.40   BALANCES OF CUSTOMERS WHO DID NOT MAKE \\nPURCHASES  \\nFIGURE P7.41   SUMMARY OF CUSTOMER BALANCES FOR CUSTOMERS \\nWHO DID NOT MAKE PURCHASES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='22fd81e8-09aa-40f7-b9ff-37fd224f5092', embedding=None, metadata={'page_label': '316', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='316   Part 3     Advanced Design and Implementation\\n42. Create a query that summarizes the value of products currently in inventory. Note \\nthat the value of each product is a result of multiplying the units currently in \\ninventory by the unit price. Use the ORDER BY clause to match the order shown \\nin Figure P7.42.\\nThe Ch07_LargeCo database (see Figure P7.44) stores data for a company that \\nsells paint products. The company tracks the sale of products to customers. \\nThe database keeps data on customers (LGCUSTOMER), sales (LGINVOICE), \\nproducts (LGPRODUCT), which products are on which invoices (LGLINE), \\nemployees (LGEMPLOYEE), the salary history of each employee (LGSALARY_\\nHISTORY), departments (LGDEPARTMENT), product brands (LGBRAND), \\nvendors (LGVENDOR), and which vendors supply each product (LGSUPPLIES). \\nSome of the tables contain only a few rows of data, while other tables are quite \\nlarge; for example, there are only eight departments, but more than 3,300 invoices \\ncontaining over 11,000 invoice lines. For Problems 45–64, a figure of the correct \\noutput for each problem is provided. If the output of the query is very large, only \\nthe first several rows of the output are shown.43. Using the results of the query created in Problem 42, find the total value of the \\n product inventory. The results are shown in Figure P7.43.FIGURE P7.42  VALUE OF PRODUCTS CURRENTLY IN INVENTORY  \\nFIGURE P7.43  TOTAL VALUE OF ALL PRODUCTS IN INVENTORY  \\nOnline \\nContent\\nProblems 44−64 are based \\non the Ch07_LargeCo data -\\nbase, which is available at \\nwww.cengagebrain.com . \\nThis database is stored in \\nMicrosoft Access format. \\nOracle, MySQL, and MS SQL \\nServer script files are avail -\\nable at www.cengagebrain.\\ncom.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a6094eee-edbb-4bde-a6ef-7b8274c76ee5', embedding=None, metadata={'page_label': '317', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    317\\n44.  Write a query to display the eight departments in the LGDEPARTMENT table.\\n45.  Write a query to display the SKU (stock keeping unit), description, type, base, cat -\\negory, and price for all products that have a PROD_BASE of water and a PROD_\\nCATEGORY of sealer (Figure P7.45).\\n46. Write a query to display the first name, last name, and email address of employees \\nhired from January 1, 2003, to December 31, 2012. Sort the output by last name and \\nthen by first name (Figure P7.46).\\n47. Write a query to display the first name, last name, phone number, title, and \\ndepartment number of employees who work in department 300 or have the title \\n“CLERK I. ” Sort the output by last name and then by first name (Figure P7.47).FIGURE P7.44  THE CH07_LARGECO ERD  \\nFIGURE P7.45  WATER-BASED SEALERS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6f2b1345-f9b9-4459-b7e3-6925d89b9560', embedding=None, metadata={'page_label': '318', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='318   Part 3     Advanced Design and Implementation\\n48. Write a query to display the employee number, last name, first name, salary “from” \\ndate, salary end date, and salary amount for employees 83731, 83745, and 84039. \\nSort the output by employee number and salary “from” date (Figure P7.48).\\n49. Write a query to display the first name, last name, street, city, state, and zip code of \\nany customer who purchased a Foresters Best brand top coat between July 15, 2015, \\nand July 31, 2015. If a customer purchased more than one such product, display the \\ncustomer’s information only once in the output. Sort the output by state, last name, \\nand then first name (Figure P7.49).\\n50. Write a query to display the employee number, last name, email address, title, and \\ndepartment name of each employee whose job title ends in the word “ ASSOCIATE. ” \\nSort the output by department name and employee title (Figure P7.50).\\n51. Write a query to display a brand name and the number of products of that brand that \\nare in the database. Sort the output by the brand name (Figure P7.51).FIGURE P7.48  SALARY HISTORY FOR SELECTED EMPLOYEES  \\nFIGURE P7.46  EMPLOYEES HIRED FROM 2003 – 2012  \\nFIGURE P7.47  CLERKS AND EMPLOYEES IN DEPARTMENT 300  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ec2fb17b-9ee8-4d30-8d3f-feb90fc405b1', embedding=None, metadata={'page_label': '319', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    319\\n52. Write a query to display the number of products in each category that have a water \\nbase (Figure P7.52).\\n53. Write a query to display the number of products within each base and type \\n combination (Figure P7.53).\\n54. Write a query to display the total inventory—that is, the sum of all products on hand \\nfor each brand ID. Sort the output by brand ID in descending order (Figure P7.54).FIGURE P7.49   CUSTOMERS WHO PURCHASED FORESTERS BEST TOP \\nCOAT  \\nFIGURE P7.51  NUMBER OF PRODUCTS OF EACH BRAND  \\nFIGURE P7.50  EMPLOYEES WITH THE TITLE OF ASSOCIATE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ca2df79d-2bc1-40fc-9d45-3f468b0082f5', embedding=None, metadata={'page_label': '320', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='320   Part 3     Advanced Design and Implementation\\n55. Write a query to display the brand ID, brand name, and average price of products \\nof each brand. Sort the output by brand name. (Results are shown with the average \\nprice rounded to two decimal places.) (Figure P7.55.)\\n56. Write a query to display the department number and most recent employee hire date \\nfor each department. Sort the output by department number (Figure P7.56).FIGURE P7.54  TOTAL INVENTORY OF EACH BRAND OF PRODUCTS  \\nFIGURE P7.55  AVERAGE PRICE OF PRODUCTS OF EACH BRAND  \\nFIGURE P7.56  MOST RECENT HIRE IN EACH DEPARTMENT  \\nFIGURE P7.52   NUMBER OF WATER-BASED PRODUCTS IN EACH \\nCATEGORY  \\nFIGURE P7.53  NUMBER OF PRODUCTS OF EACH BASE AND TYPE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='23d0f5ce-1f58-4ae6-a32f-863b14da82ed', embedding=None, metadata={'page_label': '321', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    321\\n57. Write a query to display the employee number, first name, last name, and largest \\n salary amount for each employee in department 200. Sort the output by largest \\n salary in descending order (Figure P7.57).\\n58. Write a query to display the customer code, first name, last name, and sum of all \\ninvoice totals for customers with cumulative invoice totals greater than $1,500. Sort \\nthe output by the sum of invoice totals in descending order (Figure P7.58).\\n59. Write a query to display the department number, department name, department \\nphone number, employee number, and last name of each department manager. Sort \\nthe output by department name (Figure P7.59).\\n60. Write a query to display the vendor ID, vendor name, brand name, and number of \\nproducts of each brand supplied by each vendor. Sort the output by vendor name \\nand then by brand name (Figure P7.60).FIGURE P7.57   LARGEST SALARY AMOUNT FOR EACH EMPLOYEE IN \\nDEPARTMENT 200  \\nFIGURE P7.58   LIST OF CUSTOMERS WITH CUMULATIVE PURCHASES OF \\nMORE THAN $1,500  \\nFIGURE P7.59  DEPARTMENT MANAGERS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58f2f1f8-9666-4142-ac1c-ecf15d656e73', embedding=None, metadata={'page_label': '322', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='322   Part 3     Advanced Design and Implementation\\n61. Write a query to display the employee number, last name, first name, and sum \\nof invoice totals for all employees who completed an invoice. Sort the output by \\nemployee last name and then by first name (Figure P7.61).\\n63. Write a query to display the brand ID, brand name, brand type, and average price \\nof products for the brand that has the largest average product price (Figure P7.63).\\n64. Write a query to display the manager name, department name, department phone \\nnumber, employee name, customer name, invoice date, and invoice total for the \\ndepartment manager of the employee who made a sale to a customer whose last \\nname is Hagan on May 18, 2015 (Figure P7.64).62. Write a query to display the largest average product price of any brand (Figure P7.62).FIGURE P7.60   NUMBER OF PRODUCTS OF EACH BRAND SUPPLIED BY \\nEACH VENDOR  \\nFIGURE P7.61   TOTAL VALUE OF INVOICES COMPLETED BY EACH \\nEMPLOYEE  \\nFIGURE P7.62  LARGEST AVERAGE BRAND PRICE  \\nFIGURE P7.63  BRAND WITH HIGHEST AVERAGE PRICE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b872cacd-1d9d-4275-8cfc-cd4659bb2c72', embedding=None, metadata={'page_label': '323', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    323\\nThe CIS Department at Tiny College maintains the Free Access to Current Technology (FACT) \\nlibrary of ebooks. FACT is a collection of current technology ebooks for use by faculty and stu -\\ndents. Agreements with the publishers allow patrons to electronically check out a book, which \\ngives them exclusive access to the book online through the FACT website, but only one patron \\nat a time can have access to a book. A book must have at least one author but can have many. \\nAn author must have written at least one book to be included in the system, but may have writ -\\nten many. A book may have never been checked out, but can be checked out many times by the \\nsame patron or different patrons over time. Because all faculty and staff in the department are \\ngiven accounts at the online library, a patron may have never checked out a book or they may \\nhave checked out many books over time. To simplify determining which patron currently has \\na given book checked out, a redundant relationship between BOOK and PATRON is main -\\ntained. The ERD for this system is shown in Figure P7.65 and should be used to answer Prob -\\nlems 65–95. For Problems 66–95, a figure of the correct output is provided for each problem. If \\nthe output of the query is very large, only the first several rows of the output are shown.\\n65. Write a query that displays the book title, cost and year of publication for every book \\nin the system.FIGURE P7.64   MANAGER OF EMPLOYEE MAKING A SALE TO CUSTOMER \\nHAGAN  \\nFIGURE P7.65  THE CH07_FACT ERD  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cb2ac039-4366-440b-8c99-b3f52a241d6a', embedding=None, metadata={'page_label': '324', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='324   Part 3     Advanced Design and Implementation\\n66. Write a query that displays the first and last name of every patron (Figure P7.66). (50 rows)\\n67. Write a query to display the checkout number, checkout date, and due date for every \\nbook that has been checked out (Figure P7.67). (68 rows)\\n68. Write a query to display the book number, book title, and year of publication for \\nevery book (Figure P7.68).\\nFIGURE P7.69  UNIQUE BOOK YEARS  \\nFIGURE P7.67  ALL CHECKOUTS  \\nFIGURE P7.66  ALL PATRON NAMES  \\nFIGURE P7.68  TITLE AND YEAR FOR ALL BOOKS  \\n69. Write a query to display the different years in which books have been published. \\nInclude each year only once (Figure P7.69).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a41c123f-8e06-47a5-be54-bf8c2d0899bb', embedding=None, metadata={'page_label': '325', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    325\\n70. Write a query to display the different subjects on which FACT has books. Include \\neach subject only once (Figure P7.70).\\n71. Write a query to display the book number, title, and cost of each book (Figure P7.71).\\n72. Write a query to display the checkout number, book number, patron ID, checkout \\ndate, and due date for every checkout that has ever occurred in the system. Sort the \\nresults by checkout date in descending order (Figure P7.72). (68 rows)\\n73. Write a query to display the book title, year, and subject for every book. Sort the \\nresults by book subject in ascending order, year in descending order, and then title \\nin ascending order (Figure P7.73).\\n74. Write a query to display the book number, title, and year of publication for all books \\npublished in 2012 (Figure P7.74).\\n75. Write a query to display the book number, title, and year of publication for all books \\nin the “Database” subject (Figure P7.75).FIGURE P7.71  TITLE AND REPLACEMENT COST FOR BOOKS  \\nFIGURE P7.70  UNIQUE BOOK SUBJECTS  \\nFIGURE P7.72  CHECKOUTS BY DATE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f4eb7fa6-c723-45fc-9e3e-cd452fcee15f', embedding=None, metadata={'page_label': '326', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='326   Part 3     Advanced Design and Implementation\\n76. Write a query to display the checkout number, book number, and checkout date of \\nall books checked out before April 5, 2015 (Figure P7.76).\\n77. Write a query to display the book number, title, and year of publication of all books \\npublished after 2013 and on the “Programming” subject (Figure P7.77).FIGURE P7.74  BOOKS PUBLISHED IN 2012  \\nFIGURE P7.75  DATABASE BOOKS  \\nFIGURE P7.73  BOOKS BY CASCADING SORT  \\nFIGURE P7.76  CHECKOUTS BEFORE APRIL 5TH \\nFIGURE P7.77  NEWER BOOKS ON PROGRAMMING  \\n78. Write a query to display the book number, title, year of publication, subject, and cost \\nfor all books that are on the subjects of “Middleware” or “Cloud, ” and that cost more \\nthan $70 (Figure P7.78).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04067537-3ca9-4686-9fdd-c2585077dd95', embedding=None, metadata={'page_label': '327', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    327\\n79. Write a query to display the author ID, first name, last name, and year of birth for \\nall\\xa0authors born in the decade of the 1980s (Figure P7.79).\\n80. Write a query to display the book number, title, and year of publication for all books \\nthat contain the word “Database” in the title, regardless of how it is  capitalized \\n (Figure P7.80).\\n81. Write a query to display the patron ID, first and last name of all patrons who are \\nstudents (Figure P7.81). (44 rows)\\n82. Write a query to display the patron ID, first and last name, and patron type for all \\npatrons whose last name begins with the letter “C” (Figure P7.82).FIGURE P7.78  EXPENSIVE MIDDLEWARE OR CLOUD BOOKS  \\nFIGURE P7.80  BOOK TITLES CONTAINING DATABASE  \\nFIGURE P7.79  AUTHORS BORN IN THE 1980S  \\nFIGURE P7.81  STUDENT PATRONS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5c454869-fbd8-4731-99d2-64fb8971fc54', embedding=None, metadata={'page_label': '328', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='328   Part 3     Advanced Design and Implementation\\n83. Write a query to display the author ID, first and last name of all authors whose year \\nof birth is unknown (Figure P7.83).\\n84. Write a query to display the author ID, first and last name of all authors whose year \\nof birth is known (Figure P7.84).\\n85. Write a query to display the checkout number, book number, patron ID, checkout \\ndate, and due date for all checkouts that have not yet been returned. Sort the results \\nby book number (Figure P7.85).\\n86. Write a query to display the author ID, first name, last name, and year of birth for all \\nauthors. Sort the results in descending order by year of birth, and then in ascending \\norder by last name (Figure P7.86). ( Note:  Some DBMS sort NULLs as being large \\nand some DBMS sort NULLs as being small.)FIGURE P7.83  AUTHORS WITH UNKNOWN BIRTH YEAR  \\nFIGURE P7.82  PATRONS WHOSE LAST NAME STARTS WITH ’C’  \\nFIGURE P7.84  AUTHORS WITH KNOWN BIRTH YEAR  \\nFIGURE P7.85  UNRETURNED CHECKOUTS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='090ddc50-ebc3-42cc-b782-881d1f0ab464', embedding=None, metadata={'page_label': '329', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    329\\n87. Write a query to display the number of books in the FACT system (Figure P7.87).\\n89. Write a query to display the number of books that are available (not currently \\nchecked out) (Figure P7.89).\\n90. Write a query to display the highest book cost in the system (Figure P7.90).88. Write a query to display the number of different book subjects in the FACT system \\n(Figure P7.88).FIGURE P7.86  AUTHORS BY BIRTH YEAR  \\nFIGURE P7.87  NUMBER OF BOOKS  \\nFIGURE P7.88  NUMBER OF DIFFERENT SUBJECTS  \\nFIGURE P7.89  NUMBER OF BOOKS NOT CURRENTLY CHECKED OUT  \\nFIGURE P7.90  MOST EXPENSIVE BOOK PRICE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9d5eb097-33c0-4c5c-b3f2-232c426f7a75', embedding=None, metadata={'page_label': '330', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='330   Part 3     Advanced Design and Implementation\\n92. Write a query to display the number of different patrons who have ever checked out \\na book (Figure P7.92).\\n93. Write a query to display the subject and the number of books in each subject. Sort \\nthe results by the number of books in descending order, then by subject name in \\nascending order (Figure P7.93).\\n94. Write a query to display the author ID and the number of books written by that \\nauthor. Sort the results in descending order by number of books, then in ascending \\norder by author ID (Figure P7.94).\\n95. Write a query to display the total value of all books in the library (Figure P7.95).FIGURE P7.92  DIFFERENT PATRONS TO CHECKOUT A BOOK  \\nFIGURE P7.94  NUMBER OF BOOKS PER AUTHOR  \\n91. Write a query to display the lowest book cost in the system (Figure P7.91).\\nFIGURE P7.91  LEAST EXPENSIVE BOOK PRICE  \\nFIGURE P7.93  NUMBER OF BOOKS PER SUBJECT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='21b344ba-73ab-4774-8d5a-2c44dfbaefae', embedding=None, metadata={'page_label': '331', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    331\\n96. Write the SQL code to create the table structures for the entities shown in Figure \\nP7.96. The structures should contain the attributes specified in the ERD. Use data \\ntypes that are appropriate for the data that will need to be stored in each attribute. \\nEnforce primary key and foreign key constraints as indicated by the ERD.\\n97. The following tables provide a very small portion of the data that will be kept in the \\ndatabase. The data needs to be inserted into the database for testing purposes. Write \\nthe INSERT commands necessary to place the following data in the tables that were \\ncreated in Problem 96.FIGURE P7.95  TOTAL OF ALL BOOKS  \\nFIGURE P7.96  THE CH07_MOVIECO ERD  \\nEliteVideo is a startup company providing concierge DVD kiosk service in upscale \\nneighborhoods. EliteVideo can own several copies (VIDEO) of each movie (MOVIE). \\nFor example, a kiosk may have 10 copies of the movie Twist in the Wind . In the database, \\nTwist in the Wind  would be one MOVIE, and each copy would be a VIDEO. A rental \\ntransaction (RENTAL) involves one or more videos being rented to a member (MEM -\\nBERSHIP). A video can be rented many times over its lifetime; therefore, there is an \\nM:N relationship between RENTAL and VIDEO. DETAILRENTAL is the bridge table to \\nresolve this relationship. The complete ERD is provided in Figure P7.96.\\nCases\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58578287-2d6d-4e63-a2e0-306e02b97b42', embedding=None, metadata={'page_label': '332', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='332   Part 3    Advanced Design and Implementation\\nMEMBERSHIP\\nMEM \\nNUMMEM_FNAMEMEM_LNAMEMEM_STREET MEM_CITY MEM_\\nSTATEMEM_ZIPMEM_BALANCE\\n102 Tami Dawson 2632 Takli Circle Norene TN 37136 11\\n103 Curt Knight 4025 Cornell Court Flatgap KY 41219 6\\n104 Jamal Melendez 788 East 145th Avenue Quebeck TN 38579 0\\n105 Iva Mcclain 6045 Musket Ball Circle Summit KY 42783 15\\n106 Miranda Parks 4469 Maxwell Place Germantown TN 38183 0107 Rosario Elliott 7578 Danner Avenue Columbia TN 38402 5108 Mattie Guy 4390 Evergreen Street Lily KY 40740 0\\n109 Clint Ochoa 1711 Elm Street Greeneville TN 37745 10110 Lewis Rosales 4524 Southwind Circle Counce TN 38326 0111 Stacy Mann 2789 East Cook Avenue Murfreesboro TN 37132 8112 Luis Trujillo 7267 Melvin Avenue Heiskell TN 37754 3113 Minnie Gonzales 6430 Vasili Drive Williston TN 38076 0\\nRENTAL\\nRENT_NUM RENT_DATE MEM_NUM\\n1001 01-MAR-16 103\\n1002 01-MAR-16 105\\n1003 02-MAR-16 102\\n1004 02-MAR-16 110\\n1005 02-MAR-16 111\\n1006 02-MAR-16 107\\n1007 02-MAR-16 104\\n1008 03-MAR-16 105\\n1009 03-MAR-16 111\\nDETAILRENTALRENT_\\nNUMVID_NUM DETAIL_FEE DETAIL_DUEDATE DETAIL_RETURNDATE DETAIL_  \\nDAILYLATEFEE\\n1001 34342 2 04-MAR-16 02-MAR-16\\n1001 61353 2 04-MAR-16 03-MAR-16 1\\n1002 59237 3.5 04-MAR-16 04-MAR-16 3\\n1003 54325 3.5 04-MAR-16 09-MAR-16 3\\n1003 61369 2 06-MAR-16 09-MAR-16 1\\n1003 61388 0 06-MAR-16 09-MAR-16 1\\n1004 44392 3.5 05-MAR-16 07-MAR-16 3\\n1004 34367 3.5 05-MAR-16 07-MAR-16 3\\n1004 34341 2 07-MAR-16 07-MAR-16 1\\n1005 34342 2 07-MAR-16 05-MAR-16 1\\n1005 44397 3.5 05-MAR-16 05-MAR-16 3\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2ab7fa81-e60f-4ed2-8f28-72a119202011', embedding=None, metadata={'page_label': '333', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    333\\nDETAILRENTAL\\nRENT_\\nNUMVID_NUM DETAIL_FEE DETAIL_DUEDATE DETAIL_RETURNDATE DETAIL_  \\nDAILYLATEFEE\\n1006 34366 3.5 05-MAR-16 04-MAR-16 3\\n1006 61367 2 07-MAR-16 1\\n1007 34368 3.5 05-MAR-16 3\\n1008 34369 3.5 05-MAR-16 05-MAR-16 3\\n1009 54324 3.5 05-MAR-16 3\\n1001 34366 3.5 04-MAR-16 02-MAR-16 3\\nVIDEO\\nVID_NUM VID_INDATE MOVIE_NUM\\n54321 18-JUN-15 1234\\n54324 18-JUN-15 1234\\n54325 18-JUN-15 1234\\n34341 22-JAN-14 1235\\n34342 22-JAN-14 1235\\n34366 02-MAR-16 1236\\n34367 02-MAR-16 1236\\n34368 02-MAR-16 1236\\n34369 02-MAR-16 1236\\n44392 21-OCT-15 1237\\n44397 21-OCT-15 1237\\n59237 14-FEB-16 1237\\n61388 25-JAN-14 1239\\n61353 28-JAN-13 1245\\n61354 28-JAN-13 1245\\n61367 30-JUL-15 1246\\n61369 30-JUL-15 1246\\nMOVIEMOVIE_\\nNUMMOVIE_TITLE MOVIE_YEAR MOVIE_COST MOVIE_GENRE PRICE_CODE\\n1234 The Cesar Family Christmas 2014 39.95 FAMILY 2\\n1235 Smokey Mountain Wildlife 2011 59.95 ACTION 1\\n1236 Richard Goodhope 2015 59.95 DRAMA 2\\n1237 Beatnik Fever 2014 29.95 COMEDY 2\\n1238 Constant Companion 2015 89.95 DRAMA\\n1239 Where Hope Dies 2005 25.49 DRAMA 3\\n1245 Time to Burn 2012 45.49 ACTION 1\\n1246 What He Doesn’t Know 2013 58.29 COMEDY 1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2de899de-17d4-4a7c-b6b9-11b3ac1fb34d', embedding=None, metadata={'page_label': '334', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='334   Part 3     Advanced Design and Implementation\\nPRICE\\nPRICE_CODE PRICE_DESCRIPTION PRICE_RENTFEE PRICE_DAILYLATEFEE\\n1 Standard 2 1\\n2 New Release 3.5 3\\n3 Discount 1.5 1\\n4 Weekly Special 1 .5\\nFor Questions 98–127, use the tables that were created in Problem 96 and the data that \\nwas loaded into those tables in Problem 97.\\n98. Write the SQL command to save the rows inserted in Problem 97.\\n99. Write the SQL command to change the movie year for movie number 1245 to 2013.\\n100.  Write the SQL command to change the price code for all action movies to price \\ncode 3.\\n101. Write a single SQL command to increase all price rental fee values in the PRICE \\ntable by $0.50.\\n102. Write the SQL command to save the changes made to the PRICE and MOVIE tables \\nin Problems 98–101.\\n103. Write a query to display the movie title, movie year, and movie genre for all movies. \\n(The results are shown in Figure P7.103.)\\nFIGURE P7.103  ALL MOVIES  \\nFIGURE P7.104  MOVIES BY YEAR  \\n104. Write a query to display the movie year, movie title, and movie cost sorted by movie \\nyear in descending order. (The results are shown in Figure P7.104.)\\n105. Write a query to display the movie title, movie year, and movie genre for all movies \\nsorted by movie genre in ascending order, then sorted by movie year in descending \\norder within genre. (The results are shown in Figure P7.105.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e954fc9a-749a-4b4d-83dc-3e312323de19', embedding=None, metadata={'page_label': '335', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    335\\n106. Write a query to display the movie number, movie title, and price code for all movies \\nwith a title that starts with the letter R. (The results are shown in Figure P7.106.)\\n107. Write a query to display the movie title, movie year, and movie cost for all movies \\nthat contain the word hope  in the title. Sort the results in ascending order by title. \\n(The results are shown in Figure P7.107.)\\n108. Write a query to display the movie title, movie year, and movie genre for all action \\nmovies. (The results are shown in Figure P7.108.)\\n109. Write a query to display the movie number, movie title, and movie cost for all movies \\nthat cost more than $40. (The results are shown in Figure P7.109.)\\n110. Write a query to display the movie number, movie title, movie cost, and movie genre \\nfor all action or comedy movies that cost less than $50. Sort the results in ascending \\norder by genre. (The results are shown in Figure P7.110.)FIGURE P7.105  MOVIES WITH MULTICOLUMN SORT  \\nFIGURE P7.106  MOVIES STARTING WITH R \\nFIGURE P7.107  MOVIES WITH “HOPE”  \\nFIGURE P7.108  ACTION MOVIES  \\nFIGURE P7.109  MOVIES COSTING MORE THAN $40  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='33c30c77-6cf9-454a-8072-06bb45060ccd', embedding=None, metadata={'page_label': '336', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='336   Part 3     Advanced Design and Implementation\\n111. Write a query to display the membership number, name, street, state, and balance \\nfor all members in Tennessee (TN), with a balance less than $5, and whose street \\nname ends in “ Avenue” . (The results are shown in Figure P7.111.)\\n112. Write a query to display the movie genre and the number of movies in each genre. \\n(The results are shown in Figure P7.112.)\\n113. Write a query to display the average cost of all the movies. (The results are shown \\nin\\xa0Figure P7.113.)\\n114. Write a query to display the movie genre and average cost of movies in each genre. \\n(The results are shown in Figure P7.114.)\\n115. Write a query to display the movie title, movie genre, price description, and price \\nrental fee for all movies with a price code. (The results are shown in Figure P7.115.)FIGURE P7.110  ACTION OR COMEDY MOVIES LESS THAN $50  \\nFIGURE P7.113  AVERAGE MOVIE COST  \\nFIGURE P7.114  AVERAGE COST BY GENRE  \\nFIGURE P7.111  MEMBERS WITH MULTIPLE RESTRICTIONS  \\nFIGURE P7.112  NUMBER OF MOVIES IN GENRE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='11f3eb82-d3e3-48fa-b72b-250b8befc214', embedding=None, metadata={'page_label': '337', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    337\\n116. Write a query to display the movie genre and average rental fee for movies in each \\ngenre that have a price. (The results are shown in Figure P7.116.)\\n117. Write a query to display the movie title and breakeven amount for each movie that \\nhas a price. The breakeven amount is the movie cost divided by the price rental fee \\nfor each movie that has a price; it determines the number of rentals needed to break \\neven on the purchase of the movie. (The results are shown in Figure P7.117.)\\n118. Write a query to display the movie title and movie year for all movies that have \\na\\xa0price code. (The results are shown in Figure P7.118.)\\n119. Write a query to display the movie title, movie genre, and movie cost for all movies \\nthat cost between $44.99 and $49.99. (The results are shown in Figure P7.119.)FIGURE P7.115  RENTAL FEES FOR MOVIES  \\nFIGURE P7.116  AVERAGE RENTAL FEE BY GENRE  \\nFIGURE P7.117  BREAKEVEN RENTALS  \\nFIGURE P7.118  MOVIES WITH A PRICE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='07b89193-789f-4c46-9ec8-14081394c898', embedding=None, metadata={'page_label': '338', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='338   Part 3     Advanced Design and Implementation\\n120. Write a query to display the movie title, price description, price rental fee, and genre \\nfor all movies that are in the genres of family, comedy, or drama. (The results are \\nshown in Figure P7.120.)FIGURE P7.119  MOVIES COSTS WITHIN A RANGE  \\nFIGURE P7.120  MOVIES WITHIN SPECIFIC GENRES  \\nFIGURE P7.121  BALANCES OF MEMBERSHIPS WITH RENTALS  \\nFIGURE P7.122  MINIMUM, MAXIMUM, AND AVERAGE BALANCES  \\n121. Write a query to display the membership number, first name, last name, and balance \\nof the memberships that have a rental. (The results are shown in Figure P7.121.)\\n122.  Write a query to display the minimum balance, maximum balance, and aver -\\nage balance for memberships that have a rental. (The results are shown in  \\nFigure P7.122.)\\n123.  Write a query to display the rental number, rental date, video number, movie \\ntitle, due date, and return date for all videos that were returned after the due \\ndate. Sort the results by rental number and movie title. (The results are shown \\nin Figure P7.123.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4b970a84-1abe-4bba-a642-266251711e7e', embedding=None, metadata={'page_label': '339', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 7    Introduction to Structured Query Language (SQL)    339\\n124. Write a query to display the rental number, rental date, movie title, and detail fee for \\neach movie that was returned on or before the due date. (The results are shown in \\nFigure P7.124.)\\n125. Write a query to display the movie number, movie genre, average cost of movies in \\nthat genre, cost of the individual movie, and the percentage difference between the \\naverage movie cost and the individual movie cost. The results are shown in Figure \\nP7.125. The percentage difference is the cost of the individual movie minus the aver -\\nage cost of movies in that genre, divided by the average cost of movies in that genre \\nmultiplied by 100. For example, if the average cost of movies in the family genre is \\n$25 and a given family movie costs $26, then the calculation would be [(26 − 25) / 25 \\n* 100], or 4.00 percent. In this case, the individual movie costs 4 percent more than \\nthe average family movie.\\nFIGURE P7.125  MOVIE DIFFERENCES FROM GENRE AVERAGE  \\nFIGURE P7.123  LATE VIDEO RETURNS  \\nFIGURE P7.124  ACTUAL RENTAL FEES CHARGED  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4262190a-2a5a-4602-9a16-5679451741a3', embedding=None, metadata={'page_label': '340', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 8\\nAdvanced SQL\\nIn this chapter, you will learn:\\n• How to use the advanced SQL JOIN operator syntax\\n• About the different types of subqueries and correlated queries\\n• How to use SQL functions to manipulate dates, strings, and other data\\n• About the relational set operators UNION, UNION ALL, INTERSECT, and MINUS\\n• How to create and use views and updatable views\\n• How to create and use triggers and stored procedures\\n• How to create embedded SQL\\nPreviewIn Chapter 7, Introduction to Structured Query Language (SQL), you learned the basic \\nSQL data definition and data manipulation commands. In this chapter, you build on that knowledge and learn how to use more advanced SQL features.\\nY ou will learn about the SQL relational set operators (UNION, INTERSECT, and MINUS) \\nand learn how they are used to merge the results of multiple queries. Joins are at the heart of SQL, so you must learn how to use the SQL JOIN statement to extract \\n information \\nfrom multiple tables. Y ou will also learn about the different styles of  subqueries that you \\ncan implement in a SELECT statement and about more of SQL ’s many  functions to extract \\ninformation from data, including manipulation of dates and strings and  computations \\nbased on stored or even derived data.\\nFinally, you will learn how to use triggers and stored procedures to perform actions \\nwhen a specific event occurs. Y ou will also see how SQL facilitates the application of \\n business procedures when it is embedded in a programming language such as Visual Basic .NET, C#, or COBOL.\\nData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH08_SaleCo              P\\t P\\t P\\t P\\nCH08_UV  P\\t P\\t P\\t PCH08_SimpleCo  P\\t P\\t P\\t P\\nCH08_LargeCo  P\\t P\\t P\\t P\\nCH08_SaleCo2  P\\t P\\t P\\t P\\nCH08_AviaCo  P\\t P\\t P\\t P\\nCH08_Fact  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nData Files Available on cengagebrain.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c268b8b-d4b7-4501-9212-9bd00e28743b', embedding=None, metadata={'page_label': '341', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    341\\n8-1 SQL Join Operators\\nThe relational join operation merges rows from two tables and returns the rows with one \\nof the following conditions:\\n• Have common values in common columns (natural join).\\n• Meet a given join condition (equality or inequality).\\n• Have common values in common columns or have no matching values (outer join).\\nIn Chapter 7, you learned how to use the SELECT statement in conjunction with the \\nWHERE clause to join two or more tables. For example, you can join the PRODUCT and \\nVENDOR tables through their common V_CODE by writing the following:\\nSELECT P_CODE, P_DESCRIPT, P_PRICE, V_NAME\\nFROM PRODUCT, VENDOR\\nWHERE PRODUCT.V_CODE = VENDOR.V_CODE;\\nThe preceding SQL join syntax is sometimes referred to as an “old-style” join. Note \\nthat the FROM clause contains the tables being joined and that the WHERE clause \\n contains the condition(s) used to join the tables.\\nNote the following points about the preceding query:\\n• The FROM clause indicates which tables are to be joined. If three or more tables are \\nincluded, the join operation takes place two tables at a time, from left to right. For example, if you are joining tables T1, T2, and T3, the first join is table T1 with T2; the results of that join are then joined to table T3.\\n•\\n The join condition in the WHERE clause tells the SELECT statement which rows will be returned. In this case, the SELECT statement returns all rows for which the V_CODE values in the PRODUCT and VENDOR tables are equal.\\n•\\n The number of join conditions is always equal to the number of tables being joined minus one. For example, if you join three tables (T1, T2, and T3), you will have \\ntwo join conditions (j1 and j2). All join conditions are connected through an AND \\n logical operator. The first join condition (j1) defines the join criteria for T1 and T2. The \\n second join condition (j2) defines the join criteria for the output of the first join \\nand T3.\\n• Generally, the join condition will be an equality comparison of the primary key in one table and the related foreign key in the second table.\\nJoin operations can be classified as inner joins and outer joins. The inner join is \\nthe traditional join in which only rows that meet a given criterion are selected. The join \\n criterion can be an equality condition (also called a natural join or an equijoin ) \\nor an inequality condition (also called a theta join ). An outer join returns not only \\nthe  matching rows but the rows with unmatched attribute values for one table or \\nboth tables to be joined. The SQL standard also introduces a special type of join, called a cross join, that returns the same result as the Cartesian product of two sets or tables.\\nIn this section, you will learn various ways to express join operations that meet the \\nANSI SQL standard, as outlined in Table 8.1. Remember that not all DBMS vendors \\n provide the same level of SQL support and that some do not support the join styles shown in this section. Oracle 12c is used to demonstrate the following queries; refer to your DBMS manual if you are using a different DBMS.inner join\\nA join operation in which only rows that meet a given criterion are selected. The join criterion can be an equality condition (natural join or equijoin) or an inequality condition (theta join). The inner join is the most commonly used type of join. Contrast with outer join.\\nouter join\\nA join operation that produces a table in which all unmatched pairs are retained; unmatched values in the related table are left null. Contrast with inner join.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7a3d7988-4b27-4d17-94bf-a2e871398261', embedding=None, metadata={'page_label': '342', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='342   Part 3    Advanced Design and Implementation\\nTABLE 8.1\\nSQL JOIN EXPRESSION STYLES\\nJOIN \\n CLASSIFICATIONJOIN \\nTYPESQL SYNTAX EXAMPLE DESCRIPTION\\nCROSS CROSS JOINSELECT *FROM T1, T2Returns the Cartesian product of T1 and T2  (old style)\\nSELECT *FROM T1 CROSS JOIN T2Returns the Cartesian product of T1 and T2\\nINNER Old-style JOINSELECT *FROM T1, T2WHERE T1.C1=T2.C1Returns only the rows that meet the join \\n condition in the WHERE clause (old style); only rows with matching values are selected\\nNATURAL JOINSELECT *FROM T1 NATURAL JOIN T2Returns only the rows with matching values in the matching columns; the matching columns must have the same names and similar data types\\nJOIN USINGSELECT *FROM T1 JOIN T2 USING (C1)Returns only the rows with matching values in the columns indicated in the USING clause\\nJOIN ON SELECT *\\nFROM T1 JOIN T2 ON T1.C1=T2.C1Returns only the rows that meet the join \\n condition indicated in the ON clause\\nOUTER LEFT JOINSELECT *FROM T1 LEFT OUTER JOIN T2ON T1.C1=T2.C1Returns rows with matching values and includes all rows from the left table (T1) with unmatched values\\nRIGHT JOINSELECT *FROM T1 RIGHT OUTER JOIN T2ON T1.C1=T2.C1Returns rows with matching values and includes all rows from the right table (T2) with unmatched values\\nFULL JOINSELECT *FROM T1 FULL OUTER JOIN T2ON T1.C1=T2.C1Returns rows with matching values and \\n includes \\nall rows from both tables (T1 and T2) with \\n unmatched values\\n8-1a  Cross Join\\nA cross join performs a relational product (also known as the Cartesian product ) of two \\ntables. The cross join syntax is:\\nSELECT column-list  FROM table1  CROSS JOIN table2\\nFor example, the following command:SELECT * FROM INVOICE CROSS JOIN LINE;performs a cross join of the INVOICE and LINE tables that generates 144 rows. (There\\xa0are \\n8 invoice rows and 18 line rows, yielding 8 × 18 = 144 rows.)\\nY ou can also perform a cross join that yields only specified attributes. For example, \\nyou can specify:\\nSELECT\\n INVOICE.INV_NUMBER, CUS_CODE, INV_DATE, P_CODE\\nFROM   INVOICE CROSS JOIN LINE;\\nThe results generated through that SQL statement can also be generated by using the \\nfollowing syntax:\\nSELECT  INVOICE.INV_NUMBER, CUS_CODE, INV_DATE, P_CODE\\nFROM   INVOICE, LINE;cross join\\nA join that performs a \\nrelational product (or Cartesian product) of two tables.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='743ebf89-569e-431f-acb8-cd4f08f7819c', embedding=None, metadata={'page_label': '343', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    343\\n8-1b  Natural Join\\nRecall from Chapter 3 that a natural join returns all rows with matching values in the \\nmatching columns and eliminates duplicate columns. This style of query is used when the tables share one or more common attributes with common names. The natural join syntax is:\\nSELECT column-list  FROM table1  NATURAL JOIN table2\\nThe natural join will perform the following tasks:\\n•\\n Determine the common attribute(s) by looking for attributes with identical names \\nand compatible data types.\\n• Select only the rows with common values in the common attribute(s).\\n• If there are no common attributes, return the relational product of the two tables.\\nThe following example performs a natural join of the CUSTOMER and INVOICE \\ntables and returns only selected attributes:\\nSELECT  CUS_CODE, CUS_LNAME, INV_NUMBER, INV_DATE\\nFROM   CUSTOMER NATURAL JOIN INVOICE;\\nThe SQL code and its results are shown at the top of Figure 8.1.\\nY ou are not limited to two tables when performing a natural join. For example, you \\ncan perform a natural join of the INVOICE, LINE, and PRODUCT tables and project \\nonly selected attributes by writing the following:\\nSELECT  INV_NUMBER, P_CODE, P_DESCRIPT, LINE_UNITS, LINE_PRICE\\nFROM   INVOICE NATURAL JOIN LINE NATURAL JOIN PRODUCT;\\nThe SQL code and its results are shown at the bottom of Figure 8.1.\\nOne important difference between the natural join and the old-style join syntax is that \\nthe natural join does not require the use of a table qualifier for the common attributes. In \\nthe first natural join example, you projected CUS_CODE. However, the projection did not require any table qualifier, even though the CUS_CODE attribute appears in both the CUSTOMER and INVOICE tables. The same can be said of the INV_NUMBER attribute in the second natural join example.\\nUnlike Oracle, MS SQL Server, and MySQL, Access does not support the CROSS JOIN \\n command. However, all DBMSs support producing a cross join by placing a comma between the tables in the FROM clause.Note\\nAlthough natural joins are common in theoretical discussions of databases and DBMS functionality, they are typically discouraged in most development environments. Natural joins do not document the join condition in the code, so they are harder to maintain, and many developers do not like the DBMS “guessing” about how the tables should be joined. Oracle and MySQL support NATURAL JOIN, but MS SQL Server and Access do not.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2bb22716-7aab-41d9-b843-6d8e51e5d237', embedding=None, metadata={'page_label': '344', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='344   Part 3    Advanced Design and Implementation\\nFIGURE 8.1  NATURAL JOIN RESULTS\\n8-1c  JOIN USING  Clause\\nA second way to express a join is through the USING keyword. The query returns only \\nthe rows with matching values in the column indicated in the USING clause—and that column must exist in both tables. The syntax is:\\nSELECT column-list  FROM table1  JOIN table2  USING (common-column )\\nTo see the JOIN USING query in action, perform a join of the INVOICE and LINE \\ntables by writing the following:SELECT\\n  INV_NUMBER, P_CODE, P_DESCRIPT, LINE_UNITS, LINE_PRICE\\nFROM    INVOICE JOIN LINE USING (INV_NUMBER) JOIN PRODUCT \\nUSING (P_CODE);\\nThe SQL statement produces the results shown in Figure 8.2.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d84b825d-9174-4da2-8dd0-48dd4d5b6030', embedding=None, metadata={'page_label': '345', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    345\\nAs with the NATURAL JOIN command, the JOIN USING operand does not require \\ntable qualifiers and will only return one copy of the common attribute.\\nOracle and MySQL support the JOIN USING syntax. MS SQL Server and Access do not. \\nIf JOIN USING is used in Oracle, then table qualifiers cannot be used with the common \\n attribute anywhere within the query. MySQL will allow table qualifiers on the common attribute anywhere except in the USING clause itself.NoteFIGURE 8.2  JOIN USING RESULTS  \\n8-1d  JOIN ON  Clause\\nThe previous two join styles use common attribute names in the joining tables. Another way to express a join when the tables have no common attribute names is to use the JOIN ON operand. The query will return only the rows that meet the indicated join \\n condition. The join condition will typically include an equality comparison expression of two \\n columns. (The columns may or may not share the same name, but obviously they \\nmust have comparable data types.) The syntax is:\\nSELECT column-list  FROM table1  JOIN table2  ON join-condition\\nThe following example performs a join of the INVOICE and LINE tables using the \\nON clause. The result is shown in Figure 8.3.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b05f4195-4e67-4787-85e1-c7091a445447', embedding=None, metadata={'page_label': '346', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='346   Part 3    Advanced Design and Implementation\\nSELECT   INVOICE.INV_NUMBER, PRODUCT.P_CODE, P_DESCRIPT, \\nLINE_UNITS, LINE_PRICE\\nFROM    INVOICE JOIN LINE ON INVOICE.INV_NUMBER = LINE.INV_NUMBER\\n  JOIN PRODUCT ON LINE.P_CODE = PRODUCT.P_CODE;\\nUnlike the NATURAL JOIN and JOIN USING operands, the JOIN ON clause requires \\na table qualifier for the common attributes. If you do not specify the table qualifier, you will get a “column ambiguously defined” error message.\\nKeep in mind that the JOIN ON syntax lets you perform a join even when the tables \\ndo not share a common attribute name. For example, to generate a list of all employees with the managers’ names, you can use the following (recursive) query:\\nSELECT\\n E.EMP_MGR, M.EMP_LNAME, E.EMP_NUM, E.EMP_LNAME\\nFROM   EMP E JOIN EMP M ON E.EMP_MGR = M.EMP_NUM\\nORDER BY  E.EMP_MGR;FIGURE 8.3  JOIN ON RESULTS  \\nOracle, MS SQL Server, MySQL, and Access all support the JOIN ON syntax. In many \\n environments, including the SQL code generated by Access when queries are created \\nusing the QBE window, it is common to include the optional word INNER to the join syntax. For example,\\nSELECT\\n P .P_CODE, P .P_DESCRIPT, V.V_CODE, V.V_NAME\\nFROM  PRODUCT P INNER JOIN VENDOR V ON P .V_CODE = V.V_CODE;Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bb6b8192-d8ae-4007-8afa-08fd372ff588', embedding=None, metadata={'page_label': '347', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    347\\n8-1e  Outer Joins\\nAn outer join returns not only the rows matching the join condition (that is, rows with \\nmatching values in the common columns), it returns the rows with unmatched values. The ANSI standard defines three types of outer joins: left, right, and full. The left and right designations reflect the order in which the tables are processed by the DBMS. Remember that join operations take place two tables at a time. The first table named in the FROM clause will be the left side, and the second table named will be the right side. If three or more tables are being joined, the result of joining the first two tables becomes the left side, and the third table becomes the right side.\\nThe left outer join returns not only the rows matching the join condition (that is, rows \\nwith matching values in the common column), it returns the rows in the left table with unmatched values in the right table. The syntax is:\\nSELECT\\n column-list\\nFROM   table1  LEFT [OUTER] JOIN table2  ON join-condition\\nFor example, the following query lists the product code, vendor code, and vendor name \\nfor all products and includes those vendors with no matching products:\\nSELECT  P_CODE, VENDOR.V_CODE, V_NAME\\nFROM    VENDOR LEFT JOIN PRODUCT ON VENDOR. \\nV_CODE = PRODUCT.V_CODE;\\nThe preceding SQL code and its results are shown in Figure 8.4.\\nFIGURE 8.4  LEFT JOIN RESULTS  \\nThe right outer join returns not only the rows matching the join condition (that is, \\nrows with matching values in the common column), it returns the rows in the right table with unmatched values in the left table. The syntax is:\\nSELECT\\n column-list\\nFROM   table1  RIGHT [OUTER] JOIN table2  ON join-condition\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1decaf1a-d07a-4b0f-8d2c-84bb443a67bf', embedding=None, metadata={'page_label': '348', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='348   Part 3    Advanced Design and Implementation\\nFor example, the following query lists the product code, vendor code, and vendor \\nname for all products and includes products that do not have a matching vendor \\ncode:\\nSELECT  P_CODE, VENDOR.V_CODE, V_NAME\\nFROM    VENDOR RIGHT JOIN PRODUCT ON VENDOR. \\nV_CODE = PRODUCT.V_CODE;\\nThe SQL code and its output are shown in Figure 8.5.\\nFIGURE 8.5  RIGHT JOIN RESULTS  \\nThe full outer join returns not only the rows matching the join condition (that is, rows \\nwith matching values in the common column), it returns all of the rows with unmatched values in the table on either side. The syntax is:\\nSELECT\\n column-list\\nFROM   table1  FULL [OUTER] JOIN table2  ON join-condition\\nFor example, the following query lists the product code, vendor code, and  vendor \\nname for all products and includes all product rows (products without matching  vendors) \\nas well as all vendor rows (vendors without matching products):SELECT\\n P_CODE, VENDOR.V_CODE, V_NAME\\nFROM    VENDOR FULL JOIN PRODUCT ON VENDOR. \\nV_CODE = PRODUCT.V_CODE;\\nThe SQL code and its results are shown in Figure 8.6.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='46cb731b-4bc7-4999-9546-bf844ce6cbf1', embedding=None, metadata={'page_label': '349', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    349\\n8-2 Subqueries and Correlated Queries\\nThe use of joins in a relational database allows you to get information from two or \\nmore tables. For example, the following query allows you to get customer data with its \\n respective invoices by joining the CUSTOMER and INVOICE tables.\\nSELECT   INV_NUMBER, INVOICE.CUS_CODE, CUS_LNAME, \\nCUS_FNAME\\nFROM   CUSTOMER, INVOICE\\nWHERE  CUSTOMER.CUS_CODE = INVOICE.CUS_CODE;\\nIn the previous query, the data from both tables (CUSTOMER and INVOICE) is \\n processed at once, matching rows with shared CUS_CODE values.\\nHowever, it is often necessary to process data based on other  processed data. For \\nexample, suppose that you want to generate a list of vendors who do not provide prod-ucts. (Recall that not all vendors in the VENDOR table have provided products—some are only potential  vendors.) In Chapter 7, you learned that you could generate such a list \\nby writing the following query:\\nSELECT\\n V_CODE, V_NAME FROM VENDOR\\nWHERE  V_CODE NOT IN (SELECT V_CODE FROM PRODUCT);FIGURE 8.6  FULL JOIN RESULTS  \\nOracle and MS SQL Server support the FULL JOIN syntax. MySQL and Access do not.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7c043e8f-1763-441d-9278-549c4a8ddd55', embedding=None, metadata={'page_label': '350', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"350   Part 3    Advanced Design and Implementation\\nSimilarly, to generate a list of all products with a price greater than or equal to the average \\nproduct price, you can write the following query:\\nSELECT  P_CODE, P_PRICE FROM PRODUCT\\nWHERE  P_PRICE >= (SELECT AVG(P_PRICE) FROM PRODUCT);\\nIn both queries, you needed to get information that was not previously known:\\n• What vendors provide products?\\n• What is the average price of all products?\\nIn both cases, you used a subquery to generate the required information, which could \\nthen be used as input for the originating query. Y ou learned how to use subqueries in \\nChapter 7; review their basic characteristics:\\n• A subquery is a query (SELECT statement) inside another query.\\n• A subquery is normally expressed inside parentheses.\\n• The first query in the SQL statement is known as the outer query.\\n• The query inside the SQL statement is known as the inner query.\\n• The inner query is executed first.\\n• The output of an inner query is used as the input for the outer query.\\n• The entire SQL statement is sometimes referred to as a nested query.\\nIn this section, you learn more about the practical use of subqueries. Y ou already \\nknow that a subquery is based on the use of the SELECT statement to return one or \\nmore values to another query, but subqueries have a wide range of uses. For example, you can use a subquery within a SQL data manipulation language (DML) statement such as INSERT, UPDATE, or DELETE, in which a value or list of values (such as multiple vendor codes or a table) is expected. Table 8.2 uses simple examples to summarize the use of SELECT subqueries in DML statements.\\nTABLE 8.2\\nSELECT SUBQUERY EXAMPLES\\nSELECT SUBQUERY EXAMPLES EXPLANATION\\nINSERT INTO PRODUCT\\n   SELECT * FROM P;Inserts all rows from Table P into the PRODUCT table. Both tables must have the same attributes. The subquery returns all rows from Table P .\\nUPDATE PRODUCTSET P_PRICE = (SELECT AVG(P_PRICE)\\n      FROM PRODUCT)\\nWHERE V_CODE IN (SELECT V_CODE\\n      FROM VENDOR\\n      WHERE V_AREACODE = '615')Updates the product price to the average product price, but only for products provided by vendors who have an area code equal to 615. The first subquery returns the average price; the second subquery returns the list of vendors with an area code equal to 615.\\nDELETE FROM PRODUCTWHERE V_CODE IN (SELECT V_CODE\\n      FROM VENDOR\\n      WHERE V_AREACODE = '615')Deletes the PRODUCT table rows provided by vendors with an area code equal to 615. The subquery returns the list of vendor codes with an area code equal to 615.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='332fb87f-0364-4cff-9ebb-1dfee7c4d305', embedding=None, metadata={'page_label': '351', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    351\\nUsing the examples in Table 8.2, note that the subquery is always on the right side of  \\na comparison or assigning expression. Also, a subquery can return one or more values. \\nTo be precise, the subquery can return the following:\\n• One single value (one column and one row). This subquery is used anywhere a  single \\nvalue is expected, as in the right side of a comparison expression. An example is \\nthe preceding UPDATE subquery, in which you assigned the average price to the \\n product’s price. Obviously, when you assign a value to an attribute, you are assign-ing a single value, not a list of them. Therefore, the subquery must return only one value (one column, one row). If the query returns multiple values, the DBMS will generate an error.\\n•\\n A list of values (one column and multiple rows). This type of subquery is used any-where a list of values is expected, such as when using the IN clause—for example, when comparing the vendor code to a list of vendors. Again, in this case, there is only one column of data with multiple value instances. This type of subquery is used frequently in combination with the IN operator in a WHERE conditional expression.\\n•\\n A virtual table (multicolumn, multirow set of values). This type of subquery can be used anywhere a table is expected, such as when using the FROM clause. Y ou will see an example later in this chapter.\\nIt is important to note that a subquery can return no values at all; it is a NULL. \\nIn such cases, the output of the outer query might result in an error or a null empty set, depending on where the subquery is used (in a comparison, an expression, or  \\na table\\xa0set).\\nIn the following sections, you will learn how to write subqueries within the SELECT \\nstatement to retrieve data from the database.\\n8-2a  WHERE  Subqueries\\nThe most common type of subquery uses an inner SELECT subquery on the right side of a WHERE comparison expression. For example, to find all products with a price greater than or equal to the average product price, you write the following query:\\nSELECT\\n P_CODE, P_PRICE FROM PRODUCT\\nWHERE  P_PRICE >= (SELECT AVG(P_PRICE) FROM PRODUCT);\\nThe output of the preceding query is shown in Figure 8.7. Note that this type of query, \\nwhen used in a >, <, =, >=, or <= conditional expression, requires a subquery that returns only one value (one column, one row). The value generated by the subquery must be of a comparable data type; if the attribute to the left of the comparison symbol is a character type, the subquery must return a character string. Also, if the query returns more than  \\na single value, the DBMS will generate an error.\\nSubqueries can also be used in combination with joins. For example, the following \\nquery lists all customers who ordered a claw hammer:\\nSELECT\\n DISTINCT CUS_CODE, CUS_LNAME, CUS_FNAME  \\nFROM   CUSTOMER   JOIN INVOICE USING (CUS_CODE)\\n     JOIN LINE USING (INV_NUMBER)\\n     JOIN PRODUCT USING (P_CODE)\\nWHERE   P_CODE = (SELECT P_CODE FROM PRODUCT WHERE  \\nP_DESCRIPT = 'Claw hammer');\\nThe result of the query is shown in Figure 8.7.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed1517aa-33b4-4775-8831-3743e0b54f23', embedding=None, metadata={'page_label': '352', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"352   Part 3    Advanced Design and Implementation\\nIn the preceding example, the inner query finds the P_CODE for the claw hammer. \\nThe P_CODE is then used to restrict the selected rows to those in which the P_CODE in \\nthe LINE table matches the P_CODE for “Claw hammer. ” Note that the previous query could have been written this way:\\nSELECT\\n DISTINCT CUS_CODE, CUS_LNAME, CUS_FNAME  \\nFROM   CUSTOMER   JOIN INVOICE USING (CUS_CODE)\\n     JOIN LINE USING (INV_NUMBER)\\n     JOIN PRODUCT USING (P_CODE)\\nWHERE  P_DESCRIPT = 'Claw hammer';  \\nIf the original query encounters the “Claw hammer” string in more than one product \\ndescription, you get an error message. To compare one value to a list of values, you must use an IN operand, as shown in the next section.\\n8-2b  IN Subqueries\\nWhat if you wanted to find all customers who purchased a hammer or any kind of saw or saw blade? Note that the product table has two different types of hammers: a claw \\n hammer and a sledge hammer. Also, there are multiple occurrences of products \\nthat contain “saw” in their product descriptions, including saw blades and jigsaws. In such cases, you need to compare the P_CODE not to one product code (a single value), but to a list of product code values. When you want to compare a single attribute to a list of \\n values, you use the IN operator. When the P_CODE values are \\nnot known beforehand, but they can be derived using a query, you must use an IN subquery. The following \\n example lists all customers who have purchased hammers, \\nsaws, or saw blades.FIGURE 8.7  WHERE SUBQUERY EXAMPLES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d0f38f2e-1ccf-4fa7-a554-7acc3b3320d2', embedding=None, metadata={'page_label': '353', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    353\\nSELECT  DISTINCT CUS_CODE, CUS_LNAME, CUS_FNAME  \\nFROM   CUSTOMER   JOIN INVOICE USING (CUS_CODE)\\n     JOIN LINE USING (INV_NUMBER)\\n     JOIN PRODUCT USING (P_CODE)\\nWHERE  P_CODE IN   (SELECT P_CODE FROM PRODUCT\\n     WHERE P_DESCRIPT LIKE '%hammer%'\\n     OR P_DESCRIPT LIKE '%saw%');\\nThe result of the query is shown in Figure 8.8.\\nFIGURE 8.8  IN SUBQUERY EXAMPLE  \\n8-2c  HAVING  Subqueries\\nJust as you can use subqueries with the WHERE clause, you can use a subquery with a \\nHAVING clause. The HAVING clause is used to restrict the output of a GROUP BY query by applying conditional criteria to the grouped rows. For example, to list all \\n products \\nwith a total quantity sold greater than the average quantity sold, you would write the following query:\\nSELECT\\n P_CODE, SUM(LINE_UNITS)\\nFROM   LINE\\nGROUP BY  P_CODE\\nHAVING  SUM(LINE_UNITS) > (SELECT AVG(LINE_UNITS) FROM LINE);\\nThe result of the query is shown in Figure 8.9.\\n8-2d  Multirow Subquery Operators: ANY  and ALL\\nSo far, you have learned that you must use an IN subquery to compare a value \\nto a list of values. However, the IN subquery uses an equality operator; that is, it selects only those rows that are equal to at least one of the values in the list. What happens if you need to make an inequality comparison ( > or < ) of one value to a list of values?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61f80dd6-6312-4ad1-9914-77927837f266', embedding=None, metadata={'page_label': '354', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"354   Part 3    Advanced Design and Implementation\\nFor example, suppose you want to know which products cost more than all individual \\nproducts provided by vendors from Florida:\\nSELECT  P_CODE, P_QOH * P_PRICE  \\nFROM   PRODUCT\\nWHERE  P_QOH * P_PRICE > ALL (SELECT P_QOH * P_PRICE\\n     FROM PRODUCT\\n     WHERE V_CODE IN   (SELECT V_CODE\\n     FROM VENDOR\\n     WHERE V_STATE = 'FL'));\\nThe result of the query is shown in Figure 8.10.FIGURE 8.9  HAVING SUBQUERY EXAMPLE  \\nFIGURE 8.10  MULTIROW SUBQUERY OPERATOR EXAMPLE  \\nIt is important to note the following points about the query and its output in \\nFigure\\xa08.10:\\n• The query is a typical example of a nested query.\\n• The query has one outer SELECT statement with a SELECT subquery (call it sqA) that \\ncontains a second SELECT subquery (call it sqB).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='77a913a9-9a61-404a-b393-6a4d21017822', embedding=None, metadata={'page_label': '355', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    355\\n• The last SELECT subquery (sqB) is executed first and returns a list of all vendors from \\nFlorida.\\n• The first SELECT subquery (sqA) uses the output of the second SELECT subquery (sqB). The sqA subquery returns the list of costs for all products provided by vendors from Florida.\\n•\\n The use of the ALL operator allows you to compare a single value (P_QOH *  \\nP_PRICE) with a list of values returned by the first subquery (sqA) using a compari-son operator other than equals.\\n•\\n For a row to appear in the result set, it has to meet the criterion P_QOH * P_PRICE\\xa0> ALL of the individual values returned by the subquery sqA. The values returned by sqA are a list of product costs. In fact, “greater than ALL ” is equivalent to “greater than the highest product cost of the list. ” In the same way, a condition of “less than ALL ” is equivalent to “less than the lowest product cost of the list. ”\\nAnother powerful operator is the ANY multirow operator, which you can consider \\nthe cousin of the ALL multirow operator. The ANY operator allows you to compare a single value to a list of values and select only the rows for which the inventory cost is greater than or less than any value in the list. Y ou could use the equal to ANY operator, which would be the equivalent of the IN operator.\\n8-2e  FROM  Subqueries\\nSo far you have seen how the SELECT statement uses subqueries within WHERE, HAV -\\nING, and IN statements, and how the ANY and ALL operators are used for multirow subqueries. In all of those cases, the subquery was part of a conditional expression, and it always appeared at the right side of the expression. In this section, you will learn how to use subqueries in the FROM clause.\\nAs you already know, the FROM clause specifies the table(s) from which the \\ndata will be drawn. Because the output of a SELECT statement is another table (or more precisely, a “virtual” table), you could use a SELECT subquery in the FROM clause. For example, assume that you want to know all customers who have purchased products 13-Q2/P2 and  23109-HB. All product purchases are stored \\nin the LINE table, so you can easily find out who purchased any given product by searching the P_CODE attribute in the LINE table. In this case, however, you want to know all customers who purchased both \\n products, not just one. Y ou could write \\nthe following query:\\nSELECT  DISTINCT CUSTOMER.CUS_CODE, CUSTOMER.CUS_LNAME\\nFROM  CUSTOMER,\\n  (SELECT INVOICE.CUS_CODE FROM INVOICE NATURAL JOIN LINE\\n WHERE P_CODE = '13-Q2/P2') CP1,\\n  (SELECT INVOICE.CUS_CODE FROM INVOICE NATURAL JOIN LINE\\n WHERE P_CODE = '23109-HB') CP2\\nWHERE   CUSTOMER.CUS_CODE = CP1.CUS_CODE AND  \\nCP1.CUS_CODE = CP2.CUS_CODE;\\nThe result of the query is shown in Figure 8.11.\\nNote in Figure 8.11 that the first subquery returns all customers who purchased \\n product 13-Q2/P2, while the second subquery returns all customers who purchased \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dcec2149-7a57-435d-9728-2c27e6e356bb', embedding=None, metadata={'page_label': '356', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='356   Part 3    Advanced Design and Implementation\\nproduct 23109-HB. So, in this FROM subquery, you are joining the CUSTOMER \\ntable\\xa0 with two virtual tables. The join condition selects only the rows with matching CUS_CODE values in each table (base or virtual).\\n8-2f  Attribute List Subqueries\\nThe SELECT statement uses the attribute list to indicate what columns to project in the resulting set. Those columns can be attributes of base tables, computed attributes, or the result of an aggregate function. The attribute list can also include a subquery expression, also known as an inline subquery . A subquery in the attribute list must \\nreturn one value; otherwise, an error code is raised. For example, a simple inline query can be used to list the difference between each product’s price and the average product price:\\nSELECT\\n  P_CODE, P_PRICE, (SELECT AVG(P_PRICE) FROM PRODUCT) \\nAS AVGPRICE,\\n  P_PRICE – (SELECT AVG(P_PRICE) FROM PRODUCT) AS DIFF\\nFROM   PRODUCT;\\nFigure 8.12 shows the result of the query.\\nIn Figure 8.12, note that the inline query output returns one value (the average prod-\\nuct’s price) and that the value is the same in every row. Note also that the query uses the full expression instead of the column aliases when computing the difference. In fact, if you try to use the alias in the difference expression, you will get an error message. The column alias cannot be used in computations in the attribute list when the alias is defined in the same attribute list. That DBMS requirement is the result of the way the DBMS parses and executes queries.\\nAnother example will help you understand the use of attribute list subqueries \\nand column aliases. For example, suppose that you want to know the product code, the total sales by product, and the contribution by employee of each product’s sales. To get the sales by product, you need to use only the LINE table. To compute the contribution by employee, you need to know the number of employees (from the EMPLOYEE table). As you study the tables’ structures, you can see that the LINE and EMPLOYEE tables do not share a common attribute. In fact, you do not need a common attribute. Y ou only need to know the total number of employees, not the FIGURE 8.11  FROM SUBQUERY EXAMPLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='887b0a0e-4827-4281-abed-3ef07486f412', embedding=None, metadata={'page_label': '357', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    357\\ntotal employees related to each product. So, to answer the query, you would write the \\nfollowing code:\\nSELECT  P_CODE, SUM(LINE_UNITS * LINE_PRICE) AS SALES,\\n  (SELECT COUNT(*) FROM EMPLOYEE) AS ECOUNT,\\n   SUM(LINE_UNITS * LINE_PRICE)/(SELECT COUNT(*) FROM \\nEMPLOYEE) AS CONTRIB\\nFROM   LINE\\nGROUP BY  P_CODE;\\nThe result of the query is shown in Figure 8.13.\\nAs you can see in Figure 8.13, the number of employees remains the same for each \\nrow in the result set. The use of this type of subquery is limited to certain instances when you need to include data from other tables that is not directly related to a main table or tables in the query. The value will remain the same for each row, like a constant in a programming language. (Y ou will learn another use of inline subqueries in Section 8-2g, Correlated Subqueries.) Note that you cannot use an alias in the attribute list to write the expression that computes the contribution per employee.\\nAnother way to write the same query by using column aliases requires the use of a \\nsubquery in the FROM clause, as follows:\\nSELECT\\n P_CODE, SALES, ECOUNT, SALES/ECOUNT AS CONTRIB\\nFROM   (SELECT P_CODE, SUM(LINE_UNITS * LINE_PRICE) AS SALES,\\n     (SELECT COUNT(*) FROM EMPLOYEE) AS ECOUNT\\n  FROM   LINE\\n  GROUP BY  P_CODE);FIGURE 8.12  INLINE SUBQUERY EXAMPLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0e72de0e-4649-4cd0-a3a6-1b9e13e926f0', embedding=None, metadata={'page_label': '358', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='358   Part 3    Advanced Design and Implementation\\nIn this case, you are actually using two subqueries. The subquery in the FROM clause \\nexecutes first and returns a virtual table with three columns: P_CODE, SALES, and ECOUNT. The FROM subquery contains an inline subquery that returns the number of employees as ECOUNT. Because the outer query receives the output of the inner query, you can now refer to the columns in the outer subquery by using the column aliases.\\n8-2g  Correlated Subqueries\\nUntil now, all subqueries you have learned execute independently. That is, each subquery in a command sequence executes in a serial fashion, one after another. The inner sub-query executes first; its output is used by the outer query, which then executes until the last outer query finishes (the first SQL statement in the code).\\nIn contrast, a correlated subquery is a subquery that executes once for each row \\nin the outer query. The process is similar to the typical nested loop in a programming language. For example:\\nFOR X = 1 TO 2\\n   FOR Y = 1 TO 3\\n      PRINT “X = ”X, “Y = ”Y\\n   END\\nENDwill yield the following output:X = 1\\n Y = 1\\nX = 1  Y = 2\\nX = 1  Y = 3\\nX = 2  Y = 1\\nX = 2  Y = 2\\nX = 2  Y = 3correlated subquery\\nA subquery that \\nexecutes once for each row in the outer query.FIGURE 8.13  ANOTHER EXAMPLE OF AN INLINE SUBQUERY\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5073c743-6fcd-40fd-9e61-552bd79b7386', embedding=None, metadata={'page_label': '359', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    359\\nNote that the outer loop X = 1 TO 2 begins the process by setting X = 1, and then the \\ninner loop Y = 1 TO 3 is completed for each X outer loop value. The relational DBMS uses the same sequence to produce correlated subquery results:\\n1.\\n It initiates the outer query.\\n2. For each row of the outer query result set, it executes the inner query by passing the \\nouter row to the inner query.\\nThis process is the opposite of that of the subqueries, as you have already seen. The \\nquery is called a correlated  subquery because the inner query is related  to the outer query; \\nthe inner query references a column of the outer subquery.\\nTo see the correlated subquery in action, suppose that you want to know all product \\nsales in which the units sold value is greater than the average units sold value for that product  (as opposed to the average for all  products). In that case, the following procedure \\nmust be completed:\\n1.\\n Compute the average units sold for a product.\\n2. Compare the average computed in Step 1 to the units sold in each sale row, and then \\nselect only the rows in which the number of units sold is greater.\\nThe following correlated query completes the preceding two-step process:\\nSELECT  INV_NUMBER, P_CODE, LINE_UNITS\\nFROM   LINE LS\\nWHERE  LS.LINE_UNITS > (SELECT AVG(LINE_UNITS)\\n             FROM LINE LA\\n             WHERE LA.P_CODE = LS.P_CODE);\\nThe first example in Figure 8.14 shows the result of the query.\\nFIGURE 8.14  CORRELATED SUBQUERY EXAMPLES  \\nIn the top query and its result in Figure 8.14, note that the LINE table is used more than \\nonce, so you must use table aliases. In this case, the inner query computes the average units sold of the product that matches the P_CODE of the outer query P_CODE. That is, the \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='408e60be-16b0-431c-b3af-82feb7565e2d', embedding=None, metadata={'page_label': '360', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='360   Part 3    Advanced Design and Implementation\\ninner query runs once, using the first product code found in the outer LINE table, and it \\nreturns the average sale for that product. When the number of units sold in the outer LINE row is greater than the average computed, the row is added to the \\n output. Then the inner \\nquery runs again, this time using the second product code found in the outer LINE table. The process repeats until the inner query has run for all rows in the\\xa0outer LINE table. In this case, the inner query will be repeated as many times as there are rows in the outer query.\\nTo verify the results and to provide an example of how you can combine subqueries, \\nyou can add a correlated inline subquery to the previous query. (See the second query and its results in Figure 8.14.) As you can see, the new query contains a correlated inline subquery that computes the average units sold for each product. Y ou not only get an answer, you can also verify that the answer is correct.\\nCorrelated subqueries can also be used with the EXISTS special operator. For \\n example, \\nsuppose that you want to know the names of all customers who have placed an order lately. In that case, you could use a correlated subquery like the first one shown in Figure\\xa08.15.\\nFIGURE 8.15  EXISTS CORRELATED SUBQUERY EXAMPLES  \\nSELECT  CUS_CODE, CUS_LNAME, CUS_FNAME\\nFROM   CUSTOMER\\nWHERE  EXISTS   (SELECT  CUS_CODE FROM INVOICE\\n    WHERE  INVOICE.CUS_CODE =\\n      CUSTOMER.CUS_CODE);\\nThe second example in Figure 8.15 will help you understand how to use correlated queries. For example, suppose that you want to know what vendors you must contact to order prod-ucts that are approaching the minimum quantity-on-hand value. In \\n particular, you want \\nto know the vendor code and vendor name for products with a quantity on hand that is less than double the minimum quantity. The query that answers the question is as follows:\\nSELECT\\n V_CODE, V_NAME\\nFROM  VENDOR\\nWHERE  EXISTS  (SELECT  *\\n  FROM  PRODUCT\\n  WHERE  P_QOH < P_MIN * 2\\n  AND  VENDOR.V_CODE = PRODUCT.V_CODE);\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6980a9bd-abb3-4028-b510-5b490a3afd58', embedding=None, metadata={'page_label': '361', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    361\\nIn the second query in Figure 8.15, note that:\\n1. The inner correlated subquery runs using the first vendor.\\n2. If any products match the condition (the quantity on hand is less than double the \\nminimum quantity), the vendor code and name are listed in the output.\\n3. The correlated subquery runs using the second vendor, and the process repeats itself until all vendors are used.\\n8-3 SQL Functions\\nThe data in databases is the basis of critical business information. Generating informa-tion from data often requires many data manipulations. Sometimes such data manip-ulation involves the decomposition of data elements. For example, an employee’s date of birth can\\xa0be subdivided into a day, a month, and a year. A product manufacturing code (for example, SE-05-2-09-1234-1-3/12/16-19:26:48) can be designed to record the manufacturing region, plant, shift, production line, employee number, date, and time. For years, conventional \\n programming languages have had special functions that enabled \\nprogrammers to perform data transformations like the preceding data decompositions. If you know a modern programming language, it is very likely that the SQL functions in this section will look familiar.\\nSQL functions are very useful tools. Y ou’ll need to use functions when you want to list \\nall employees ordered by year of birth, or when your marketing department wants you to generate a list of all customers ordered by zip code and the first three digits of their telephone numbers. In both of these cases, you’ll need to use data elements that are not present as such in the database. Instead, you will need a SQL function that can be derived from an existing attribute. Functions always use a numerical, date, or string value. The value may be part of the command itself (a constant or literal) or it may be an attribute located in a table. Therefore, a function may appear anywhere in a SQL statement where a value or an attribute can be used.\\nThere are many types of SQL functions, such as arithmetic, trigonometric, string, \\ndate, and time functions. This section will not explain all of these functions in detail, but it will give you a brief overview of the most useful ones.\\nAlthough the main DBMS vendors support the SQL functions covered here, the syntax or degree of support will probably differ. In fact, DBMS vendors invariably add their own func -\\ntions to products to lure new customers. The functions covered in this section represent just a small portion of functions supported by your DBMS. Read your DBMS SQL reference manual for a complete list of available functions.Note\\n8-3a  Date and Time Functions\\nAll SQL-standard DBMSs support date and time functions. All date functions take one parameter of a date or character data type and return a value (character, numeric, or date type). Unfortunately, date/time data types are implemented differently by different DBMS vendors. The problem occurs because the ANSI SQL standard defines date data \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f266bc10-d42e-4380-96d5-a5a2adaf1cbd', embedding=None, metadata={'page_label': '362', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='362   Part 3    Advanced Design and Implementation\\ntypes, but it does not specify how those data types are to be stored. Instead, it lets the \\nvendor deal with that issue.\\nBecause date/time functions differ from vendor to vendor, this section will cover \\nbasic date/time functions for MS Access, SQL Server, and Oracle. Table 8.3 shows a list of selected MS Access and SQL Server date/time functions.\\nTABLE 8.3\\nSELECTED MS ACCESS AND SQL SERVER DATA/TIME FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nCONVERT (MS SQL Server)Convert can be used to perform a wide array of data type conversions as discussed next. It can also be used to format date data.Syntax:CONVERT(varchar(length), date_value, fmt_code)fmt_code = format used; can be:1: MM/DD/YY101: MM/DD/YYYY2: YY.MM.DD102: YYYY.MM.DD3: DD/MM/YY103: DD/MM/YYYYDisplays the product code and date the product was last received into stock for all products:SELECT\\n P_CODE, CONVERT(VARCHAR(8), P_INDATE, 1)\\nFROM  PRODUCT;\\nSELECT  P_CODE, CONVERT(VARCHAR(10), P_INDATE, 102)\\nFROM  PRODUCT;\\nYEARReturns a four-digit yearSyntax:YEAR(date_value)Lists all employees born in 1982:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n YEAR(EMP_DOB) AS YEAR\\nFROM  EMPLOYEE\\nWHERE  YEAR(EMP_DOB) = 1982;\\nMONTHReturns a two-digit month codeSyntax:MONTH(date_value)Lists all employees born in November:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n MONTH(EMP_DOB) AS MONTH\\nFROM  EMPLOYEE\\nWHERE  MONTH(EMP_DOB) = 11;\\nDAYReturns the number of the daySyntax:DAY(date_value)Lists all employees born on the 14th day of the month:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n DAY(EMP_DOB) AS DAY\\nFROM  EMPLOYEE\\nWHERE  DAY(EMP_DOB) = 14;\\nDATE() MS AccessGETDATE() SQL ServerReturns today’s dateLists how many days are left until Christmas:SELECT #25-Dec-2016# – DATE();Note two features:•\\n  There is no FROM clause, which is acceptable in Access and MS SQL Server.\\n•  The Christmas date is enclosed in number signs ( # ) because you are doing date arithmetic.\\nIn MS SQL Server:Use GETDATE() to get the current system date. To compute the difference between dates, use the DATEDIFF function (see below).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c18257a4-25e6-4559-9350-ffb053c11911', embedding=None, metadata={'page_label': '363', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    363\\nTable 8.4 shows the equivalent date/time functions used in Oracle. Note that Oracle \\nuses the same function (TO_CHAR) to extract the various parts of a date. Also, another \\nfunction (TO_DATE) is used to convert character strings to a valid Oracle date format that can be used in date arithmetic.TABLE 8.3  (CONTINUED)\\nSELECTED MS ACCESS AND SQL SERVER DATA/TIME FUNCTIONS\\nDATEADD SQL ServerAdds a number of selected time peri-ods to a dateSyntax:DATEADD(datepart, number, date)Adds a number of dateparts to a given date. Dateparts can be minutes, hours, days, weeks, months, quarters, or years. For example:SELECT\\n DATEADD(day,90, P_INDATE) AS DueDate\\nFROM   PRODUCT;\\nThe preceding example adds 90 days to P_INDATE.In MS Access, use the following:SELECT\\n P_INDATE+90 AS DueDate\\nFROM   PRODUCT;\\nDATEDIFF SQL ServerSubtracts two datesSyntax:DATEDIFF(datepart, startdate, enddate)Returns the difference between two dates expressed in a selected datepart. For example:SELECT\\n DATEDIFF(day, P_INDATE, GETDATE()) AS DaysAgo\\nFROM   PRODUCT;\\nIn MS Access, use the following:SELECT\\n DATE() - P_INDATE AS DaysAgo\\nFROM   PRODUCT;\\nTABLE 8.4\\nSELECTED ORACLE DATE/TIME FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nTO_CHARReturns a character string or a for-matted string from a date valueSyntax:TO_CHAR(date_value, fmt)fmt = format used; can be:MONTH: name of monthMON: three-letter month nameMM: two-digit month nameD: number for day of weekDD: number for day of monthDAY: name of day of weekYYYY: four-digit year valueYY: two-digit year valueLists all employees born in 1982:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n TO_CHAR(EMP_DOB, 'YYYY') AS YEAR\\nFROM  EMPLOYEE\\nWHERE  TO_CHAR(EMP_DOB, 'YYYY') = '1982';\\nLists all employees born in November:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n TO_CHAR(EMP_DOB, 'MM') AS MONTH\\nFROM  EMPLOYEE\\nWHERE  TO_CHAR(EMP_DOB, 'MM') = '11';\\nLists all employees born on the 14th day of the month:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n TO_CHAR(EMP_DOB, 'DD') AS DAY\\nFROM  EMPLOYEE\\nWHERE  TO_CHAR(EMP_DOB, 'DD') = '14';\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd2e6171-0d54-48a7-b95a-7ff7308d3cbc', embedding=None, metadata={'page_label': '364', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"364   Part 3    Advanced Design and Implementation\\nTABLE 8.4  (CONTINUED)\\nSELECTED ORACLE DATE/TIME FUNCTIONS\\nTO_DATE\\nReturns a date value using a character string and a date format mask; also used to translate a date between formatsSyntax:TO_DATE(char_value, fmt)fmt = format used; can be:MONTH: name of monthMON: three-letter month nameMM: two-digit month nameD: number for day of weekDD: number for day of monthDAY: name of day of weekYYYY: four-digit year valueYY: two-digit year valueLists the approximate age of employees on the company’s tenth anniversary date (11/25/2016):SELECT\\n EMP_LNAME, EMP_FNAME,\\n EMP_DOB, '11/25/2016' AS ANIV_DATE,\\n (TO_DATE('11/25/2004' ,'MM/DD/YYYY') - EMP_DOB)/365 AS YEARS\\nFROM  EMPLOYEE\\nORDER BY YEARS;Note the following:•\\n '11/25/2016' is a text string, not a date.\\n•  The TO_DATE function translates the text string to a valid Oracle date used in date arithmetic.\\nHow many days are there between Thanksgiving and Christmas 2016?SELECT\\n TO_DATE('2016/12/25' ,'YYYY/MM/DD') –\\n TO_DATE('NOVEMBER 27, 2016' ,'MONTH DD, YYYY')\\nFROM  DUAL;\\nNote the following:•\\n  The TO_DATE function translates the text string to a valid Oracle date used in date arithmetic.\\n•\\n  DUAL is Oracle’s pseudo-table, used only for cases in which a table is not really needed.\\nSYSDATEReturns today’s dateLists how many days are left until Christmas:SELECT\\n TO_DATE('25-Dec-2016' ,'DD-MON-YYYY') - SYSDATE\\nFROM  DUAL;\\nNotice two things:•\\n  DUAL is Oracle’s pseudo-table, used only for cases in which a table is not really needed.\\n•\\n  The Christmas date is enclosed in a TO_DATE function to translate the date to a valid date format.\\nADD_MONTHSAdds a number of months or years to a dateSyntax:ADD_MONTHS(date_value, n)n = number of monthsLists all products with their expiration date (two years from the purchase date):SELECT\\n P_CODE, P_INDATE, ADD_MONTHS(P_INDATE,24)\\nFROM  PRODUCT\\nORDER BY  ADD_MONTHS(P_INDATE,24);\\nLAST_DAYReturns the date of the last day of the month given in a dateSyntax:LAST_DAY(date_value)Lists all employees who were hired within the last seven days of a month:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_HIRE_DATE\\nFROM  EMPLOYEE\\nWHERE  EMP_HIRE_DATE >=LAST_DAY(EMP_HIRE_DATE)-7;\\nTable 8.5 shows the equivalent functions for MySQL.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='960822f7-847a-4a96-9e02-b910617d1173', embedding=None, metadata={'page_label': '365', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    365\\nTABLE 8.5\\nSELECTED MYSQL DATE/TIME FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nDate_Format\\nReturns a character string or a formatted string from\\xa0a date valueSyntax:DATE_FORMAT(date_value, fmt)fmt = format used; can be:%M: name of month%m: two-digit month number%b: abbreviated month name%d: number of day of month%W: weekday name%a: abbreviated weekday name%Y: four-digit year%y: two-digit yearDisplays the product code and date the product was last \\n received \\ninto stock for all products:SELECT\\n P_CODE, DATE_FORMAT(P_INDATE, '%m/%d/%y')\\nFROM  PRODUCT;\\nSELECT  P_CODE, DATE_FORMAT(P_INDATE, '%M %d, %Y')\\nFROM  PRODUCT;\\nYEARReturns a four-digit yearSyntax:YEAR(date_value)Lists all employees born in 1982:SELECT\\n  EMP_LNAME, EMP_FNAME, EMP_DOB,  YEAR(EMP_DOB) AS YEAR\\nFROM\\n EMPLOYEE\\nWHERE  YEAR(EMP_DOB) = 1982;\\nMONTHReturns a two-digit month codeSyntax:MONTH(date_value)Lists all employees born in November:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n MONTH(EMP_DOB) AS MONTH\\nFROM  EMPLOYEE\\nWHERE  MONTH(EMP_DOB) = 11;\\nDAYReturns the number of the daySyntax:DAY(date_value)Lists all employees born on the 14th day of the month:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_DOB,\\n DAY(EMP_DOB) AS DAY\\nFROM  EMPLOYEE\\nWHERE  DAY(EMP_DOB) = 14;\\nADDDATEAdds a number of days to a dateSyntax:ADDDATE(date_value, n)n = number of daysDATE_ADDAdds a number of days, months, or years to a date.This is similar to ADDDATE except it is more robust.It allows the user to specify the date unit to add.Syntax:DATE_ADD(date, INTERVAL n unit)n = number to addunit = date unit, can be:DAY: add n daysWEEK: add n weeksMONTH: add n monthsYEAR: add n yearsList all products with the date they will have been on the shelf for 30 days.SELECT\\n P_CODE, P_INDATE, ADDDATE(P_INDATE, 30)\\nFROM  PRODUCT\\nORDER BY  ADDDATE(P_INDATE, 30);\\nLists all products with their expiration date (two years from the purchase date):SELECT\\n  P_CODE, P_INDATE, DATE_ADD(P_INDATE,  INTERVAL 2 YEAR)\\nFROM\\n PRODUCT\\nORDER BY  DATE_ADD(P_INDATE, INTERVAL 2 YEAR);\\nLAST_DAYReturns the date of the last day of the month given in a dateSyntax:LAST_DAY(date_value)Lists all employees who were hired within the last seven days of a month:SELECT\\n EMP_LNAME, EMP_FNAME, EMP_HIRE_DATE\\nFROM  EMPLOYEE\\nWHERE   EMP_HIRE_DATE >= DATE_ADD(LAST_DAY (EMP_HIRE_DATE), INTERVAL -7 DAY);\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='837a1c4d-416a-4e1a-875a-68fc725ddb70', embedding=None, metadata={'page_label': '366', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='366   Part 3    Advanced Design and Implementation\\n8-3b  Numeric Functions\\nNumeric functions can be grouped in many different ways, such as algebraic, trigono-\\nmetric, and logarithmic. In this section, you will learn two very useful functions. Do not confuse the SQL aggregate functions you saw in the previous chapter with the numeric functions in this section. The first group operates over a set of values (multiple rows—hence, the name aggregate functions), while the numeric functions covered here operate over a single row. Numeric functions take one numeric parameter and return one value. Table 8.6 shows a selected group of available numeric functions.\\nTABLE 8.6\\nSELECTED NUMERIC FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nABSReturns the absolute value of a numberSyntax:ABS(numeric_value)In Oracle, use the following:SELECT\\n 1.95, −1.93, ABS(1.95), ABS(−1.93)\\nFROM  DUAL;\\nIn MS Access, MySQL, and MS SQL Server, use the following:SELECT\\n 1.95, −1.93, ABS(1.95), ABS(−1.93);\\nROUNDRounds a value to a specified precision (number of digits)Syntax:ROUND(numeric_value, p)p = precisionLists the product prices rounded to one and zero decimal places:SELECT\\n P_CODE, P_PRICE,\\n ROUND(P_PRICE,1) AS PRICE1,\\n ROUND(P_PRICE,0) AS PRICE0\\nFROM  PRODUCT;\\nCEIL/CEILING/FLOORReturns the smallest integer greater than or equal to a number or returns the largest integer equal to or less than a number, respectivelySyntax:CEIL(numeric_value) Oracle or MySQLCEILING(numeric_value) MS SQL Server or MySQLFLOOR(numeric_value)Lists the product price, the smallest integer greater than or equal to the product price, and the largest integer equal to or less than the product price.In Oracle or MySQL, use the following:SELECT\\n P_PRICE, CEIL(P_PRICE), FLOOR(P_PRICE)\\nFROM  PRODUCT;\\nIn MS SQL Server or MySQL, use the following:SELECT\\n P_PRICE, CEILING(P_PRICE), FLOOR(P_PRICE)\\nFROM  PRODUCT;\\nMS Access does not support these functions. Note that MySQL supports both CEIL and CEILING.\\n8-3c  String Functions\\nString manipulations are among the most-used functions in programming. If you have ever created a report using any programming language, you know the importance of properly concatenating strings of characters, printing names in uppercase, or knowing the length of a given attribute. Table 8.7 shows a subset of useful string manipulation functions.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='daa8537f-70b4-4b06-9523-e78f044986b8', embedding=None, metadata={'page_label': '367', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    367\\nTABLE 8.7\\nSELECTED STRING FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nConcatenation\\n|| Oracle+ Access and MS SQL Server& AccessCONCAT() MySQLConcatenates data from two different character columns and returns a single column.Syntax:strg_value || strg_valuestrg_value + strg_valuestrg_value & strg_valueCONCAT(strg_value, strg_value)The CONCAT function can only accept two string \\n values so nested CONCAT functions are required when more than two values are to be concatenated.Lists all employee names (concatenated).In Oracle, use the following:SELECT\\n EMP_LNAME || ' , ' || EMP_FNAME AS NAME\\nFROM  EMPLOYEE;\\nIn Access and MS SQL Server, use the following:SELECT\\n EMP_LNAME + ' , ' + EMP_FNAME AS NAME\\nFROM  EMPLOYEE;\\nIn MySQL, use the following:SELECT\\n  CONCAT(CONCAT(EMP_LNAME, ' , '),  EMP_FNAME AS NAME\\nFROM\\n EMPLOYEE;\\nUPPER Oracle, MS SQL Server, and MySQLUCASE MySQL and AccessLOWER Oracle, MS SQL Server, and MySQLLCASE MySQL and AccessReturns a string in all capital or all lowercase lettersSyntax:UPPER(strg_value)UCASE(strg_value)LOWER(strg_value)LCASE(strg_value)Lists all employee names in all capital letters (concatenated).In Oracle, use the following:SELECT\\n UPPER(EMP_LNAME || ' , ' || EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn MS SQL Server, use the following:SELECT\\n UPPER(EMP_LNAME + ' , ' + EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn Access, use the following:SELECT\\n UCASE(EMP_LNAME & ' , ' & EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn MySQL, use the following:SELECT\\n  UPPER(CONCAT(CONCAT(EMP_LNAME, ' , '),  EMP_FNAME AS NAME\\nFROM\\n EMPLOYEE;\\nLists all employee names in all lowercase letters (concatenated).In Oracle, use the following:SELECT\\n LOWER(EMP_LNAME || ' , ' || EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn MS SQL Server, use the following:SELECT\\n LOWER(EMP_LNAME + ' , ' + EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn Access, use the following:SELECT\\n LCASE(EMP_LNAME & ' , ' & EMP_FNAME) AS NAME\\nFROM  EMPLOYEE;\\nIn MySQL, use the following:SELECT\\n  LOWER(CONCAT(CONCAT(EMP_LNAME, ' , '),  EMP_FNAME AS NAME\\nFROM\\n EMPLOYEE;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='747ff9fd-7b97-4d3c-ba72-724eba10f2c1', embedding=None, metadata={'page_label': '368', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='368   Part 3    Advanced Design and Implementation\\nTABLE 8.7  (CONTINUED)\\nSELECTED STRING FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nSUBSTRING\\nReturns a substring or part of a given string \\n parameterSyntax:SUBSTR(strg_value, p, l) Oracle and MySQLSUBSTRING(strg_value,p,l) MS SQLServer and MySQLMID(strg_value,p,l) Accessp = start positionl = length of charactersIf the length of characters is omitted, the functions will return the remainder of the string value.Lists the first three characters of all employee phone numbers.In Oracle or MySQL, use the following:SELECT\\n EMP_PHONE, SUBSTR(EMP_PHONE,1,3) AS PREFIX\\nFROM  EMPLOYEE;\\nIn MS SQL Server or MySQL, use the following:SELECT\\n EMP_PHONE, SUBSTRING(EMP_PHONE,1,3) AS PREFIX\\nFROM  EMPLOYEE;\\nIn Access, use the following:SELECT\\n EMP_PHONE, MID(EMP_PHONE, 1,3) AS PREFIX\\nFROM  EMPLOYEE;\\nLENGTHReturns the number of characters in a string valueSyntax:LENGTH(strg_value) Oracle and MySQLLEN(strg_value) MS SQL Server and AccessLists all employee last names and the length of their names in descending order by last name length.In Oracle and MySQL, use the following:SELECT\\n EMP_LNAME, LENGTH(EMP_LNAME) AS NAMESIZE\\nFROM  EMPLOYEE;\\nIn MS Access and SQL Server, use the following:SELECT\\n EMP_LNAME, LEN(EMP_LNAME) AS NAMESIZE\\nFROM  EMPLOYEE;\\n8-3d  Conversion Functions\\nConversion functions allow you to take a value of a given data type and convert it to the equivalent value in another data type. In Section 8-3a, you learned about two basic Oracle SQL conversion functions: TO_CHAR and TO_DATE. Note that the TO_CHAR function takes a date value and returns a character string representing a day, a month, or a year. In the same way, the TO_DATE function takes a character string represent-ing a date and returns an actual date in Oracle format. SQL Server uses the CAST and CONVERT functions to convert one data type to another. A summary of the selected functions is shown in Table 8.8.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b71b7da-2e80-4be4-a11e-3a3d0348f4cf', embedding=None, metadata={'page_label': '369', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    369\\nTABLE 8.8\\nSELECTED CONVERSION FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nNumeric or Date to Character:\\nTO_CHAR OracleCAST Oracle, MS SQL Server, MySQLCONVERT MS SQL Server, MySQLCSTR AccessReturns a character string from a numeric or date value.Syntax:TO_CHAR(value-to-convert, fmt)fmt = format used; can be:9 = displays a digit0 = displays a leading zero, = displays the comma. = displays the decimal point$= displays the dollar signB = leading blankS = leading signMI = trailing minus signCAST (value-to-convert AS char(length))Note that Oracle and MS SQL Server can use CAST to convert the numeric data into fixed length or variable length character data type.MySQL cannot CAST into variable length \\n character \\ndata, only fixed length.MS SQL Server:CONVERT(varchar(length), value-to-convert)MySQL:CONVERT(value-to-convert, char(length))The primary difference between CAST and CONVERT is that CONVERT can also be used to change the char-acter set of the data.CSTR(value-to-convert)Lists all product prices, product received date, and percent discount using formatted values.TO_CHAR:SELECT\\n P_CODE,\\n TO_CHAR(P_PRICE,'999.99') AS PRICE,\\n TO_CHAR(P_INDATE, 'MM/DD/YYYY') AS INDATE,\\n TO_CHAR(P_DISCOUNT,'0.99') AS DISC\\nFROM  PRODUCT;\\nCAST in Oracle and MS SQL Server:SELECT\\n P_CODE, CAST(P_PRICE AS VARCHAR(8)) AS PRICE,\\n CAST(P_INDATE AS VARCHAR(20)) AS INDATE,\\n CAST(P_DISCOUNT AS VARCHAR(4)) AS DISC\\nFROM  PRODUCT;\\nCAST in MySQL:SELECT\\n P_CODE, CAST(P_PRICE AS CHAR(8)) AS PRICE,\\n CAST(P_INDATE AS CHAR(20)) AS INDATE,\\n CAST(P_DISCOUNT AS CHAR(4)) AS DISC\\nFROM  PRODUCT;\\nCONVERT in MS SQL Server:SELECT\\n P_CODE, CONVERT(VARCHAR(8), P_PRICE) AS PRICE,\\n CONVERT(VARCHAR(20), P_INDATE) AS INDATE,\\n CONVERT(VARCHAR(4), P_DISC) AS DISC\\nFROM  PRODUCT;\\nCONVERT in MySQL:SELECT\\n P_CODE, CONVERT(P_PRICE, CHAR(8)) AS PRICE,\\n CONVERT(P_INDATE, CHAR(20)) AS INDATE,\\n CONVERT(P_DISC, CHAR(4)) AS DISC\\nFROM  PRODUCT;\\nCSTR in Access:SELECT\\n P_CODE, CSTR(P_PRICE) AS PRICE,\\n CSTR(P_INDATE) AS INDATE,\\n CSTR(P_DISC) AS DISCOUNT\\nFROM  PRODUCT;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4945d292-5ad9-4b7e-9b7f-8da08bf02e47', embedding=None, metadata={'page_label': '370', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"370   Part 3    Advanced Design and Implementation\\nTABLE 8.8  (CONTINUED)\\nSELECTED CONVERSION FUNCTIONS\\nFUNCTION EXAMPLE(S)\\nString to Number:\\nTO_NUMBER OracleCAST Oracle, MS SQL Server, MySQLCONVERT MS SQL Server, MySQLCINT AccessCDEC AccessReturns a number from a character stringSyntax:Oracle:TO_NUMBER(char_value, fmt)fmt = format used; can be:9 = indicates a digitB = leading blankS = leading signMI = trailing minus signCAST (value-to-convert as numeric-data type) Note that in addition to the INTEGER and DECIMAL(l,d) data types, Oracle supports NUMBER and MS SQL Server supports NUMERIC.MS SQL Server:CONVERT(value-to-convert, decimal(l,d))MySQL:CONVERT(value-to-convert, decimal(l,d))Other than the data type to be converted into, these functions operate the same as described above.CINT in Access returns the number in the integer data type, while CDEC returns decimal data type.Converts text strings to numeric values when importing data to a table from another source in text format; for example, the query shown here uses the TO_NUMBER function to convert text formatted to Oracle default numeric values using the format masks given.TO_NUMBER:SELECT\\n TO_NUMBER('−123.99' , 'S999.99'),\\n TO_NUMBER('99.78−' ,'B999.99MI')\\nFROM  DUAL;\\nCAST:SELECT\\n CAST('−123.99' AS DECIMAL(8,2)),\\n CAST('−99.78' AS DECIMAL(8,2));\\nThe CAST function does not support the trailing sign on the character string.CINT and CDEC:SELECT\\n CINT('−123'), CDEC('−123.99');\\nCASE Oracle, MS SQL Server, MySQLDECODE OracleSWITCH AccessCompares an attribute or expression with a series of values and returns an associated value or a default value if no match is foundSyntax:DECODE:DECODE(e, x, y, d)e = attribute or expressionx = value with which to compare ey = value to return in e = xd = default value to return if e is not equal to xCASE:CASE When conditionTHEN value1 ELSE value2 ENDSWITCH:SWITCH(e1, x, e2, y, TRUE, d)e1 = comparison expressionx = value to return if e1 is truee2 = comparison expressiony = value to return if e2 is trueTRUE = keyword indicating the next value is the defaultd = default value to return if none of the expressions were trueThe following example returns the sales tax rate for specified states:Compares V_STATE to 'CA'; if the values match, it returns .08.Compares V_STATE to 'FL'; if the values match, it returns .05.Compares V_STATE to 'TN'; if the values match, it returns .085.If there is no match, it returns 0.00 (the default value).SELECT\\n V_CODE, V_STATE,\\n DECODE(V_STATE,'CA' ,.08,'FL' ,.05, 'TN' ,.085, 0.00)\\n AS TAX\\nFROM  VENDOR;\\nCASE:SELECT\\n V_CODE, V_STATE,\\nCASE  WHEN V_STATE = 'CA' THEN .08\\nWHEN V_STATE = 'FL' THEN .05WHEN V_STATE = 'TN' THEN .085\\n ELSE 0.00 END AS TAX\\nFROM  VENDOR\\nSWITCH:SELECT\\n V_CODE, V_STATE,\\n SWITCH(V_STATE ='CA' ,.08,\\n V_STATE = 'FL' ,.05,\\n V_STATE = 'TN' ,.085,\\n TRUE, 0.00) AS TAX\\nFROM  VENDOR;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b708909b-9792-4646-a602-eb5e131373c7', embedding=None, metadata={'page_label': '371', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    371\\n8-4 Relational Set Operators\\nIn Chapter 3, The Relational Database Model, you learned about the eight general \\nrelational operators. In this section, you will learn how to use three SQL commands—UNION, INTERSECT, and EXCEPT (MINUS)—to implement the union, intersection, and difference relational operators.\\nIn previous chapters, you learned that SQL data manipulation commands are set-\\n \\noriented; that is, they operate over entire sets of rows and columns (tables) at once. Y ou can combine two or more sets to create new sets (or relations). That is precisely what the UNION, INTERSECT, and EXCEPT (MINUS) statements do. In relational database terms, you can use the words sets, relations , and tables  interchangeably because they all \\nprovide a conceptual view of the data set as it is presented to the relational database user.\\nThe SQL standard defines the operations that all DBMSs must perform on data, but it leaves the implementation details to the DBMS vendors. Therefore, some advanced SQL features might not work on all DBMS implementations. Also, some DBMS vendors might \\n implement \\nadditional features not found in the SQL standard. The SQL standard defines UNION, \\n INTERSECT, and EXCEPT as the keywords for the UNION, INTERSECT, and DIFFERENCE \\n relational operators, and these are the names used in MS SQL Server. However, Oracle uses MINUS as the name of the DIFFERENCE operator instead of EXCEPT. Other RDBMS \\n vendors \\nmight use a different command name or might not implement a given  command at all. \\nFor example, Access and MySQL do not have direct support for INTERSECT or  DIFFERENCE \\noperations because that functionality can be achieved using combinations of joins and subqueries. To learn more about the ANSI/ISO SQL standards and find out how to obtain the latest standard documents in electronic form, check the ANSI website (www.ansi.org).Note\\nUNION, INTERSECT, and EXCEPT (MINUS) work properly only if relations are \\nunion-compatible, which means that the number of attributes must be the same and their corresponding data types must be alike. In practice, some RDBMS vendors require the data types to be compatible but not exactly the same. For example, compatible data types are V ARCHAR (35) and CHAR (15). Both attributes store character (string) \\n values; the only difference is the string size. Another example of compatible data types is \\n NUMBER and SMALLINT. Both data types are used to store numeric values.\\nset-oriented\\nDealing with or related to sets, or groups of things. In the relational model, SQL operators are set-oriented because they operate over entire sets of rows and columns at once.\\nunion-compatible\\nTwo or more tables that share the same number of columns and have columns with compatible data types or domains.\\nSome DBMS products might require union-compatible tables to have identical data types.Note\\n8-4a  UNION\\nSuppose that SaleCo has bought another company. SaleCo’s management wants to make sure that the acquired company’s customer list is properly merged with its own customer list. Because some customers might have purchased goods from both companies, the two lists might contain common customers. SaleCo’s management wants to make sure that customer records are not duplicated when the two customer lists are merged. The UNION query is a perfect tool for generating a combined listing of customers—one that excludes duplicate records.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98052b37-0721-42e9-a365-ff61421fca82', embedding=None, metadata={'page_label': '372', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='372   Part 3     Advanced Design and Implementation\\nThe UNION statement combines rows from two or more queries without including \\nduplicate rows . The syntax of the UNION statement is:\\nquery  UNION query\\nIn other words, the UNION statement combines the output of two SELECT queries. \\n(Remember that the SELECT statements must be union-compatible. That is, they must \\nreturn the same number of attributes and similar data types.)\\nTo demonstrate the use of the UNION statement in SQL, use the CUSTOMER and \\nCUSTOMER_2 tables in the Ch08_SaleCo database. To show the combined CUSTOMER \\nand CUSTOMER_2 records without duplicates, the UNION query is written as follows:\\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER\\nUNION  \\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER_2;\\nFigure 8.16 shows the contents of the CUSTOMER and CUSTOMER_2 tables and the \\nresult of the UNION query. Although MS Access is used to show the results here, similar \\nresults can be obtained with Oracle, MS SQL Server, and MySQL.\\nFIGURE 8.16  UNION QUERY RESULTS  \\nTable name: CUSTOMERDatabase name: Ch08_SaleCo\\nQuery name: qryUNION-of-CUSTOMER-and-CUST OMER_2\\nTable name: CUSTOMER_2\\nNote the following in Figure 8.16:\\n• The CUSTOMER table contains 10 rows, while the CUSTOMER_2 table contains \\nseven rows.\\n• Customers Dunne and Olowski are included in the CUSTOMER table as well as the \\nCUSTOMER_2 table.\\n• The UNION query yields 15 records because the duplicate records of customers \\nDunne and Olowski are not included. In short, the UNION query yields a unique set \\nof records.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fea89986-a987-429d-9570-3998a4325081', embedding=None, metadata={'page_label': '373', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    373\\nThe UNION statement can be used to unite more than just two queries. For example, \\nassume that you have four union-compatible queries named T1, T2, T3, and T4. With \\nthe UNION statement, you can combine the output of all four queries into a single result set. The SQL statement will be similar to this:\\nSELECT column-list FROM T1\\nUNIONSELECT column-list FROM T2UNIONSELECT column-list FROM T3UNIONSELECT column-list FROM T4;\\n8-4b  UNION ALL\\nIf SaleCo’s management wants to know how many customers are on both  the  CUSTOMER \\nand CUSTOMER_2 lists, a UNION ALL query can be used to produce a relation that retains the duplicate rows. Therefore, the following query will keep all rows from both queries (including the duplicate rows) and return 17 rows.\\nSELECT\\n  CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER\\nUNION ALL  \\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, CUS_PHONE\\nFROM\\n  CUSTOMER_2;\\nRunning the preceding UNION ALL query produces the result shown in Figure 8.17.\\nLike the UNION statement, the UNION ALL statement can be used to unite more than just two queries.\\n8-4c  INTERSECT\\nIf SaleCo’s management wants to know which customer records are duplicated in the CUSTOMER and CUSTOMER_2 tables, the INTERSECT statement can be used to combine rows from two queries, returning only the rows that appear in both sets. The syntax for the INTERSECT statement is:\\nquery  INTERSECT query\\nTo generate the list of duplicate customer records, you can use the following commands:SELECT\\n  CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER\\nThe SQL standard calls for the elimination of duplicate rows when the UNION SQL  statement \\nis used. However, some DBMS vendors might not adhere to that standard. Check your DBMS manual to see if the UNION statement is supported, and if so, how  it is supported.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b641bd4-9e9d-47bc-8311-2ef2750e5cf8', embedding=None, metadata={'page_label': '374', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"374   Part 3     Advanced Design and Implementation\\nINTERSECT  \\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER_2;\\nFIGURE 8.18  INTERSECT QUERY RESULTS  \\nFIGURE 8.17  UNION ALL QUERY RESULTS  \\nTable name: CUSTOMERDatabase name: Ch08_SaleCo\\nQuery name: qryUNION-ALL-of-CUSTOMER-and-CUSTOMER_2\\nTable name: CUSTOMER_2\\nThe INTERSECT statement can be used to generate additional useful customer informa -\\ntion. For example, the following query returns the customer codes for all customers who \\nare in area code 615 and who have made purchases. (If a customer has made a  purchase, \\nthere must be an invoice record for that customer.)\\nSELECT  CUS_CODE FROM CUSTOMER WHERE CUS_AREACODE = '615'\\nINTERSECT  \\nSELECT  DISTINCT CUS_CODE FROM INVOICE;\\nFigure 8.18 shows both sets of SQL statements and their output.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a8aa2e6c-a99a-42ce-bbf3-901dae502599', embedding=None, metadata={'page_label': '375', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    375\\n8-4d  EXCEPT (MINUS)\\nThe EXCEPT statement in SQL combines rows from two queries and returns only \\nthe rows that appear in the first set but not in the second. The syntax for the EXCEPT statement in MS SQL Server and the MINUS statement in Oracle is:\\nquery  EXCEPT query\\nandquery  MINUS query\\nFor example, if the SaleCo managers want to know which customers in the CUSTOMER \\ntable are not found in the CUSTOMER_2 table, they can use the following commands in Oracle:\\nSELECT\\n  CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM   CUSTOMER\\nMINUS  \\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, CUS_PHONE\\nFROM\\n  CUSTOMER_2;\\nIf the managers want to know which customers in the CUSTOMER_2 table are not found in the CUSTOMER table, they merely switch the table designations:\\nSELECT\\n  CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, \\nCUS_PHONE\\nFROM    CUSTOMER_2\\nMINUS  \\nSELECT   CUS_LNAME, CUS_FNAME, CUS_INITIAL, CUS_AREACODE, CUS_PHONE\\nFROM\\n  CUSTOMER;\\nAccess and MySQL do not support the INTERSECT query. These DBMSs are able to give the desired results using alternative query formats. For example, INTERSECT results can also be produced in Access and MySQL through an inner join that includes all of the attributes to be returned in the join condition. The query:\\nSELECT CUS_AREACODE FROM CUSTOMER\\nINTERSECTSELECT V_AREACODE FROM VENDOR;\\ncan also be produced without the INTERSECT command with the query:\\nSELECT DISTINCT CUS_AREACODEFROM CUSTOMER JOIN VENDOR ON CUS_AREACODE = V_AREACODE;Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='05dc1bd6-2cde-481b-9ad1-e228796fe2b9', embedding=None, metadata={'page_label': '376', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"376   Part 3    Advanced Design and Implementation\\nUsers of MS SQL Server would substitute the keyword EXCEPT in place of MINUS, \\nbut otherwise the syntax is exactly the same. Y ou can extract useful information by \\ncombining MINUS with various clauses such as WHERE. For example, the following query returns the customer codes for all customers in area code 615 minus the ones who have made purchases, leaving the customers in area code 615 who have not made purchases.\\nSELECT\\n CUS_CODE FROM CUSTOMER WHERE CUS_AREACODE = '615'\\nMINUS  \\nSELECT  DISTINCT CUS_CODE FROM INVOICE;\\nFigure 8.19 shows the preceding three SQL statements and their output.\\nFIGURE 8.19  MINUS QUERY RESULTS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='014a76eb-55bb-45c2-86d5-bdae7c1ec014', embedding=None, metadata={'page_label': '377', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    377\\n8-4e  Syntax Alternatives\\nIf your DBMS does not support the INTERSECT or EXCEPT (MINUS) statements, you \\ncan use IN and NOT IN subqueries to obtain similar results. For example, the following \\nquery will produce the same results as the INTERSECT query shown in Section 8-4c:\\nSELECT  CUS_CODE FROM CUSTOMER\\nWHERE  CUS_AREACODE = '615' AND\\n  CUS_CODE IN (SELECT DISTINCT CUS_CODE FROM INVOICE);\\nFigure 8.20 shows the use of the INTERSECT alternative.\\nFIGURE 8.20  INTERSECT ALTERNATIVE  \\nTable name: CUSTOMERDatabase name: Ch08_SaleCo\\nTable name: INVOICE\\nQuery name: qry-INTERSECT-Alternative\\nUsing the same alternative to the MINUS statement, you can generate the output for \\nthe third MINUS query shown in Section 8-4d by entering the following:\\nSELECT  CUS_CODE FROM CUSTOMER\\nWHERE  CUS_AREACODE = '615' AND\\n   CUS_CODE NOT IN (SELECT DISTINCT CUS_CODE FROM \\nINVOICE);\\nThe results of the query are shown in Figure 8.21. Note that the query output includes \\nonly the customers in area code 615 who have not made any purchases and therefore \\nhave not generated invoices.\\n8-5 Virtual Tables: Creating a View\\nAs you learned earlier, the output of a relational operator such as SELECT is another \\nrelation (or table). Suppose that at the end of each day, you would like to have a list of \\nall products to reorder—that is, products with a quantity on hand that is less than or \\nequal to the minimum quantity. Instead of typing the same query at the end of each day, \\nwouldn’t it be better to permanently save that query in the database? That is the function \\nof a relational view. A view  is a virtual table based on a SELECT query. The query can \\ncontain columns, computed columns, aliases, and aggregate functions from one or more \\ntables. The tables on which the view is based are called base tables .view\\nA virtual table based on \\na SELECT query that is \\nsaved as an object in the \\ndatabase.\\nbase table\\nThe table on which a \\nview is based.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0456bda3-7de9-4f5f-bdb1-90de019472a0', embedding=None, metadata={'page_label': '378', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='378   Part 3     Advanced Design and Implementation\\nY ou can create a view by using the CREATE  VIEW  command:\\nCREATE VIEW viewname  AS SELECT query\\nThe CREATE VIEW statement is a data definition command that stores the subquery \\n specification—the SELECT statement used to generate the virtual table—in the data dictionary.\\nThe first SQL command set in Figure 8.22 shows the syntax used to create a view named \\nPRICEGT50. This view contains only the designated three attributes (P_DESCRIPT,  \\nP_QOH, and P_PRICE) and only rows in which the price is over $50. The second SQL \\ncommand sequence in Figure 8.22 shows the rows that make up the view.\\nCREATE VIEW\\nA SQL command that \\ncreates a logical, “virtual” \\ntable. The view can be \\ntreated as a real table.FIGURE 8.21  MINUS ALTERNATIVE  \\nTable name: CUSTOMERDatabase name: Ch08_SaleCo\\nTable name: INVOICE\\nQuery name: qry-MINUS-Alternative\\nFIGURE 8.22  CREATING A VIRTUAL TABLE WITH THE CREATE VIEW COMMAND\\nNote to MS Access Users\\nThe CREATE VIEW command is not directly supported in MS Access. To create a view in  \\nMS Access, you simply create a SQL query and then save it.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ca594e2-6cae-4770-909d-97435673a335', embedding=None, metadata={'page_label': '379', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    379\\nA relational view has several special characteristics:\\n• Y ou can use the name of a view anywhere a table name is expected in a SQL statement.\\n• Views are dynamically updated. That is, the view is re-created on demand each time \\nit is invoked. Therefore, if new products are added or deleted to meet the criterion \\nP_PRICE > 50.00, those new products will automatically appear or disappear in the \\nPRICEGT50 view the next time the view is invoked.\\n• Views provide a level of security in the database because they can restrict users to \\nseeing only specified columns and rows in a table. For example, if you have a  company \\nwith hundreds of employees in several departments, you could give each  department \\nsecretary a view of certain attributes only for the employees who belong to that \\n secretary’s department.\\n• Views may also be used as the basis for reports. For example, if you need a report that \\nshows a summary of total product cost and quantity-on-hand statistics grouped by \\nvendor, you could create a PROD_STATS view as:\\nCREATE VIEW PROD_STATS AS\\nSELECT   V_CODE, SUM(P_QOH*P_PRICE) AS TOTCOST, MAX(P_QOH) \\nAS MAXQTY , MIN(P_QOH) AS MINQTY , AVG(P_QOH) AS \\nAVGQT Y\\nFROM   PRODUCT\\nGROUP BY  V_CODE;\\n8-5a  Updatable Views\\nOne of the most common operations in production database environments is to use \\nbatch update routines to update a master table attribute (field) with transaction data. \\nAs the name implies, a batch update routine  pools multiple transactions into a single \\nbatch to update a master table field in a single operation . For example, a batch update \\n routine is commonly used to update a product’s quantity on hand based on summary \\nsales transactions. Such routines are typically run as overnight batch jobs to update \\nthe quantity on hand of products in inventory. For example, the sales transactions \\nperformed by traveling salespeople can be entered during periods when the system is \\noffline.\\nTo perform a batch update routine, begin by defining the master product table \\n(PRODMASTER) and the product monthly sales totals table (PRODSALES) shown in \\nFigure 8.23. Note the 1:1 relationship between the two tables.\\nbatch update \\nroutine\\nA routine that pools \\ntransactions into a \\nsingle group to update a \\nmaster table in a single \\noperation.FIGURE 8.23  THE PRODMASTER AND PRODSALES TABLES  \\nTable name: PRODMASTERDatabase name: Ch08_UV\\nTable name: PRODSALES\\nThe PRODMASTER and \\nPRODSALES tables are in \\nthe Ch08_UV databases \\nfor the different DBMSs, \\nwhich are available at \\nwww.cengagebrain.com .Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a25a29d7-ddac-4219-af0f-865c429c5fa7', embedding=None, metadata={'page_label': '380', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='380   Part 3    Advanced Design and Implementation\\nUsing the tables in Figure 8.23, update the PRODMASTER table by subtracting the \\nPRODSALES table’s product monthly sales quantity (PS_QTY) from the PRODMASTER \\ntable’s PROD_QOH. To produce the required update, the update query would be written like this:\\nUPDATE\\n PRODMASTER, PRODSALES\\nSET  PRODMASTER.PROD_QOH = PROD_QOH – PS_QTY\\nWHERE  PRODMASTER.PROD_ID = PRODSALES.PROD_ID;\\nNote that the update statement reflects the following sequence of events:\\n• Join the PRODMASTER and PRODSALES tables.\\n• Update the PROD_QOH attribute (using the PS_QTY value in the PRODSALES \\ntable) for each row of the PRODMASTER table with matching PROD_ID values in the PRODSALES table.\\nUpdating using multiple tables in MS SQL Server requires the UPDATE FROM syntax. The\\xa0above code would be written in MS SQL Server as the following:\\nUPDATE PRODMASTERSET PROD_QOH = PROD_QOH – PS_QTYFROM PRODMASTER JOIN PRODSALES ON PRODMASTER.PROD_ID = PRODSALES.PROD_ID;Note\\nTo be used in a batch update, the PRODSALES data must be stored in a base table \\nrather than in a view. The query will work in MySQL and Access, but Oracle will return the error message shown in Figure 8.24.\\nFIGURE 8.24  THE ORACLE UPDATE ERROR MESSAGE  \\nOracle produced the error message because it expected to find a single table name \\nin the UPDATE statement. In fact, you cannot join tables in the UPDATE statement in Oracle. To solve that problem, you have to create an updatable  view. As its name suggests, \\nan updatable view can be used to update attributes in any base table(s) used in the view. \\nY ou must realize that not all views are updatable. Actually, several restrictions govern updatable views, and some of them are vendor-specific.updatable view\\nA view that can update attributes in base tables that are used in the view.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='792481bb-c6a7-43fb-baf1-3494e5c7fd27', embedding=None, metadata={'page_label': '381', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    381\\nThe most common updatable view restrictions are as follows:\\n• GROUP BY expressions or aggregate functions cannot be used.\\n• Y ou cannot use set operators such as UNION, INTERSECT, and MINUS.\\n• Most restrictions are based on the use of JOINs or group operators in views. More \\n specifically, the base table to be updated must be key-preserved, meaning that \\nthe\\xa0 values of the primary key of the base table must still be unique by definition in \\nthe view.\\nAn updatable view named PSVUPD has been created, as shown in Figure 8.25.\\nWhile the examples in this section are generated in Oracle, the same code and techniques also work in MS SQL Server, MySQL, and Access. To see what additional restrictions are placed on updatable views by the DBMS you are using, check the appropriate DBMS documentation.Note\\nFIGURE 8.25  CREATING AN UPDATABLE VIEW  \\nOne easy way to determine whether a view can be used to update a base table is to \\nexamine the view’s output. If the primary key columns of the base table you want to update still have unique values in the view, the base table is updatable. For example, if the PROD_ID column of the view returns the A123 or BX34 values more than once, the PRODMASTER table cannot be updated through the view.\\nAfter creating the updatable view shown in Figure 8.25, you can use the UPDATE \\n command to update the view, thereby updating the PRODMASTER table. Figure\\xa08.26 shows how the UPDATE command is used and shows the final contents of the \\n PRODMASTER table after the UPDATE has been executed.\\nAlthough the batch update procedure just illustrated meets the goal of updating a \\nmaster table with data from a transaction table, the preferred real-world solution to the update problem is to use procedural SQL, which you will learn about later in this chapter.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4c87a13a-0e80-482b-b87b-1bb7ddecebfc', embedding=None, metadata={'page_label': '382', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='382   Part 3    Advanced Design and Implementation\\n8-6 Sequences\\nIf you use MS Access, you might be familiar with the AutoNumber data type, which you \\ncan use to define a column in your table that will be automatically populated with unique numeric values. In fact, if you create a table in MS Access and forget to define a primary key, MS Access will offer to create a primary key column; if you accept, you will notice that MS Access creates a column named “ID” with an AutoNumber data type. After you define a column as an AutoNumber type, every time you insert a row in the table, MS Access will automatically add a value to that column, starting with 1 and increasing the value by 1 in every new row you add. Also, you cannot include that column in your INSERT statements—Access will not let you edit that value at all. MS SQL Server tradi-tionally has used the Identity column property to serve a similar purpose. In MS SQL Server, a table can have at most one column defined as an Identity column. This column behaves similarly to an MS Access column with the AutoNumber data type. MySQL uses the AUTO_INCREMENT property during table creation to indicate that values for an attribute should be generated in the same fashion. AUTO_INCREMENT can be adjusted to start with a value other than 1. Similar to IDENTITY columns in MS SQL Server, only one column in a table can have AUTO_INCREMENT specified, and that column must also be defined as the primary key of the table.\\nOracle does not support the AutoNumber data type, or Auto_Increment column \\nproperties. Traditionally, Oracle uses a sequence to assign values to a column on a table. However, beginning in Oracle 12c, Oracle has added support for Identity \\n columns, \\nand beginning in MS SQL Server 2012, SQL Server supports sequences. There are many similarities in the use of sequences across these DBMS so a database programmer who is comfortable with one should be able to easily transition to the other. \\n However, FIGURE 8.26  PRODMASTER TABLE UPDATE, USING AN UPDATABLE VIEW\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ae71a812-5c66-4f8f-8557-faf01528ec89', embedding=None, metadata={'page_label': '383', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    383\\na\\xa0sequence is very different from the Access AutoNumber data type and deserves closer \\nscrutiny:\\n• Sequences are an independent object in the database. (Sequences are not a data type.)\\n• Sequences have a name.\\n• Sequences can be used anywhere a value is expected.\\n• Sequences are not tied to a table or a column.\\n• Sequences generate a numeric value that can be assigned to any column in any table.\\n• The table attribute to which you assigned a value based on a sequence can be edited \\nand modified.\\nThe basic syntax to create a sequence is as follows:\\nCREATE SEQUENCE name  [START WITH n] [INCREMENT BY n]  \\n[CACHE | NOCACHE]\\nwhere\\n• name  is the name of the sequence.\\n• n is an integer value that can be positive or negative.\\n• START WITH specifies the initial sequence value. (The default value is 1.)\\n• INCREMENT BY determines the value by which the sequence is incremented. \\n(The\\xa0default increment value is 1. The sequence increment can be positive or negative to enable you to create ascending or descending sequences.)\\n•\\n The CACHE or NOCACHE/NO CACHE clause indicates whether the DBMS will \\n preallocate sequence numbers in memory. Oracle uses NOCACHE as one word and preallocates 20 values by default. SQL Server uses NO CACHE as two words. If a cache size is not specified in SQL Server, then the DBMS will determine a default cache size that is not guaranteed to be consistent across different databases.\\nFor example, you could create a sequence to automatically assign values to the \\n customer code each time a new customer is added, and create another sequence to \\n automatically assign values to the invoice number each time a new invoice is added. The SQL code to accomplish those tasks is:\\nCREATE SEQUENCE CUS_CODE_SEQ START WITH 20010 NOCACHE;CREATE SEQUENCE INV_NUMBER_SEQ START WITH 4010 NOCACHE;\\nRemember, SQL Server uses NO CACHE as two words so the corresponding commands in \\nSQL Server would be:\\nCREATE SEQUENCE CUS_CODE_SEQ START WITH 20010 NO CACHE;CREATE SEQUENCE INV_NUMBER_SEQ START WITH 4010 NO CACHE;Note\\nY ou can check all of the sequences you have created by using the following SQL  \\ncommand, as illustrated in Figure 8.27.\\nSELECT * FROM USER_SEQUENCES;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='03c4ae9c-b35b-4fd2-ad21-8c20ddea7889', embedding=None, metadata={'page_label': '384', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"384   Part 3    Advanced Design and Implementation\\nOracle and SQL Server differ slightly in the syntax for retrieving a value from the \\nsequence. In SQL Server, the phrase NEXT V ALUE FOR <sequence_name> causes the \\nsequence to generate and return the next value. In Oracle, you must use two special \\n pseudo-columns: NEXTV AL and CURRV AL. NEXTV AL retrieves the next available value from a sequence, and CURRV AL retrieves the current value of a sequence. For example, you can use the following code to enter a new customer in SQL Server:\\nINSERT INTO CUSTOMERV ALUES (NEXT V ALUE FOR CUS_CODE_SEQ, 'Connery', 'Sean', NULL, '615',  \\n'898-2007', 0.00);\\nIn Oracle, you would use:INSERT INTO CUSTOMERV ALUES (CUS_CODE_SEQ.NEXTV AL, 'Connery', 'Sean', NULL, '615', '898-2007', 0.00);The preceding SQL statement adds a new customer to the CUSTOMER table and \\nassigns the value 20010 to the CUS_CODE attribute. Examine some important sequence characteristics:\\n•\\n CUS_CODE_SEQ.NEXTV AL retrieves the next available value from the sequence.\\n• Each time you use NEXTV AL, the sequence is incremented.\\n• Once a sequence value is used (through NEXTV AL), it cannot be used again. If your \\nSQL statement rolls back for some reason, the sequence value does not roll back. If you issue another SQL statement (with another NEXTV AL), the next available sequence value will be returned to the user—it will look like the sequence skips a number.\\n•\\n Y ou can issue an INSERT statement without using the sequence.FIGURE 8.27  ORACLE SEQUENCE  \\nSQL Server also stores sequences as schema level objects so they can be viewed with the command\\nSELECT * FROM SYS.SEQUENCES;Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d358e8db-13a1-4860-bd27-79fb98317aca', embedding=None, metadata={'page_label': '385', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    385\\nIn Oracle, CURRV AL retrieves the current value of a sequence—that is, the last \\nsequence number used, which was generated with a NEXTV AL. Y ou cannot use CUR -\\nRV AL unless a NEXTV AL was issued previously in the same session. The main use for \\nCURRV AL is to enter rows in dependent tables. For example, the INVOICE and LINE tables are related in a one-to-many relationship through the INV_NUMBER attri-bute. Y ou can use the INV_NUMBER_SEQ sequence to automatically generate invoice  \\nnumbers. Then, using CURRV AL, you can get the latest INV_NUMBER used and assign it to the related INV_NUMBER foreign key attribute in the LINE table. For example:\\nINSERT\\n INTO  INVOICE  V ALUES   (INV_NUMBER_SEQ.NEXTV AL, \\n20010, SYSDATE);\\nINSERT  INTO  LINE  V ALUES   (INV_NUMBER_SEQ.CURRV AL, 1,'13-Q2/P2', 1, 14.99);\\nINSERT\\n INTO  LINE  V ALUES   (INV_NUMBER_SEQ.CURRV AL, 2,'23109-HB', 1, 9.95);\\nCOMMIT;\\n    \\nThe results are shown in Figure 8.28.\\nFIGURE 8.28  ORACLE SEQUENCE EXAMPLES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c5eba01-48c3-4102-90ce-53bf7aef0a87', embedding=None, metadata={'page_label': '386', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='386   Part 3    Advanced Design and Implementation\\nThe reason that CURRVAL can only be used in the same session as a NEXTVAL is because \\nthe value returned by CURRVAL is not actually provided by the sequence. Remember, the sequence will not generate a value twice. Whenever NEXTVAL is called, Oracle makes a note of the call, which sequence was called, and what number was provided in the user’s session information. When CURRVAL is invoked, the DBMS will look in the session informa-tion to see what the last value provided to that user by that sequence was. This is very pow -\\nerful in a multiuser environment. For example, imagine that Maria and Zameer are working in the same database application and with the same data. When Maria calls on a sequence with NEXTVAL, she is provided a new value. If Zameer calls the same sequence with NEXT -\\nVAL, he is provided a number different from Maria’s number. If, in her same session, Maria now calls on the sequence with CURRVAL, she is not provided with the last number that the sequence generated (which was given to Zameer), but she is given the last number that the sequence provided to her session! Similarly, CURRVAL would provide Zameer with the last value provided to his session. Since this information about the last value provided by the sequence to each user is kept in the user’s session information, when Maria discon-nects from the database, ending her session, that information is lost. If she reconnects to the database, she will be starting a new session. If she immediately calls on CURRVAL, she will get an error because the DBMS does not have a record of that session being provided any values from the sequence.Note\\nIn the example shown in Figure 8.28, INV_NUMBER_SEQ.NEXTV AL retrieves the \\nnext available sequence number (4010) and assigns it to the INV_NUMBER column in the INVOICE table. Also note the use of the SYSDATE attribute to automatically insert the current date in the INV_DATE attribute. Next, the following two INSERT statements add the products being sold to the LINE table. In this case, INV_NUMBER_SEQ.CURRV AL  \\nrefers to the last-used INV_NUMBER_SEQ sequence number (4010). In this way, the relationship between INVOICE and LINE is established automatically. The COMMIT statement at the end of the command sequence makes the changes permanent. Of course, you can also issue a ROLLBACK statement, in which case the rows you inserted in the INVOICE and LINE tables would be rolled back (but remember that the sequence number would not). Once you use a sequence number with NEXTV AL, there is no way to reuse it! This “no-reuse” characteristic is designed to guarantee that the sequence will always gen -\\nerate unique values.\\nAt this writing, SQL Server does not provide a direct equivalent to Oracle’s CURRVAL. If you wish to find the last number generated by a sequence in SQL Server, you can retrieve it by querying the metadata, but this will only give the last number generated by the sequence for any user.Note\\nRemember these points when you think about sequences:\\n• The use of sequences is optional. Y ou can enter the values manually.\\n• A sequence is not associated with a table. As in the examples in Figure 8.28, two distinct sequences were created (one for customer code values and one for invoice number values), but you could have created just one sequence and used it to generate unique values for both tables.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2a6be172-4d38-4527-a986-47ca540408a8', embedding=None, metadata={'page_label': '387', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    387\\nFinally, you can drop a sequence from a database with a DROP SEQUENCE com-\\nmand. For example, to drop the sequences created earlier, you would type:\\nDROP SEQUENCE CUS_CODE_SEQ;\\nDROP SEQUENCE INV_NUMBER_SEQ;\\nDropping a sequence does not delete the values you assigned to table attributes (CUS_\\nCODE and INV_NUMBER); it deletes only the sequence object from the database. The values  you assigned to the table columns (CUS_CODE and INV_NUMBER) remain in \\nthe database.\\nBecause the CUSTOMER and INVOICE tables are used in the following examples, \\nyou will want to keep the original data set. Therefore, you can delete the customer, invoice, and line rows you just added by using the following commands:\\nDELETE FROM INVOICE WHERE INV_NUMBER = 4010;\\nDELETE FROM CUSTOMER WHERE CUS_CODE = 20010;COMMIT;\\nThose commands delete the recently added invoice, all of the invoice line rows \\n associated \\nwith the invoice (the LINE table’s INV_NUMBER foreign key was defined with the ON \\nDELETE CASCADE option), and the recently added customer. The  COMMIT statement \\nsaves all changes to permanent storage.\\nThe SQL standard defines the use of Identity columns and sequence objects. However, some DBMS vendors might not adhere to the standard. Check your DBMS documentation.Note\\nAt this point, you need to re-create the CUS_CODE_SEQ and INV_NUMBER_SEQ sequences, as they will be used again later in the chapter. Enter:\\nCREATE SEQUENCE CUS_CODE_SEQ START WITH 20010 NOCACHE;CREATE SEQUENCE INV_NUMBER_SEQ START WITH 4010 NOCACHE;Note\\n8-7 Procedural SQL\\nThus far, you have learned to use SQL to read, write, and delete data in the database. For example, you learned to update values in a record, to add records, and to delete records. Unfortunately, SQL does not support the conditional  execution of procedures that are \\ntypically supported by a programming language using the general format:\\nIF <condition>\\n      THEN <perform procedure>\\n           ELSE <perform alternate procedure>\\nEND IF\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb091ef8-7bdc-4e7d-86fa-e0a2c0587891', embedding=None, metadata={'page_label': '388', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='388   Part 3    Advanced Design and Implementation\\nSQL also fails to support looping operations in programming languages that permit \\nthe execution of repetitive actions typically encountered in a programming environ-\\nment. The typical format is:\\nDO WHILE\\n     <perform procedure>\\nEND DOTraditionally, if you wanted to perform a conditional or looping type of operation (that \\nis, a procedural type of programming using an IF-THEN-ELSE or DO-WHILE state-ment), you would use a programming language such as Visual Basic .NET, C#, or Java. Although that approach is still common, it usually involves the duplication of application code in many programs. Therefore, when procedural changes are required, modifica-tions must be made in many different programs. An environment characterized by such redundancies often creates data-management problems.\\nA better approach is to isolate critical code and then have all application programs \\ncall the shared code. The advantage of this modular approach is that the application code is isolated in a single program, thus yielding better maintenance and logic control. In any case, the rise of distributed databases and object-oriented databases required that more application code be stored and executed within the database. (For more informa-tion on these databases, see Chapter 12, Distributed Database Management Systems, and Appendix G, Object-Oriented Databases, at www.cengagebrain.com, respectively.) To meet that requirement, most RDBMS vendors created numerous programming  \\nlanguage extensions. Those extensions include:\\n•\\n Flow-control procedural programming structures (IF-THEN-ELSE, DO-WHILE)  \\nfor logic representation\\n• Variable declaration and designation within the procedures\\n• Error management\\nTo remedy the lack of procedural functionality in SQL and to provide some stan-\\ndardization within the many vendor offerings, the SQL-99 standard defined the use of \\npersistent stored modules. A persistent stored module (PSM) is a block of code con-\\ntaining standard SQL statements and procedural extensions that is stored and executed at the DBMS server. The PSM represents business logic that can be encapsulated, stored, and shared among multiple database users. A PSM lets an administrator assign specific access rights to a stored module to ensure that only authorized users can use it. Support for PSMs is left to each vendor to implement. In fact, for many years, some RDBMSs (such as Oracle, SQL Server, and DB2) supported stored procedure modules within the database before the official standard was promulgated.\\nMS SQL Server implements PSMs via Transact-SQL and other language extensions, \\nthe most notable of which are the .NET family of programming languages. Oracle imple-ments PSMs through its procedural SQL language. MySQL uses a procedural version of SQL that is similar in many respects to the Oracle procedural language. Procedural Language SQL (PL/SQL) is a language that makes it possible to use and store procedural code and SQL statements within the database and to merge SQL and traditional pro-gramming constructs, such as variables, conditional processing (IF-THEN-ELSE), basic loops (FOR and WHILE loops), and error trapping. The procedural code is executed as a unit by the DBMS when it is invoked (directly or indirectly) by the end user. End users can use PL/SQL to create:\\n•\\n Anonymous PL/SQL blocks\\n• Triggers (covered in Section 8-7a)persistent stored \\nmodule (PSM)\\nA block of code with standard SQL statements and procedural extensions that is stored and executed at the DBMS server.\\nProcedural \\n Language SQL  \\n(PL/SQL)\\nAn Oracle-specific programming language based on SQL with procedural extensions designed to run inside the Oracle database. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc3973e8-f3a5-44bd-8e37-85d8155c564b', embedding=None, metadata={'page_label': '389', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    389\\n• Stored procedures (covered in Section 8-7b and Section 8-7c)\\n• PL/SQL functions (covered in Section 8-7d)\\nDo not confuse PL/SQL functions with SQL ’s built-in aggregate functions such as \\nMIN and MAX. SQL built-in functions can be used only within SQL statements, while \\nPL/SQL functions are mainly invoked within PL/SQL programs such as triggers and stored procedures. Functions can also be called within SQL statements, provided that they conform to very specific rules that are dependent on your DBMS environment.\\nFIGURE 8.29  ANONYMOUS PL/SQL BLOCK EXAMPLES  \\nPL/SQL, triggers, and stored procedures are illustrated within the context of an Oracle DBMS. All examples in the following sections assume the use of Oracle RDBMS.Note\\nUsing Oracle SQL*Plus, you can write a PL/SQL code block by enclosing the  \\ncommands inside BEGIN and END clauses. For example, the following PL/SQL block inserts a new row in the VENDOR table, as shown in Figure 8.29.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1741b874-0a3e-4d32-a147-cba587a13a0a', embedding=None, metadata={'page_label': '390', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"390   Part 3    Advanced Design and Implementation\\nBEGIN  \\n INSERT INTO VENDOR\\n V ALUES (25678,'Microsoft Corp.', 'Bill Gates','765','546-8484','W A','N');\\nEND;  \\n/ \\nThe PL/SQL block shown in Figure 8.29 is known as an anonymous PL/SQL block \\nbecause it has not been given a specific name. The block’s last line uses a forward slash \\n( / ) to indicate the end of the command-line entry. This type of PL/SQL block executes as soon as you press Enter after typing the forward slash. Following the PL/SQL block’s execution, you will see the message “PL/SQL procedure successfully completed. ”\\nSuppose that you want a more specific message displayed on the SQL*Plus screen \\nafter a procedure is completed, such as “New Vendor Added. ” To produce a more specific message, you must do two things:\\n1.\\n At the SQL > prompt, type SET SERVEROUTPUT ON. This SQL*Plus command \\nenables the client console (SQL*Plus) to receive messages from the server side (Oracle DBMS). Remember, just like standard SQL, the PL/SQL code (anonymous blocks, triggers, and procedures) are executed at the server side, not at the client side. To stop receiving messages from the server, you would enter SET SERVEROUTPUT OFF.\\n2.\\n To send messages from the PL/SQL block to the SQL*Plus console, use the DBMS_OUTPUT.PUT_LINE function.\\nThe following anonymous PL/SQL block inserts a row in the VENDOR table and \\ndisplays the message “New Vendor Added!” (see Figure 8.29).\\nBEGIN\\n \\n INSERT INTO VENDOR\\n V ALUES (25772, 'Clue Store', 'Issac Hayes', '456','323-2009', 'V A', 'N');\\n DBMS_OUTPUT.PUT_LINE('New Vendor Added!');\\nEND;  \\n/ \\nIn Oracle, you can use the SQL*Plus command SHOW ERRORS to help you  diagnose errors \\nfound in PL/SQL blocks. The SHOW ERRORS command yields additional  debugging \\ninformation whenever you generate an error after creating or executing a PL/SQL block.\\nThe following example of an anonymous PL/SQL block demonstrates several of the con -\\nstructs supported by the procedural language. Remember that the exact syntax of the language \\nis vendor-dependent; in fact, many vendors enhance their products with proprietary features.\\nDECLARE  \\nW_P1 NUMBER(3) := 0;  \\nW_P2 NUMBER(3) := 10;  \\nW_NUM NUMBER(2) := 0;  \\nBEGIN  \\nWHILE W_P2 < 300 LOOP  \\n  SELECT COUNT(P_CODE) INTO W_NUM FROM PRODUCT\\n  WHERE P_PRICE BETWEEN W_P1 AND W_P2;\\n   DBMS_OUTPUT  .PUT_LINE('There are ' || W_NUM || ' Products with \\nprice between ' || W_P1 || ' and ' || W_P2);\\n  W_P1 := W_P2 + 1;\\n  W_P2 := W_P2 + 50;\\nEND LOOP;  \\nEND;  \\n/ anonymous PL/SQL block\\nA PL/SQL block that has not been given a specific name.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e64f5568-a9b4-48b5-9975-a9b3f09e6b08', embedding=None, metadata={'page_label': '391', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    391\\nThe block’s code and execution are shown in Figure 8.30.\\nFIGURE 8.30  ANONYMOUS PL/SQL BLOCK WITH VARIABLES AND LOOPS  \\nThe PL/SQL block shown in Figure 8.30 has the following characteristics:\\n• The PL/SQL block starts with the DECLARE section, in which you declare the  \\nvariable names, the data types, and, if desired, an initial value. Supported data types \\nare shown in Table 8.9.\\n• A WHILE loop is used. Note the following syntax:\\nWHILE condition  LOOP\\n    PL/SQL statements;\\nEND LOOP\\n• The SELECT statement uses the INTO keyword to assign the output of the query to a PL/SQL variable. Y ou can use the INTO keyword only inside a PL/SQL block of code. If the SELECT statement returns more than one value, you will get an error.\\n•\\n Note the use of the string concatenation symbol ( || ) to display the output.\\n• Each statement inside the PL/SQL code must end with a semicolon ( ; ).\\nThe most useful feature of PL/SQL blocks is that they let you create code that can be \\nnamed, stored, and executed—either implicitly or explicitly—by the DBMS. That\\xa0capa-bility is especially desirable when you need to use triggers and stored procedures, which you will explore next.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='de3839b0-7943-449d-b8a0-7c6f2458e0ea', embedding=None, metadata={'page_label': '392', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='392   Part 3    Advanced Design and Implementation\\n8-7a  Triggers\\nAutomating business procedures and automatically maintaining data integrity and \\n consistency are critical in a modern business environment. One of the most critical busi-\\nness procedures is proper inventory management. For example, you want to make sure that current product sales can be supported with sufficient product availability. There-fore, you must ensure that a product order is written to a vendor when that product’s inventory drops below its minimum allowable quantity on hand. Better yet, how about ensuring that the task is completed automatically?\\nTo automate product ordering, you first must make sure the product’s quantity on \\nhand reflects an up-to-date and consistent value. After the appropriate product availabil-ity requirements have been set, two key issues must be addressed:\\n1.\\n Business logic requires an update of the product quantity on hand each time there is \\na sale of that product.\\n2. If the product’s quantity on hand falls below its minimum allowable inventory level, the product must be reordered.\\nTo accomplish these two tasks, you could write multiple SQL statements: one to \\nupdate the product quantity on hand and another to update the product reorder flag. Next, you would have to run each statement in the correct order each time there was a new sale. Such a multistage process would be inefficient because a series of SQL statements must be written and executed each time a product is sold. Even worse, this SQL environment requires that someone must remember to perform the SQL tasks.\\nPL/SQL blocks can contain only standard SQL data manipulation language (DML) com-mands such as SELECT, INSERT, UPDATE, and DELETE. The use of data definition language (DDL) commands is not directly supported in a PL/SQL block.NoteTABLE 8.9\\nPL/SQL BASIC DATA TYPES\\nDATA TYPE DESCRIPTION\\nCHAR Character values of a fixed length; for example:W_ZIP CHAR(5)\\nVARCHAR2 Variable-length character values; for example:W_FNAME VARCHAR2(15)\\nNUMBER Numeric values; for example:W_PRICE NUMBER(6,2)\\nDATE Date values; for example:W_EMP_DOB DATE\\n%TYPE Inherits the data type from a variable that you declared previously or from an \\n attribute of a database table; for example:W_PRICE PRODUCT.P_PRICE%TYPEAssigns W_PRICE the same data type as the P_PRICE column in the PRODUCT table\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c238c78f-8f72-43be-be31-35f88b97e7d9', embedding=None, metadata={'page_label': '393', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    393\\nA trigger is procedural SQL code that is automatically  invoked by the RDBMS upon \\nthe occurrence of a given data manipulation event. It is useful to remember that:\\n• A trigger is invoked before or after a data row is inserted, updated, or deleted.\\n• A trigger is associated with a database table.\\n• Each database table may have one or more triggers.\\n• A trigger is executed as part of the transaction that triggered it.\\nTriggers are critical to proper database operation and management. For example:\\n• Triggers can be used to enforce constraints that cannot be enforced at the DBMS \\ndesign and implementation levels.\\n• Triggers add functionality by automating critical actions and providing appropriate warnings and suggestions for remedial action. In fact, one of the most common uses for triggers is to facilitate the enforcement of referential integrity.\\n•\\n Triggers can be used to update table values, insert records in tables, and call other stored procedures.\\nTriggers play a critical role in making the database truly useful; they also add processing \\npower to the RDBMS and to the database system as a whole. Oracle recommends triggers for:\\n•\\n Auditing purposes (creating audit logs)\\n• Automatic generation of derived column values\\n• Enforcement of business or security constraints\\n• Creation of replica tables for backup purposes\\nTo see how a trigger is created and used, examine a simple inventory management \\nproblem. For example, if a product’s quantity on hand is updated when the product is \\nsold, the system should automatically check whether the quantity on hand falls below its minimum allowable quantity. To demonstrate that process, use the PRODUCT table in Figure 8.31. Note the use of the minimum order quantity (P_MIN_ORDER) and \\n product reorder flag (P_REORDER) columns. The P_MIN_ORDER indicates the \\n minimum quantity for restocking an order. The P_REORDER column is a numeric field that \\n indicates whether the product needs to be reordered (1 = Y es, 0 = No). The  initial  \\nP_REORDER values are set to 0 (No) to serve as the basis for the initial trigger development.trigger\\nA procedural SQL code that is automatically invoked by the relational database management system when a data manipulation event occurs.\\nFIGURE 8.31  THE PRODUCT TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='28c7b30e-4a8d-491c-b0a9-d343dc625d02', embedding=None, metadata={'page_label': '394', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='394   Part 3    Advanced Design and Implementation\\nOracle and MS SQL Server allow a trigger to include multiple triggering conditions; that \\nis, any combination of INSERT, UPDATE, and/or DELETE. MySQL allows only one triggering condition per trigger. Therefore, if a certain set of actions should be taken in the case of multiple events, for example, during an UPDATE or an INSERT, then two separate triggers are required in MySQL. To reduce having duplicate code in both triggers, it is a common practice to create a stored procedure that performs the common actions, then have both triggers call the same stored procedure.\\nPreviously, Access did not support triggers for tables. However, starting with Access \\n2013, “Table Events” have been added that provide trigger functionality. A table can have events before and/or after rows are inserted, updated, or deleted.NoteGiven the PRODUCT table listing shown in Figure 8.31, create a trigger to evaluate \\nthe product’s quantity on hand, P_QOH. If the quantity on hand is below the minimum quantity shown in P_MIN, the trigger will set the P_REORDER column to 1, which \\n represents “Y es. ” The syntax to create a trigger in Oracle is as follows:\\nCREATE OR REPLACE TRIGGER trigger_name\\n[BEFORE / AFTER] [DELETE / INSERT / UPDATE OF column_name ] ON table_name\\n[FOR EACH ROW][DECLARE][variable_namedata type [:=initial_value ] ]\\nBEGINPL/SQL instructions;…END;\\nAs you can see, a trigger definition contains the following parts:\\n•\\n The triggering timing : BEFORE or AFTER. This timing indicates when the trigger’s PL/\\nSQL code executes—in this case, before or after the triggering statement is completed.\\n• The triggering event: The statement that causes the trigger to execute (INSERT, \\nUPDATE, or DELETE).\\n  –  The triggering level: The two types of triggers are statement-level triggers and row-level triggers.A statement-level trigger is assumed if you omit the FOR EACH ROW keywords. This type of trigger is executed once, before or after the trigger -\\ning statement is completed. This is the default case.\\n  –  A row-level trigger requires use of the FOR EACH ROW keywords. This type \\nof trigger is executed once for each row affected by the triggering statement. (In\\xa0other words, if you update 10 rows, the trigger executes 10 times.)\\n•\\n The triggering action: The PL/SQL code enclosed between the BEGIN and END \\n keywords. Each statement inside the PL/SQL code must end with a semicolon ( ; ).statement-level trigger\\nA SQL trigger that is assumed if the FOR EACH ROW keywords are omitted. This type of trigger is executed once, before or after the triggering statement completes, and is the default case.\\nrow-level trigger\\nA trigger that is executed once for each row affected by the triggering SQL statement. A row-level trigger requires the use of the FOR EACH ROW keywords in the trigger declaration.\\nIn the PRODUCT table’s case, you will create a statement-level trigger that is implicitly \\nexecuted AFTER an UPDATE of the P_QOH attribute for an existing row or AFTER an INSERT of a new row in the PRODUCT table. The trigger action executes an UPDATE statement that compares the P_QOH with the P_MIN column. If the value of P_QOH is equal to or less than P_MIN, the trigger updates the P_REORDER to 1. To create the trigger, Oracle’s SQL*Plus will be used. The trigger code is shown in Figure 8.32.Online \\nContent\\nOracle users can run \\nthe PRODLIST.SQL script file to format the output of the PRO\\n-\\nDUCT table shown in Figure 8.31. The script file is \\n available at www.  \\ncengagebrain.com.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3ad62c1-9f0f-4f09-bf2e-d273380c50e2', embedding=None, metadata={'page_label': '395', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    395\\nFIGURE 8.33  VERIFYING THE TRG_PRODUCT_REORDER TRIGGER EXECUTION  \\nTo test the TRG_PRODUCT_REORDER trigger, update the quantity on hand of \\nproduct '11QER/31' to 4. After the UPDATE completes, the trigger is automatically fired \\nand the UPDATE statement inside the trigger code sets the P_REORDER to 1 for all products that are below the minimum. (See Figure 8.33.)\\nThe trigger shown in Figure 8.33 seems to work, but what happens if you reduce the \\nminimum quantity of product '2232/QWE'? Figure 8.34 shows that when you update the minimum quantity, the quantity on hand of the product '2232/QWE' falls below the new minimum, but the reorder flag is still 0. Why?\\nThe answer is simple: you updated the P_MIN column, but the trigger is never \\n executed. TRG_PRODUCT_ REORDER executes only after an update of the P_QOH column! To avoid that inconsistency, you must modify the trigger event to exe-cute after\\xa0an update of the P_MIN field, too. The updated trigger code is shown in Figure\\xa08.35.FIGURE 8.32  CREATING THE TRG_PRODUCT_REORDER TRIGGER  \\nThe source code for the stored procedures in this section is available at www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f081e99b-7a36-4c24-9803-8e6cb45d6fbd', embedding=None, metadata={'page_label': '396', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"396   Part 3    Advanced Design and Implementation\\nFIGURE 8.34  THE P_REORDER VALUE MISMATCH AFTER UPDATE OF THE P_MIN ATTRIBUTE  \\nFIGURE 8.35  SECOND VERSION OF THE TRG_PRODUCT_REORDER TRIGGER\\nTo test this new trigger version, change the minimum quantity for product '23114-\\nAA' to 10. After that update, the trigger makes sure that the reorder flag is properly set \\nfor all of the products in the PRODUCT table. (See Figure 8.36.)\\nThis second version of the trigger seems to work well, but nothing happens if you \\nchange the P_QOH value for product '11QER/31', as shown in Figure 8.37! (Note that the reorder flag is still  set to 1.) Why didn’t the trigger change the reorder flag to 0?\\nThe answer is that the trigger does not consider all possible cases. Examine the second \\nversion of the TRG_PRODUCT_REORDER trigger code (Figure 8.35) in more detail:\\n•\\n The trigger fires after the triggering statement is completed. Therefore, the DBMS \\nalways executes two statements (INSERT plus UPDATE or UPDATE plus UPDATE). That is, after you update P_MIN or P_QOH or you insert a new row in the \\n PRODUCT \\ntable, the trigger executes another UPDATE statement automatically.\\n• The triggering action performs an UPDATE of all  the rows in the PRODUCT table, \\neven if the triggering statement updates just one row! This can affect the performance of \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0b6a5ee9-a9e6-46b5-ab54-e484df27dc3f', embedding=None, metadata={'page_label': '397', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    397\\nthe database. Imagine what will happen if you have a PRODUCT table with 519,128 \\nrows and you insert just one product. The trigger will update all 519,129 rows, \\n including the rows that do not need an update!\\n• The trigger sets the P_REORDER value only to 1; it does not reset the value to 0, even if such an action is clearly required when the inventory level is back to a value greater than the minimum value.\\nIn short, the second version of the TRG_PRODUCT_REORDER trigger still does \\nnot complete all of the necessary steps. Now modify the trigger to handle all update \\n scenarios, as shown in Figure 8.38.FIGURE 8.37  THE P_REORDER VALUE MISMATCH AFTER INCREASING THE P_QOH VALUE  \\nFIGURE 8.36  SUCCESSFUL TRIGGER EXECUTION AFTER THE P_MIN VALUE IS UPDATED  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='85b558d0-bfa7-4836-a83f-34ff0fd90512', embedding=None, metadata={'page_label': '398', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='398   Part 3    Advanced Design and Implementation\\nThe trigger in Figure 8.38 sports several new features:\\n• The trigger is executed before  the actual triggering statement is completed. In \\n Figure\\xa08.38, the triggering timing is defined in line 2, BEFORE INSERT OR UPDATE. \\nThis clearly indicates that the triggering statement is executed before the INSERT or UPDATE completes, unlike the previous trigger examples.\\n•\\n The trigger is a row-level trigger instead of a statement-level trigger. The FOR EACH ROW keywords make the trigger a row-level trigger. Therefore, this trigger executes once for each row affected by the triggering statement.\\n•\\n The trigger action uses the :NEW attribute reference to change the value of the  \\nP_REORDER attribute.\\nThe use of the :NEW attribute references deserves a more detailed explanation. To \\nunderstand its use, you must first consider a basic computing tenet: all changes are done first in primary memory, then transferred to permanent memory. In other words, the com-puter cannot change anything directly in permanent storage (on disk). It must first read the data from permanent storage to primary memory, then make the change in primary memory, and finally write the changed data back to permanent memory (on disk).\\nThe DBMS operates in the same way, with one addition. Because ensuring data \\nintegrity is critical, the DBMS makes two copies of every row being changed by a DML (INSERT, UPDATE, or DELETE) statement. Y ou will learn more about this in \\n Chapter\\xa010, \\nTransaction Management and Concurrency Control. The first copy contains the original (“old”) values of the attributes before the changes. The second copy contains the changed (“new”) values of the attributes that will be permanently saved to the database after any changes made by an INSERT, UPDATE, or DELETE. Y ou can use :OLD to refer to the original values; you can use :NEW to refer to the changed values (the values that will  \\nbe stored in the table). Y ou can use :NEW and :OLD attribute references only within the PL/SQL code of a database trigger action. For example:\\n•\\n IF :NEW .P_QOH < = :NEW .P_MIN compares the quantity on hand with the mini-\\nmum quantity of a product. Remember that this is a row-level trigger. Therefore, this comparison is made for each row that is updated by the triggering statement.\\n•\\n Although the trigger is a BEFORE trigger, this does not mean that the triggering state-ment has not executed yet. To the contrary, the triggering statement has already taken place; otherwise, the trigger would not have fired and the :NEW values would not exist. Remember, BEFORE means before  the changes are permanently saved to disk, \\nbut after  the changes are made in memory.\\n•\\n The trigger uses the :NEW reference to assign a value to the P_REORDER  column \\nbefore the UPDATE or INSERT results are permanently stored in the table. FIGURE 8.38  THE THIRD VERSION OF THE TRG_PRODUCT_REORDER TRIGGER\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7fc5e066-3c49-45ed-92a2-704d16b6d6cc', embedding=None, metadata={'page_label': '399', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 8    Advanced SQL    399\\nThe\\xa0assignment is always made to the :NEW value (never to the :OLD value), and the \\nassignment always uses the := assignment operator. The :OLD values are read-only values; you cannot change them. Note that :NEW .P_REORDER := 1; assigns the value 1 to the P_REORDER column and :NEW .P_REORDER := 0; assigns the value 0 to the P_REORDER column.\\n•\\n This new trigger version does not use any DML statements!\\nBefore testing the new trigger, note that product '11QER/31' currently has a quantity \\non hand that is above the minimum quantity, yet the reorder flag is set to 1. Given that condition, the reorder flag must be 0. After creating the new trigger, you can execute an UPDATE statement to fire it, as shown in Figure 8.39.\\nFIGURE 8.39  EXECUTION OF THE THIRD TRIGGER VERSION  \\nNote the following important features of the code in Figure 8.39:\\n• The trigger is automatically invoked for each affected row—in this case, all rows of the PRODUCT table. If your triggering statement would have affected only three rows, not all PRODUCT rows would have the correct P_REORDER value set, which is why the triggering statement was set up as shown in Figure 8.38.\\n•\\n The trigger will run only if you insert a new product row or update P_QOH or  \\nP_MIN. If you update any other attribute, the trigger will not run.\\nY ou can also use a trigger to update an attribute in a table other than the one being \\nmodified. For example, suppose that you would like to create a trigger that automatically reduces the quantity on hand of a product with every sale. To accomplish that task, you must create a trigger for the LINE table that updates a row in the PRODUCT table. The sample code for that trigger is shown in Figure 8.40.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd05a98b-427c-400f-98f9-e28aec31cd47', embedding=None, metadata={'page_label': '400', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='400   Part 3    Advanced Design and Implementation\\nNote that the TRG_LINE_PROD row-level trigger executes after inserting a new \\ninvoice’s LINE and reduces the quantity on hand of the recently sold product by the num-\\nber of units sold. This row-level trigger updates a row in a different table (  PRODUCT), \\nusing the :NEW values of the recently added LINE row.\\nA third trigger example shows the use of variables within a trigger. In this case, you \\nwant to update the customer balance (CUS_BALANCE) in the CUSTOMER table after inserting every new LINE row. This trigger code is shown in Figure 8.41.FIGURE 8.40   TRG_LINE_PROD TRIGGER TO UPDATE THE PRODUCT \\n QUANTITY ON HAND\\nFIGURE 8.41  TRG_LINE_CUS TRIGGER TO UPDATE THE CUSTOMER BALANCE\\nCarefully examine the trigger in Figure 8.41.\\n• The trigger is a row-level trigger that executes after each new LINE row is inserted.\\n• The DECLARE section in the trigger is used to declare any variables used inside the trigger code.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1de826ee-b2f2-49b3-a993-d8ea40f02cab', embedding=None, metadata={'page_label': '401', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    401\\n• Y ou can declare a variable by assigning a name, a data type, and (optionally) an initial \\nvalue, as in the case of the W_TOT variable.\\n• The first step in the trigger code is to get the customer code (CUS_CODE) from the\\xa0related INVOICE table. Note that the SELECT statement returns only one \\n attribute (CUS_CODE) \\nfrom the INVOICE table. Also note that the attribute returns only one value as specified by the use of the WHERE clause, to restrict the query output to a single value.\\n•\\n Note the use of the INTO clause within the SELECT statement. Y ou use the INTO clause to assign a value from a SELECT statement to a variable (W_CUS) used within a trigger.\\n•\\n The second step in the trigger code computes the total of the line by multiplying :NEW .LINE_UNITS by :NEW .LINE_PRICE and assigning the result to the W_TOT variable.\\n•\\n The final step updates the customer balance by using an UPDATE statement and the W_TOT and W_CUS trigger variables.\\n•\\n Double dashes (--) are used to indicate comments within the PL/SQL block.\\nTo summarize the triggers created in this section:\\n• TRG_PRODUCT_REORDER is a row-level trigger that updates P_REORDER in PROD-UCT when a new product is added or when the P_QOH or P_MIN columns are updated.\\n•\\n TRG_LINE_PROD is a row-level trigger that automatically reduces the P_QOH in PRODUCT when a new row is added to the LINE table.\\n•\\n TRG_LINE_CUS is a row-level trigger that automatically increases the CUS_ BALANCE in CUSTOMER when a new row is added in the LINE table.\\nThe use of triggers facilitates the automation of multiple data management tasks. \\nAlthough triggers are independent objects, they are associated with database tables. When you delete a table, all its trigger objects are deleted with it. However, if you needed to delete a trigger without deleting the table, you could use the following command:\\nDROP TRIGGER trigger_name\\nTrigger Action Based on Conditional DML Predicates  Y ou could also create \\ntriggers whose actions depend on the type of DML statement (INSERT, UPDATE, or \\nDELETE) that fires the trigger. For example, you could create a trigger that executes after an INSERT, an UPDATE, or a DELETE on the PRODUCT table. But how do you know which one of the three statements caused the trigger to execute? In those cases, you could use the following syntax:\\nIF INSERTING THEN … END IF;\\nIF UPDATING THEN … END IF;IF DELETING THEN … END IF;\\n8-7b  Stored Procedures\\nA stored procedure is a named collection of procedural and SQL statements. Just like \\ndatabase triggers, stored procedures are stored in the database. One of the major advan-tages of stored procedures is that they can be used to encapsulate and represent business transactions. For example, you can create a stored procedure to represent a product sale, a credit update, or the addition of a new customer. By doing that, you can encapsulate SQL statements within a single stored procedure and execute them as a single transac-tion. There are two clear advantages to the use of stored procedures:\\n•\\n Stored procedures substantially reduce network traffic and increase performance. \\nBecause the procedure is stored at the server, there is no transmission of individual stored procedure\\n(1) A named collection of procedural and SQL statements. (2) Business logic stored on a server in the form of SQL code or another DBMS-specific procedural language.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba20c172-a01f-4b56-a83a-499a018e8dc2', embedding=None, metadata={'page_label': '402', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='402   Part 3    Advanced Design and Implementation\\nSQL statements over the network. The use of stored procedures improves system  \\nperformance because all transactions are executed locally on the RDBMS, so each \\nSQL statement does not have to travel over the network.\\n• Stored procedures help reduce code duplication by means of code isolation and code sharing (creating unique PL/SQL modules that are called by application programs), thereby minimizing the chance of errors and the cost of application development and maintenance.\\nTo create a stored procedure, you use the following syntax:\\nCREATE OR REPLACE PROCEDURE procedure_name  [(argument  [IN/OUT]  \\ndata-type, … )]\\n  [IS/AS]\\n  [variable_namedata type [:=initial_value ] ]\\nBEGIN\\n PL/SQL or SQL statements;\\n …\\nEND;\\nNote the following important points about stored procedures and their syntax:\\n• argument  specifies the parameters that are passed to the stored procedure. A stored \\nprocedure could have zero or more arguments or parameters.\\n• IN/OUT indicates whether the parameter is for input, output, or both.\\n• data-type is one of the procedural SQL data types used in the RDBMS. The data types \\nnormally match those used in the RDBMS table creation statement.\\n• Variables can be declared between the keywords IS and BEGIN. Y ou must specify the variable name, its data type, and (optionally) an initial value.\\nTo illustrate stored procedures, assume that you want to create a procedure  \\n(PRC_PROD_DISCOUNT) to assign an additional 5 percent discount for all \\n products \\nwhen the quantity on hand is more than or equal to twice the minimum quantity. \\n Figure\\xa08.42 shows how the stored procedure is created.\\nFIGURE 8.42  CREATING THE PRC_PROD_DISCOUNT STORED PROCEDURE\\nNote in Figure 8.42 that the PRC_PROD_DISCOUNT stored procedure uses the \\nDBMS_OUTPUT.PUT_LINE function to display a message when the procedure \\n executes. (This action assumes that you previously ran SET SERVEROUTPUT ON.)Online \\nContent\\nThe source code for \\nthe\\xa0 triggers in this \\n section is available at www.cengagebrain.com .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0666eb7f-73bb-4e4a-a121-6c3723b62a44', embedding=None, metadata={'page_label': '403', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    403\\nTo execute the stored procedure, you must use the following syntax:\\nEXEC procedure_name [(parameter_list)];\\nFor example, to see the results of running the PRC_PROD_DISCOUNT stored \\n procedure, you can use the EXEC PRC_PROD_DISCOUNT command shown in \\nFigure\\xa08.43.\\nFIGURE 8.43  RESULTS OF THE PRC_PROD_DISCOUNT STORED PROCEDURE  \\nUsing Figure 8.43 as your guide, you can see how the product discount attribute was \\nincreased by 5 percent for all products with a quantity on hand that was more than or equal to twice the minimum quantity. (Compare the first PRODUCT table listing to the second PRODUCT table listing.)\\nOne of the main advantages of procedures is that you can pass values to them. For \\nexample, the previous PRC_PROD_DISCOUNT procedure worked well, but what if you want to make the percentage increase an input variable? In that case, you can pass an argument to represent the rate of increase to the procedure. Figure 8.44 shows the code for that procedure.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a7fd9e10-bd15-431f-b639-a61176c22ee0', embedding=None, metadata={'page_label': '404', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='404   Part 3    Advanced Design and Implementation\\nFigure 8.45 shows the execution of the second version of the PRC_PROD_ \\nDISCOUNT stored procedure. Note that if the procedure requires arguments, they must \\nbe enclosed in parentheses and separated by commas.FIGURE 8.44  SECOND VERSION OF THE PRC_PROD_DISCOUNT STORED PROCEDURE  \\nFIGURE 8.45   RESULTS OF THE SECOND VERSION OF THE PRC_PROD_  \\nDISCOUNT STORED PROCEDURE  \\nStored procedures are also useful to encapsulate shared code to represent business \\ntransactions. For example, you can create a simple stored procedure to add a new cus-tomer. By using a stored procedure, all programs can call it by name each time a new customer is added. Naturally, if new customer attributes are added later, you will need to modify the stored procedure. However, the programs that use the stored procedure will not need to know the name of the newly added attribute; they will need to add only a new parameter to the procedure call. (Notice the PRC_CUS_ADD stored procedure shown in Figure 8.46.)\\nAs you examine Figure 8.46, note these features:\\n•\\n The PRC_CUS_ADD procedure uses several parameters, one for each required \\n attribute in the CUSTOMER table.\\n• The stored procedure uses the CUS_CODE_SEQ sequence to generate a new \\n customer code.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='25ab9de0-f4c9-401f-845c-aa36c70e2880', embedding=None, metadata={'page_label': '405', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    405\\n• The required parameters—those specified in the table definition—must be included \\nand can be null only  when the table specifications permit nulls for that parameter. \\nFor example, note that the second customer addition was unsuccessful because the CUS_AREACODE is a required attribute and cannot be null.\\n•\\n The procedure displays a message in the SQL*Plus console to let the user know that the customer was added.\\nThe next two examples further illustrate the use of sequences within stored \\n procedures. In this case, create two stored procedures:\\n1. The PRC_INV_ADD procedure adds a new invoice.\\n2. The PRC_LINE_ADD procedure adds a new product line row for a given invoice.\\nBoth procedures are shown in Figure 8.47. Note the use of a variable in the  \\nPRC_LINE_ADD procedure to get the product price from the PRODUCT table.\\nTo test the procedures shown in Figure 8.47:\\n1. Call the PRC_INV_ADD procedure with the new invoice data as arguments.\\n2. Call the PRC_LINE_ADD procedure and pass the product line arguments.\\nThat process is illustrated in Figure 8.48.FIGURE 8.46  THE PRC_CUS_ADD STORED PROCEDURE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='988ec2f6-9f3e-4f70-9dc5-8893ec49d43f', embedding=None, metadata={'page_label': '406', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='406   Part 3    Advanced Design and Implementation\\nFIGURE 8.47  THE PRC_INV_ADD AND PRC_LINE_ADD STORED PROCEDURES  \\nFIGURE 8.48  TESTING THE PRC_INV_ADD AND PRC_LINE_ADD PROCEDURES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c302ba46-e23f-4cc2-9e96-2bbf3821eb50', embedding=None, metadata={'page_label': '407', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    407\\n8-7c  PL/SQL Processing with Cursors\\nUntil now, all of the SQL statements you have used inside a PL/SQL block (trigger or \\nstored procedure) have returned a single value. If the SQL statement returns more than one value, you will generate an error. If you want to use a SQL statement that returns more than one value inside your PL/SQL code, you need to use a cursor. A cursor is a special construct used in procedural SQL to hold the data rows returned by a SQL query. Y ou can think of a cursor as a reserved area of memory in which the output of the query is stored, like an array holding columns and rows. Cursors are held in a reserved memory area in the DBMS server, not in the client computer.\\nThere are two types of cursors: implicit and explicit. An implicit cursor is automati -\\ncally created in procedural SQL when the SQL statement returns only one value. Up to this point, all of the examples created an implicit cursor. An explicit cursor is created to hold the output of a SQL statement that may return two or more rows (but could return zero rows or only one). To create an explicit cursor, you use the following syntax inside a PL/SQL DECLARE section:\\nCURSOR cursor_name IS select-query;Once you have declared a cursor, you can use specific PL/SQL cursor processing \\n commands (OPEN, FETCH, and CLOSE) anywhere between the BEGIN and END \\n keywords of the PL/SQL block. Table 8.10 summarizes the main use of each command.\\nCursor-style processing involves retrieving data from the cursor one row at a time. \\nOnce you open a cursor, it becomes an active data set. That data set contains a “current” \\nrow pointer. Therefore, after opening a cursor, the current row is the first row of the cursor.\\nWhen you fetch a row from the cursor, the data from the “current” row in the cursor \\nis copied to the PL/SQL variables. After the fetch, the “current” row pointer moves to the next row in the set and continues until it reaches the end of the cursor.\\nHow do you know what number of rows are in the cursor? Or how do you know when \\nyou have reached the end of the cursor data set? Y ou know because cursors have special attributes that convey important information. Table 8.11 summarizes the cursor attributes.cursor\\nA special construct used in procedural SQL to hold the data rows returned by a SQL query. A cursor may be considered a reserved area of memory in which query output is stored, like an array holding columns and rows. Cursors are held in a reserved memory area in the DBMS server, not in the client computer.\\nimplicit cursor\\nA cursor that is automatically created in procedural SQL when the SQL statement returns only one row.\\nexplicit cursor\\nIn procedural SQL, a cursor created to hold the output of a SQL statement that may return two or more rows, but could return zero or only one row.\\nTABLE 8.10\\nCURSOR PROCESSING COMMANDS\\nCURSOR COMMAND EXPLANATION\\nOPEN Opening the cursor executes the SQL command and populates the cursor with data, \\n opening the cursor for processing. The cursor declaration command only reserves a named memory area for the cursor; it does not populate the cursor with the data. Before you can use a cursor, you need to open it. For example:OPEN cursor_name\\nFETCH Once the cursor is opened, you can use the FETCH command to retrieve data from the \\n cursor and copy it to the PL/SQL variables for processing. The syntax is:FETCH cursor_name INTO variable1 [, variable2, …]\\nThe PL/SQL variables used to hold the data must be declared in the DECLARE section and \\nmust have data types compatible with the columns retrieved by the SQL command. If the cursor’s SQL statement returns five columns, there must be five PL/SQL variables to receive the data from the cursor.\\nThis type of processing resembles the one-record-at-a-time processing used in previous \\n database models. The first time you fetch a row from the cursor, the first row of data from the cursor is copied to the PL/SQL variables; the second time you fetch a row from the \\n cursor, the second row of data is placed in the PL/SQL variables; and so on.\\nCLOSE The CLOSE command closes the cursor for processing.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8f7d6f1f-8e5d-49f6-b8de-8814d2f72b72', embedding=None, metadata={'page_label': '408', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='408   Part 3    Advanced Design and Implementation\\nTo illustrate the use of cursors, use a simple stored procedure example to list the \\n products that have a greater quantity on hand than the average quantity on hand for all \\nproducts. The code is shown in Figure 8.49.TABLE 8.11\\nCURSOR ATTRIBUTES\\nATTRIBUTE DESCRIPTION\\n%ROWCOUNT Returns the number of rows fetched so far. If the cursor is not OPEN, it returns an error. If no FETCH \\nhas been done but the cursor is OPEN, it returns 0.\\n%FOUND Returns TRUE if the last FETCH returned a row, and FALSE if not. If the cursor is not OPEN, it returns \\nan error. If no FETCH has been done, it contains NULL.\\n%NOTFOUND Returns TRUE if the last FETCH did not return any row, and FALSE if it did. If the cursor is not OPEN, \\nit\\xa0returns an error. If no FETCH has been done, it contains NULL.\\n%ISOPEN Returns TRUE if the cursor is open (ready for processing) or FALSE if the cursor is closed.\\nRemember, before you can use a cursor, you must open it.\\nFIGURE 8.49  A SIMPLE PRC_CURSOR_EXAMPLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='797b195d-9784-411b-b9fd-dae22e9f1b1b', embedding=None, metadata={'page_label': '409', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    409\\nAs you examine the stored procedure code shown in Figure 8.49, note the following \\nimportant characteristics:\\n• Lines 2 and 3 use the %TYPE data type in the variable definition section. As indi-\\ncated in Table 8.9, the %TYPE data type indicates that the given variable inherits the data type from a previously declared variable or from an attribute of a data-base table. In this case, you are using the %TYPE to indicate that the W_P_CODE and W_P_DESCRIPT will have the same data type as the respective columns in the PRODUCT table. This way, you ensure that the PL/SQL variable will have a \\n compatible data type.\\n• Line 5 declares the PROD_CURSOR cursor.\\n• Line 12 opens the PROD_CURSOR cursor and populates it.\\n• Line 13 uses the LOOP statement to loop through the data in the cursor, fetching one row at a time.\\n•\\n Line 14 uses the FETCH command to retrieve a row from the cursor and place it in the respective PL/SQL variables.\\n•\\n Line 15 uses the EXIT command to evaluate when there are no more rows in the  \\ncursor (using the %NOTFOUND cursor attribute) and to exit the loop.\\n• Line 19 uses the %ROWCOUNT cursor attribute to obtain the total number of rows processed.\\n•\\n Line 21 issues the CLOSE PROD_CURSOR command to close the cursor.\\nThe use of cursors, combined with standard SQL, makes working with relational \\ndatabases very desirable because programmers can work in the best of both worlds: set-\\n oriented processing and record-oriented processing. Any experienced programmer \\nknows to use the tool that best fits the job. Sometimes you will be better off manipulating data in a set-oriented environment; at other times, it might be better to use a record-\\n \\noriented environment. Procedural SQL lets you have your proverbial cake and eat it too. Procedural SQL provides functionality that enhances the capabilities of the DBMS while maintaining a high degree of manageability.\\n8-7d  PL/SQL Stored Functions\\nUsing programmable or procedural SQL, you can also create your own stored functions. Stored procedures and functions are very similar. A stored function is basically a named group of procedural and SQL statements that returns a value, as indicated by a RETURN statement in its program code. To create a function, you use the following syntax:\\nCREATE FUNCTION function_name  (argument  IN data-type, … ) RETURN data-type [IS]\\nBEGIN\\n PL/SQL statements;\\n …\\n RETURN (value or expression );\\nEND;Stored functions can be invoked only from within stored procedures or triggers, and \\ncannot be invoked from SQL statements unless the function follows some very specific compliance rules. Remember not to confuse built-in SQL functions (such as MIN, MAX, and AVG) with stored functions.stored function\\nA named group of procedural and SQL statements that returns a value, as indicated by a RETURN statement in its program code.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0ed07ea-df27-495b-92d9-ef32061f50ee', embedding=None, metadata={'page_label': '410', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='410   Part 3    Advanced Design and Implementation\\n8-8 Embedded SQL\\nThere is little doubt that SQL ’s popularity as a data manipulation language is due in \\npart to its ease of use and its powerful data-retrieval capabilities. In the real world, however, database systems are related to other systems and programs, and you still need a conventional programming language such as Visual Basic .NET, C#, or COBOL to integrate database systems with other programs and systems. If you are developing web applications, you are most likely familiar with Visual Studio .NET, Java, ASP , or \\n ColdFusion. Y et, almost regardless of the programming tools you use, if your web appli -\\ncation or Windows-based GUI system requires access to a database such as MS Access, SQL Server, Oracle, or DB2, you will likely need to use SQL to manipulate the data in the database.\\nEmbedded SQL is a term used to refer to SQL statements contained within an appli-\\ncation programming language such as Visual Basic .NET, C#, COBOL, or Java. The \\n program being developed might be a standard binary executable in Windows or Linux, or it might be a web application designed to run over the Internet. No matter what lan-guage you use, if it contains embedded SQL statements, it is called the host language. Embedded SQL is still the most common approach to maintaining procedural capa-bilities in DBMS-based applications. However, mixing SQL with procedural languages requires that you understand some key differences between the two.\\n•\\n Run-time mismatch. Remember that SQL is a nonprocedural, interpreted language; \\nthat is, each instruction is parsed, its syntax is checked, and it is executed one instruc-tion at a time. (The authors are particularly grateful for the thoughtful comments provided by Emil T. Cipolla.) All of the processing takes place at the server side. Meanwhile, the host language is generally a binary-executable program (also known as a compiled program ). The host program typically runs at the client side in its own \\nmemory space, which is different from the DBMS environment.\\n•\\n Processing mismatch . Conventional programming languages (COBOL, ADA, \\n FORTRAN, Pascal, C++, and PL/I) process one data element at a time. Although you can use arrays to hold data, you still process the array elements one row at a time. This is especially true for file manipulation, where the host language typically manipulates data one record at a time. However, newer programming environments such as Visual Studio .NET have adopted several object-oriented extensions that help the program-mer manipulate data sets in a cohesive manner.\\n•\\n Data type mismatch . SQL provides several data types, but some of them might not \\nmatch data types used in different host languages (for example, the DATE and V ARCHAR2 data types).\\nTo bridge the differences, the embedded SQL standard defines a framework to \\n integrate SQL within several programming languages. The embedded SQL framework defines the following:\\n•\\n A standard syntax to identify embedded SQL code within the host language (EXEC \\nSQL/END-EXEC).\\n• A standard syntax to identify host variables, which are variables in the host language that receive data from the database (through the embedded SQL code) and process the data in the host language. All host variables are preceded by a colon ( : ).\\n•\\n A communication area used to exchange status and error information between SQL and the host language. This communication area contains two variables—SQLCODE and SQLSTATE.embedded SQL\\nSQL statements contained within application programming languages such as COBOL, C++, ASP , Java, and ColdFusion.\\nhost language\\nAny language that contains embedded SQL\\n statements.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='50a32393-67a7-435b-b451-361c3349ea76', embedding=None, metadata={'page_label': '411', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    411\\nAnother way to interface host languages and SQL is through the use of a call-level \\ninterface (CLI), in which the programmer writes to an application programming inter -\\nface (API). A common CLI in Windows is provided by the Open Database Connectivity \\n(ODBC) interface.\\nBefore continuing, you should explore the process required to create and run an \\nexecutable program with embedded SQL statements. If you have ever programmed in COBOL or C++, you are familiar with the multiple steps required to generate the final executable program. Although the specific details vary among language and DBMS ven-dors, the following general steps are standard:\\n1.\\n The programmer writes embedded SQL code within the host language instructions. \\nThe code follows the standard syntax required for the host language and embedded SQL.\\n2.\\n A preprocessor is used to transform the embedded SQL into specialized procedure calls that are DBMS- and language-specific. The preprocessor is provided by the DBMS vendor and is specific to the host language.\\n3.\\n The program is compiled using the host language compiler. The compiler creates an object code module for the program containing the DBMS procedure calls.\\n4.\\n The object code is linked to the respective library modules and generates the execut-able program. This process binds the DBMS procedure calls to the DBMS run-time libraries. Additionally, the binding process typically creates an “access plan” module that contains instructions to run the embedded code at run time.\\n5.\\n The executable is run, and the embedded SQL statement retrieves data from the database.\\nNote that you can embed individual SQL statements or even an entire PL/SQL block. \\nUp to this point in the book, you have used a DBMS-provided application (SQL*Plus) to write SQL statements and PL/SQL blocks in an interpretive mode to address one-time  \\nor ad hoc data requests. However, it is extremely difficult and awkward to use ad hoc  \\nqueries to process transactions inside a host language. Programmers typically embed SQL statements within a host language that is compiled once and executed as often as needed. To embed SQL into a host language, follow this syntax:\\nEXEC SQL\\n  SQL statement;\\nEND-EXEC.The preceding syntax will work for SELECT, INSERT, UPDATE, and DELETE state-\\nments. For example, the following embedded SQL code will delete employee 109, George Smith, from the EMPLOYEE table:\\nEXEC SQL\\n  DELETE FROM EMPLOYEE WHERE EMP_NUM = 109;\\nEND-EXEC.Remember, the preceding embedded SQL statement is compiled to generate an execut-\\nable statement. Therefore, the statement is fixed permanently and cannot change (unless, of course, the programmer changes it). Each time the program runs, it deletes the same row. In short, the preceding code is good only for the first run; all subsequent runs will likely generate an error. Clearly, this code would be more useful if you could specify a variable to indicate the employee number to be deleted.Additional coverage of CLIs and ODBC is avail-able in Appendix F, \\n Client/Server Systems, and Appendix J, Web Database Development with ColdFusion, at www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='17c0e73b-57ee-43af-95e6-3451f6b544d2', embedding=None, metadata={'page_label': '412', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='412   Part 3    Advanced Design and Implementation\\nIn embedded SQL, all host variables are preceded by a colon ( : ). The host variables \\nmay be used to send data from the host language to the embedded SQL, or they may \\nbe used to receive the data from the embedded SQL. To use a host variable, you must first declare it in the host language. Common practice is to use similar host variable names as the SQL source attributes. For example, if you are using COBOL, you would define the host variables in the Working Storage section. Then you would refer to them in the embedded SQL section by preceding them with a colon. For example, to delete an employee whose employee number is represented by the host variable W_EMP_NUM, you would write the following code:\\nEXEC SQL\\n  DELETE FROM EMPLOYEE WHERE EMP_NUM = :W_EMP_NUM;\\nEND-EXEC.At run time, the host variable value will be used to execute the embedded SQL statement. \\nWhat happens if the employee you are trying to delete does not exist in the database? How do you know that the statement has been completed without errors? As mentioned previously, the embedded SQL standard defines a SQL communication area to hold sta-tus and error information. In COBOL, such an area is known as the SQLCA area and is defined in the Data Division as follows:\\nEXEC SQL\\n  INCLUDE SQLCA\\nEND-EXEC.The SQLCA area contains two variables for status and error reporting. Table 8.12 shows \\nsome of the main values returned by the variables and their meaning.\\nTABLE 8.12\\nSQL STATUS AND ERROR REPORTING VARIABLES\\nVARIABLE NAME VALUE EXPLANATION\\nSQLCODE Old-style error reporting supported for backward compatibility only; returns an integer value (positive or negative)\\n0 Successful completion of command\\n100 No data; the SQL statement did not return any rows and did not select, update, \\nor delete any rows\\n−999 Any negative value indicates that an error occurred\\nSQLSTATE Added by SQL-92 standard to provide predefined error codes; defined as a  character string (5 characters long)\\n00000 Successful completion of command\\nMultiple values in the format XXYYY where:XX-> represents the class codeYYY-> represents the subclass code\\nThe following embedded SQL code illustrates the use of the SQLCODE within  \\na COBOL program.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='741042ea-475e-4780-bc0e-c7891f4ad6e6', embedding=None, metadata={'page_label': '413', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    413\\nEXEC SQL\\n SELECT   EMP_LNAME, EMP_LNAME INTO :W_EMP_FNAME, \\n:W_EMP_LNAME WHERE EMP_NUM = :W_EMP_NUM;\\nEND-EXEC.IF SQLCODE = 0 THEN\\n PERFORM DATA_ROUTINE\\nELSE\\n PERFORM ERROR_ROUTINE\\nEND-IF.\\nIn this example, the SQLCODE host variable is checked to determine whether the query \\ncompleted successfully. If it did, the DATA_ROUTINE is performed; otherwise, the ERROR_ROUTINE is performed.\\nJust as with PL/SQL, embedded SQL requires the use of cursors to hold data from a \\nquery that returns more than one value. If COBOL is used, the cursor can be declared either in the Working Storage section or in the Procedure Division. The cursor must be declared and processed, as you learned earlier in Section 8-7c. To declare a cursor, you use the syntax shown in the following example:\\nEXEC SQL\\n DECLARE PROD_CURSOR FOR\\n SELECT  P_CODE, P_DESCRIPT FROM PRODUCT\\n WHERE  P_QOH > (SELECT AVG(P_QOH) FROM PRODUCT);\\nEND-EXEC.Next, you must open the cursor to make it ready for processing:EXEC SQL\\n OPEN PROD_CURSOR;\\nEND-EXEC.To process the data rows in the cursor, you use the FETCH command to retrieve one \\nrow of data at a time and place the values in the host variables. The SQLCODE must be checked to ensure that the FETCH command completed successfully. This section of code typically constitutes part of a routine in the COBOL program. Such a routine is executed with the PERFORM command. For example:\\nEXEC SQL\\n FETCH PROD_CURSOR INTO :W_P_CODE, :W_P_DESCRIPT;\\nEND-EXEC.\\nIF SQLCODE = 0 THEN\\n PERFORM DATA_ROUTINE\\nELSE\\n PERFORM ERROR_ROUTINE\\nEND-IF.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bff12af3-3b57-4624-b3b0-5b23cc5ab093', embedding=None, metadata={'page_label': '414', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='414   Part 3    Advanced Design and Implementation\\nWhen all rows have been processed, you close the cursor as follows:\\nEXEC SQL\\n   CLOSE PROD_CURSOR;\\nEND-EXEC.Thus far, you have seen examples of embedded SQL in which the programmer used \\npredefined SQL statements and parameters. Therefore, the end users of the programs are limited to the actions that were specified in the application programs. That style of embedded SQL is known as static SQL, meaning that the SQL statements will not change while the application is running. For example, the SQL statement might read like this:\\nSELECT\\n P_CODE, P_DESCRIPT, P_QOH, P_PRICE\\n  FROM PRODUCT\\nWHERE  P_PRICE > 100;\\nNote that the attributes, tables, and conditions are known in the preceding SQL \\n statement. Unfortunately, end users seldom work in a static environment. They are \\nmore likely to require the flexibility of defining their data access requirements on the fly. \\n Therefore, the end user requires that SQL be as dynamic as the data access \\nrequirements.\\nDynamic SQL is a term used to describe an environment in which the SQL statement \\nis not known in advance; instead, the SQL statement is generated at run time. At run time in a dynamic SQL environment, a program can generate the SQL statements that are required to respond to ad hoc queries. In such an environment, neither the program-mer nor the end user is likely to know precisely what kind of queries will be generated or how they will be structured. For example, a dynamic SQL equivalent of the preceding example could be:\\nSELECT\\n :W_ATTRIBUTE_LIST\\nFROM   :W_TABLE\\nWHERE  :W_CONDITION;\\nNote that the attribute list and the condition are not known until the end user  specifies \\nthem. W_TABLE, W_ATTRIBUTE_LIST, and W_CONDITION are text  variables that \\ncontain the end-user input values used in the query generation. Because the  program \\nuses the end-user input to build the text variables, the end user can run the\\xa0 same \\n program multiple times to generate varying outputs. For example, in one instance, \\nthe\\xa0end user\\xa0might want to know which products cost less than $100; in another case, the end user might want to know how many units of a given product are available for sale at any given moment.\\nAlthough dynamic SQL is clearly flexible, such flexibility carries a price. Dynamic SQL \\ntends to be much slower than static SQL. Dynamic SQL also requires more \\n computer \\nresources (overhead). Finally, you are more likely to find inconsistent levels of support and incompatibilities among DBMS vendors.static SQL\\nA style of embedded SQL in which the SQL statements do not change while the application is running.\\ndynamic SQL\\nAn environment in which the SQL statement is not known in advance, but instead is generated at run time. In a dynamic SQL environment, a program can generate the SQL statements that are required to respond to ad hoc queries.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='da06da0c-1de3-48cf-a4f1-7644fc9749ad', embedding=None, metadata={'page_label': '415', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    415\\n• Operations that join tables can be classified as inner joins and outer joins. An inner \\njoin is the traditional join in which only rows that meet a given criterion are selected. An outer join returns the matching rows as well as the rows with unmatched attribute values for one table or both tables to be joined.\\n•\\n A natural join returns all rows with matching values in the matching columns and eliminates duplicate columns. This style of query is used when the tables share a com-mon attribute with a common name. One important difference between the syntax for a natural join and for the old-style join is that the natural join does not require the use of a table qualifier for the common attributes. In practice, natural joins are often discouraged because the common attribute is not specified within the command, making queries more difficult to understand and maintain.\\n•\\n Joins may use keywords such as USING and ON. If the USING clause is used, the query will return only the rows with matching values in the column indicated in the USING clause; that column must exist in both tables. If the ON clause is used, the query will return only the rows that meet the specified join condition.\\n•\\n Subqueries and correlated queries are used when it is necessary to process data based on other  processed data. That is, the query uses results that were previously unknown \\nand that are generated by another query. Subqueries may be used with the FROM, WHERE, IN, and HAVING clauses in a SELECT statement. A subquery may return a single row or multiple rows.\\n•\\n Most subqueries are executed in a serial fashion. That is, the outer query initiates the data request, and then the inner subquery is executed. In contrast, a correlated subquery is a subquery that is executed once for each row in the outer query. That process is similar to the typical nested loop in a programming language. A correlated subquery is so named because the inner query is related to the outer query—the inner query references a column of the outer subquery.\\n•\\n SQL functions are used to extract or transform data. The most frequently used functions are date and time functions. The results of the function output can be used to store values in a database table, to serve as the basis for the computation of derived variables, or to serve as a basis for data comparisons. Function formats can be vendor-specific. Aside from time and date functions, there are numeric and string functions as well as conversion functions that convert one data format to another.\\n•\\n SQL provides relational set operators to combine the output of two queries to  generate \\na new relation. The UNION and UNION ALL set operators combine the output of two or more queries and produce a new relation with all unique (UNION) or dupli-cate (UNION ALL) rows from both queries. The INTERSECT relational set operator selects only the common rows. The EXCEPT (MINUS) set operator selects only the rows that are different. UNION, INTERSECT, and EXCEPT require union-\\n compatible \\nrelations.\\n• In Oracle and SQL Server, sequences may be used to generate values to be assigned to a record. For example, a sequence may be used to number invoices automatically. MS Access uses an AutoNumber data type to generate numeric sequences, and MySQL uses the AUTO_INCREMENT property during table creation. Oracle and SQL Server can use the Identity column property to designate the column that will have Summary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4c09d4c0-4f52-4e58-96b3-779ac364e800', embedding=None, metadata={'page_label': '416', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='416   Part 3    Advanced Design and Implementation\\nsequential numeric values automatically assigned to it. There can only be one Identity \\ncolumn per table.\\n• Procedural Language SQL (PL/SQL) can be used to create triggers, stored procedures, and PL/SQL functions. A trigger is procedural SQL code that is automatically invoked by the DBMS upon the occurrence of a specified data manipulation event (UPDATE, INSERT, or DELETE). Triggers are critical to proper database operation and manage-ment. They help automate various transaction and data management processes, and they can be used to enforce constraints that are not enforced at the DBMS design and implementation levels.\\n•\\n A stored procedure is a named collection of SQL statements. Just like database trig-gers, stored procedures are stored in the database. One of the major advantages of stored procedures is that they can be used to encapsulate and represent complete business transactions. Use of stored procedures substantially reduces network traffic and increases system performance. Stored procedures also help reduce code duplica-tion by creating unique PL/SQL modules that are called by the application programs, thereby minimizing the chance of errors and the cost of application development and maintenance.\\n•\\n When SQL statements are designed to return more than one value inside the PL/SQL code, a cursor is needed. Y ou can think of a cursor as a reserved area of memory in which the output of the query is stored, like an array holding columns and rows. Cur -\\nsors are held in a reserved memory area in the DBMS server, rather than in the client computer. There are two types of cursors: implicit and explicit.\\n•\\n Embedded SQL refers to the use of SQL statements within an application program-ming language such as Visual Basic .NET, C#, COBOL, or Java. The language in which the SQL statements are embedded is called the host language. Embedded SQL is still the most common approach to maintaining procedural capabilities in DBMS-based applications.\\nanonymous PL/SQL block\\nbase tablebatch update routinecorrelated subqueryCREATE VIEWcross joincursordynamic SQLembedded SQLexplicit cursorhost languageimplicit cursorinner joinouter joinpersistent stored module \\n(PSM)\\nProcedural Language SQL \\n(PL/SQL)\\nrow-level triggersequenceset-orientedstatement-level triggerstatic SQLstored functionstored proceduretriggerunion-compatibleupdatable viewview\\nKey Terms\\nFlashcards and  crossword \\npuzzles for key term \\n practice\\xa0are available at \\nwww.  cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38070a71-a5eb-498d-a0ff-175bb193ca94', embedding=None, metadata={'page_label': '417', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    417\\n1. What is a CROSS JOIN? Give an example of its syntax.\\n2. What three join types are included in the OUTER JOIN classification?\\n3. Using tables named T1 and T2, write a query example for each of the three join \\ntypes you described in Question 2. Assume that T1 and T2 share a common column named C1.\\n4.\\n What is a subquery, and what are its basic characteristics?\\n5. What are the three types of results that a subquery can return?\\n6. What is a correlated subquery? Give an example.\\n7. Explain the difference between a regular subquery and a correlated subquery.\\n8. What does it mean to say that SQL operators are set-oriented?\\n9. The relational set operators UNION, INTERSECT, and EXCEPT (MINUS) work properly only when the relations are union-compatible. What does union-compati-ble mean, and how would you check for this condition?\\n10.\\n What is the difference between UNION and UNION ALL? Write the syntax for each.\\n11. Suppose you have two tables: EMPLOYEE and EMPLOYEE_1. The EMPLOYEE table contains the records for three employees: Alice Cordoza, John Cretchakov, and Anne McDonald. The EMPLOYEE_1 table contains the records for employees John Cretchakov and Mary Chen. Given that information, list the query output for the UNION query.\\n12.\\n Given the employee information in Question 11, list the query output for the UNION ALL query.\\n13.\\n Given the employee information in Question 11, list the query output for the INTERSECT query.\\n14.\\n Given the employee information in Question 11, list the query output for the EXCEPT (MINUS) query of EMPLOYEE to EMPLOYEE_1.\\n15.\\n Why does the order of the operands (tables) matter in an EXCEPT (MINUS) query but not in a UNION query?\\n16.\\n What MS Access and SQL Server function should you use to calculate the number of days between your birth date and the current date?\\n17.\\n What Oracle function should you use to calculate the number of days between your birth date and the current date?\\n18.\\n Suppose a PRODUCT table contains two attributes, PROD_CODE and VEND_CODE. Those two attributes have values of ABC, 125, DEF, 124, GHI, 124, and JKL, 123, respectively. The VENDOR table contains a single attribute, VEND_CODE, with values 123, 124, 125, and 126, respectively. (The VEND_CODE attribute in the PRODUCT table is a foreign key to the VEND_CODE in the VENDOR table.) Given that information, what would be the query output for:\\n  a. A UNION query based on the two tables?\\n  b. A UNION ALL query based on the two tables?\\n  c. An INTERSECT query based on the two tables?\\n  d. An EXCEPT (MINUS) query based on the two tables?\\nReview Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aad3f098-ae61-4c45-bb1e-588873124c31', embedding=None, metadata={'page_label': '418', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='418   Part 3     Advanced Design and Implementation\\n19. What string function should you use to list the first three characters of a company’s \\nEMP_LNAME values? Give an example using a table named EMPLOYEE. Provide \\nexamples for Oracle and SQL Server.\\n20. What is a sequence? Write its syntax.\\n21. What is a trigger, and what is its purpose? Give an example.\\n22. What is a stored procedure, and why is it particularly useful? Give an example.\\n23. What is embedded SQL and how is it used?\\n24. What is dynamic SQL, and how does it differ from static SQL?\\nProblems\\nUse the database tables in Figure P8.1 as the basis for Problems 1–18.\\nFIGURE P8.1  CH08_SIMPLECO DATABASE TABLES  \\nTable name: CUSTOMERDatabase name: Ch08_SimpleCo\\nTable name: INVOICE\\nTable name: CUSTOMER_2\\nFIGURE P8.3  COMBINED LIST OF CUSTOMERS WITHOUT DUPLICATES\\n1. Create the tables. (Use the MS Access example shown in Figure P8.1 to see what \\ntable names and attributes to use.)\\n2. Insert the data into the tables you created in Problem 1.\\n3. Write the query that will generate a combined list of customers from the tables \\n CUSTOMER and CUSTOMER_2 that do not include the duplicate customer \\nrecords. Only the customer named Juan Ortega shows up in both customer tables. \\n(Figure P8.3)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5d2b902f-4089-404e-a289-cae7484b9b0d', embedding=None, metadata={'page_label': '419', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    419\\n4. Write the query that will generate a combined list of customers to include the \\n duplicate customer records. (Figure P8.4)\\nFIGURE P8.4  COMBINED LIST OF CUSTOMERS WITH DUPLICATES  \\nFIGURE P8.5  DUPLICATE CUSTOMER RECORD\\nFIGURE P8.6  CUSTOMERS UNIQUE TO THE CUSTOMER_2 TABLE\\n5. Write the query that will show only the duplicate customer records. (Figure P8.5)\\n6. Write the query that will generate only the records that are unique to the \\n CUSTOMER_2 table. (Figure P8.6)\\n7. Write the query to show the invoice number, customer number, customer name, \\ninvoice date, and invoice amount for all customers in the CUSTOMER table with a \\nbalance of $1,000 or more. (Figure P8.7)\\nFIGURE P8.8   INVOICE AMOUNTS COMPARED TO THE AVERAGE  \\nINVOICE AMOUNT\\nFIGURE P8.7  INVOICES OF CUSTOMERS WITH A BALANCE OVER $1000  \\n8. Write the query for all the invoices that will show the invoice number, invoice amount, \\naverage invoice amount, and difference between the average invoice amount and the \\nactual invoice amount. (Figure P8.8)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e0d53125-3399-42f5-b29b-1c3dfcea57d6', embedding=None, metadata={'page_label': '420', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"420   Part 3    Advanced Design and Implementation\\n9. Write the query that will write Oracle sequences to produce automatic customer \\nnumber and invoice number values. Start the customer numbers at 1000 and the invoice numbers at 5000.\\n10.\\n Modify the CUSTOMER table to include two new attributes: CUST_DOB and CUST_AGE. Customer 1000 was born on March 15, 1979, and customer 1001 was born on December 22, 1988.\\n11.\\n Assuming that you completed Problem 10, write the query that will list the names and ages of your customers.\\n12.\\n Assuming that the CUSTOMER table contains a CUST_AGE attribute, write the query to update the values in that attribute. (Hint : Use the results of the previous \\nquery.)\\n13.\\n Write the query that lists the average age of your customers. (Assume that the CUSTOMER table has been modified to include the CUST_DOB and the derived CUST_AGE attribute.)\\n14.\\n Write the trigger to update the CUST_BALANCE in the CUSTOMER table when a new invoice record is entered. (Assume that the sale is a credit sale.) Test the trigger using the following new INVOICE record:\\n  8005, 1001, '27-APR-16', 225.40\\n  Name the trigger trg_updatecustbalance.\\n15. Write a procedure to add a new customer to the CUSTOMER table. Use the  following \\nvalues in the new record:\\n  1002, 'Rauthor', 'Peter', 0.00\\n  Name the procedure prc_cust_add. Run a query to see if the record has been added.\\n16.\\n Write a procedure to add a new invoice record to the INVOICE table. Use the \\n following values in the new record:\\n  8006, 1000, '30-APR-16', 301.72\\n  Name the procedure prc_invoice_add. Run a query to see if the record has been added.\\n17.\\n Write a trigger to update the customer balance when an invoice is deleted. Name the trigger trg_updatecustbalance2.\\n18.\\n Write a procedure to delete an invoice, giving the invoice number as a parameter. Name the procedure prc_inv_delete. Test the procedure by deleting invoices 8005 and 8006.\\nUse the Ch08_LargeCo database shown in Figure P8.19 to work Problems 19–27. For problems with very large result sets, only the first several rows of output are shown in the following figures.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c1625b42-d0d5-436e-8dd8-ef2878c0c806', embedding=None, metadata={'page_label': '421', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    421\\n19. Write a query to display the products that have a price greater than $50.\\n20. Write a query to display the current salary for each employee in department 300. \\nAssume that only current employees are kept in the system, and therefore the most \\ncurrent salary for each employee is the entry in the salary history with a NULL end \\ndate. Sort the output in descending order by salary amount. (Figure P8.20)FIGURE P8.19  THE LARGECO ERD  \\nFIGURE P8.20  CURRENT SALARY FOR EMPLOYEES IN DEPARTMENT 300  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3b4c0a3b-c1eb-44e0-b644-d5f3dd4584fe', embedding=None, metadata={'page_label': '422', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='422   Part 3     Advanced Design and Implementation\\n21. Write a query to display the starting salary for each employee. The starting salary \\nwould be the entry in the salary history with the oldest salary start date for each \\nemployee. Sort the output by employee number. (Figure P8.21)\\nFIGURE P8.21  STARTING SALARY FOR EACH EMPLOYEE\\nFIGURE P8.22  INVOICES FOR SEALER AND TOP COAT OF THE SAME BRAND  \\nFIGURE P8.23  EMPLOYEES WITH MOST BINDER PRIME UNITS SOLD  \\n22. Write a query to display the invoice number, line numbers, product SKUs, product \\ndescriptions, and brand ID for sales of sealer and top coat products of the same \\nbrand on the same invoice. (Figure P8.22)\\n23. The Binder Prime Company wants to recognize the employee who sold the most of \\nits products during a specified period. Write a query to display the employee  number, \\nemployee first name, employee last name, email address, and total units sold for the \\nemployee who sold the most Binder Prime brand products between November 1, \\n2015, and December 5, 2015. If there is a tie for most units sold, sort the output by \\nemployee last name. (Figure P8.23)\\n24. Write a query to display the customer code, first name, and last name of all custom -\\ners who have had at least one invoice completed by employee 83649 and at least one \\ninvoice completed by employee 83677. Sort the output by customer last name and \\nthen first name. (Figure P8.24)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3a2cee4-f793-46e3-8f7c-d1d2a70c050b', embedding=None, metadata={'page_label': '423', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    423\\n25. LargeCo is planning a new promotion in Alabama (AL) and wants to know about \\nthe largest purchases made by customers in that state. Write a query to display \\nthe customer code, customer first name, last name, full address, invoice date, and \\ninvoice total of the largest purchase made by each customer in Alabama. Be certain \\nto include any customers in Alabama who have never made a purchase; their invoice \\ndates should be NULL and the invoice totals should display as 0. (Figure P8.25)FIGURE P8.24   CUSTOMERS WITH INVOICES FILLED BY EMPLOYEES  \\n83649 AND 83677\\nFIGURE P8.25  LARGEST PURCHASES OF CUSTOMERS IN AL\\nFIGURE P8.26   AVERAGE PRICE AND TOTAL UNITS SOLD OF PRODUCTS  \\nBY BRAND\\n26. One of the purchasing managers is interested in the impact of product prices on the \\nsale of products of each brand. Write a query to display the brand name, brand type, \\naverage price of products of each brand, and total units sold of products of each brand. \\nEven if a product has been sold more than once, its price should only be included \\nonce in the calculation of the average price. However, you must be careful because \\nmultiple products of the same brand can have the same price, and each of those prod -\\nucts must be included in the calculation of the brand’s average price. (Figure P8.26)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1dde5361-aa84-415a-b35f-f8d06c1be968', embedding=None, metadata={'page_label': '424', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='424   Part 3     Advanced Design and Implementation\\n27. The purchasing manager is still concerned about the impact of price on sales. Write \\na query to display the brand name, brand type, product SKU, product description, \\nand price of any products that are not a premium brand, but that cost more than the \\nmost expensive premium brand products. (Figure P8.27)\\nFIGURE P8.27   NON-PREMIUM PRODUCTS THAT ARE MORE EXPENSIVE \\nTHAN PREMIUM PRODUCTS\\nFIGURE P8.28  CH08_SALECO2 DATABASE TABLES  \\nTable name: CUSTOMERDatabase name: Ch08_SaleCo2\\nTable name: INVOICE\\nTable name: LINETable name: PRODUCT\\nTable name: VENDOR\\nUse the Ch08_SaleCo2 database shown in Figure P8.28 to work Problems 28–31.\\n28. Create a trigger named trg_line_total  to write the LINE_TOTAL value in the LINE \\ntable every time you add a new LINE row. (The LINE_TOTAL value is the product \\nof the LINE_UNITS and LINE_PRICE values.)\\n29. Create a trigger named trg_line_prod  that automatically updates the quantity on \\nhand for each product sold after a new LINE row is added.\\n30. Create a stored procedure named prc_inv_amounts  to update the INV_SUB -\\nTOTAL, INV_TAX, and INV_TOTAL. The procedure takes the invoice number \\nas a parameter. The INV_SUBTOTAL is the sum of the LINE_TOTAL amounts \\nfor the invoice, the INV_TAX is the product of the INV_SUBTOTAL and the tax \\nrate (8 percent), and the INV_TOTAL is the sum of the INV_SUBTOTAL and the \\nINV_TAX.Online \\nContent\\nThe Ch08_SaleCo2  \\ndatabase used in Prob -\\nlems 28–31 is available at \\nwww.cengagebrain.com ,  \\nas are the script files to \\nduplicate this data set  \\nin Oracle, MySQL, and \\nSQL Server.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='82ef07fa-123a-4fae-808e-6384021ba1db', embedding=None, metadata={'page_label': '425', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    425\\n31. Create a procedure named prc_cus_balance_update  that will take the invoice \\nnumber as a parameter and update the customer balance. ( Hint : Y ou can use the \\nDECLARE section to define a TOTINV numeric variable that holds the computed \\ninvoice total.)\\nUse the Ch08_AviaCo database shown in Figure P8.32 to work Problems 32–43.\\nFIGURE P8.32  CH08_AVIACO DATABASE TABLES  \\nTable name: CHARTER Database name: Ch08_AviaCo\\nTable name: EARNEDRA TING\\nTable name: CREW Table name: CUSTOMER\\nTable name: EMPLOYEETable name: RATING\\nTable name: MODEL\\nTable name: AIRCRAFT\\n Table name: PILOT\\n32. Modify the MODEL table to add the attribute and insert the values shown in the \\nfollowing table.\\nATTRIBUTE NAME ATTRIBUTE \\n DESCRIPTIONATTRIBUTE \\nTYPEATTRIBUTE VALUES\\nMOD_WAIT_CHG Waiting charge per \\nhour for each modelNumeric $100 for C-90A\\n$50 for PA23-250\\n$75 for PA31-350\\n33. Write the queries to update the MOD_W AIT_CHG attribute values based on \\n Problem 32.The Ch08_AviaCo data -\\nbase used in Problems \\n32–43 is available at www.\\ncengagebrain.com , as are \\nthe script files to duplicate \\nthis data set in Oracle, SQL \\nServer, and MySQL.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a7fb3f3e-cc78-44ed-a32d-244a9a6a8a8c', embedding=None, metadata={'page_label': '426', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='426   Part 3    Advanced Design and Implementation\\n34. Modify the CHARTER table to add the attributes shown in the following table.\\nATTRIBUTE NAME ATTRIBUTE DESCRIPTION ATTRIBUTE TYPE\\nCHAR_WAIT_CHG Waiting charge for each model (copied from the MODEL table) Numeric\\nCHAR_FLT_CHG_HR Flight charge per mile for each model (copied from the MODEL table \\nusing the MOD_CHG_MILE attribute)Numeric\\nCHAR_FLT_CHG Flight charge (calculated by CHAR_HOURS_FLOWN ×  \\nCHAR_FLT_CHG_HR)Numeric\\nCHAR_TAX_CHG CHAR_FLT_CHG × tax rate (8%) Numeric\\nCHAR_TOT_CHG CHAR_FLT_CHG + CHAR_TAX_CHG Numeric\\nCHAR_PYMT Amount paid by customer Numeric\\nCHAR_BALANCE Balance remaining after payment Numeric\\n35. Write the sequence of commands required to update the CHAR_W AIT_CHG \\n attribute values in the CHARTER table. (Hint : Use either an updatable view or a \\nstored procedure.)\\n36. Write the sequence of commands required to update the CHAR_FLT_CHG_HR \\nattribute values in the CHARTER table. (Hint : Use either an updatable view or a \\nstored procedure.)\\n37. Write the command required to update the CHAR_FLT_CHG attribute values in the CHARTER table.\\n38.\\n Write the command required to update the CHAR_TAX_CHG attribute values in the CHARTER table.\\n39.\\n Write the command required to update the CHAR_TOT_CHG attribute values in the CHARTER table.\\n40.\\n Modify the PILOT table to add the attribute shown in the following table.\\nATTRIBUTE NAME ATTRIBUTE DESCRIPTION ATTRIBUTE TYPE\\nPIL_PIC_HRS Pilot in command (PIC) hours; updated by adding the CHARTER table’s CHAR_HOURS_FLOWN to the PIL_PIC_HRS when the CREW table shows the CREW_JOB to be PilotNumeric\\n41. Create a trigger named trg_char_hours that automatically updates the AIRCRAFT table when a new CHARTER row is added. Use the CHARTER table’s CHAR_HOURS_FLOWN to update the AIRCRAFT table’s AC_TTAF, AC_TTEL, and AC_TTER values.\\n42.\\n Create a trigger named trg_pic_hours that automatically updates the PILOT table when a new CREW row is added and the CREW table uses a Pilot CREW_JOB entry. Use the CHARTER table’s CHAR_HOURS_FLOWN to update the PILOT table’s PIL_PIC_HRS only when the CREW table uses a Pilot CREW_JOB entry.\\n43.\\n Create a trigger named trg_cust_balance that automatically updates the CUS-TOMER table’s CUS_BALANCE when a new CHARTER row is added. Use the CHARTER table’s CHAR_TOT_CHG as the update source. (Assume that all charter charges are charged to the customer balance.)\\nProblems 44–67 use the Ch08_Fact database shown in Figure P8.44. For problems with very large results sets, only the first several rows of output are shown in the following figures.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='acc0d407-4150-4928-aa16-df1a806a2635', embedding=None, metadata={'page_label': '427', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    427\\n44. Write a query to display all rows in the PATRON table.\\n45. Write a query to display the patron ID, book number, and days kept for each check -\\nout. “Days Kept” is the difference from the date on which the book is returned to the \\ndate it was checked out. (Figure P8.45)\\n46. Write a query to display the patron ID, patron full name, and patron type for each \\npatron. (Figure P8.46)FIGURE P8.44  THE CH08_FACT ERD\\nFIGURE P8.45  DAYS KEPT\\n FIGURE P8.46   PATRON AND PATRON  \\nTYPE\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b06aa06f-51a1-417c-ab0d-c7af5ed06b55', embedding=None, metadata={'page_label': '428', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='428   Part 3     Advanced Design and Implementation\\n47. Write a query to display the book number, title with year, and subject for each book. \\n(Figure P8.47)\\nFIGURE P8.47  BOOK TITLE WITH YEAR\\nFIGURE P8.48  BOOKS WRITTEN BY AUTHOR  \\nFIGURE P8.49  AUTHORS OF BOOKS  \\n48. Write a query to display the author last name, author first name, and book number \\nfor each book written by that author. (Figure P8.48)\\n49. Write a query to display the author ID, book number, title, and year for each book. \\n(Figure P8.49)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f4c0c58-de31-4b21-b169-5319adc588f1', embedding=None, metadata={'page_label': '429', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    429\\n50. Write a query to display the author last name, first name, book title, and year for \\neach book. (Figure P8.50)\\nFIGURE P8.50  AUTHOR NAME AND BOOK TITLE\\nFIGURE P8.51  CURRENTLY CHECKED OUT BOOKS\\nFIGURE P8.52  SORTED PATRONS WITH FULL NAMES  \\n51. Write a query to display the patron ID, book number, patron first name and last \\nname, and book title for all currently checked out books. (Remember to use the \\nredundant relationship described in the assignment instructions for current check -\\nouts.) Sort the output by patron last name and book title. (Figure P8.51)\\n52. Write a query to display the patron ID, full name (first and last), and patron type for \\nall patrons. Sort the results by patron type, then by last name and first name. Ensure \\nthat all sorting is case insensitive. (Figure P8.52)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d2ba6160-1223-49c0-a629-0611ccfd2344', embedding=None, metadata={'page_label': '430', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='430   Part 3     Advanced Design and Implementation\\n53. Write a query to display the book number and the number of times each book \\nhas been checked out. Do not include books that have never been checked out. \\n(Figure\\xa0P8.53)\\nFIGURE P8.54  BOOKS ON CLOUD COMPUTING\\nFIGURE P8.55  CURRENTLY CHECKED OUT BOOKS WITH AUTHOR  \\nFIGURE P8.53  TIMES CHECKED OUT\\n54. Write a query to display the author ID, first and last name, book number, and book \\ntitle of all books in the subject “Cloud” . Sort the results by book title and then by \\nauthor last name. (Figure P8.54)\\n55. Write a query to display the book number, title, author last name, author first name, \\npatron ID, last name, and patron type for all books currently checked out to a patron. \\nSort the results by book title. (Figure P8.55)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='741c49ab-ae02-4624-aca1-b619db3c99ef', embedding=None, metadata={'page_label': '431', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    431\\n56. Write a query to display the book number, title, and number of times each book has \\nbeen checked out. Include books that have never been checked out. Sort the results \\nin descending order by the number times checked out, then by title. (Figure P8.56)\\nFIGURE P8.56  NUMBER OF CHECKOUTS FOR EVERY BOOK\\nFIGURE P8.57  BOOKS WITH MORE THAN 5 CHECKOUTS  \\nFIGURE P8.58  BOOKS BY AUTHOR FOR PATRON “MILES”  \\n57. Write a query to display the book number, title, and number of times each book has \\nbeen checked out. Limit the results to books that have been checked out more than \\nfive times. Sort the results in descending order by the number of times checked out, \\nand then by title. (Figure P8.57)\\n58. Write a query to display the author ID, author last name, book title, checkout date, \\nand patron last name for all the books written by authors with the last name “Bruer” \\nthat have ever been checked out by patrons with the last name “Miles” . (Figure P8.58)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f0610a01-7254-45e7-82d2-06860f3d6b87', embedding=None, metadata={'page_label': '432', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='432   Part 3     Advanced Design and Implementation\\n59. Write a query to display the patron ID, first and last name of all patrons that have \\nnever checked out any book. Sort the result by patron last name then first name. \\n(Figure P8.59)\\nFIGURE P8.59  PATRONS THAT NEVER CHECKED OUT A BOOK  \\n60. Write a query to display the patron ID, last name, number of times that patron has \\never checked out a book, and the number of different books the patron has ever \\nchecked out. For example, if a given patron has checked out the same book twice, \\nthat would count as two checkouts but only one book. Limit the results to only \\npatrons that have made at least three checkouts. Sort the results in descending order \\nby number of books, then in descending order by number of checkouts, then in \\nascending order by patron ID. (Figure P8.60)\\nFIGURE P8.60  CHECKOUTS AND BOOKS BY PATRON\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2c56f8c2-ba49-49a8-99e9-f914342cafad', embedding=None, metadata={'page_label': '433', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    433\\n61. Write a query to display the average number of days a book is kept during a check -\\nout. (Figure P8.61)\\nFIGURE P8.61  AVERAGE DAYS KEPT  \\nFIGURE P8.62  AVERAGE DAYS KEPT BY PATRON  \\nFIGURE P8.63  LEAST EXPENSIVE BOOKS  \\n62. Write a query to display the patron ID and the average number of days that patron \\nkeeps books during a checkout. Limit the results to only patrons that have at least \\nthree checkouts. Sort the results in descending order by the average days the book is \\nkept. (Figure P8.62)\\n63. Write a query to display the book number, title, and cost of books that have the low -\\nest cost of any books in the system. Sort the results by book number. (Figure P8.63)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2a6cd29a-fbf9-4351-8889-a88d8c0d3824', embedding=None, metadata={'page_label': '434', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='434   Part 3     Advanced Design and Implementation\\n64. Write a query to display the author ID, first and last name for all authors that have \\nnever written a book with the subject Programming. Sort the results by author last \\nname. (Figure P8.64)\\nFIGURE P8.64  AUTHORS THAT HAVE NEVER WRITTEN ON PROGRAMMING\\nFIGURE P8.65  BOOKS WITH AVERAGE COST BY SUBJECT  \\nFIGURE P8.66  NUMBER OF BOOKS BY CLOUD AUTHORS\\n65. Write a query to display the book number, title, subject, average cost of books within \\nthat subject, and the difference between each book’s cost and the average cost of \\nbooks in that subject. Sort the results by book title. (Figure P8.65)\\n66. Write a query to display the book number, title, subject, author last name, and the \\nnumber of books written by that author. Limit the results to books in the Cloud \\n subject. Sort the results by book title and then author last name. (Figure P8.66)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a0c51f6c-425b-43d5-9596-0840d7acf8e5', embedding=None, metadata={'page_label': '435', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    435\\n67. Write a query to display the lowest average cost of books within a subject and the \\nhighest average cost of books within a subject. (Figure P8.67)\\nFIGURE P8.67  LOWEST AND HIGHEST AVERAGE SUBJECT COSTS\\nThe following problems expand on the EliteVideo case from Chapter 7. To complete \\nthe following problems, you must have first completed the table creation and data-entry \\nrequirements specified in Problems 96 and 97 in Chapter 7.\\n68. Alter the DETAILRENTAL table to include a derived attribute named DETAIL_\\nDAYSLATE to store integers of up to three digits. The attribute should accept null \\nvalues.\\n69. Update the DETAILRENTAL table to set the values in DETAIL_RETURNDATE to \\ninclude a time component. Make each entry match the values shown in the follow -\\ning table.\\nRENT_NUM VID_NUM DETAIL_RETURNDATE\\n1001 34342 02-MAR-16 10:00am\\n1001 61353 03-MAR-16 11:30am\\n1002 59237 04-MAR-16 03:30pm\\n1003 54325 09-MAR-16 04:00pm\\n1003 61369 09-MAR-16 04:00pm\\n1003 61388 09-MAR-16 04:00pm\\n1004 44392 07-MAR-16 09:00am\\n1004 34367 07-MAR-16 09:00am\\n1004 34341 07-MAR-16 09:00am\\n1005 34342 05-MAR-16 12:30pm\\n1005 44397 05-MAR-16 12:30pm\\n1006 34366 04-MAR-16 10:15pm\\n1006 61367\\n1007 34368\\n1008 34369 05-MAR-16 09:30pm\\n1009 54324\\n1001 34366 02-MAR-16 10:00am\\n70. Alter the VIDEO table to include an attribute named VID_STATUS to store charac -\\nter data up to four characters long. The attribute should not accept null values. The \\nattribute should have a constraint to enforce the domain (“IN” , “OUT” , and “LOST”) \\nand have a default value of “IN” .\\nCases\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a04f7653-07d0-454d-a02e-9495cf6e4557', embedding=None, metadata={'page_label': '436', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='436   Part 3    Advanced Design and Implementation\\n71. Update the VID_STATUS attribute of the VIDEO table using a subquery to set \\nthe VID_STATUS to “OUT” for all videos that have a null value in the DETAIL_RETURNDATE attribute of the DETAILRENTAL table.\\n72.\\n Alter the PRICE table to include an attribute named PRICE_RENTDAYS to store integers of up to two digits. The attribute should not accept null values, and it should have a default value of 3.\\n73.\\n Update the PRICE table to place the values shown in the following table in the PRICE_RENTDAYS attribute.\\nPRICE_CODE PRICE_RENTDAYS\\n1 5\\n2 3\\n3 5\\n4 7\\n74. Create a trigger named trg_late_return that will write the correct value to DETAIL_DAYSLATE in the DETAILRENTAL table whenever a video is returned. The \\n trigger should execute as a BEFORE trigger when the DETAIL_RETURNDATE or DETAIL_DUEDATE attributes are updated. The trigger should satisfy the following conditions:\\n  a. If the return date is null, then the days late should also be null.\\n  b.  If the return date is not null, then the days late should determine if the video is returned late.\\n  c.  If the return date is noon of the day after the due date or earlier, then the video is not considered late, and the days late should have a value of zero (0).\\n  d.  If the return date is past noon of the day after the due date, then the video is considered late, so the number of days late must be calculated and stored.\\n75.\\n Create a trigger named trg_mem_balance that will maintain the correct value in the membership balance in the MEMBERSHIP table when videos are returned late. The trigger should execute as an AFTER trigger when the due date or return date attributes are updated in the DETAILRENTAL table. The trigger should satisfy the following conditions:\\n  a.  Calculate the value of the late fee prior to the update that triggered this execu-tion of the trigger. The value of the late fee is the days late multiplied by the daily late fee. If the previous value of the late fee was null, then treat it as zero (0).\\n  b.  Calculate the value of the late fee after the update that triggered this execution of the trigger. If the value of the late fee is now null, then treat it as zero (0).\\n  c.  Subtract the prior value of the late fee from the current value of the late fee to determine the change in late fee for this video rental.\\n  d.  If the amount calculated in Part c is not zero (0), then update the membership \\n balance by the amount calculated for the membership associated with this rental.\\n76. Create a sequence named rent_num_seq to start with 1100 and increment by 1. Do\\xa0not cache any values.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f1b3e8ec-d8b2-4e85-aa39-006b7ea5f0ed', embedding=None, metadata={'page_label': '437', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 8    Advanced SQL    437\\n77. Create a stored procedure named prc_new_rental to insert new rows in the RENTAL \\ntable. The procedure should satisfy the following conditions:\\n  a. The membership number will be provided as a parameter.\\n  b.  Use a Count() function to verify that the membership number exists in the MEMBERSHIP table. If it does not exist, then a message should be displayed that the membership does not exist and no data should be written to the database.\\n  c.  If the membership does exist, then retrieve the membership balance and \\n display\\xa0 a message that the balance amount is the previous balance. (For \\n example, if the membership has a balance of $5.00, then display “Previous balance: $5.00” .)\\n  d.  Insert a new row in the rental table using the sequence created in Case \\n Question\\xa076 to generate the value for RENT_NUM, the current system date for the RENT_DATE value, and the membership number provided as the value for MEM_NUM.\\n78.\\n Create a stored procedure named prc_new_detail to insert new rows in the \\n DETAILRENTAL table. The procedure should satisfy the following requirements:\\n  a. The video number will be provided as a parameter.\\n  b.  Verify that the video number exists in the VIDEO table. If it does not exist, then display a message that the video does not exist, and do not write any data to the database.\\n  c.  If the video number does exist, then verify that the VID_STATUS for the video is “IN” . If the status is not “IN” , then display a message that the video’s return must be entered before it can be rented again, and do not write any data to the database.\\n  d.  If the status is “IN” , then retrieve the values of the video’s PRICE_RENTFEE, PRICE_DAILYLATEFEE, and PRICE_RENTDAYS from the PRICE table.\\n  e.  Calculate the due date for the video rental by adding the number of days in PRICE_RENTDAYS to 11:59:59PM (hours:minutes:seconds) in the current \\n system date.\\n  f.  Insert a new row in the DETAILRENTAL table using the previous value returned by RENT_NUM_SEQ as the RENT_NUM, the video number pro-vided in the parameter as the VID_NUM, the PRICE_RENTFEE as the value for DETAIL_FEE, the due date calculated above for the DETAIL_DUEDATE, PRICE_DAILYLATEFEE as the value for DETAIL_DAILYLATEFEE, and null for the DETAIL_RETURNDATE.\\n79.\\n Create a stored procedure named prc_return_video to enter data about the return of videos that have been rented. The procedure should satisfy the following requirements.\\n  a. The video number will be provided as a parameter.\\n  b.  Verify that the video number exists in the VIDEO table. If it does not exist, \\n display a message that the video number provided was not found and do not write any data to the database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='69f8697b-2e9e-4078-8c47-c56f9e3cfe15', embedding=None, metadata={'page_label': '438', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='438   Part 3    Advanced Design and Implementation\\n  c.  If the video number does exist, then use a Count() function to ensure that the \\nvideo has only one record in DETAILRENTAL for which it does not have a return date. If more than one row in DETAILRENTAL indicates that the video is rented but not returned, display an error message that the video has multiple outstanding rentals and do not write any data to the database.\\n  d.  If the video does not have any outstanding rentals, then update the video status to “IN” for the video in the VIDEO table, and display a message that the video had no outstanding rentals but is now available for rental. If the video has only one outstanding rental, then update the return date to the current system date, and update the video status to “IN” for that video in the VIDEO table. Then \\n display a message that the video was successfully returned.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e625ff2c-8c4f-4230-9a1e-2ec36a7fc782', embedding=None, metadata={'page_label': '439', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 9\\nDatabase Design\\nIn this chapter, you will learn:\\n• That a sound database design is the foundation for a successful information system, and that the \\ndatabase design must reflect the information system of which the database is a part\\n• That successful information systems are developed within a framework known as the Systems \\nDevelopment Life Cycle (SDLC)\\n• That within the information system, the most successful databases are subject to frequent \\nevaluation and revision within a framework known as the Database Life Cycle (DBLC)\\n• How to conduct evaluation and revision within the SDLC and DBLC frameworks\\n• About database design strategies: top-down versus bottom-up design and centralized versus \\ndecentralized design\\nPreviewDatabases are a part of a larger picture called an information system. Database designs \\nthat fail to recognize this fact are not likely to be successful. Database designers must rec-ognize that the database is a critical means to an end rather than an end in itself. Managers want the database to serve their management needs, but too many databases seem to force managers to alter their routines to fit the database requirements.\\nInformation systems don’t just happen; they are the product of a carefully staged devel-\\nopment process. Systems analysis is used to determine the need for an information system and to establish its limits. Within systems analysis, the actual information system is cre-ated through a process known as systems development.\\nThe creation and evolution of information systems follows an iterative pattern called \\nthe Systems Development Life Cycle (SDLC), which is a continuous process of creation, maintenance, enhancement, and replacement of the information system. A similar cycle applies to databases: the database is created, maintained, enhanced, and eventually replaced. The Database Life Cycle (DBLC) is carefully traced in this chapter, and is shown in the context of the larger Systems Development Life Cycle.\\nAt the end of the chapter, you will be introduced to some classical approaches to data-\\nbase design: top-down versus bottom-up and centralized versus decentralized.\\nBecause it is purely conceptual, this chapter does not reference any data files.NoteData Files Available on cengagebrain.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8913fae5-2ff8-4fa8-8a20-b3c982ab517e', embedding=None, metadata={'page_label': '440', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='440   Part 3     Advanced Design and Implementation\\n9-1 The Information System\\nBasically, a database is a carefully designed and constructed repository of facts. The \\ndatabase is part of a larger whole known as an information system , which provides \\nfor data collection, storage, transformation, and retrieval. The information system also \\nhelps transform data into information, and it allows for the management of both data \\nand information. Thus, a complete information system is composed of people, hardware, \\nsoftware, the database(s), application programs, and procedures. Systems analysis  is the \\nprocess that establishes the need for an information system and its extent. The process of \\ncreating an information system is known as systems development .\\nOne key characteristic of current information systems is the strategic value of infor -\\nmation in the age of global business. Therefore, information systems should always be \\naligned with strategic business mission and goals; the view of isolated and independent \\ninformation systems is no longer valid. Current information systems should always be \\nintegrated with the company’s enterprise-wide information systems architecture.\\nWithin the framework of systems development, applications transform data into the \\ninformation that forms the basis for decision making. Applications usually generate formal \\nreports, tabulations, and graphic displays designed to produce insight from the informa -\\ntion. Figure 9.1 illustrates that every application is composed of two parts: the data and the \\ncode (program instructions) by which the data is transformed into information. The data \\nand code work together to represent real-world business functions and activities. At any \\ngiven moment, physically stored data represents a snapshot of the business, but the picture \\nis not complete without an understanding of the business activities represented by the code.information system \\n(IS)\\nA system that provides \\nfor data collection, \\nstorage, and retrieval; \\nfacilitates the \\ntransformation of data \\ninto information; and \\nmanages both data \\nand information. An \\ninformation system is \\ncomposed of hardware, \\nthe DBMS and other \\nsoftware, database(s), \\npeople, and procedures.\\nsystems analysis\\nThe process that \\nestablishes the need for \\nan information system \\nand its extent.\\nsystems \\ndevelopment\\nThe process of creating \\nan information system.\\nThis chapter does not mean to cover all aspects of systems analysis and development, which \\nare usually covered in a separate course or book. However, this chapter should help you better \\nunderstand the issues associated with database design, implementation, and management, all \\nof which are affected by the information system in which the database is a critical component.Note\\nFIGURE 9.1  GENERATING INFORMATION FOR DECISION MAKING  \\nThe performance of an information system depends on three factors:\\n• Database design and implementation\\n• Application design and implementation\\n• Administrative procedures\\nApplication\\ncodeInformation\\nDecisions Data\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6aa440e5-fe8c-47ae-9d64-132e515b4433', embedding=None, metadata={'page_label': '441', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    441\\nThis book emphasizes the database design and implementation segment of the \\ntriad—arguably the most important of the three. However, failure to address the other \\ntwo segments will likely yield a poorly functioning information system. Creating a sound information system is hard work: systems analysis and development require extensive planning to ensure that all of the activities will interface with each other, that they will complement each other, and that they will be completed on time.\\nIn a broad sense, the term database development describes the process of database \\ndesign and implementation. The primary objective in database design is to create com-plete, normalized, nonredundant (to the greatest extent possible), and fully integrated conceptual, logical, and physical database models. The implementation phase includes creating the database storage structure, loading data into the database, and providing for data management. Consideration should be taken to design and implement a database that is flexible and scalable over time. Although most designs typically focus on solving current problems, it is important to create a design that is flexible enough to adapt to future changes (such as performance, size, or reporting requirements).\\nTo make the procedures discussed in this chapter broadly applicable, the chapter focuses on \\nthe elements that are common to all information systems. Most of the processes and procedures described in this chapter do not depend on the size, type, or complexity of the database being implemented. However, the procedures that would be used to design a small database, such as one for a neighborhood shoe store, do not precisely scale up to the procedures that would be needed to design a database for a large corporation or even a segment of such a corporation. To use an analogy, building a small house requires a blueprint, just as building the Golden Gate Bridge did, but the bridge required far more complex planning, analysis, and design.\\nThe next sections will trace the overall Systems Development Life Cycle and the \\nrelated Database Life Cycle. Once you are familiar with those processes and procedures, you will learn about various approaches to database design, such as top-down versus bottom-up and centralized versus decentralized design.\\nThe Systems Development Life Cycle is a general framework through which you can track and understand the activities required to develop and maintain information systems. Within that framework, there are several ways to complete various tasks specified in the SDLC. For example, this book focuses on ER modeling and on relational database design and implementation, and that focus is maintained in this chapter. However, there are alternative methodologies:\\n• Unified Modeling Language (UML) provides object-oriented tools to support the tasks associated with the development of information systems. UML is covered in Appendix H, Unified Modeling Language (UML), at www.cengagebrain.com.\\n• Rapid Application Development (RAD)1 is an iterative software development methodol-\\nogy that uses prototypes, CASE tools, and flexible management to develop application systems. RAD started as an alternative to traditional structured development, which suffered from long deliverable times and unfulfilled requirements.\\n• Agile Software Development2 is a framework for developing software applications \\nthat divides the work into smaller subprojects to obtain valuable deliverables in shorter times and with better cohesion. This method emphasizes close communi-cation among all users and continuous evaluation with the purpose of increasing customer satisfaction.\\nAlthough the development methodologies may change, the basic framework within \\nwhich they are used does not change.Note\\n1 See Rapid Application Development , James Martin, Prentice-Hall, Macmillan College Division, 1991.\\n2 For more information about Agile Software Development, go to www.agilealliance.org .database \\ndevelopment\\nThe process of database design and implementation.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd55a1b4-9f6f-4df6-8c58-008100d8e471', embedding=None, metadata={'page_label': '442', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='442   Part 3     Advanced Design and Implementation\\n9-2 The Systems Development Life Cycle\\nThe Systems Development Life Cycle (SDLC)  traces the history of an information system. \\nPerhaps more important to the system designer, the SDLC provides the big picture within \\nwhich the database design and application development can be mapped out and evaluated.\\nAs illustrated in Figure 9.2, the traditional SDLC is divided into five phases: planning, \\nanalysis, detailed systems design, implementation, and maintenance. The SDLC is an \\niterative process rather than a sequential process. For example, the details of the feasibil -\\nity study might help refine the initial assessment, and the details discovered during the \\nuser requirements portion of the SDLC might help refine the feasibility study.\\nBecause the Database Life Cycle fits into and resembles the SDLC, a brief description \\nof the SDLC is in order.\\n9-2a  Planning\\nThe SDLC planning phase yields a general overview of the company and its objectives. \\nAn initial assessment of the information flow-and-extent requirements must be made \\nduring this discovery portion of the SDLC. Such an assessment should answer some \\nimportant questions:\\n• Should the existing system be continued?  If the information generator does its job well, \\nthere is no point in modifying or replacing it. To quote an old saying, “If it ain’t broke, \\ndon’t fix it. ”Systems \\nDevelopment Life \\nCycle (SDLC)\\nThe cycle that traces the \\nhistory of an information \\nsystem. The SDLC \\nprovides the big picture \\nwithin which database \\ndesign and application \\ndevelopment can \\nbe mapped out and \\nevaluated.FIGURE 9.2  THE SYSTEMS DEVELOPMENT LIFE CYCLE (SDLC)  \\nPlanning\\nAnalysis\\nDetailed\\nsystems design\\nImplementation\\nMaintenancePhase\\nInitial assessment\\nFeasibility study\\nUser requirements\\nExisting system evaluation\\nLogical system design\\nDetailed system speciﬁcation\\nCoding, testing, and debugging\\nInstallation, ﬁne-tuning\\nEvaluation\\nMaintenance\\nEnhancementAction(s) Section\\n9-2a\\n9-2b\\n9-2c\\n9-2d\\n9-2e\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5fef6654-dc83-4705-b3c3-9a469c6929b0', embedding=None, metadata={'page_label': '443', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    443\\n• Should the existing system be modified? If the initial assessment indicates deficiencies \\nin the extent and flow of the information, minor (or even major) modifications might be needed. When considering modifications, the participants in the initial assessment must remember the distinction between wants and needs.\\n•\\n Should the existing system be replaced? The initial assessment might indicate that the current system’s flaws are beyond fixing. Given the effort required to create a new sys-tem, a careful distinction between wants and needs is perhaps even more important in this case than it is when modifying the system.\\nParticipants in the SDLC’s initial assessment must begin to study and evaluate alter -\\nnative solutions. If a new system is necessary, the next question is whether it is feasible. The feasibility study must address the following:\\n•\\n The technical aspects of hardware and software requirements. The decisions might not \\nyet be vendor-specific, but they must address the nature of the hardware requirements (desktop computer, multiprocessor computer, mainframe, or supercomputer) and the software requirements (single-user or multiuser operating systems, database type and software, programming languages to be used by the applications, and so on).\\n•\\n The system cost. The admittedly mundane question “Can we afford it?” is crucial. The answer might force a careful review of the initial assessment. A million-dollar solu-tion to a thousand-dollar problem is not defensible. At some point, the decision may be between building a system “in-house” or buying (and customizing) a third-party vendor system. In the long run, you need to find a cost-effective solution that best serves the needs (present and future) of the organization.\\n•\\n The operational cost . Does the company possess the human, technical, and finan-\\ncial resources to keep the system operational? Should the feasibility study include the cost of management and end-user support needed to implement operational procedures to ensure the success of this system? What would be the impact of this new system in the company’s culture? People’s resistance to change should never be underestimated.\\n3\\nEven if you choose to “buy” rather than to “build, ” the system implementation must \\nbe carefully planned for it to be successful. Whatever the chosen option (build or buy), an analysis must be done to deploy the solution across the organization in ways that min-imize cost and culture changes, while maximizing value. The SDLC provides a frame-work for sound planning and implementation.\\n9-2b  Analysis\\nProblems defined during the planning phase are examined in greater detail during the analysis phase. A macro analysis must be made both of individual needs and organiza-tional needs, addressing questions such as:\\n•\\n What are the requirements of the current system’s end users?\\n• Do those requirements fit into the overall information requirements?\\nThe analysis phase of the SDLC is, in effect, a thorough audit  of user requirements.\\nThe existing hardware and software systems are also studied during the analysis phase. \\nThe result of the analysis should be a better understanding of the system’s functional \\nareas, actual and potential problems, and opportunities.\\n3 “ At Zappos, 210 employees decide to leave rather than work with ’no bosses, ’” Jena McGregor, Washington \\nPost, May 8, 2015.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='57de9f5c-19bc-427d-90c1-dab59af1ee63', embedding=None, metadata={'page_label': '444', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='444   Part 3    Advanced Design and Implementation\\nEnd users and the system designer(s) must work together to identify processes and \\nuncover potential problem areas. Such cooperation is vital to defining the appropriate \\nperformance objectives by which the new system can be judged.\\nAlong with a study of user requirements and the existing systems, the analysis phase \\nalso includes the creation of a logical systems design. The logical design must specify the appropriate conceptual data model, inputs, processes, and expected output requirements.\\nWhen creating a logical design, the designer might use tools such as data flow dia-\\ngrams (DFDs), hierarchical input process output (HIPO) diagrams, entity relation-ship (ER) diagrams, and even some application prototypes. The database design’s data-modeling activities take place at this point to discover and describe all entities and their attributes, and the relationships among the entities within the database.\\nDefining the logical system also yields functional descriptions of the system’s com-\\nponents (modules) for each process within the database environment. All data transfor -\\nmations (processes) are described and documented, using systems analysis tools such as DFDs. The conceptual data model is validated against those processes.\\n9-2c  Detailed Systems Design\\nIn the detailed systems design phase, the designer completes the design of the system’s processes. The design includes all the necessary technical specifications for the screens, menus, reports, and other devices that might help make the system a more efficient infor -\\nmation generator. The steps are laid out for conversion from the old system to the new system. Training principles and methodologies are also planned and must be submitted for management’s approval.\\n9-2d  Implementation\\nDuring the implementation phase, the hardware, DBMS software, and application programs are installed, and the database design is implemented. During the initial stages of the implementation phase, the system enters into a cycle of coding, testing, and debugging until it is ready to be delivered. The actual database is created, and the system is customized by the creation of tables and views, user authorizations, and so on.\\nThe database contents might be loaded interactively or in batch mode, using a variety \\nof methods and devices:\\n•\\n Customized user programs\\n• Database interface programs\\n• Conversion programs that import the data from a different file structure, using batch \\nprograms, a database utility, or both\\nThe system is subjected to exhaustive testing until it is ready for use. Traditionally, \\nthe implementation and testing of a new system took 50 to 60 percent of the total \\nBecause this book has focused on the details of systems design, it has not explicitly rec -\\nognized until now that management approval is needed at all stages of the process. Such approval is needed because a “go” decision requires funding. There are many “go” and “no go” decision points along the way to a completed systems design!Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='976cba3e-30b8-4f31-81e9-5b2c50248e3a', embedding=None, metadata={'page_label': '445', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    445\\ndevelopment time. However, the advent of sophisticated application generators and \\ndebugging tools has substantially decreased coding and testing time. After testing is concluded, the final documentation is reviewed and printed and end users are trained. The system is in full operation at the end of this phase, but it will be continuously eval-uated and fine-tuned.\\n9-2e  Maintenance\\nAlmost as soon as the system is operational, end users begin to request changes in it. Those changes generate system maintenance activities, which can be grouped into three types:\\n•\\n Corrective maintenance  in response to systems errors\\n• Adaptive maintenance  due to changes in the business environment\\n• Perfective maintenance  to enhance the system\\nBecause every request for structural change requires retracing the SDLC steps, the \\nsystem is, in a sense, always at some stage of the SDLC.\\nEach system has a predetermined operational life span, but its actual life span depends \\non its perceived utility. There are several reasons for reducing the operational life of cer -\\ntain systems. Rapid technological change is one reason, especially for systems based on \\nprocessing speed and expandability. Another common reason is the cost of maintaining a system.\\nIf the system’s maintenance cost is high, its value becomes suspect. Computer-aided \\nsoftware engineering (CASE) tools, such as System Architect or Visio Professional, help produce better systems within a reasonable amount of time and at a reasonable cost. In addition, CASE-produced applications are more structured, better documented, and especially standardized , which tends to prolong the operational life of systems by making \\nthem easier and cheaper to update and maintain.\\n9-3 The Database Life Cycle\\nWithin the larger information system, the database is subject to a life cycle as well. The Database Life Cycle (DBLC) contains six phases, as shown in Figure 9.3: database initial study, database design, implementation and loading, testing and evaluation, operation, and maintenance and evolution.\\n9-3a  The Database Initial Study\\nIf a designer has been called in, chances are that the current system has failed to perform functions deemed vital by the company. (Y ou don’t call the plumber unless the pipes leak.) Therefore, in addition to examining the current system’s operation within the com-pany, the designer must determine how and why the current system fails. That means spending a lot of time talking and listening to end users. Although database design is a technical business, it is also people-oriented. Database designers must be excellent com-municators and must have finely tuned interpersonal skills.\\nDepending on the complexity and scope of the database environment, the database \\ndesigner might be a lone operator or part of a systems development team composed of a project leader, one or more senior systems analysts, and one or more junior systems analysts. The word designer  is used generically here to cover a wide range of design team \\ncompositions.computer-aided systems engineering (CASE)\\nTools used to automate part or all of the Systems Development Life Cycle.\\nDatabase Life Cycle (DBLC)\\nA cycle that traces the history of a database within an information system. The cycle is divided into six phases: initial study, design, implementation and loading, testing and evaluation, operation and maintenance, and evolution.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5e83f15f-28b7-4f07-921d-f1a768004b1d', embedding=None, metadata={'page_label': '446', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='446   Part 3     Advanced Design and Implementation\\nThe overall purpose of the database initial study is to:\\n• Analyze the company situation\\n• Define problems and constraints\\n• Define objectives\\n• Define scope and boundaries\\nFigure 9.4 depicts the interactive and iterative processes required to complete the first \\nphase of the DBLC successfully. Note that the database initial study phase leads to the \\ndevelopment of database system objectives. Using Figure 9.4 as a discussion template, \\nexamine each of its components in greater detail.\\nAnalyze the Company Situation  The company situation  describes the general condi -\\ntions in which a company operates, its organizational structure, and its mission. To ana -\\nlyze the company situation, the database designer must learn the company’s operational \\ncomponents, how they function, and how they interact.\\nThe following issues must be resolved:\\n• What is the organization’s general operating environment, and what is its mission within \\nthat environment?  The design must satisfy the operational demands created by the FIGURE 9.3  THE DATABASE LIFE CYCLE (DBLC)  \\nDatabase initial\\nstudy\\nDatabase design\\nImplementation\\nand loading\\nTesting and\\nevaluation\\nOperation\\nMaintenance and\\nevolutionPhase\\nAnalyze the company situationAction(s) Section\\n9-3a\\n9-3b\\n9-3c\\n9-3d\\n9-3e\\n9-3fDeﬁne problems and constraints\\nDeﬁne objectives\\nDeﬁne scope and boundaries\\nCreate the conceptual design\\nDBMS software selection\\nCreate the logical design\\nCreate the physical design\\nInstall the DBMS\\nCreate the database(s)\\nLoad or convert the data\\nTest the database\\nFine-tune the database\\nEvaluate the database and its application programs\\nProduce the required information ﬂow\\nIntroduce changes\\nMake enhancements\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ede3318c-6a79-436f-8e44-9f89a8ad006b', embedding=None, metadata={'page_label': '447', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    447\\norganization’s mission. For example, a mail-order business probably has operational \\nrequirements for its database that are quite different from those of a manufacturing \\nbusiness.\\n• What is the organization’s structure?  Knowing who controls what and who reports to \\nwhom is quite useful when you need to define required information flows, specific \\nreport and query formats, and so on.\\nDefine Problems and Constraints  The designer has both formal and informal \\nsources of information. If the company has existed for any length of time, it already \\nhas a system in place (either manual or computer-based). How does the existing system \\nfunction? What input does the system require? What documents does the system gener -\\nate? By whom and how is the system output used? Studying the paper trail can be very \\ninformative. In addition to the official version of the system’s operation, there is also the \\nmore informal, perhaps more real version; the designer must be shrewd enough to see \\nhow these differ.\\nThe process of defining problems might initially appear to be unstructured. Company \\nend users often cannot precisely describe the larger scope of company operations or \\nidentify the real problems encountered during company operations. Often the mana -\\ngerial view of a company’s operation and its problems is different from that of the end \\nusers, who perform the actual routine work.FIGURE 9.4  A SUMMARY OF ACTIVITIES IN THE DATABASE INITIAL STUDY  \\nAnalysis of the\\ncompany situation\\nCompany operations Company objectives Company structure\\nDeﬁnition of \\nproblems and constraints\\nDatabase system \\nspeciﬁcations\\nScope Objectives Boundaries\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='267691e5-52a0-44be-ac69-1b6a442511f5', embedding=None, metadata={'page_label': '448', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='448   Part 3    Advanced Design and Implementation\\nDuring the initial problem definition process, the designer is likely to collect very \\nbroad problem descriptions. For example, note the following concerns expressed by the \\npresident of a fast-growing, transnational manufacturing company:\\nAlthough the rapid growth is gratifying, members of the management team are con-cerned that such growth is beginning to undermine the ability to maintain a high customer service standard, and perhaps worse, to diminish manufacturing standards control.\\nThe problem definition process quickly leads to a host of general problem descrip-\\ntions. For example, the marketing manager comments:\\nI’m working with an antiquated filing system. We manufacture more than 1,700 spe-\\ncialty machine parts. When a regular customer calls in, we can’t get a very quick inventory scan. If a new customer calls in, we can’t do a current parts search by using a simple description, so we often do a machine setup for a part that we have in inven-tory. That’s wasteful. And of course, some new customers get irritated when we can’t give a quick response.\\nThe production manager comments:At best, it takes hours to generate the reports I need for scheduling purposes. I don’t \\nhave hours for quick turnarounds. It’s difficult to manage what I don’t have informa-tion about.\\nI don’t get quick product request routing. Take machine setup. Right now I’ve got \\noperators either waiting for the right stock or getting it themselves when a new part is scheduled for production. I can’t afford to have an operator doing chores that a much lower-paid worker ought to be doing. There’s just too much waiting around with the current scheduling. I’m losing too much time, and my schedules back up. Our over -\\ntime bill is ridiculous.\\nI sometimes produce parts that are already in inventory because we don’t seem to be \\nable to match what we’ve got in inventory with what we have scheduled. Shipping yells at me because I can’t turn out the parts, and often they’ve got them in inventory one bay down. That’s costing us big bucks sometimes.\\nNew reports can take days or even weeks to get to my office. And I need a ton of \\nreports to schedule personnel, downtime, training, etc. I can’t get new reports that I need NOW . What I need is the ability to get quick updates on percent defectives, percent rework, the effectiveness of training, you name it. I need such reports by shift, by date, by any characteristic I can think of to help me manage scheduling, training, you name it.\\nA machine operator comments:It takes a long time to set my stuff up. If I get my schedule banged up because John \\ndoesn’t get the paperwork on time, I wind up looking for setup specs, startup material, bin assignments, and other stuff. Sometimes I spend two or three hours just setting up. Now you know why I can’t meet schedules. I try to be productive, but I’m spending too much time getting ready to do my job.\\nAfter the initial declarations, the database designer must continue to probe carefully \\nto generate additional information that will help define the problems within the larger \\nframework of company operations. How does the problem of the marketing manager’s \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='62c9f0d1-5953-40f4-892a-d731f4021c45', embedding=None, metadata={'page_label': '449', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    449\\ncustomer fit within the broader set of marketing department activities? How does the \\nsolution to the customer’s problem help meet the objectives of the marketing depart-ment and the rest of the company? How do the marketing department’s activities relate to those of the other departments? That last question is especially important. Note that there are common threads in the problems described by the marketing and production department managers. If the inventory query process can be improved, both depart-ments are likely to find simple solutions to at least some of their problems.\\nFinding precise answers is important, especially concerning the operational relation-\\nships among business units. If a proposed system will solve the marketing department’s problems but exacerbate those of the production department, not much progress will have been made. Using an analogy, suppose that your home water bill is too high. Y ou have determined the problem: the faucets leak. The solution? Y ou step outside and cut off the water supply to the house. However, is that an adequate solution, or would the replacement of faucet washers do a better job of solving the problem? Y ou might find this scenario simplistic, yet almost any experienced database designer can find similar instances of database problem solving, although they are admittedly more complicated.\\nEven the most complete and accurate problem definition does not always lead to the \\nperfect solution. The real world usually intrudes to limit the design of even the most ele-gant database by imposing constraints such as time, budget, and personnel. If you must have a solution within a month and within a $12,000 budget, you cannot take two years to develop a database at a cost of $100,000. The designer must learn to distinguish between what’s perfect and what’s possible.\\nDefine Objectives  A proposed database system must be designed to help solve at \\nleast the major problems identified during the problem discovery process. As the list of problems unfolds, several common sources are likely to be discovered. In the previous example, both the marketing manager and the production manager seem to be plagued by inventory inefficiencies. If the designer can create a database that sets the stage for more efficient parts management, both departments gain. The initial objective, therefore, might be to create an efficient inventory query and management system.\\nWhen trying to develop solutions, the database designer must look for the source of the problems. Many database systems have failed to satisfy the end users because they were designed to treat the symptoms of the problems rather than their source.Note\\nNote that the initial study phase also yields proposed problem solutions. The designer’s  \\njob is to make sure that his or her database system objectives correspond to those envi-sioned by the end user(s). In any case, the database designer must begin to address the following questions:\\n•\\n What is the proposed system’s initial objective?\\n• Will the system interface with other existing or future systems in the company?\\n• Will the system share the data with other systems or users?\\nDefine Scope and Boundaries  The designer must recognize two sets of limits: \\nscope and boundaries. The system’s scope defines the extent of the design according to \\noperational requirements. Will the database design encompass the entire organization, one or more departments within the organization, or one or more functions of a single scope\\nThe part of a system that defines the extent of the design, according to operational requirements.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f8914ce3-f023-4926-87cc-df7ddb7468b9', embedding=None, metadata={'page_label': '450', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='450   Part 3    Advanced Design and Implementation\\ndepartment? The designer must know the “size of the ballpark. ” Knowing the scope \\nhelps define the required data structures, the type and number of entities, the physical size of the database, and so on.\\nThe proposed system is also subject to limits known as boundaries, which are \\nexternal to the system. Has any designer ever been told, “We have all the time in the world” or “Use an unlimited budget and as many people as needed to make the design come together”? Boundaries are also imposed by existing hardware and software. Ideally, the designer can choose the hardware and software that will best accomplish the system goals. In fact, software selection is an important aspect of the Systems Development Life Cycle. Unfortunately, in the real world, a system must often be designed around existing hardware. Thus, the scope and boundaries become the factors that force the design into a specific mold, and the designer’s job is to design the best system possible within those constraints. (Note that prob-lem definitions and the objectives must sometimes be reshaped to meet the system scope and boundaries.)\\n9-3b  Database Design\\nThe second phase of the DBLC focuses on the design of the database model that will support company operations and objectives. This is arguably the most critical DBLC phase: making sure that the final product meets user and system requirements. In the process of database design, you must concentrate on the data characteristics required to build the database model. At this point, there are two views of the data within the system: the business view of data as a source of information and the designer’s view of the data structure, its access, and the activities required to transform the data into information. Figure 9.5 contrasts those views. Note that you can summarize the dif-ferent views by looking at the terms what  and how . Defining data is an integral part of \\nthe DBLC’s second phase.\\nAs you examine the procedures required to complete the design phase in the DBLC, \\nremember these points:\\n•\\n The process of database design is loosely related to the analysis and design of a larger \\nsystem. The data component is only one element of a larger information system.\\n• The systems analysts or systems programmers are in charge of designing the other system components. Their activities create the procedures that will help transform the data within the database into useful information.\\n•\\n The database design does not constitute a sequential process. Rather, it is an iterative process that provides continuous feedback designed to trace previous steps.\\nThe database design process is depicted in Figure 9.6. The figure shows that there are \\nthree essential stages: conceptual, logical, and physical design, plus the DBMS selec-tion decision, which is critical to determine the type of logical and physical designs to be created. The design process starts with conceptual design and moves to the logical and physical design stages. At each stage, more details about the data model design are determined and documented. Y ou could think of the conceptual design as the overall data as seen by the end user, the logical design as the data as seen by the DBMS, and the physical design as the data as seen by the operating system’s storage management devices.\\nIt is important to note that the overwhelming majority of database designs and imple-\\nmentations are based on the relational model, and therefore use the relational model constructs and techniques. When you finish the design activities, you will have a com-plete database design ready to be implemented.\\nboundaries\\nThe external limits to which any proposed system is subjected. These limits include budgets, personnel, and existing hardware and software.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d59f938b-a41f-4434-859e-a614c9865a71', embedding=None, metadata={'page_label': '451', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    451\\nDatabase design activities are covered in detail in Sections 9-4 (Conceptual Design), \\n9-5 (DBMS Software Selection), 9-6 (Logical Design), and 9-7 (Physical Design).\\n9-3c  Implementation and Loading\\nThe output of the database design phase is a series of instructions detailing the cre -\\nation of tables, attributes, domains, views, indexes, security constraints, and storage \\nand performance guidelines. In this phase, you actually implement all these design \\nspecifications.\\nInstall the DBMS  This step is required only when a new dedicated instance of the \\nDBMS is necessary for the system. In many cases, the organization will have made a \\nparticular DBMS the standard to leverage investments in the technology and the skills \\nthat employees have already developed. The DBMS may be installed on a new server \\nor on existing servers. One current trend is called virtualization. Virtualization  is a \\ntechnique that creates logical representations of computing resources that are inde -\\npendent of the underlying physical computing resources. This technique is used in \\nmany areas of computing, such as the creation of virtual servers, virtual storage, and \\nvirtual private networks. In a database environment, database virtualization refers to FIGURE 9.5  TWO VIEWS OF DATA: BUSINESS MANAGER AND DESIGNER  \\nCompany DatabaseCompany\\nPurchasing Engineering Manufacturing\\nShared informationManager’s view\\nDesigner’s viewWhat  are the problems?\\nWhat  are the solutions?\\nWhat  information is needed to\\nimplement the solutions?\\nWhat  data is required to\\ngenerate the desired information?\\nHow must the data be structured?\\nHow will the data be accessed?\\nHow is the data transformed\\ninto information?\\nvirtualization\\nA technique that creates \\nlogical representations \\nof computing resources \\nthat are independent of \\nthe underlying physical \\ncomputing resources.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3f32213a-21c9-42ec-951a-5fa0d112c7c9', embedding=None, metadata={'page_label': '452', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='452   Part 3     Advanced Design and Implementation\\nthe installation of a new instance of the DBMS on a virtual server running on shared \\nhardware. This is normally a task that involves system and network administrators to \\ncreate appropriate user groups and services in the server configuration and network \\nrouting. Another common trend is the use of cloud database services such Microsoft  \\nSQL Database Service or Amazon Relational Database Services (RDS). This new gen -\\neration of services allows user to create databases that could be easily managed, tested, \\nand scaled up as needed.\\nCreate the Database(s)  In most modern relational DBMSs, a new database imple -\\nmentation requires the creation of special storage-related constructs to house the end-\\nuser tables. The constructs usually include the storage group (or file groups), the table \\nspaces, and the tables. Figure 9.7 shows that a storage group can contain more than one \\ntable space and that a table space can contain more than one table.\\nFor example, the implementation of the logical design in IBM’s DB2 would require \\nthe following:\\n1. The system administrator (SYSADM) would create the database storage group. This \\nstep is mandatory for such mainframe databases as DB2. Other DBMS software may \\ncreate equivalent storage groups automatically when a database is created. (See Step \\n2.) Consult your DBMS documentation to see if you must create a storage group, and \\nif so, what the command syntax must be.\\n2. The SYSADM creates the database within the storage group.\\n3. The SYSADM assigns the rights to use the database to a database administrator (DBA).\\n4. The DBA creates the table space(s) within the database.FIGURE 9.6  DATABASE DESIGN PROCESS  \\n• Data analysis and requirements\\n• Entity Relationship modeling and normalization\\n• Data model veriﬁcation\\n• Distributed database design*• Determine end-user views, outputs, and transaction requirements\\n• Deﬁne entities, attributes, domains, and relationships\\n• Draw ER diagrams; normalize entity attributes\\n• Identify ER modules and validate insert, update, and delete rules\\n• Validate reports, queries, views, integrity, access, and security\\n• Deﬁne the fragmentation and allocation strategy\\nDBMS and Hardware Independent\\nDBMS Dependent\\nHardware Dependent• Determine DBMS and data model to use\\n• Deﬁne tables, columns, relationships, and constraints\\n• Normalized set of tables\\n• Ensure entity and referential integrity; deﬁne column constraints\\n• Ensure the model supports user requirements\\n• Deﬁne tables, indexes, and views’ physical organization\\n• Deﬁne users, security groups, roles, and access controls\\n• Deﬁne database and query execution parameters• Map conceptual model to logical model components\\n• Validate logical model using normalization\\n• Validate logical model integrity constraints\\n• Validate logical model against user requirementsConceptual\\nDesign\\nDBMS\\nSelectionSelect the DBMS\\nLogical\\nDesignSection Stage Steps Activities\\nPhysical\\nDesign9-59-4\\n9-6\\n9-7\\n* See Chapter 12, Distributed Database Management Systems\\n+ See Chapter 11, Database Performance Tuning and Query Optimization• Deﬁne data storage organization\\n• Deﬁne integrity and security measures\\n• Determine performance measures+\\nOnline \\nContent\\nTwo appendixes at \\nwww.cengagebrain.com  \\nprovide a concise exam -\\nple of simple real-world \\ndatabase development: \\nAppendix B, The Uni -\\nversity Lab: Conceptual \\nDesign, and Appendix C, \\nThe University Lab: Con -\\nceptual Design Verifica -\\ntion, Logical Design, and \\nImplementation.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8405bb9f-c5f6-409b-a374-b2e2bda9e31a', embedding=None, metadata={'page_label': '453', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    453\\n5. The DBA creates the table(s) within the table space(s).\\n6. The DBA assigns access rights to the table spaces and to the tables within specified \\ntable spaces. Access rights may be limited to views rather than to whole tables. The \\ncreation of views is not required for database access in the relational environment, \\nbut views are desirable from a security standpoint. For example, using the following \\ncommand, access rights to a table named PROFESSOR may be granted to the user \\nLynn Eilers, whose identification code is LEILERS:\\nGRANT SELECT ON PROFESSOR TO USER LEILERS;\\nLoad or Convert the Data  After the database has been created, the data must be \\nloaded into the database tables. Typically, the data will have to be migrated from the \\nprior version of the system. Often, data to be included in the system must be aggre -\\ngated from multiple sources. In a best-case scenario, all of the data will be in a relational \\ndatabase so that it can be readily transferred to the new database. However, in some  \\ncases data may have to be imported from other relational databases, nonrelational  \\ndatabases, flat files, legacy systems, or even manual paper-and-pencil systems. If the \\ndata format does not support direct importing into the new database, conversion \\nprograms may have to be created to reformat the data for importing. In a worst-case  \\nscenario, much of the data may have to be manually entered into the database. Once \\nthe data has been loaded, the DBA works with the application developers to test and \\nevaluate the database.\\nLoading existing data into a cloud-based database service sometimes can be expen -\\nsive. The reason for this is that most cloud services are priced based not only on the \\nvolume of data to be stored but also on the amount of data that travels over the network. \\nIn such cases, loading a 1 TB database could be a very expensive proposition. Therefore, FIGURE 9.7  PHYSICAL ORGANIZATION OF A DB2 DATABASE ENVIRONMENT  \\nTableTable\\nTable space\\nTableTable spaceTable\\nTableTableTable\\nTable spaceTable spaceDatabaseStorage group\\nTable space\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b6e19c66-851f-435a-b5a9-77cd2374ab6f', embedding=None, metadata={'page_label': '454', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='454   Part 3    Advanced Design and Implementation\\nsystem administrators must be very careful in reading and negotiating the terms of cloud \\nservice contracts to ensure that there will be no “hidden” costs.\\n9-3d  Testing and Evaluation\\nIn the design phase, decisions were made to ensure integrity, security, performance, and recoverability of the database. During implementation and loading, these plans were put into place. In testing and evaluation, the DBA tests and fine-tunes the database to ensure that it performs as expected. This phase occurs in conjunction with application program-ming. Programmers use database tools to prototype  the applications during coding of \\nthe programs. Tools such as report generators, screen painters, and menu generators are especially useful to application programmers.\\nTest the Database  During this step, the DBA tests the database to ensure that it \\nmaintains the integrity and security of the data. Data integrity is enforced by the DBMS through the proper use of primary and foreign key rules. Many DBMSs also support the creation of domain constraints and database triggers. Testing will ensure that these constraints were properly designed and implemented. Data integrity is also the result of properly implemented data management policies, which are part of a comprehensive data administration framework. For a more detailed study of this topic, see The DBA ’s Managerial Role section in Chapter 16, Database Administration and Security.\\nPreviously, users and roles were created to grant users access to the data. In this stage, \\nnot only must those privileges be tested, but the broader view of data privacy and secu-rity must be addressed. Data stored in the company database must be protected from access by unauthorized users. (It does not take much imagination to predict the likely results if students have access to a student database or if employees have access to payroll data!) Consequently, you must test for at least the following:\\n•\\n Physical security allows only authorized personnel physical access to specific areas. \\nDepending on the type of database implementation, however, establishing physical security might not always be practical. For example, a university student research database is not a likely candidate for physical security.\\n•\\n Password security allows the assignment of access rights to specific authorized users. Password security is usually enforced at login time at the operating system level.\\n•\\n Access rights can be established through the use of database software. The assignment of access rights may restrict operations (CREATE, UPDATE, DELETE, and so on) on predetermined objects such as databases, tables, views, queries, and reports.\\n•\\n Audit trails  are usually provided by the DBMS to check for access violations. Although \\nthe audit trail is an after-the-fact device, its mere existence can discourage unautho-rized use.\\n•\\n Data encryption can render data useless to unauthorized users who might have  \\nviolated some of the database security layers.\\n• Diskless workstations  allow end users to access the database without being able to \\ndownload the information from their workstations.\\nFor a more detailed discussion of security issues, refer to Chapter 16, Database \\nAdministration and Security.\\nFine-Tune the Database  Database performance can be difficult to evaluate because \\nthere are no standards for measuring it, but it is typically one of the most important factors in database implementation. Different systems will place different performance \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b740bb5-d8d3-4303-9d3f-b72099a88d85', embedding=None, metadata={'page_label': '455', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    455\\nrequirements on the database. Systems that support rapid transactions will require the \\ndatabase to be implemented so that they provide superior performance during high vol-umes of inserts, updates, and deletes. Other systems, like decision support systems, may require superior performance for complex data retrieval tasks. Many factors can affect the database’s performance on various tasks, including the hardware and software envi-ronment in which the database exists. Naturally, the characteristics and volume of the data also affect database performance: a search of 10 tuples is faster than a search of 100,000 tuples. Other important factors in database performance include system and database configuration parameters such as data placement, access path definition, the use of indexes, and buffer size. For a more in-depth discussion of database performance issues, see Chapter 11, Database Performance Tuning and Query Optimization.\\nEvaluate the Database and Its Application Programs  As the database and appli-\\ncation programs are created and tested, the system must also be evaluated using a more holistic approach. Testing and evaluation of the individual components should culmi-nate in a variety of broader system tests to ensure that all of the components interact properly to meet the needs of the users. At this stage, integration issues and deployment plans are refined, user training is conducted, and system documentation is finalized. Once the system receives final approval, it must be a sustainable resource for the organi-zation. To ensure that the data contained in the database is protected against loss, backup and recovery plans are tested.\\nTimely data availability is crucial for almost every database. Unfortunately, the data-\\nbase can lose data through unintended deletions, power outages, and other causes. Data backup and recovery procedures create a safety valve, ensuring the availability of con-sistent data. Typically, database vendors encourage the use of fault-tolerant components such as uninterruptible power supply (UPS) units, RAID storage devices, clustered serv-ers, and data replication technologies to ensure the continuous operation of the database in case of a hardware failure. Even with these components, backup and restore functions constitute a very important part of daily database operations. Some DBMSs provide functions that allow the database administrator to schedule automatic database backups to permanent storage devices such as disks, DVDs, tapes, and online storage. Database backups can be performed at different levels:\\n•\\n A full backup, or dump , of the entire database. In this case, all database objects are \\nbacked up in their entirety.\\n• A differential backup of the database, in which only the objects that have been \\nupdated or modified since the last full backup are backed up.\\n• A transaction log backup, which backs up only the transaction log operations that \\nare not reflected in a previous backup copy of the database. In this case, no other \\ndatabase objects are backed up. (For a complete explanation of the transaction log, see Chapter 10, Transaction Management and Concurrency Control.)\\nThe database backup is stored in a secure place, usually in a different building from \\nthe database itself, and is protected against dangers such as fire, theft, flood, and other potential calamities. The main purpose of the backup is to guarantee database restoration following a hardware or software failure.\\nFailures that plague databases and systems are generally induced by software, hard-\\nware, programming exemptions, transactions, or external factors. Table 9.1 summarizes the most common sources of database failure.\\nDepending on the type and extent of the failure, the recovery process ranges from a \\nminor short-term inconvenience to a major long-term rebuild. Regardless of the extent of the required recovery process, recovery is not possible without a usable backup.full backup (database dump)\\nA complete copy of an entire database saved and periodically updated in a separate location. A full backup ensures a full recovery of all data after a physical disaster or database integrity failure.\\ndifferential backup\\nA level of database backup in which only the last modifications to the database are copied.\\ntransaction log backup\\nA backup of only the transaction log operations that are not reflected in a previous backup copy of the database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='473fd01d-d396-4438-8b7e-97fc93f366e3', embedding=None, metadata={'page_label': '456', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='456   Part 3    Advanced Design and Implementation\\nDatabase recovery generally follows a predictable scenario. First, the type and extent \\nof the required recovery are determined. If the entire database needs to be recovered to \\na consistent state, the recovery uses the most recent backup copy of the database in a known consistent state. The backup copy is then rolled forward to restore all subsequent transactions by using the transaction log information. If the database needs to be recov-ered but the committed portion of the database is still usable, the recovery process uses the transaction log to “undo” all of the transactions that were not committed (see Chap-ter 10, Transaction Management and Concurrency Control).\\nAt the end of this phase, the database completes an iterative process of testing, evalu-\\nation, and modification that continues until the system is certified as ready to enter the operational phase.\\n9-3e  Operation\\nOnce the database has passed the evaluation stage, it is considered operational. At that point, the database, its management, its users, and its application programs constitute a complete information system.\\nThe beginning of the operational phase invariably starts the process of system evolu-\\ntion. As soon as all of the targeted end users have entered the operations phase, problems that could not have been foreseen during the testing phase begin to surface. Some of the problems are serious enough to warrant emergency “patchwork, ” while others are merely minor annoyances. For example, if the database design is implemented to interface with the web, the sheer volume of transactions might cause even a well-designed system to TABLE 9.1\\nCOMMON SOURCES OF DATABASE FAILURE\\nSOURCE DESCRIPTION EXAMPLE\\nSoftware Software-induced failures may be traceable \\nto the operating system, the DBMS software, application programs, or viruses and other malware.In January 2015, a security vulnerability was found for Oracle E-Business Suite that could cause serious data compromise.\\n4\\nHardware Hardware-induced failures may include memory \\nchip errors, disk crashes, bad disk sectors, and disk-full errors.A bad memory module or a multiple hard disk failure in a database system can bring it to an abrupt stop.\\nProgramming exemptionsApplication programs or end users may roll back transactions when certain conditions are defined. Programming exemptions can also be caused by malicious or improperly tested code that can be exploited by hackers.Hackers constantly search for ways to exploit unprotected web database systems. For example, in February 2015, Anthem, the second largest health insurer, announced that it was hacked and data for 80 million customers might have been exposed.\\n5\\nTransactions The system detects deadlocks and aborts one of \\nthe transactions. (See Chapter 10.)Deadlock occurs when executing multiple simultaneous transactions.\\nExternal factors Backups are especially important when a \\nsystem suffers complete destruction from fire, earthquake, flood, or other natural disaster.In 2012, Hurricane Sandy hit the northeastern United States, causing data and service losses worth billions of dollars across multiple states.\\n4 “Oracle Patches Backdoor Vulnerability, Recommends Disabling SSL, ” January 21, 2015. Url: https://\\nthreatpost.com/oracle-patches-backdoor-vulnerability-recommends-disabling-ssl/110555\\n5 “Massive data hack of health insurer Anthem potentially exposes millions, ” Fred Barbash and Abby Phillip,  \\nFebruary 5, 2015, Washington Post. http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/20/2015 \\n-is-already-the-year-of-the-health-care-hack-and-its-only-going-to-get-worse/\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='36780fb3-d6d2-4c47-9244-2df633d01039', embedding=None, metadata={'page_label': '457', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    457\\nbog down. In that case, the designers have to identify the source of the bottleneck and \\nproduce alternative solutions. Those solutions may include using load-balancing soft-ware to distribute the transactions among multiple computers, increasing the available cache for the DBMS, and so on. The demand for change is the designer’s constant con-cern, which leads to phase 6, maintenance and evolution.\\n9-3f  Maintenance and Evolution\\nThe database administrator must be prepared to perform routine maintenance activities within the database. Some of the required periodic maintenance activities include:\\n•\\n Preventive maintenance (backup)\\n• Corrective maintenance (recovery)\\n• Adaptive maintenance (enhancing performance, adding entities and attributes, and \\nso on)\\n• Assignment of access permissions and their maintenance for new and old users\\n• Generation of database access statistics to improve the efficiency and usefulness of system audits and to monitor system performance\\n•\\n Periodic security audits based on the system-generated statistics\\n• Monthly, quarterly, or yearly system usage summaries for internal billing or budget-ing purposes\\nThe likelihood of new information requirements and the demand for additional \\nreports and new query formats require application changes and possible minor changes in the database components and contents. These changes can be easily implemented only when the database design is flexible and when all documentation is updated and online. Eventually, even the best-designed database environment will no longer be capable of incorporating such evolutionary changes, and then the whole DBLC process begins anew.\\nAs you can see, many of the activities described in the DBLC are similar to those in \\nthe SDLC. This should not be surprising because the SDLC is the framework within which the DBLC activities take place. A summary of the parallel activities that occur within the SDLC and DBLC is shown in Figure 9.8.\\n9-4 Conceptual Design\\nRecall that the second phase of the DBLC is database design, which comprises three stages: conceptual design, logical design, and physical design, plus the critical decision of DBMS selection. Conceptual design is the first stage in the database design process. The goal at this stage is to design a database that is independent of database software and physical details. The output of this process is a conceptual data model that describes the main data entities, attributes, relationships, and constraints of a given problem domain. This design is descriptive and narrative in form. In other words, it is generally composed of a graphical representation as well as textual descriptions of the main data elements, relationships, and constraints.\\nIn this stage, data modeling is used to create an abstract database structure that rep-\\nresents real-world objects in the most realistic way possible. The conceptual model must embody a clear understanding of the business and its functional areas. At this level of abstraction, the type of hardware and database model to be used might not have been identified yet. Therefore, the design must be software- and hardware-independent so that the system can be set up within any platform chosen later.\\nconceptual design\\nA process that uses data-modeling techniques to create a model of a database structure that represents real-world objects as realistically as possible. The design is both software- and hardware-independent.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d0745e5b-fdf8-48a1-8e24-39d2dcf46f58', embedding=None, metadata={'page_label': '458', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='458   Part 3     Advanced Design and Implementation\\nKeep in mind the following minimal data rule :\\nAll that is needed is there, and all that is there is needed .\\nIn other words, make sure that all data needed is in the model and that all data in \\nthe model is needed. All data elements required by the database transactions must be \\ndefined in the model, and all data elements defined in the model must be used by at least \\none database transaction.\\nHowever, as you apply the minimal data rule, avoid excessive short-term bias. Focus \\nnot only on the immediate data needs of the business but on future data needs. Thus, the \\ndatabase design must leave room for future modifications and additions, ensuring that \\nthe business’s investment in information resources will endure.\\nThe conceptual design has four steps, which are listed in Table 9.2.FIGURE 9.8  PARALLEL ACTIVITIES IN THE DBLC AND THE SDLC  \\nDatabase maintenance\\nand evolutionOperation\\nApplication program\\nmaintenanceTesting and\\nevaluationImplementation\\nand loadingDatabase designDatabase initial\\nstudySystem \\ndesign\\nSystem \\nimplementationCreation\\nLoading\\nFine-tuningConceptual\\nLogical\\nPhysicalDBLC SDLC\\nAnalysis\\nDetailed design\\nCoding\\nTesting and \\nevaluationScreens\\nReports\\nProcedures\\nPrototyping\\nDebugging\\nminimal data rule\\nDefined as “All that is \\nneeded is there, and all \\nthat is there is needed.” \\nIn other words, all data \\nelements required by \\ndatabase transactions \\nmust be defined in the \\nmodel, and all data \\nelements defined in the \\nmodel must be used by \\nat least one database \\ntransaction.TABLE 9.2\\nCONCEPTUAL DESIGN STEPS\\nSTEP ACTIVITY\\n1 Data analysis and requirements\\n2 Entity relationship modeling and normalization\\n3 Data model verification\\n4 Distributed database design\\nThe following sections cover these steps in more detail.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='66fdfd22-f174-4b57-8374-b0d93495c53d', embedding=None, metadata={'page_label': '459', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    459\\n9-4a  Data Analysis and Requirements\\nThe first step in conceptual design is to discover the characteristics of the data ele-\\nments. An effective database is an information factory that produces key ingredients for successful decision making. Appropriate data element characteristics are those that can be transformed into appropriate information. Therefore, the designer’s efforts are focused on:\\n•\\n Information needs . What kind of information is needed? That is, what output (reports \\nand queries) must be generated by the system, what information does the current \\nsystem generate, and to what extent is that information adequate?\\n• Information users . Who will use the information? How is the information to be used? \\nWhat are the various end-user data views?\\n• Information sources . Where is the information to be found? How is the information to \\nbe extracted once it is found?\\n• Information constitution . What data elements are needed to produce the information? \\nWhat are the data attributes? What relationships exist in the data? What is the data volume? How frequently is the data used? What data transformations will be used to generate the required information?\\nThe designer obtains the answers to those questions from a variety of sources to  \\ncompile the necessary information:\\n•\\n Developing and gathering end-user data views. The database designer and the end \\nuser(s) jointly develop a precise description of end-user data views, which in turn are used to help identify the database’s main data elements.\\n•\\n Directly observing the current system: existing and desired output. The end user usually has an existing system in place, whether it is manual or computer-based. The designer reviews the existing system to identify the data and its characteristics. The designer examines the input forms and files (tables) to discover the data type and volume. If the end user already has an automated system in place, the designer carefully examines the current and desired reports to describe the data required to support the reports.\\n•\\n Interfacing with the systems design group. As noted earlier in this chapter, the database design process is part of the SDLC. In some cases, the systems analyst in charge of designing the new system will also develop the conceptual database model. (This is usually true in a decentralized environment.) In other cases, the database design is considered part of the DBA ’s job. The presence of a DBA usually implies the existence of a formal data-processing department. The DBA designs the database according to the specifications created by the systems analyst.\\nTo develop an accurate data model, the designer must have a thorough understanding \\nof the company’s data types and their extent and uses. But data does not, by itself, yield the required understanding of the total business. From a database point of view, the collection of data becomes meaningful only when business rules are defined. Remember from Chapter 2, Data Models, that a business rule  is a brief and precise description of a \\npolicy, procedure, or principle within a specific organization’s environment. Business rules, derived from a detailed description of an organization’s operations, help to create and enforce actions within that organization’s environment. When business rules are written properly, they define entities, attributes, relationships, connectivities, cardinali-ties, and constraints.\\nTo be effective, business rules must be easy to understand, and they must be \\nwidely disseminated to ensure that every person in the organization shares a common \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='08c6149e-40b4-4f75-ae83-f136101591b7', embedding=None, metadata={'page_label': '460', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='460   Part 3    Advanced Design and Implementation\\ninterpretation of the rules. Using simple language, business rules describe the main and \\ndistinguishing characteristics of the data as viewed by the company . Examples of business \\nrules are as follows:\\n• A customer may make many payments on an account.\\n• Each payment on an account is credited to only one customer.\\n• A customer may generate many invoices.\\n• Each invoice is generated by only one customer.\\nGiven their critical role in database design, business rules must not be established \\ncasually. Poorly defined or inaccurate business rules lead to database designs and imple-\\nmentations that fail to meet the needs of the organization’s end users.\\nIdeally, business rules are derived from a formal description of operations, \\nwhich is a document that provides a precise, up-to-date, and thoroughly reviewed description of the activities that define an organization’s operating environment. (To the database designer, the operating environment is both the data sources and the data users.) Naturally, an organization’s operating environment is dependent on the organization’s mission. For example, the operating environment of a university would be quite different from that of a steel manufacturer, an airline, or a nursing home. Y et, no matter how different the organizations may be, the data analysis  and \\nrequirements component of the database design is enhanced when the data envi-ronment and data use are described accurately and precisely within a description of operations.\\nIn a business environment, the main sources of information for the description of \\noperations—and therefore of business rules—are company managers, policymakers, department managers, and written documentation such as company procedures, stan-dards, and operations manuals. A faster and more direct source of business rules is direct interviews with end users. Unfortunately, because perceptions differ, the end user can be a less reliable source when it comes to specifying business rules. For example, a mainte-nance department mechanic might believe that any mechanic can initiate a maintenance procedure, when actually only mechanics with inspection authorization should perform such a task. This distinction might seem trivial, but it has major legal consequences. Although end users are crucial contributors to the development of business rules, it pays to verify end-user perceptions. Often, interviews with several people who perform the same job yield very different perceptions of their job components. While such a discov-ery might point to “management problems, ” that general diagnosis does not help the database designer. Given the discovery of such problems, the database designer’s job is to reconcile the differences and verify the results of the reconciliation to ensure that the business rules are appropriate and accurate.\\nKnowing the business rules enables the designer to fully understand how the busi-\\nness works and what role the data plays within company operations. Consequently, the designer must identify the company’s business rules and analyze their impact on the nature, role, and scope of data.\\nBusiness rules yield several important benefits in the design of new systems:\\n•\\n They help standardize the company’s view of data.\\n• They constitute a communications tool between users and designers.\\n• They allow the designer to understand the nature, role, and scope of the data.\\n• They allow the designer to understand business processes.\\n• They allow the designer to develop appropriate relationship participation rules and foreign key constraints. See Chapter 4, Entity Relationship (ER) Modeling.description of operations\\nA document that provides a precise, detailed, up-to-date, and thoroughly reviewed description of the activities that define an organization’s operating environment.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fa769b9c-3c2f-429b-8804-cd1f2b1dac31', embedding=None, metadata={'page_label': '461', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    461\\nThe last point is especially noteworthy: whether a given relationship is mandatory or \\noptional is usually a function of the applicable business rule.\\n9-4b  Entity Relationship Modeling and Normalization\\nBefore creating the ER model, the designer must communicate and enforce appropriate \\nstandards to be used in the documentation of the design. The standards include the use of diagrams and symbols, documentation writing style, layout, and any other conven-tions to be followed during documentation. Designers often overlook this very import-ant requirement, especially when they are working as members of a design team. Failure to standardize documentation often means a failure to communicate later, and commu-nications failures often lead to poor design work. In contrast, well-defined and enforced standards make design work easier and promise (but do not guarantee) a smooth inte-gration of all system components.\\nBecause the business rules usually define the nature of the relationship(s) among the \\nentities, the designer must incorporate them into the conceptual model. The process of defining business rules and developing the conceptual model using ER diagrams can be described using the steps shown in Table 9.3.\\n6\\nSome of the steps listed in Table 9.3 take place concurrently, and some, such as the \\nnormalization process, can generate a demand for additional entities and/or attributes, thereby causing the designer to revise the ER model. For example, while identifying two main entities, the designer might also identify the composite bridge entity that represents the many-to-many relationship between the two main entities.\\nTo review, suppose that you are creating a conceptual model for the JollyGood \\nMovie Rental Corporation, whose end users want to track customers’ DVD movie kiosk rentals. The simple ER diagram presented in Figure 9.9 shows a composite entity that helps track customers and their video rentals. Business rules define the optional nature of the relationships between the entities VIDEO and CUSTOMER. For exam-ple, customers are not required to check out a video. A video need not be checked out in order to exist in the kiosk. A customer may rent many videos, and a video may be rented by many customers. In particular, note the composite RENTAL entity that con-nects the two main entities.TABLE 9.3\\nDEVELOPING THE CONCEPTUAL MODEL USING ER DIAGRAMS\\nSTEP ACTIVITY\\n1 Identify, analyze, and refine the business rules.\\n2 Identify the main entities, using the results of Step 1.3 Define the relationships among the entities, using the results of Steps 1 and 2.4 Define the attributes, primary keys, and foreign keys for each of the entities.5 Normalize the entities. (Remember that entities are implemented as tables in an RDBMS.)6 Complete the initial ER diagram.7 Validate the ER model against the end users’ information and processing requirements.8 Modify the ER model, using the results of Step 7.\\n6 See “Linking Rules to Models, ” Alice Sandifer and Barbara von Halle, Database Programming and Design, \\n4(3), March 1991, pp. 13−16. Although the source seems dated, it remains the current standard. The tech-\\nnology has changed substantially, but the process has not.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5100c79d-646f-40a3-bcd2-759cebcc0044', embedding=None, metadata={'page_label': '462', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='462   Part 3     Advanced Design and Implementation\\nAs you will likely discover, the initial ER model may be subjected to several revi -\\nsions before it meets the system’s requirements. Such a revision process is quite natural. \\nRemember that the ER model is a communications tool as well as a design blueprint. \\nTherefore, when you meet with the proposed system users, the initial ER model should \\ngive rise to questions such as “Is this really what you meant?” For example, the ERD \\nshown in Figure 9.9 is far from complete. Clearly, many more attributes must be defined \\nand the dependencies must be checked before the design can be implemented. In addi -\\ntion, the design cannot yet support typical video rental transactions. For example, each \\nvideo is likely to have many copies available for rental purposes. However, if the VIDEO \\nentity shown in Figure 9.9 is used to store the titles as well as the copies, the design trig -\\ngers the data redundancies shown in Table 9.4.\\nThe initial ERD shown in Figure 9.9 must be modified to reflect the answer to the \\nquestion “Is more than one copy available for each title?” Also, payment transactions \\nmust be supported. (Y ou will have an opportunity to modify this initial design in Prob -\\nlem 5 at the end of the chapter.)\\nFrom the preceding discussion, you might get the impression that ER modeling activ -\\nities such as entity and attribute definition, normalization, and verification take place in a \\nprecise sequence. In fact, once you have completed the initial ER model, chances are that \\nyou will move back and forth among the activities until you are satisfied that the ER model \\naccurately represents a database design that can meet the required system demands. The \\nactivities often take place in parallel, and the process is iterative. Figure 9.10 summarizes \\nthe ER modeling interactions. Figure 9.11 summarizes the array of design tools and infor -\\nmation sources that the designer can use to produce the conceptual model.\\nAll objects (entities, attributes, relations, views, and so on) are defined in a data dictio -\\nnary, which is used in tandem with the normalization process to help eliminate data anom -\\nalies and redundancy problems. During this ER modeling process, the designer must:\\n• Define entities, attributes, primary keys, and foreign keys. (The foreign keys serve as \\nthe basis for the relationships among the entities.)\\n• Make decisions about adding new primary key attributes to satisfy end-user and  \\nprocessing requirements.FIGURE 9.9  JOLLYGOOD MOVIE RENTAL ERD  \\nTABLE 9.4\\nDATA REDUNDANCIES IN THE VIDEO TABLE\\nVIDEO_ID VIDEO_TITLE VIDEO_COPY VIDEO_CHG VIDEO_DAYS\\nSF-12345FT-1 Adventures on Planet III 1 $1.09 1\\nSF-12345FT-2 Adventures on Planet III 2 $1.09 1\\nSF-12345FT-3 Adventures on Planet III 3 $1.09 1\\nWE-5432GR-1 TipToe Canoe and Tyler 2: A Journey 1 $1.09 2\\nWE-5432GR-2 TipToe Canoe and Tyler 2: A Journey 2 $1.09 2\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9cc96685-0d8a-4e23-9635-c891d4cb2a4e', embedding=None, metadata={'page_label': '463', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    463\\nFIGURE 9.10  ER MODELING IS AN ITERATIVE PROCESS BASED ON MANY ACTIVITIES  \\nFIGURE 9.11  CONCEPTUAL DESIGN TOOLS AND INFORMATION SOURCES  \\nDatabase initial study\\nDBLC\\nprocesses and \\ndatabase transactions\\nVeriﬁcation AttributesInitial ER model\\nNormalizationData analysis\\nUser views and\\nbusiness rules\\nFinal ER model\\nConceptual model\\nDeﬁnition\\nand\\nvalidationDesign tools Information sources\\nERDBusiness rules and \\ndata constraints\\nData ﬂow diagrams\\n(DFD)*\\nProcess functional\\ndescriptions (FD)*\\n(user views)ER diagram\\nNormalization\\nData dictionary\\n* Output generated by the systems analysis and design activities\\n• Make decisions about the treatment of composite and multivalued attributes.\\n• Make decisions about adding derived attributes to satisfy processing requirements.\\n• Make decisions about the placement of foreign keys in 1:1 relationships.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='17019830-890d-4b61-9c16-c1135219f591', embedding=None, metadata={'page_label': '464', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='464   Part 3    Advanced Design and Implementation\\n• Avoid unnecessary ternary relationships.\\n• Draw the corresponding ER diagram.\\n• Normalize the entities.\\n• Include all data element definitions in the data dictionary.\\n• Make decisions about standard naming conventions.\\nThe naming conventions requirement is important, yet it is frequently ignored at the \\ndesigner’s risk. Real database design is generally accomplished by teams. Therefore, it \\nis important to ensure that team members work in an environment in which naming standards are defined and enforced. Proper documentation is crucial to the successful completion of the design, and adherence to the naming conventions serves database designers well. In fact, a common refrain from users seems to be: “I didn’t know why you made such a fuss over naming conventions, but now that I’m doing this stuff for real, I’ve become a true believer. ”\\n9-4c  Data Model Verification\\nData model verification is one of the last steps in the conceptual design stage, and it is one of the most critical. In this step, the ER model must be verified against the proposed system processes to corroborate that they can be supported by the database model. Veri-fication requires that the model be run through a series of tests against:\\n•\\n End-user data views\\n• All required transactions: SELECT, INSERT, UPDATE, and DELETE operations\\n• Access rights and security\\n• Business-imposed data requirements and constraints\\nBecause real-world database design is generally done by teams, the database design \\nis probably divided into major components known as modules. A module is an infor -\\nmation system component that handles a specific business function, such as inventory, \\norders, or payroll. Under these conditions, each module is supported by an ER segment that is a subset or fragment of an enterprise ER model. Working with modules accom-plishes several important ends:\\n•\\n The modules (and even the segments within them) can be delegated to design groups \\nwithin teams, greatly speeding up the development work.\\n• The modules simplify the design work. The large number of entities within a complex design can be daunting. Each module contains a more manageable number of entities.\\n•\\n The modules can be prototyped quickly. Implementation and application program-ming trouble spots can be identified more readily. Quick prototyping is also a great confidence builder.\\n•\\n Even if the entire system cannot be brought online quickly, the implementation of one or more modules will demonstrate that progress is being made and that at least part of the system is ready to begin serving the end users.\\nAs useful as modules are, they represent a loose collection of ER model fragments \\nthat could wreak havoc in the database if left unchecked. For example, the ER model fragments:\\n•\\n Might present overlapping, duplicated, or conflicting views of the same data\\n• Might not be able to support all processes in the system’s modulesmodule\\n(1) A design \\nsegment that can be implemented as an autonomous unit, and is sometimes linked to produce a system. (2) An information system component that handles a specific function, such as inventory, orders, or payroll.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b640a05e-26d2-4446-8f55-da7548e0477b', embedding=None, metadata={'page_label': '465', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    465\\nTo avoid these problems, it is better if the modules’ ER fragments are merged into a \\nsingle enterprise ER model. This process starts by selecting a central ER model segment \\nand iteratively adding more ER model segments one at a time. At each stage, for each new entity added to the model, you need to validate that the new entity does not overlap or conflict with a previously identified entity in the enterprise ER model.\\nMerging the ER model segments into an enterprise ER model triggers a careful reeval-\\nuation of the entities, followed by a detailed examination of the attributes that describe those entities. This process serves several important purposes:\\n•\\n The emergence of the attribute details might lead to a revision of the entities them-\\nselves. Perhaps some of the components first believed to be entities will instead turn out to be attributes within other entities. Or, a component that was originally con-sidered an attribute might turn out to contain a sufficient number of subcomponents to warrant the introduction of one or more new entities.\\n•\\n The focus on attribute details can provide clues about the nature of relationships as they are defined by the primary and foreign keys. Improperly defined relationships lead to implementation problems first and to application development problems later.\\n•\\n To satisfy processing and end-user requirements, it might be useful to create a new primary key to replace an existing primary key. For example, in the example illus-trated in Figure 9.9, a surrogate primary key (RENTAL_ID) could be introduced to replace the original primary key composed of VIDEO_ID and CUST_NUM.\\n•\\n Unless the entity details (the attributes and their characteristics) are precisely defined, it is difficult to evaluate the extent of the design’s normalization. Knowledge of the normalization levels helps guard against undesirable redundancies.\\n•\\n A careful review of the rough database design blueprint is likely to lead to revi-sions. Those revisions will help ensure that the design is capable of meeting end-user requirements.\\nAfter finishing the merging process, the resulting enterprise ER model is verified \\nagainst each of the module’s processes. The ER model verification process is detailed in Table 9.5.\\nTABLE 9.5\\nTHE ER MODEL VERIFICATION PROCESS\\nSTEP ACTIVITY\\n1 Identify the ER model’s central entity.\\n2 Identify each module and its components.3 Identify each module’s transaction requirements:\\nInternal: updates/inserts/deletes/queries/reports\\nExternal: module interfaces\\n4 Verify all processes against system requirements.\\n5 Make all necessary changes suggested in Step 4.6 Repeat Steps 2–5 for all modules.\\nKeep in mind that this process requires the continuous verification of business trans-\\nactions as well as system and user requirements. The verification sequence must be \\nrepeated for each of the system’s modules. Figure 9.12 illustrates the iterative nature of the process.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8d50fe14-46e1-470f-9d66-393bc8265cd5', embedding=None, metadata={'page_label': '466', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='466   Part 3     Advanced Design and Implementation\\nThe verification process starts with selecting the central (most important) entity, \\nwhich is the focus for most of the system’s operations.\\nTo identify the central entity, the designer selects the entity involved in the greatest \\nnumber of the model’s relationships. In the ER diagram, it is the entity with more lines \\nconnected to it than any other.\\nThe next step is to identify the module or subsystem to which the central entity belongs \\nand to define that module’s boundaries and scope. The entity belongs to the module that \\nuses it most frequently. Once each module is identified, the central entity is placed within \\nthe module’s framework to let you focus on the module’s details.\\nWithin the central entity/module framework, you must\\n• Ensure the module’s cohesivity . The term cohesivity  describes the strength of the relation -\\nships found among the module’s entities. A module must display high cohesivity —that is, \\nthe entities must be strongly related, and the module must be complete and self-sufficient.\\n• Analyze each module’s relationships with other modules to address module coupling . \\nModule coupling  describes the extent to which modules are independent of one \\nanother. Modules must display low coupling , indicating that they are independent \\nof other modules. Low coupling decreases unnecessary intermodule dependencies, \\nthereby allowing the creation of a truly modular system and eliminating unnecessary \\nrelationships among entities.\\nProcesses may be classified according to their:\\n• Frequency (daily, weekly, monthly, yearly, or exceptions)\\n• Operational type (INSERT or ADD, UPDATE or CHANGE, DELETE, queries and \\nreports, batches, maintenance, and backups)FIGURE 9.12  ITERATIVE ER MODEL VERIFICATION PROCESS  \\nER model veriﬁedYes\\nNoIdentify central entity,\\nmodules, and components\\nDeﬁne processes and\\ntransaction steps\\nVerify ER model\\nMake changes\\nto ER modelDoes ER\\nrequire changes?\\ncohesivity\\nThe strength of the \\nrelationships between a \\nmodule’s components. \\nModule cohesivity must \\nbe high.\\nmodule coupling\\nThe extent to \\nwhich modules are \\nindependent of one \\nanother.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1700e7d3-2337-4227-b6b9-c5729dc44e7b', embedding=None, metadata={'page_label': '467', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    467\\nAll identified processes must be verified against the ER model. If necessary, appropri-\\nate changes are implemented. The process verification is repeated for all of the model’s \\nmodules. Y ou can expect that additional entities and attributes will be incorporated into the conceptual model during its validation.\\nAt this point, a conceptual model has been defined as hardware- and software-  \\nindependent. Such independence ensures the system’s portability across platforms. Por -\\ntability can extend the database’s life by making it possible to migrate to another DBMS and hardware platform.\\n9-4d  Distributed Database Design\\nAlthough not a requirement for most databases, some may need to be distributed among multiple geographical locations. Processes that access the database may also vary from one location to another. For example, a retail process and a warehouse storage process are likely to be found in different physical locations. If the database data and processes will be distributed across the system, portions of a database, known as database frag-ments, may reside in several physical locations. A database fragment is a subset of a database that is stored at a given location. The database fragment may be a subset of rows or columns from one or multiple tables.\\nDistributed database design defines the optimum allocation strategy for database \\nfragments to ensure database integrity, security, and performance. The allocation strat-egy determines how to partition the database and where to store each fragment. The design implications introduced by distributed processes are examined in detail in Chap-ter 12, Distributed Database Management Systems.\\n9-5 DBMS Software Selection\\nThe selection of DBMS software is critical to the information system’s smooth operation. Consequently, the advantages and disadvantages of the proposed DBMS software should be carefully studied. To avoid false expectations, the end user must be made aware of the limitations of both the DBMS and the database.\\nAlthough the factors that affect the purchasing decision vary from company to com-\\npany, some of the most common are:\\n•\\n Cost . This includes the original purchase price, along with maintenance, operational, \\nlicense, installation, training, and conversion costs.\\n• DBMS features and tools. Some database software includes a variety of tools \\nthat facilitate application development. For example, the availability of query by example (QBE), screen painters, report generators, application generators, and data dictionaries helps to create a more pleasant work environment for both the end user and the application programmer. Database administrator facili-ties, query facilities, ease of use, performance, security, concurrency control, transaction processing, and third-party support also influence DBMS software selection.\\n•\\n Underlying model . This can be hierarchical, network, relational, object/relational, or \\nobject-oriented.\\n• Portability . A DBMS can be portable across platforms, systems, and languages.\\n• DBMS hardware requirements. Items to consider include processor(s), RAM, disk space, and so on.database fragment\\nA subset of a distributed database. Although the fragments may be stored at different sites within a computer network, the set of all fragments is treated as a single database. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e2d3187d-db27-4293-b552-34cfe4987c02', embedding=None, metadata={'page_label': '468', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='468   Part 3    Advanced Design and Implementation\\n9-6 Logical Design\\nLogical design is the second stage in the database design process. The logical design \\ngoal is to design an enterprise-wide database that is based on a specific data model but independent of physical-level details. Logical design requires that all objects in the con-ceptual model be mapped to the specific constructs used by the selected database model. For example, the logical design for a relational DBMS includes the specifications for the relations (tables), relationships, and constraints (in other words, domain definitions, data validations, and security views).\\nThe logical design is generally performed in four steps, which are listed in Table 9.6.\\nSuch steps, like most of the data-modeling process, are not necessarily performed \\nsequentially, but in an iterative fashion. The following sections cover these steps in more \\ndetail.\\n9-6a  Map the Conceptual Model to the Logical Model\\nThe first step in creating the logical design is to map the conceptual model to the cho-sen database constructs. Because this book deals primarily with relational databases, and because most current database design projects are based on the relational database model, this section focuses on logical design using relational constructs. In the real world, logical design generally involves translating the ER model into a set of relations (tables), columns, and constraint definitions. The process of translating the conceptual model into a set of relations is depicted in Table 9.7.\\nRemember, the steps indicated in Table 9.7 are not sequential but iterative. The exam-\\nple of the Simple College ER model shown in Figure 9.13 illustrates this process.\\nAs indicated in Table 9.7, the first step in the logical design stage is to map strong \\nentities to tables. Recall from Chapter 4 that a strong entity is one that resides in the “1” logical design\\nA stage in the design phase that matches the conceptual design to the specific constructs of the selected DBMS and is therefore software-dependent. Logical design is used to translate the conceptual design into the internal model for a selected database management system, such as DB2, SQL Server, Oracle, IMS, Informix, Access, or Ingress.TABLE 9.6\\nLOGICAL DESIGN STEPS\\nSTEP ACTIVITY\\n1 Map the conceptual model to logical model components.\\n2 Validate the logical model using normalization.3 Validate the logical model integrity constraints.4 Validate the logical model against user requirements.\\nTABLE 9.7\\nMAPPING THE CONCEPTUAL MODEL TO THE RELATIONAL MODEL\\nSTEP ACTIVITY\\n1 Map strong entities.2 Map supertype/subtype relationships.3 Map weak entities.4 Map binary relationships.5 Map higher-degree relationships.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4fa3b7ee-b5cc-432b-8f89-ef5ec9ba5bf8', embedding=None, metadata={'page_label': '469', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    469\\nside of all its relationships—that is, an entity that does not have a mandatory attribute \\nthat is a foreign key to another table. Therefore, the first entities to be translated into \\ntables would be the EMPLOYEE and COURSE entities. In this case, you define the \\ntable name, its columns, and their characteristics. For example, the relation definitions \\nfor the strong entities of Simple College would be:\\nCOURSE (CRS_CODE , CRS_TITLE, CRS_DESCRIPT, CRS_CREDIT)\\nPRIMARY KEY:  CRS_CODE\\nEMPLOYEE ( EMP_NUM , EMP_LNAME, EMP_FNAME, EMP_INITIAL, EMP_E_MAIL)\\nPRIMARY KEY:  EMP_NUM\\nOnce all strong entities are mapped, you are ready to map any entities involved in  \\na supertype/subtype relationship or any weak entities. In the case of Simple College, the \\nPROFESSOR entity is a subtype of the EMPLOYEE entity. PROFESSOR is also a weak \\nentity because it inherits its primary key from EMPLOYEE and is existence-dependent \\non EMPLOYEE. At this point, you could also start defining the relationships between \\nsupertype and subtype entities. For example:\\nPROFESSOR (EMP_NUM , PROF_SPECIALTY , PROF_RANK)\\nPRIMARY KEY:  EMP_NUM\\nFOREIGN KEY:  EMP_NUM REFERENCES EMPLOYEE\\nNext, you start mapping all binary relationships. In the previous example, you defined \\nthe supertype/subtype relationship between EMPLOYEE and PROFESSOR. This is an \\ninstance that demonstrates the iterative nature of the process. Continuing with the Sim -\\nple College ER model, you would define the CLASS relation and define its 1:M relation -\\nships with PROFESSOR and COURSE:\\nCLASS (CLASS_CODE , EMP_NUM , CLASS_TIME, CLASS_DAYS, CRS_CODE )\\nPRIMARY KEY:  CLASS_CODE\\nFOREIGN KEYS:  EMP_NUM REFERENCES PROFESSOR\\n   CRS_CODE REFERENCES COURSE\\nNext, you will proceed with all relationships between three or more entities until \\nall relationships in the model are clearly defined. The logical design’s tables must cor -\\nrespond to the entities (EMPLOYEE, PROFESSOR, COURSE, and CLASS) shown in FIGURE 9.13  THE SIMPLE COLLEGE CONCEPTUAL MODEL  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='db4b3dde-8284-4d4b-9310-f7fe4d9d790f', embedding=None, metadata={'page_label': '470', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='470   Part 3    Advanced Design and Implementation\\nthe conceptual design of Figure 9.13, and the table columns must correspond to the \\nattributes specified in the conceptual design. The final outcome of this process is a list of relations, attributes, and relationships that will be the basis for the next step.\\n9-6b  Validate the Logical Model Using Normalization\\nThe logical design should contain only properly normalized tables. The process of map-ping the conceptual model to the logical model may unveil some new attributes or the discovery of new multivalued or composite attributes. Therefore, it’s very likely that new attributes may be added to tables, or that entire new tables may be added to the logical model. For each identified table (old and new), you must ensure that all attributes are fully dependent on the identified primary key and that the tables are in at least third normal form (3NF).\\nAs indicated throughout this section, database design is an iterative process. Activities \\nsuch as normalization take place at different stages in the design process. Each time you reiterate a step, the model is further refined and better documented. New attributes may be created and assigned to the proper entities. Functional dependencies among deter -\\nminant and dependent attributes are evaluated and data anomalies are prevented via normalization.\\n9-6c  Validate Logical Model Integrity Constraints\\nThe translation of the conceptual model into a logical model also requires definition of the attribute domains and appropriate constraints. For example, the domain definitions for the CLASS_CODE, CLASS_DAYS, and CLASS_TIME attributes displayed in the CLASS entity in Figure 9.13 are written this way:\\nCLASS_CODE is a valid class code.\\nType: numeric\\nRange:\\xa0low\\xa0value=1000\\xa0high\\xa0value=9999Display format: 9999Length: 4\\nCLASS_DAYS is a valid day code.\\nType: characterDisplay format: XXXValid entries: MWF, TR, M, T, W, R, F, SLength: 3\\nCLASS_TIME is a valid time.\\nType: characterDisplay format: 99:99 (24-hour clock)Display range: 06:00 to 22:00Length: 5\\nAll these defined constraints must be supported by the logical data model. In this stage, \\nyou must map these constraints to the proper relational model constraints. For example, the CLASS_DAYS attribute is character data that should be restricted to a list of valid character combinations. Here, you define this attribute to have a CHECK IN constraint to enforce that the only allowed values are “MWF” , “TR” , “M” , “T” , “W” , “R” , “F” , and “S” . \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a3d2f138-2be9-4218-a968-ad5393379b77', embedding=None, metadata={'page_label': '471', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    471\\nDuring this step, you also define which attributes are mandatory and which are optional, \\nand ensure that all entities maintain entity and referential integrity.\\nThe right to use the database is also specified during the logical design phase. Who \\nwill be allowed to use the tables, and what portions of the tables will be available to which users? Within a relational framework, the answers to those questions require the defini-tion of appropriate views. For example, a given process may require the creation of the following view to get data about the class schedules:\\nCREATE VIEW vSCHEDULE AS\\nSELECT  EMP_LNAME, EMP_FNAME, CLASS_CODE, CRS_TITLE, CLASS_TIME, CLASS_DAYS\\nFROM PROFESSOR, CLASS, COURSE\\nWHERE PROFESSOR.EMP_NUM = CLASS.EMP_NUM AND\\nCLASS.CRS_CODE = COURSE.CRS_CODE\\nSpecial attention is needed at this stage to ensure that all views can be resolved \\nand that security is enforced to ensure the privacy of the data. Additionally, if you are \\nworking with a distributed database design, data could be stored at multiple locations, and each location may have different security restrictions. After validating the logical model integrity constraints, you are ready to validate the model against the end-user requirements.\\n9-6d  Validate the Logical Model Against User Requirements\\nThe logical design translates the software-independent conceptual model into a soft-ware-dependent model. The final step in the logical design process is to validate all logical model definitions against all end-user data, transaction, and security require-ments. A process similar to the one depicted in Table 9.5 takes place again to ensure the correctness of the logical model. The stage is now set to define the physical requirements that allow the system to function within the selected DBMS/hardware environment.\\n9-7 Physical Design\\nPhysical design is the process of determining the data storage organization and data access characteristics of the database to ensure its integrity, security, and performance. This is the last stage in the database design process. The storage characteristics are a func-tion of the types of devices supported by the hardware, the type of data access methods supported by the system, and the DBMS. Physical design can become a very technical job that affects not only the accessibility of the data in the storage device(s) but the per -\\nformance of the system.\\nThe physical design stage consists of the steps in Table 9.8.\\nphysical design\\nA stage of database design that maps the data storage and access characteristics of a database. Because these characteristics are a function of the types of devices supported by the hardware, the data access methods supported by the system physical design are both hardware- and software-dependent. See also physical model.\\nTABLE 9.8\\nPHYSICAL DESIGN STEPS\\nSTEP ACTIVITY\\n1 Define data storage organization.\\n2 Define integrity and security measures.3 Determine performance measurements.\\nThe following sections cover these steps in more detail.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='49cbe69b-2c61-45f7-9bb2-561394bc5688', embedding=None, metadata={'page_label': '472', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='472   Part 3    Advanced Design and Implementation\\n9-7a  Define Data Storage Organization\\nBefore you can define data storage organization, you must determine the volume of data \\nto be managed and the data usage patterns.\\n• Knowing the data volume will help you determine how much storage space to reserve \\nfor the database. To do this, the designer follows a process similar to the one used during ER model verification. For each table, identify all possible transactions, their frequency, and volume. For each transaction, you determine the amount of data to be added or deleted from the database. This information will help you determine the amount of data to be stored in the related table.\\n•\\n Conversely, knowing how frequently new data is inserted, updated, and retrieved will help the designer determine the data usage patterns. Usage patterns are critical, particularly in distributed database design. For example, are there any weekly batch uploads or monthly aggregation reports to be generated? How frequently is new data added to the system?\\nEquipped with the two previous pieces of information, the designer must:\\n•\\n Determine the location and physical storage organization for each table. As you saw in Section 9-3c, tables are stored in table spaces, and a table space can hold data from multiple tables. In this step, the designer assigns which tables will use which table spaces, and assigns the location of the table spaces. For example, a useful technique available in most relational databases is the use of clustered tables. The clustered tables storage technique stores related rows from two related tables in adjacent data blocks on disk. This ensures that the data is stored in sequentially adjacent locations, thereby reducing data access time and increasing system performance.\\n•\\n Identify indexes and the type of indexes to be used for each table. As you saw in previous chapters, indexes are useful for ensuring the uniqueness of data values in a column and to facilitate data lookups. Y ou also know that the DBMS automatically creates a unique index for the primary key of each table. Y ou will learn in Chapter 11 about the various types of index organization. In this step, you identify all required indexes and determine the best type of organization to use based on the data usage patterns and performance requirements.\\n•\\n Identify the views and the type of views to be used on each table. As you learned in Chapter 8, a view is useful to limit access to data based on user or transaction needs. Views can also be used to simplify processing and end-user data access. In this step the designer must ensure that all views can be implemented and that they provide only the required data. The designer must also become familiar with the types of views supported by the DBMS and how they could help meet system goals.\\n9-7b  Define Integrity and Security Measures\\nOnce the physical organization of the tables, indexes, and views are defined, the database is ready for the end users. However, before users can access the data in the database, they must be properly authenticated. In this step of physical design, two tasks must be addressed:\\n•\\n Define user and security groups and roles. User management is more a function of \\ndatabase administration than database design. However, as a designer you must know the different types of users and groups of users to properly enforce database security. Most DBMS implementations support the use of database roles. A database role is a set of database privileges that could be assigned as a unit to a user or group. For exam-ple, you could define an Advisor role that has Read access to the vSCHEDULE view.clustered table\\nA storage technique that stores related rows from two related tables in adjacent data blocks on disk.\\ndatabase role\\nA set of database privileges that could be assigned as a unit to a user or group.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1eaf1747-d202-4a8f-9dbe-ecca7afe2ba5', embedding=None, metadata={'page_label': '473', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    473\\n• Assign security controls . The DBMS also allows administrators to assign specific access \\nrights for database objects to a user or group of users. For example, you could assign \\nthe SELECT and UPDATE access rights to the user leilers on the CLASS table. An access right could also be revoked from a specific user or groups of users. This fea-ture could come in handy during database backups, scheduled maintenance events, or even during data breach incidents.\\n9-7c  Determine Performance Measures\\nPhysical design becomes more complex when data is distributed at different locations because the performance is affected by the communication media’s throughput. Given such complexities, it is not surprising that designers favor database software that hides as many of the physical-level activities as possible. Despite the fact that relational models tend to hide the complexities of the computer’s physical characteristics, the performance of relational databases is affected by physical storage properties. For example, perfor -\\nmance can be affected by characteristics of the storage media, such as seek time, sector and block (page) size, buffer pool size, and the number of disk platters and read/write heads. In addition, factors such as the creation of an index can have a considerable effect on the relational database’s performance—that is, data access speed and efficiency.\\nIn summary, physical design performance measurement deals with fine-tuning the \\nDBMS and queries to ensure that they will meet end-user performance requirements.\\nFor a detailed discussion of database performance and query optimization techniques that could be used, see Chapter 11, Database Performance Tuning and Query Optimization.Note\\nThe preceding sections have separated the discussions of logical and physical  \\ndesign activities. In fact, logical and physical design can be carried out in parallel,  \\non a table-by-table basis. Such parallel activities require the designer to have a thor -\\nough understanding of the software and hardware to take full advantage of their characteristics.\\n9-8 Database Design Strategies\\nThere are two classical approaches to database design:\\n• Top-down design starts by identifying the data sets and then defines the data ele-\\nments for each of those sets. This process involves the identification of different entity types and the definition of each entity’s attributes.\\n•\\n Bottom-up design first identifies the data elements (items) and then groups them together in data sets. In other words, it first defines attributes, and then groups them to form entities.\\nThe two approaches are illustrated in Figure 9.14. Selecting a primary emphasis on top-\\ndown or bottom-up procedures often depends on the scope of the problem or on personal preferences. Although the two methodologies are complementary rather than mutually exclusive, a primary emphasis on a bottom-up approach may be more productive for small databases with few entities, attributes, relations, and transactions. For situations in which the number, variety, and complexity of entities, relations, and transactions is overwhelming, top-down design\\nA design philosophy that begins by defining the main structures of a system and then moves to define the smaller units within those structures. In database design, this process first identifies entities and then defines the attributes within the entities.\\nbottom-up design \\nA design philosophy that begins by identifying individual design components and then aggregates them into larger units. In database design, the process begins by defining attributes and then groups them into entities.\\nPhysical design is par -\\nticularly important in the older hierarchical and network models described in Appen-dixes K and L, The Hier -\\narchical Database Model and The Network Data-base Model, respec -\\ntively. Both appendixes are available at www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='da5991fa-3190-4a4b-a4eb-71b5d08fef05', embedding=None, metadata={'page_label': '474', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='474   Part 3     Advanced Design and Implementation\\na primarily top-down approach may be easier. Most companies have standards for systems \\ndevelopment and database design already in place.\\n9-9 Centralized Versus Decentralized Design\\nThe two general approaches to database design (bottom-up and top-down) can be influ -\\nenced by factors such as the scope and size of the system, the company’s management \\nstyle, and the company’s structure (centralized or decentralized). Depending on these \\nfactors, the database design may be based on two very different design philosophies: \\ncentralized and decentralized.\\nCentralized design  is productive when the data component has a relatively small \\nnumber of objects and procedures. The design can be carried out and represented in a \\nfairly simple database. Centralized design is typical of relatively simple, small databases \\nand can be successfully done by a single database administrator or by a small, infor -\\nmal design team. The company operations and the scope of the problem are sufficiently \\nlimited to allow even a single designer to define the problem(s), create the conceptual \\ndesign, verify the conceptual design with the user views, define system processes and \\ndata constraints to ensure the efficacy of the design, and ensure that the design will com -\\nply with all the requirements. (Although centralized design is typical for small compa -\\nnies, do not make the mistake of assuming that it is limited to small companies. Even \\nlarge companies can operate within a relatively simple database environment.) Figure \\n9.15 summarizes the centralized design option. Note that a single conceptual design is \\ncompleted and then validated in the centralized design approach.\\nDecentralized design  might be used when the system’s data component has a con -\\nsiderable number of entities and complex relations on which very complex operations are FIGURE 9.14  TOP-DOWN VS. BOTTOM-UP DESIGN SEQUENCING  \\nB\\no\\nt\\nt\\no\\nm\\nU\\npT\\no\\np\\nD\\no\\nw\\nnConceptual model\\nEntity Entity\\nAttribute Attribute Attribute Attribute\\nEven when a primarily top-down approach is selected, the normalization process that \\nrevises existing table structures is inevitably a bottom-up technique. ER models con -\\nstitute a top-down process even when the selection of attributes and entities can be \\ndescribed as bottom-up. Because both the ER model and normalization techniques \\nform the basis for most designs, the top-down versus bottom-up debate may be based \\non a theoretical distinction rather than an actual difference.Note\\ncentralized design\\nA process by which \\nall database design \\ndecisions are carried \\nout centrally by a \\nsmall group of people. \\nSuitable in a top-down \\ndesign approach \\nwhen the problem \\ndomain is relatively \\nsmall, as in a single unit \\nor department in an \\norganization.\\ndecentralized design\\nA process in which \\nconceptual design \\nmodels subsets of an \\norganization’s database \\nrequirements, which \\nare then aggregated \\ninto a complete design. \\nSuch modular designs \\nare typical of complex \\nsystems with a relatively \\nlarge number of objects \\nand procedures.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='578d70e9-532e-4285-b5f3-a2a041f8c039', embedding=None, metadata={'page_label': '475', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    475\\nperformed. Decentralized design is also often used when the problem itself is spread across \\nseveral operational sites and each element is a subset of the entire data set. (See Figure 9.16.)\\nIn large and complex projects, the database typically cannot be designed by only one \\nperson. Instead, a carefully selected team of database designers tackles a complex data -\\nbase project. Within the decentralized design framework, the database design task is \\ndivided into several modules. Once the design criteria have been established, the lead \\ndesigner assigns design subsets or modules to design groups within the team.FIGURE 9.15  CENTRALIZED DESIGN  \\nConceptual model\\nUser views System processes Data constraintsConceptual model veriﬁcation\\nData dictionary\\nFIGURE 9.16  DECENTRALIZED DESIGN  \\nData component\\nPurchasing Engineering Manufacturing\\nViews\\nProcesses\\nConstraintsViews\\nProcesses\\nConstraintsViews\\nProcesses\\nConstraints\\nAggregationSubmodule criteria\\nConceptual\\nmodels\\nVeriﬁcation\\nConceptual model\\nData dictionary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7dfc3eaf-e19b-412f-a925-fc5cbef0c18c', embedding=None, metadata={'page_label': '476', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='476   Part 3     Advanced Design and Implementation\\nBecause each design group focuses on modeling a subset of the system, the definition \\nof boundaries and the interrelation among data subsets must be very precise. Each design \\ngroup creates a conceptual data model corresponding to the subset being modeled. Each \\nconceptual model is then verified individually against the user views, processes, and con -\\nstraints for each of the modules. After the verification process has been completed, all \\nmodules are integrated into one conceptual model. Because the data dictionary describes \\nthe characteristics of all objects within the conceptual data model, it plays a vital role in the \\nintegration process. After the subsets have been aggregated into a larger conceptual model, \\nthe lead designer must verify that it still can support all of the required transactions.\\nKeep in mind that the aggregation process requires the designer to create a single \\nmodel in which various aggregation problems must be addressed. (See Figure 9.17.)\\nFIGURE 9.17  SUMMARY OF AGGREGATION PROBLEMS  \\nEntity XSynonyms : Two departments use different names for the same entity.\\nDepartment A\\nEntity X\\nEntity Y\\nEntity X\\nEntity X1 Entity X2EMPLOYEE\\nSECRETARY PILOTLabel used:\\nDepartment BX\\nY\\nHomonyms : Two different entities are addressed by the same label.\\n(Department B uses the label X to describe both entity X and entity Y.)\\nEntity and entity subclass : The entities X1 and X2 are subsets of entity X.\\nExample:\\nName\\nAddress\\nPhoneCommon\\nattributes\\nDepartment A Typing speed\\nClassiﬁcationHours ﬂown\\nLicenseDistinguishing\\nattributes\\nConﬂicting object deﬁnitions : Attributes for the entity PROFESSOR\\nConﬂicting\\ndeﬁnitionsPrimary key:\\nPhone attribute:Payroll Dept.\\nPROF_SSN\\n898-2853Label used:\\nX\\nX\\nDepartment B\\nSystems Dept.\\nPROF_NUM\\n2853\\n• Synonyms and homonyms . Various departments might know the same object by \\ndifferent names (synonyms), or they might use the same name to address different \\nobjects (homonyms). The object can be an entity, an attribute, or a relationship.\\n• Entity and entity subtypes . An entity subtype might be viewed as a separate entity by one \\nor more departments. The designer must integrate such subtypes into a higher-level entity.\\n• Conflicting object definitions . Attributes can be recorded as different types (character, \\nnumeric), or different domains can be defined for the same attribute. Constraint defi -\\nnitions can vary as well. The designer must remove such conflicts from the model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d83fd8c3-2d4e-44f2-b412-384b449681db', embedding=None, metadata={'page_label': '477', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    477\\n• An information system is designed to help transform data into information and to \\nmanage both data and information. Thus, the database is a very important part of the information system. Systems analysis is the process that establishes the need for an information system and its extent. Systems development is the process of creating an information system.\\n•\\n The Systems Development Life Cycle (SDLC) traces the history of an application within the information system. The SDLC can be divided into five phases: planning, analysis, detailed systems design, implementation, and maintenance. The SDLC is an iterative process rather than a sequential process.\\n•\\n The Database Life Cycle (DBLC) describes the history of the database within the infor -\\nmation system. The DBLC is composed of six phases: database initial study, database design, implementation and loading, testing and evaluation, operation, and main-tenance and evolution. Like the SDLC, the DBLC is iterative rather than sequential.\\n•\\n The conceptual portion of the design may be subject to several variations based on two basic design philosophies: bottom-up versus top-down and centralized versus decentralized.Summary\\nbottom-up design\\nboundariescentralized designclustered tablescohesivitycomputer-aided software \\nengineering (CASE)\\nconceptual designdatabase developmentdatabase fragmentDatabase Life Cycle (DBLC)database roledecentralized designdescription of operationsdifferential backupfull backupinformation systemlogical designminimal data rulemodulemodule couplingphysical designscopesystems analysissystems developmentSystems Development  \\nLife Cycle (SDLC)\\ntop-down designtransaction log backupvirtualization\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. What is an information system? What is its purpose?\\n2. How do systems analysis and systems development fit into a discussion about infor -\\nmation systems?\\n3. What does the acronym SDLC mean, and what does an SDLC portray?\\n4. What does the acronym DBLC mean, and what does a DBLC portray?\\n5. Discuss the distinction between centralized and decentralized conceptual database \\ndesign.Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='12c449ca-6c94-4816-9ee7-61b90b06d873', embedding=None, metadata={'page_label': '478', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='478   Part 3    Advanced Design and Implementation\\n6. What is the minimal data rule in conceptual design? Why is it important?\\n7. Discuss the distinction between top-down and bottom-up approaches in database \\ndesign.\\n8. What are business rules? Why are they important to a database designer?\\n9. What is the data dictionary’s function in database design?\\n10. What steps are required in the development of an ER diagram? (Hint : See Table 9.3.)\\n11. List and briefly explain the activities involved in the verification of an ER model.\\n12. What factors are important in a DBMS software selection?\\n13. List and briefly explain the four steps performed during the logical design stage.\\n14. List and briefly explain the three steps performed during the physical design stage.\\n15. What three levels of backup may be used in database recovery management? Briefly describe what each backup level does.\\n1. The ABC Car Service & Repair Centers are owned by the Silent Car Dealership; ABC services and repairs only silent cars. Three ABC centers provide service and repair for the entire state.\\n Each of the three centers is independently managed and operated by a shop manager, a receptionist, and at least eight mechanics. Each center maintains a fully stocked parts inventory.\\n Each center also maintains a manual file system in which each car’s maintenance  \\nhistory is kept: repairs made, parts used, costs, service dates, owner, and so on. Files  \\nare also kept to track inventory, purchasing, billing, employees’ hours, and payroll.\\n Y ou have been contacted by one of the center’s managers to design and implement a computerized database system. Given the preceding information, do the following:\\na.\\n Indicate the most appropriate sequence of activities by labeling each of the  \\nfollowing steps in the correct order. (For example, if you think that “Load  \\nthe database” is the appropriate first step, label it “1. ”)\\n  Normalize the conceptual model.\\n  Obtain a general description of company operations.\\n  Load the database.\\n  Create a description of each system process.\\n  Test the system.\\n  Draw a data flow diagram and system flowcharts.\\n  Create a conceptual model using ER diagrams.\\n Create the application programs.\\n  Interview the mechanics.\\n  Create the file (table) structures.\\n  Interview the shop manager.Problems\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='944ea15c-f19a-45aa-a398-4f369d3cd1c9', embedding=None, metadata={'page_label': '479', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 9    Database Design    479\\nb. Describe the various modules that you believe the system should include.\\nc. How will a data dictionary help you develop the system? Give examples.\\nd. What general (system) recommendations might you make to the shop manager? \\nFor example, if the system will be integrated, what modules will be integrated? What benefits would be derived from such an integrated system? Include several general recommendations.\\ne.\\n What is the best approach to conceptual database design? Why?\\nf. Name and describe at least four reports the system should have. Explain their use. Who will use those reports?\\n2.\\n Suppose that you have been asked to create an information system for a manufac-turing plant that produces nuts and bolts of many shapes, sizes, and functions. What questions would you ask, and how would the answers affect the database design?\\na.\\n What do you envision the SDLC to be?\\nb. What do you envision the DBLC to be?\\n3. Suppose that you perform the same functions noted in Problem 2 for a larger ware-housing operation. How are the two sets of procedures similar? How and why are they different?\\n4.\\n Using the same procedures and concepts employed in Problem 1, how would you create an information system for the Tiny College example in Chapter 4?\\n5.\\n Write the proper sequence of activities for the design of a video rental database. (The initial ERD was shown in Figure 9.9.) The design must support all rental activities, customer payment tracking, and employee work schedules, as well as track which employees checked out the videos to the customers. After you finish writing the design activity sequence, complete the ERD to ensure that the database design can be successfully implemented. (Make sure that the design is normalized properly and that it can support the required transactions.)\\n6.\\n In a construction company, a new system has been in place for a few months and now there is a list of possible changes/updates that need to be done. For each of the changes/updates, specify what type of maintenance needs to be done: (a) corrective, (b) adaptive, and (c) perfective.\\na.\\n An error in the size of one of the fields has been identified and it needs to be updated status field needs to be changed.\\nb.\\n The company is expanding into a new type of service and this will require to enhancing the system with a new set of tables to support this new service and integrate it with the existing data.\\nc.\\n The company has to comply with some government regulations. To do this, it will require adding a couple of fields to the existing system tables.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd740f01-3635-4ee4-8138-642c8dcea783', embedding=None, metadata={'page_label': '480', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='480   Part 3    Advanced Design and Implementation\\n7. Y ou have been assigned to design the database for a new soccer club. Indicate the \\nmost appropriate sequence of activities by labeling each of the following steps in the correct order. (For example, if you think that “Load the database” is the appropriate first step, label it “1. ”)\\n Create the application programs.\\n Create a description of each system process.\\n Test the system.\\n Load the database.\\n Normalize the conceptual model.\\n Interview the soccer club president.\\n Create a conceptual model using ER diagrams.\\n Interview the soccer club director of coaching.\\n Create the file (table) structures.\\n Obtain a general description of the soccer club operations.\\n Draw a data flow diagram and system flowcharts.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='70758321-07a2-4d20-a05f-11e44da0b7be', embedding=None, metadata={'page_label': '481', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 4\\nAdvanced Database Concepts\\n10 Transaction Management and Concurrency Control\\n11\\n12\\n13\\n14Database Performance Tuning and Query Optimization\\nDistributed Database Management Systems\\nBusiness Intelligence and Data Warehouses\\nBig Data Analytics and NoSQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2b706ea2-4f32-4d4f-aa66-bfa36cc794db', embedding=None, metadata={'page_label': '482', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 10\\nTransaction Management and Concurrency Control\\nIn this chapter, you will learn:\\n• About database transactions and their properties\\n• What concurrency control is and what role it plays in maintaining the database’s integrity\\n• What locking methods are and how they work\\n• How stamping methods are used for concurrency control\\n• How optimistic methods are used for concurrency control\\n• How database recovery management is used to maintain database integrity\\nPreviewDatabase transactions reflect real-world transactions that are triggered by events such as \\nbuying a product, registering for a course, or making a deposit into a checking account. Transactions are likely to contain many parts, such as updating a customer’s account, adjusting product inventory, and updating the seller’s accounts receivable. All parts of a transaction must be successfully completed to prevent data integrity problems. Therefore, executing and managing transactions are important database system activities.\\nIn this chapter you will learn about the main properties of database transactions (ato-\\nmicity, consistency, isolation, and durability, plus serializability for concurrent trans-actions). After defining the transaction properties, the chapter shows how SQL can be used to represent transactions, and how transaction logs can ensure the DBMS’s ability to recover transactions.\\nWhen many transactions take place at the same time, they are called concurrent trans-\\nactions . Managing the execution of such transactions is called concurrency control . This \\nchapter discusses some of the problems that can occur with concurrent transactions (lost updates, uncommitted data, and inconsistent retrievals) and the most common algo-rithms for concurrency control: locks, time stamping, and optimistic methods. Finally, you will see how database recovery management can ensure that a database’s contents are restored to a valid consistent state in case of a hardware or software failure.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH10_SaleCo              P\\t P\\t P\\t P CH10_ABC_Markets  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3921234c-9d22-4a6b-8ade-e2a21a2df901', embedding=None, metadata={'page_label': '483', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    483\\n10-1  What Is a Transaction?\\nTo illustrate what transactions are and how they work, use the Ch10_SaleCo database. \\nThe relational diagram for the database is shown in Figure 10.1.\\nAs you examine the relational diagram in Figure 10.1, note the following features:\\n• The design stores the customer balance (CUST_BALANCE) value in the CUSTOMER \\ntable to indicate the total amount owed by the customer. The CUST_BALANCE attri -\\nbute is increased when the customer makes a purchase on credit, and it is decreased \\nwhen the customer makes a payment. Including the current customer account bal -\\nance in the CUSTOMER table makes it easy to write a query to determine the current \\nbalance for any customer and to generate important summaries such as total, average, \\nminimum, and maximum balances.\\n• The ACCT_TRANSACTION table records all customer purchases and payments  \\nto track the details of customer account activity.\\nY ou could change the design of the Ch10_SaleCo database to reflect accounting \\npractice more precisely, but the implementation provided here will enable you to track \\nthe transactions well enough to understand the chapter’s discussions.FIGURE 10.1  THE CH10_SALECO DATABASE RELATIONAL DIAGRAM  \\nAlthough SQL commands illustrate several transaction and concurrency control issues, you \\nshould be able to follow the discussions even if you have not studied Chapter 7, Intro -\\nduction to Structured Query Language (SQL), and Chapter 8, Advanced SQL. If you don’t \\nknow SQL, ignore the SQL commands and focus on the discussions. If you have a working \\nknowledge of SQL, you can use the Ch10_SaleCo database to generate your own SELECT \\nand UPDATE examples and to augment the material in Chapters 7 and 8 by writing your \\nown triggers and stored procedures.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c1138b9d-bc39-4844-943c-4c0118935b32', embedding=None, metadata={'page_label': '484', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='484   Part 4    Advanced Database Concepts\\nTo understand the concept of a transaction, suppose that you sell a product to a customer. \\nFurthermore, suppose that the customer may charge the purchase to his or her account. Given that scenario, your sales transaction consists of at least the following parts:\\n•\\n Y ou must write a new customer invoice.\\n• Y ou must reduce the quantity on hand in the product’s inventory.\\n• Y ou must update the account transactions.\\n• Y ou must update the customer balance.\\nThe preceding sales transaction must be reflected in the database. In database terms, \\na transaction is any action that reads from or writes to a database. A transaction may \\nconsist of the following:\\n• A simple SELECT statement to generate a list of table contents.\\n• A series of related UPDATE statements to change the values of attributes in various \\ntables.\\n• A series of INSERT statements to add rows to one or more tables.\\n• A combination of SELECT, UPDATE, and INSERT statements.\\nThe sales transaction example includes a combination of INSERT and UPDATE \\nstatements.\\nGiven the preceding discussion, you can augment the definition of a transaction. A \\ntransaction is a logical  unit of work that must be entirely completed or entirely aborted; no \\nintermediate states are acceptable. In other words, a multicomponent transaction, such as the previously mentioned sale, must not be partially completed. Updating only the inven-tory or only the accounts receivable is not acceptable. All of the SQL statements in the transaction must be completed successfully. If any of the SQL statements fail, the entire transaction is rolled back to the original database state that existed before the transaction started. A successful transaction changes the database from one consistent state to another. A consistent database state is one in which all data integrity constraints are satisfied.\\nTo ensure consistency of the database, every transaction must begin with the database \\nin a known consistent state. If the database is not in a consistent state, the transaction will yield an inconsistent database that violates its integrity and business rules. For that reason, subject to limitations discussed later, all transactions are controlled and executed by the DBMS to guarantee database integrity.\\nMost real-world database transactions are formed by two or more database requests. \\nA database request is the equivalent of a single SQL statement in an application pro-\\ngram or transaction. For example, if a transaction is composed of two UPDATE state-ments and one INSERT statement, the transaction uses three database requests. In turn, each database request generates several input/output (I/O) operations that read from or write to physical storage media.\\n10-1a  Evaluating Transaction Results\\nNot all transactions update the database. Suppose that you want to examine the CUSTOMER table to determine the current balance for customer number 10016. Such a transaction can be completed by using the following SQL code:\\nSELECT CUST_NUMBER, CUST_BALANCE\\nFROM CUSTOMER\\nWHERE CUST_NUMBER = 10016;\\nAlthough the query does not make any changes in the CUSTOMER table, the SQL \\ncode represents a transaction because it accesses  the database. If the database existed in transaction\\nA sequence of database \\nrequests that accesses the database. A transaction is a logical unit of work; that is, it must be entirely completed or aborted—no intermediate ending states are accepted. All transactions must have the properties of atomicity, consistency, isolation, and durability.\\nconsistent database state\\nA database state in which all data integrity constraints are satisfied.\\ndatabase request\\nThe equivalent of a single SQL statement in an application program or a transaction.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3a86097a-affd-4a73-b8fb-0d67be73d398', embedding=None, metadata={'page_label': '485', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\" Chapter 10    Transaction Management and Concurrency Control    485\\na consistent state before the access, the database remains in a consistent state after the \\naccess because the transaction did not alter the database.\\nRemember that a transaction may consist of a single SQL statement or a collection of \\nrelated SQL statements. Revisit the previous sales example to illustrate a more complex \\ntransaction, using the Ch10_SaleCo database. Suppose that on January 18, 2016, you \\nregister the credit sale of one unit of product 89-WRE-Q to customer 10016 for $277.55. \\nThe required transaction affects the INVOICE, LINE, PRODUCT, CUSTOMER, and \\nACCT_TRANSACTION tables. The SQL statements that represent this transaction are \\nas follows:\\nINSERT INTO INVOICE\\nV ALUES (1009, 10016,'18-Jan-2016', 256.99, 20.56, 277.55, 'cred', 0.00, 277.55);\\nINSERT INTO LINE\\nV ALUES (1009, 1, '89-WRE-Q', 1, 256.99, 256.99);\\nUPDATE PRODUCT\\nSET PROD_QOH = PROD_QOH – 1\\nWHERE PROD_CODE = '89-WRE-Q';\\nUPDATE CUSTOMER\\nSET CUST_BALANCE = CUST_BALANCE + 277.55\\nWHERE CUST_NUMBER = 10016;\\nINSERT INTO ACCT_TRANSACTION\\nV ALUES (10007, '18-Jan-16', 10016, 'charge', 277.55);\\nCOMMIT;\\nThe results of the successfully completed transaction are shown in Figure 10.2. \\n(All records involved in the transaction are outlined in red.)\\nFIGURE 10.2  TRACING THE TRANSACTION IN THE CH10_SALECO DATABASE  \\nTable name: PRODUCTTable name: INVOICE Table name: LINEDatabase name: Ch10_SaleCo\\nTable name: ACCT_TRANSACTION Table name: CUSTOMER\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='90254981-fc79-40e7-8228-b835559376bc', embedding=None, metadata={'page_label': '486', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"486   Part 4    Advanced Database Concepts\\nTo better understand the transaction results, note the following:\\n• A new row 1009 was added to the INVOICE table. In this row, derived attribute values \\nwere stored for the invoice subtotal, the tax, the invoice total, and the invoice balance.\\n• The LINE row for invoice 1009 was added to reflect the purchase of one unit of prod-uct 89-WRE-Q with a price of $256.99. In this row, the derived attribute values for the line amount were stored.\\n•\\n Product 89-WRE-Q’s quantity on hand (PROD_QOH) in the PRODUCT table was reduced by one, from 12 to 11.\\n•\\n The customer balance (CUST_BALANCE) for customer 10016 was updated by adding $277.55 to the existing balance (the initial value was $0.00).\\n•\\n A new row was added to the ACCT_TRANSACTION table to reflect the new account transaction number 10007.\\n•\\n The COMMIT statement was used to end a successful transaction. (See Section 10-1c.)\\nNow suppose that the DBMS completes the first three SQL statements. Further -\\nmore, suppose that during the execution of the fourth statement (the UPDATE of the  \\nCUSTOMER table’s CUST_BALANCE value for customer 10016), the computer system loses electrical power. If the computer does not have a backup power supply, the transaction  \\ncannot be completed. Therefore, the INVOICE and LINE rows were added, and the PROD-UCT table was updated to represent the sale of product 89-WRE-Q, but customer 10016 was not charged, nor was the required record written in the ACCT_TRANSACTION table. The database is now in an inconsistent state, and it is not usable for subsequent transac -\\ntions. Assuming that the DBMS supports transaction management, the DBMS will roll back the database to a previous consistent state .\\nAlthough the DBMS is designed to recover a database to a previous consistent \\nBy default, MS Access does not support transaction management as discussed here. More sophisticated DBMSs, such as Oracle, SQL Server, and DB2, support the transaction man-agement components discussed in this chapter. MS Access supports transaction manage -\\nment though specialized application programing interfaces (API) such as the Workspace or the DBEngine objects of the Data Access Objects (DAO) database middleware (see Chapter 15, Database Connectivity and Web Technologies for more information.)Note\\nstate when an interruption prevents the completion of a transaction, the transaction itself is defined by the end user or programmer and must be semantically correct. The DBMS cannot guarantee that the semantic meaning of the transaction truly represents the real-world event. For example, suppose that following the sale of 10 units of product 89-WRE-Q, the inventory UPDATE commands were written this way:\\nUPDATE PRODUCT\\nSET PROD_QOH = PROD_QOH + 10\\nWHERE PROD_CODE = '89-WRE-Q';\\nThe sale should have decreased  the PROD_QOH value for product 89-WRE-Q by 10. \\nInstead, the UPDATE added  10 to product 89-WRE-Q’s PROD_QOH value.\\nAlthough the UPDATE command’s syntax is correct, its use yields incorrect results, \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='03956e71-bea1-42ed-8c31-8d86a0da0694', embedding=None, metadata={'page_label': '487', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    487\\nthat is, a database inconsistent with the real-world event. Y et, the DBMS will execute the \\ntransaction anyway. The DBMS cannot evaluate whether the transaction represents the real-world event correctly; that is the end user’s responsibility. End users and program-mers are capable of introducing many errors in this fashion. Imagine the consequences of reducing the quantity on hand for product 1546-QQ2 instead of product 89-WRE-Q or of crediting the CUST_BALANCE value for customer 10012 rather than customer 10016.\\nClearly, improper or incomplete transactions can have a devastating effect on \\ndatabase integrity. Some DBMSs—especially  the relational variety—provide means \\nby which the user can define enforceable constraints based on business rules. Other integrity rules, such as those governing referential and entity integrity, are enforced automatically by the DBMS when the table structures are properly defined, thereby letting the DBMS validate some transactions. For example, if a transaction inserts a new customer number into a customer table and the number already exists, the DBMS will end the transaction with an error code to indicate a violation of the primary key integrity rule.\\n10-1b  Transaction Properties\\nEach individual transaction must display atomicity , consistency , isolation , and durability . \\nThese four properties are sometimes referred to as the ACID test. Let’s look briefly at each of the properties.\\n•\\n Atomicity requires that all  operations (SQL requests) of a transaction be completed; \\nif not, the transaction is aborted. If a transaction T1 has four SQL requests, all four \\nrequests must be successfully completed; otherwise, the entire transaction is aborted. In other words, a transaction is treated as a single, indivisible, logical unit of work.\\n•\\n Consistency indicates the permanence of the database’s consistent state. A trans-action takes a database from one consistent state to another. When a transaction is completed, the database must be in a consistent state. If any of the transaction parts violates an integrity constraint, the entire transaction is aborted.\\n•\\n Isolation means that the data used during the execution of a transaction cannot be used by a second transaction until the first one is completed. In other words, if trans-action T1 is being executed and is using the data item X, that data item cannot be accessed by any other transaction (T2 … Tn) until T1 ends. This property is particu-larly useful in multiuser database environments because several users can access and update the database at the same time.\\n•\\n Durability ensures that once transaction changes are done and committed, they can-not be undone or lost, even in the event of a system failure.\\nIn addition to the individual transaction properties indicated above, there is another \\nimportant property that applies when executing multiple transactions concurrently. For example, let’s assume that the DBMS has three transactions (T1, T2 and T3) executing at the same time. To properly carry out transactions, the DBMS must schedule the concur -\\nrent execution of the transaction’s operations. In this case, each individual transaction must comply with the ACID properties and, at the same time, the schedule of such mul-tiple transaction operations must exhibit the property of serializability. Serializability ensures that the schedule for the concurrent execution of the transactions yields consis-tent results. This property is important in multiuser and distributed databases in which multiple transactions are likely to be executed concurrently. Naturally, if only a single transaction is executed, serializability is not an issue.atomicity\\nThe transaction property that requires all parts of a transaction to be treated as a single, indivisible, logical unit of work. All parts of a transaction must be completed or the entire transaction is aborted.\\nconsistency\\nA database condition in which all data integrity constraints are satisfied. To ensure consistency of a database, every transaction must begin with the database in a known consistent state. If not, the transaction will yield an inconsistent database that violates its integrity and business rules.\\nisolation\\nA database transaction property in which a data item used by one transaction is not available to other transactions until the first one ends.\\ndurability\\nThe transaction property that ensures that once transaction changes are done and committed, they cannot be undone or lost, even in the event of a system failure.\\nserializability\\nA property in which the selected order of concurrent transaction operations creates the same final database state that would have been produced if the transactions had been executed in a serial fashion.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='52cb9d45-479a-4f2d-924d-656dbbf3c726', embedding=None, metadata={'page_label': '488', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"488   Part 4    Advanced Database Concepts\\nA single-user database system automatically ensures serializability and isolation of \\nthe database because only one transaction is executed at a time. The atomicity, consis-\\ntency, and durability of transactions must be guaranteed by single-user DBMSs. (Even a single-user DBMS must manage recovery from errors created by OS-induced interrup-tions, power interruptions, and abnormal application terminations or crashes.)\\nMultiuser databases are typically subject to multiple concurrent transactions. There-\\nfore, the multiuser DBMS must implement controls to ensure serializability and isolation of transactions—in addition to atomicity and durability—to guard the database’s consis-tency and integrity. For example, if several concurrent transactions are executed over the same data set and the second transaction updates the database before the first transac-tion is finished, the isolation property is violated and the database is no longer consistent. The DBMS must manage the transactions by using concurrency control techniques to avoid undesirable situations.\\n10-1c  Transaction Management with SQL\\nThe American National Standards Institute (ANSI) has defined standards that govern SQL database transactions. Transaction support is provided by two SQL statements: COMMIT and ROLLBACK. The ANSI standards require that when a transaction sequence is initiated by a user or an application program, the sequence must continue through all succeeding SQL statements until one of the following four events occurs:\\n•\\n A COMMIT statement is reached, in which case all changes are permanently recorded \\nwithin the database. The COMMIT statement automatically ends the SQL transaction.\\n• A ROLLBACK statement is reached, in which case all changes are aborted and the database is rolled back to its previous consistent state.\\n•\\n The end of a program is successfully reached, in which case all changes are perma-nently recorded within the database. This action is equivalent to COMMIT.\\n•\\n The program is abnormally terminated, in which case the database changes are aborted and the database is rolled back to its previous consistent state. This action is equivalent to ROLLBACK.\\nThe use of COMMIT is illustrated in the following simplified sales example, which \\nupdates a product’s quantity on hand (PROD_QOH) and the customer’s balance when the customer buys two units of product 1558-QW1 priced at $43.99 per unit (for a total of $87.98) and charges the purchase to the customer’s account:\\nUPDATE PRODUCT\\nSET PROD_QOH = PROD_QOH – 2\\nWHERE PROD_CODE = '1558-QW1';UPDATE CUSTOMERSET CUST_BALANCE = CUST_BALANCE + 87.98\\nWHERE CUST_NUMBER = '10011';COMMIT;\\n(Note that the example is simplified to make it easy to trace the transaction. In the \\nCh10_SaleCo database, the transaction would involve several additional table updates.)\\nThe COMMIT statement used in the preceding example is not necessary if the \\nUPDATE statement is the application’s last action and the application terminates nor -\\nmally. However, good programming practice dictates that you include the COMMIT \\nstatement at the end of a transaction declaration.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='65a66cfe-c405-4270-8698-4aff3cb50b82', embedding=None, metadata={'page_label': '489', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    489\\nA transaction begins implicitly when the first SQL statement is encountered. Not all \\nSQL implementations follow the ANSI standard; some (such as SQL Server) use trans-\\naction management statements such as the following to indicate the beginning of a new transaction:\\nBEGIN TRANSACTION;\\nOther SQL implementations allow you to assign characteristics for the transactions \\nas parameters to the BEGIN statement. For example, the Oracle RDBMS uses the SET \\nTRANSACTION statement to declare the start of a new transaction and its properties.\\n10-1d  The Transaction Log\\nA DBMS uses a transaction log to keep track of all transactions that update the data-base. The DBMS uses the information stored in this log for a recovery requirement triggered by a ROLLBACK statement, a program’s abnormal termination, or a system failure such as a network discrepancy or a disk crash. Some RDBMSs use the trans-action log to recover a database forward  to a currently consistent state. After a server \\nfailure, for example, Oracle automatically rolls back uncommitted transactions and rolls forward transactions that were committed but not yet written to the physical database. This behavior is required for transactional correctness and is typical of any transactional DBMS.\\nWhile the DBMS executes transactions that modify the database, it also automatically \\nupdates the transaction log. The transaction log stores the following:\\n•\\n A record for the beginning of the transaction.\\n• For each transaction component (SQL statement):\\n –The type of operation being performed (INSERT, UPDATE, DELETE).\\n –The names of the objects affected by the transaction (the name of the table).\\n –The “before” and “after” values for the fields being updated.\\n –Pointers to the previous and next transaction log entries for the same transaction.\\n• The ending (COMMIT) of the transaction.\\nAlthough using a transaction log increases the processing overhead of a DBMS, the \\nability to restore a corrupted database is worth the price.\\nTable 10.1 illustrates a simplified transaction log that reflects a basic transaction \\ncomposed of two SQL UPDATE statements. If a system failure occurs, the DBMS will \\nexamine the transaction log for all uncommitted or incomplete transactions and restore (ROLLBACK) the database to its previous state on the basis of that information. When the recovery process is completed, the DBMS will write in the log all committed transac-tions that were not physically written to the database before the failure occurred.\\nIf a ROLLBACK is issued before the termination of a transaction, the DBMS will \\nrestore the database only for that particular transaction, rather than for all of them, to maintain the durability  of the previous transactions. In other words, committed transac-\\ntions are not rolled back.\\nThe transaction log is a critical part of the database, and it is usually implemented as \\none or more files that are managed separately from the actual database files. The trans-action log is subject to common dangers such as disk-full conditions and disk crashes. Because the transaction log contains some of the most critical data in a DBMS, some implementations support logs on several different disks to reduce the consequences  \\nof a system failure. transaction log\\nA feature used by the DBMS to keep track of all transaction operations that update the database. The information stored in this log is used by the DBMS for recovery purposes.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8bd5ce1e-fdde-46ad-81cf-da615f9ae1b1', embedding=None, metadata={'page_label': '490', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='490   Part 4    Advanced Database Concepts\\n10-2  Concurrency Control\\nCoordinating the simultaneous execution of transactions in a multiuser database system \\nis known as concurrency control. The objective of concurrency control is to ensure the serializability of transactions in a multiuser database environment. To achieve this goal, most concurrency control techniques are oriented toward preserving the isolation prop-erty of concurrently executing transactions. Concurrency control is important because the simultaneous execution of transactions over a shared database can create several data integrity and consistency problems. The three main problems are lost updates, uncom-mitted data, and inconsistent retrievals.\\n10-2a  Lost Updates\\nThe lost update problem occurs when two concurrent transactions, T1 and T2, are \\nupdating the same data element and one of the updates is lost (overwritten by the other transaction). To see an illustration of lost updates, examine a simple PROD-UCT table. One of the table’s attributes is a product’s quantity on hand (PROD_QOH). Assume that you have a product whose current PROD_QOH value is 35. Also assume that two concurrent transactions, T1 and T2, occur and update the PROD_QOH value for some item in the PRODUCT table. The transactions are shown in Table 10.2.\\nTABLE 10.2\\nTWO CONCURRENT TRANSACTIONS TO UPDATE QOH\\nTRANSACTION COMPUTATION\\nT1: Purchase 100 units PROD_QOH = PROD_QOH + 100\\nT2: Sell 30 units PROD_QOH = PROD_QOH − 30TABLE 10.1\\nA TRANSACTION LOG\\nTRL_IDTRX_NUMPREV PTRNEXT PTROPERATION TABLE ROW ID ATTRIBUTE BEFORE \\nVALUEAFTER VALUE\\n341 101 Null 352 START ****Start \\nTransaction\\n352 101 341 363 UPDATE PRODUCT 1558-QW1 PROD_QOH 25 23\\n363 101 352 365 UPDATE CUSTOMER 10011 CUST_ \\nBALANCE525.75 615.73\\n365 101 363 Null COMMIT **** End of \\nTransaction\\nTRL_ID = Transaction log record ID\\nTRX_NUM = Transaction numberPTR = Pointer to a transaction log record ID\\n(Note: The transaction number is automatically assigned by the DBMS.)\\nconcurrency control\\nA DBMS feature that coordinates the simultaneous execution of transactions in a multiprocessing database system while preserving data integrity.\\nlost update\\nA concurrency control problem in which a data update is lost during the concurrent execution of transactions.\\nTable 10.3 shows the serial execution of the transactions under normal circumstances, \\nyielding the correct answer PROD_QOH = 105.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0bd42038-42b2-4526-bb51-aa84930ea6dc', embedding=None, metadata={'page_label': '491', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    491\\nHowever, suppose that a transaction can read a product’s PROD_QOH value from \\nthe table before  a previous transaction has been committed, using the same  product. The \\nsequence depicted in Table 10.4 shows how the lost update problem can arise. Note that \\nthe first transaction (T1) has not yet been committed when the second transaction (T2) is executed. Therefore, T2 still operates on the value 35, and its subtraction yields 5 in memory. In the meantime, T1 writes the value 135 to disk, which is promptly overwrit-ten by T2. In short, the addition of 100 units is “lost” during the process.TABLE 10.3\\nSERIAL EXECUTION OF TWO TRANSACTIONS\\nTIME TRANSACTION STEP STORED VALUE\\n1 T1 Read PROD_QOH 35\\n2 T1 PROD_QOH = 35 + 100\\n3 T1 Write PROD_QOH 135\\n4 T2 Read PROD_QOH 135\\n5 T2 PROD_QOH = 135 − 30\\n6 T2 Write PROD_QOH 105\\nTABLE 10.4\\nLOST UPDATES\\nTIME TRANSACTION STEP STORED VALUE\\n1 T1 Read PROD_QOH 35\\n2 T2 Read PROD_QOH 35\\n3 T1 PROD_QOH = 35 + 100\\n4 T2 PROD_QOH = 35 − 30\\n5 T1 Write PROD_QOH (lost update) 135\\n6 T2 Write PROD_QOH 5\\nTABLE 10.5\\nTRANSACTIONS CREATING AN UNCOMMITTED DATA PROBLEM\\nTRANSACTION COMPUTATION\\nT1: Purchase 100 units PROD_QOH = PROD_QOH + 100 (Rolled back)\\nT2: Sell 30 units PROD_QOH = PROD_QOH − 30uncommitted data\\nA concurrency control problem in which a transaction accesses uncommitted data from another transaction.10-2b  Uncommitted Data\\nThe phenomenon of uncommitted data occurs when two transactions, T1 and T2, are executed concurrently and the first transaction (T1) is rolled back after the second transaction (T2) has already accessed the uncommitted data—thus violating the iso-lation property of transactions. To illustrate that possibility, use the same transactions described during the lost updates discussion. T1 has two atomic parts, one of which is the update of the inventory; the other possible part is the update of the invoice total (not shown). T1 is forced to roll back due to an error during the updating of the invoice’s total; it rolls back all the way, undoing the inventory update as well. This time the T1 transac-tion is rolled back to eliminate the addition of the 100 units. (See Table 10.5.) Because T2 subtracts 30 from the original 35 units, the correct answer should be 5.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6650808-7154-4a94-a809-6cb5337609f3', embedding=None, metadata={'page_label': '492', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='492   Part 4    Advanced Database Concepts\\nTable 10.6 shows how the serial execution of these transactions yields the correct \\nanswer under normal circumstances.\\nTable 10.7 shows how the uncommitted data problem can arise when the ROLLBACK \\nis completed after T2 has begun its execution.TABLE 10.6\\nCORRECT EXECUTION OF TWO TRANSACTIONS\\nTIME TRANSACTION STEP STORED VALUE\\n1 T1 Read PROD_QOH 35\\n2 T1 PROD_QOH = 35 + 100\\n3 T1 Write PROD_QOH 135\\n4 T1 *****ROLLBACK ***** 35\\n5 T2 Read PROD_QOH 35\\n6 T2 PROD_QOH = 35 − 30\\n7 T2 Write PROD_QOH 5\\nTABLE 10.7\\nAN UNCOMMITTED DATA PROBLEM\\nTIME TRANSACTION STEP STORED VALUE\\n1 T1 Read PROD_QOH 35\\n2 T1 PROD_QOH = 35 + 100\\n3 T1 Write PROD_QOH 135\\n4 T2 Read PROD_QOH (Read uncommitted data) 135\\n5 T2 PROD_QOH = 135 − 30\\n6 T1 ***** ROLLBACK ***** 35\\n7 T2 Write PROD_QOH 105\\n10-2c  Inconsistent Retrievals\\nInconsistent retrievals occur when a transaction accesses data before and after one or \\nmore other transactions finish working with such data. For example, an inconsistent retrieval would occur if transaction T1 calculated some summary (aggregate) function over a set of data while another transaction (T2) was updating the same data. The prob-lem is that the transaction might read some data before it is changed and other data after  \\nit is changed, thereby yielding inconsistent results.\\nTo illustrate the problem, assume the following conditions:\\n1.\\n T1 calculates the total quantity on hand of the products stored in the PRODUCT table.\\n2.\\n At the same time, T2 updates the quantity on hand (PROD_QOH) for two of the PRODUCT table’s products.\\nThe two transactions are shown in Table 10.8.inconsistent retrievals\\nA concurrency control problem that arises when a transaction-calculating summary (aggregate) functions over a set of data while other transactions are updating the data, yielding erroneous results.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3a339fc-5543-4435-a7ff-1ed6116527a5', embedding=None, metadata={'page_label': '493', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    493\\nWhile T1 calculates the total quantity on hand (PROD_QOH) for all items, T2 rep-\\nresents the correction of a typing error: the user added 10 units to product 1558-QW1’s \\nPROD_QOH but meant to add the 10 units to product 1546-QQ2’s PROD_QOH. To correct the problem, the user adds 10 to product 1546-QQ2’s PROD_QOH and sub-tracts 10 from product 1558-QW1’s PROD_QOH. (See the two UPDATE statements in Table 10.8.) The initial and final PROD_QOH values are reflected in Table 10.9. (Only a few PROD_CODE values are shown for the PRODUCT table. To illustrate the point, the sum for the PROD_QOH values is shown for these few products.)\\nAlthough the final results shown in Table 10.9 are correct after the adjustment, Table \\n10.10 demonstrates that inconsistent retrievals are possible during the transaction execu-tion, making the result of T1’s execution incorrect. The “ After” summation shown in Table 10.10 reflects that the value of 25 for product 1546-QQ2 was read after  the WRITE state-\\nment was completed. Therefore, the “ After” total is 40 + 25 = 65. The “Before” total reflects that the value of 23 for product 1558-QW1 was read before  the next WRITE statement was \\ncompleted to reflect the corrected update of 13. Therefore, the “Before” total is 65 + 23 = 88.\\nThe computed answer of 102 is obviously wrong because you know from Table 10.9 \\nthat the correct answer is 92. Unless the DBMS exercises concurrency control, a multiuser database environment can create havoc within the information system.\\n10-2d  The Scheduler\\nY ou now know that severe problems can arise when two or more concurrent transactions are executed. Y ou also know that a database transaction involves a series of database I/O operations that take the database from one consistent state to another. Finally, you know TABLE 10.8\\nRETRIEVAL DURING UPDATE\\nTRANSACTION T1 TRANSACTION T2\\nSELECT SUM(PROD_QOH) FROM PRODUCT UPDATE PRODUCTSET PROD_QOH = PROD_QOH + 10WHERE PROD_CODE = 1546-QQ2\\nUPDATE PRODUCT\\nSET PROD_QOH = PROD_QOH − 10WHERE PROD_CODE = 1558-QW1\\nCOMMIT;\\nTABLE 10.9\\nTRANSACTION RESUL TS: DATA ENTRY CORRECTION\\nBEFORE AFTER\\nPROD_CODE PROD_QOH PROD_QOH\\n11QER/31 8 8\\n13-Q2/P2 32 32\\n1546-QQ2 15 (15 + 10)    25\\n1558-QW1 23 (23 − 10)    13\\n2232-QTY 8 8\\n2232-QWE 6 6\\nTotal 92 92\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ae1a48e8-c0d2-485b-a843-25b7aec284e2', embedding=None, metadata={'page_label': '494', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"494   Part 4    Advanced Database Concepts\\nthat database consistency can be ensured only before and after the execution of transac-\\ntions. A database always moves through an unavoidable temporary state of inconsistency during a transaction’s execution if such a transaction updates multiple tables and rows. (If the transaction contains only one update, then there is no temporary inconsistency.) The temporary inconsistency exists because a computer executes the operations serially, one after another. During this serial process, the isolation property of transactions pre-vents them from accessing the data not yet released by other transactions. This consider -\\nation is even more important today, with the use of multicore processors that can execute several instructions at the same time. What would happen if two transactions executed concurrently and they were accessing the same data?\\nIn previous examples, the operations within a transaction were executed in an arbi-\\ntrary order. As long as two transactions, T1 and T2, access unrelated  data, there is no \\nconflict and the order of execution is irrelevant to the final outcome. However, if the transactions operate on related data or the same data, conflict is possible among the transaction components and the selection of one execution order over another might have some undesirable consequences. So, how is the correct order determined, and who determines that order? Fortunately, the DBMS handles that tricky assignment by using a built-in scheduler.\\nThe scheduler is a special DBMS process that establishes the order in which the oper -\\nations are executed within concurrent transactions. The scheduler interleaves  the exe-\\ncution of database operations to ensure serializability and isolation of transactions. To determine the appropriate order, the scheduler bases its actions on concurrency control algorithms, such as locking or time stamping methods, which are explained in the next sections. However, it is important to understand that not all transactions are serializable. The DBMS determines what transactions are serializable and proceeds to interleave the execution of the transaction’s operations. Generally, transactions that are not serializable are executed on a first-come, first-served basis by the DBMS. The scheduler’s main job is to create a serializable schedule of a transaction’s operations, in which the interleaved execution of the transactions (T1, T2, T3, etc.) yields the same results as if the transac-tions were executed in serial order (one after another).TABLE 10.10\\nINCONSISTENT RETRIEVALS\\nTIME TRANSACTION ACTION VALUE TOTAL\\n1 T1 Read PROD_QOH for PROD_CODE = '11QER/31' 8 8\\n2 T1 Read PROD_QOH for PROD_CODE = '13-Q2/P2' 32 40\\n3 T2 Read PROD_QOH for PROD_CODE = '1546-QQ2' 15\\n4 T2 PROD_QOH = 15 + 10\\n5 T2 Write PROD_QOH for PROD_CODE = '1546-QQ2' 25\\n6 T1 Read PROD_QOH for PROD_CODE = '1546-QQ2' 25 (After) 65\\n7 T1 Read PROD_QOH for PROD_CODE = '1558-QW1' 23 (Before) 88\\n8 T2 Read PROD_QOH for PROD_CODE = '1558-QW1' 23\\n9 T2 PROD_QOH = 23 − 10\\n10 T2 Write PROD_QOH for PROD_CODE = '1558-QW1' 13\\n11 T2 ***** COMMIT *****\\n12 T1 Read PROD_QOH for PROD_CODE = '2232-QTY' 8 96\\n13 T1 Read PROD_QOH for PROD_CODE = '2232-QWE' 6 102\\nscheduler\\nThe DBMS component that establishes the order in which concurrent transaction operations are executed. The scheduler interleaves the execution of database operations in a specific sequence to ensure serializability.\\nserializable schedule\\nIn transaction management, a schedule of operations in which the interleaved execution of the transactions yields the same result as if they were executed in serial order.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9483a53-adf9-494c-a40b-f56c719ae465', embedding=None, metadata={'page_label': '495', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    495\\nThe scheduler also makes sure that the computer’s central processing unit (CPU) and \\nstorage systems are used efficiently. If there were no way to schedule the execution of \\ntransactions, all of them would be executed on a first-come, first-served basis. The prob-lem with that approach is that processing time is wasted when the CPU waits for a READ or WRITE operation to finish, thereby losing several CPU cycles. In short, first-come, first-served scheduling tends to yield unacceptable response times within the multiuser DBMS environment. Therefore, some other scheduling method is needed to improve the efficiency of the overall system.\\nAdditionally, the scheduler facilitates data isolation to ensure that two transactions do \\nnot update the same data element at the same time. Database operations might require READ and/or WRITE actions that produce conflicts. For example, Table 10.11 shows the possible conflict scenarios when two transactions, T1 and T2, are executed concurrently over the same data. Note that in Table 10.11, two operations are in conflict when they access the same data and at least one of them is a WRITE operation.\\nSeveral methods have been proposed to schedule the execution of conflicting opera-\\ntions in concurrent transactions. These methods are classified as locking, time stamping, and optimistic. Locking methods, discussed next, are used most frequently.\\n10-3   Concurrency Control with Locking Methods\\nLocking methods are one of the most common techniques used in concurrency control because they facilitate the isolation of data items used in concurrently executing trans-actions. A lock guarantees exclusive use of a data item to a current transaction. In other words, transaction T2 does not have access to a data item that is currently being used by transaction T1. A transaction acquires a lock prior to data access; the lock is released (unlocked) when the transaction is completed so that another transaction can lock the data item for its exclusive use. This series of locking actions assumes that concurrent transactions might attempt to manipulate the same data item at the same time. The use of locks based on the assumption that conflict between transactions is likely is usually referred to as pessimistic locking.\\nRecall from Sections 10-1a and 10-1b that data consistency cannot be guaranteed \\nduring  a transaction; the database might be in a temporary inconsistent state when sev-\\neral updates are executed. Therefore, locks are required to prevent another transaction from reading inconsistent data.\\nMost multiuser DBMSs automatically initiate and enforce locking procedures. All \\nlock information is handled by a lock manager, which is responsible for assigning and policing the locks used by the transactions.lock\\nA device that guarantees unique use of a data item in a particular transaction operation. A transaction requires a lock prior to data access; the lock is released after the operation’s execution to enable other transactions to lock the data item for their own use.\\npessimistic locking\\nThe use of locks based on the assumption that conflict between transactions is likely.\\nlock manager\\nA DBMS component that is responsible for assigning and releasing locks.TABLE 10.11\\nREAD/WRITE CONFLICT SCENARIOS: CONFLICTING DATABASE OPERATIONS MATRIX\\nTRANSACTIONS\\nT1 T2 RESULT\\nOperations Read Read No conflict\\nRead Write Conflict\\nWrite Read Conflict\\nWrite Write Conflict\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2ee93e69-ab3e-4bef-8a2e-0b47df6ef4fe', embedding=None, metadata={'page_label': '496', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='496   Part 4     Advanced Database Concepts\\n10-3a  Lock Granularity\\nLock granularity  indicates the level of lock use. Locking can take place at the following \\nlevels: database, table, page, row, or even field (attribute).\\nDatabase Level  In a database-level lock , the entire database is locked, thus prevent -\\ning the use of any tables in the database by transaction T2 while transaction T1 is being  \\nexecuted. This level of locking is good for batch processes, but it is unsuitable for  \\nmultiuser DBMSs. Y ou can imagine how s-l-o-w data access would be if thousands of \\ntransactions had to wait for the previous transaction to be completed before the next one \\ncould reserve the entire database. Figure 10.3 illustrates the database-level lock; because \\nof it, transactions T1 and T2 cannot access the same database concurrently even when \\nthey use different tables .\\nTable Level  In a table-level lock , the entire table is locked, preventing access to any \\nrow by transaction T2 while transaction T1 is using the table. If a transaction requires \\naccess to several tables, each table may be locked. However, two transactions can access \\nthe same database as long as they access different tables.\\nTable-level locks, while less restrictive than database-level locks, cause traffic jams \\nwhen many transactions are waiting to access the same table. Such a condition is espe -\\ncially irksome if the lock forces a delay when different transactions require access to \\ndifferent parts of the same table—that is, when the transactions would not interfere with \\neach other. Consequently, table-level locks are not suitable for multiuser DBMSs. Figure \\n10.4 illustrates the effect of a table-level lock. Note that transactions T1 and T2 cannot \\naccess the same table even when they try to use different rows; T2 must wait until T1 \\nunlocks the table.lock granularity\\nThe level of lock use. \\nLocking can take place \\nat the following levels: \\ndatabase, table, page, \\nrow, and field (attribute).\\ndatabase-level lock\\nA type of lock that \\nrestricts database access \\nto the owner of the lock \\nand allows only one user \\nat a time to access the \\ndatabase. This lock works \\nfor batch processes but \\nis unsuitable for online \\nmultiuser DBMSs.\\ntable-level lock\\nA locking scheme \\nthat allows only one \\ntransaction at a time \\nto access a table. A \\ntable-level lock locks an \\nentire table, preventing \\naccess to any row by \\ntransaction T2 while \\ntransaction T1 is using \\nthe table.FIGURE 10.3  DATABASE-LEVEL LOCKING SEQUENCE  \\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9Time\\nTable A\\nTable BPayroll Database\\nTransaction 1 (T1)\\n(Update T able A)\\nLock database request\\nLocked OK\\nUnlockedTransaction 2 (T2)\\n(Update Table B)\\nLock database request\\nWAIT\\nLocked OK\\nUnlocked\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3da587e-f9d1-4415-8bff-e521615afd60', embedding=None, metadata={'page_label': '497', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    497\\nPage Level  In a page-level lock , the DBMS locks an entire diskpage. A diskpage , or \\npage , is the equivalent of a diskblock , which can be described as a directly addressable \\nsection of a disk. A page has a fixed size, such as 4K, 8K, or 16K. For example, if you want \\nto write only 73 bytes to a 4K page, the entire 4K page must be read from disk, updated in \\nmemory, and written back to disk. A table can span several pages, and a page can contain \\nseveral rows of one or more tables. Page-level locks are currently the most frequently \\nused locking method for multiuser DBMSs. An example of a page-level lock is shown in \\nFigure 10.5. Note that T1 and T2 access the same table while locking different diskpages. \\nIf T2 requires the use of a row located on a page that is locked by T1, T2 must wait until \\nT1 unlocks the page.\\npage-level lock\\nIn this type of lock, the \\ndatabase management \\nsystem locks an entire \\ndiskpage, or section of \\na disk. A diskpage can \\ncontain data for one or \\nmore rows and from one \\nor more tables.\\ndiskpage (page)\\nIn permanent storage, \\nthe equivalent of a disk \\nblock, which can be \\ndescribed as a directly \\naddressable section of \\na disk. A diskpage has a \\nfixed size, such as 4K, 8K, \\nor 16K.FIGURE 10.4  AN EXAMPLE OF A TABLE-LEVEL LOCK  \\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9TimeTable A Transaction 1 (T1)\\n(Update row 5)\\nLock T able A request\\nLocked OK\\nUnlocked (end of transaction 1)Transaction 2 (T2)\\n(Update row 30)\\nLock T able A request\\nWAIT\\nLocked OK\\nUnlocked\\n(end of transaction 2)Payroll Database\\nFIGURE 10.5  AN EXAMPLE OF A PAGE-LEVEL LOCK  \\nPage 1\\nPage 21\\n2\\n3\\n4\\n5\\n6\\n7Time\\nTable ATransaction 1 (T1)\\n(Update row 1)\\nLock page 1 request\\nLocked OK\\nUnlock page 1\\n(end of transaction)Transaction 2 (T2)\\n(Update rows 5 and 2)\\nLock page 2 request\\nLock page 1 request\\nOK\\nUnlock pages 1 and 2\\n(end of transaction)1\\n2\\n3\\n4\\n5\\n6Locked\\nRow numberPayroll Database\\nOK\\nLockedWAIT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c6ccc84-19c8-4f1d-b9c8-f010525b047d', embedding=None, metadata={'page_label': '498', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='498   Part 4     Advanced Database Concepts\\nRow Level  A row-level lock  is much less restrictive than the locks discussed earlier. \\nThe DBMS allows concurrent transactions to access different rows of the same table even \\nwhen the rows are located on the same page. Although the row-level locking approach \\nimproves the availability of data, its management requires high overhead because a \\nlock exists for each row in a table of the database involved in a conflicting transaction.  \\nModern DBMSs automatically escalate a lock from a row level to a page level when the \\napplication session requests multiple locks on the same page. Figure 10.6 illustrates the \\nuse of a row-level lock.\\nNote in Figure 10.6 that both transactions can execute concurrently, even when the \\nrequested rows are on the same page. T2 must wait only if it requests the same row as T1.\\nField Level  The field-level lock  allows concurrent transactions to access the same row \\nas long as they require the use of different fields (attributes) within that row. Although \\nfield-level locking clearly yields the most flexible multiuser data access, it is rarely imple -\\nmented in a DBMS because it requires an extremely high level of computer overhead and \\nbecause the row-level lock is much more useful in practice.\\n10-3b  Lock Types\\nRegardless of the level of granularity of the lock, the DBMS may use different lock types \\nor modes: binary or shared/exclusive.\\nBinary  A binary lock  has only two states: locked (1) or unlocked (0). If an object such \\nas a database, table, page, or row is locked by a transaction, no other transaction can use \\nthat object. If an object is unlocked, any transaction can lock the object for its use. Every \\ndatabase operation requires that the affected object be locked. As a rule, a transaction \\nmust unlock the object after its termination. Therefore, every transaction requires a lock \\nand unlock operation for each accessed data item. Such operations are automatically \\nmanaged and scheduled by the DBMS; the user does not lock or unlock data items. \\n(Every DBMS has a default-locking mechanism. If the end user wants to override the \\ndefault settings, the LOCK TABLE command and other SQL commands are available for \\nthat purpose.)\\nThe binary locking technique is illustrated in Table 10.12, using the lost update prob -\\nlem you encountered in Table 10.4. Note that the lock and unlock features eliminate FIGURE 10.6  AN EXAMPLE OF A ROW-LEVEL LOCK  \\n1\\n2\\n3\\n4\\n5\\n6Time\\nTable ATransaction 1 (T1)\\n(Update row 1)\\nLock row 1 request\\nOKTransaction 2 (T2)\\n(Update row 2)\\n1\\n2\\n3\\n4\\n5\\n6Lock row 2 request\\nRow numberLocked\\nUnlock row 1\\n(end of transaction)Payroll Database\\nOKLocked\\nUnlock row 2\\n(end of transaction)Page 1\\nPage 2\\nrow-level lock\\nA less restrictive \\ndatabase lock in which \\nthe DBMS allows \\nconcurrent transactions \\nto access different rows \\nof the same table, even \\nwhen the rows are on \\nthe same page.\\nfield-level lock\\nA lock that allows \\nconcurrent transactions \\nto access the same row \\nas long as they require \\nthe use of different fields \\n(attributes) within that \\nrow. This type of lock \\nyields the most flexible \\nmultiuser data access \\nbut requires a high level \\nof computer overhead.\\nbinary lock\\nA lock that has only \\ntwo states: locked  (1) \\nand unlocked  (0). If a \\ndata item is locked by \\na transaction, no other \\ntransaction can use that \\ndata item.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e3566af8-b058-4e32-95f5-19801fbb7332', embedding=None, metadata={'page_label': '499', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    499\\nthe lost update problem because the lock is not released until the WRITE statement \\nis completed. Therefore, a PROD_QOH value cannot be used until it has been prop-erly updated. However, binary locks are now considered too restrictive to yield opti-mal concurrency conditions. For example, the DBMS will not allow two transactions to read the same database object even though neither transaction updates the database and therefore no concurrency problems can occur. Remember from Table 10.11 that concur -\\nrency conflicts occur only when two transactions execute concurrently and one of them updates the database.\\nShared/Exclusive  An exclusive lock exists when access is reserved specifi-\\ncally for the transaction that locked the object. The exclusive lock must be used when the potential for conflict exists (see Table 10.11). A shared lock exists when concurrent transactions are granted read access on the basis of a common lock.  \\nA shared lock produces no conflict as long as all the concurrent transactions are read-only.\\nA shared lock is issued when a transaction wants to read data from the database and \\nno exclusive lock is held on that data item. An exclusive lock is issued when a transaction wants to update (write) a data item and no locks are currently held on that data item by any other transaction. Using the shared/exclusive locking concept, a lock can have three states: unlocked, shared (read), and exclusive (write).\\nAs shown in Table 10.11, two transactions conflict only when at least one is a write \\ntransaction. Because the two read transactions can be safely executed at once, shared locks allow several read transactions to read the same data item concurrently. For exam-ple, if transaction T1 has a shared lock on data item X and transaction T2 wants to read data item X, T2 may also obtain a shared lock on data item X.\\nIf transaction T2 updates data item X, an exclusive lock is required by T2 over data \\nitem X. The exclusive lock is granted if and only if no other locks are held on the data item  (this condition is known as the mutual exclusive rule: only one transaction at a \\ntime can own an exclusive lock on an object.) Therefore, if a shared (or exclusive) lock is already held on data item X by transaction T1, an exclusive lock cannot be granted to transaction T2, and T2 must wait to begin until T1 commits. In other words, a shared lock will always block an exclusive (write) lock; hence, decreasing transaction concurrency.exclusive lock\\nAn exclusive lock is issued when a transaction requests permission to update a data item and no locks are held on that data item by any other transaction. An exclusive lock does not allow other transactions to access the database.\\nshared lock\\nA lock that is issued when a transaction requests permission to read data from a database and no exclusive locks are held on the data by another transaction. A shared lock allows other read-only transactions to access the database.\\nmutual exclusive rule\\nA condition in which only one transaction at a time can own an exclusive lock on the same object.TABLE 10.12\\nAN EXAMPLE OF A BINARY LOCK\\nTIME TRANSACTION STEP STORED VALUE\\n1 T1 Lock PRODUCT\\n2 T1 Read PROD_QOH 15\\n3 T1 PROD_QOH = 15 + 10\\n4 T1 Write PROD_QOH 25\\n5 T1 Unlock PRODUCT\\n6 T2 Lock PRODUCT\\n7 T2 Read PROD_QOH 23\\n8 T2 PROD_QOH = 23 − 10\\n9 T2 Write PROD_QOH 13\\n10 T2 Unlock PRODUCT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='23caf255-d597-490e-873e-440b1e3b973c', embedding=None, metadata={'page_label': '500', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='500   Part 4    Advanced Database Concepts\\nAlthough the use of shared locks renders data access more efficient, a shared/exclu-\\nsive lock schema increases the lock manager’s overhead for several reasons:\\n• The type of lock held must be known before a lock can be granted.\\n• Three lock operations exist: READ_LOCK to check the type of lock, WRITE_LOCK \\nto issue the lock, and UNLOCK to release the lock.\\n• The schema has been enhanced to allow a lock upgrade from shared to exclusive and a lock downgrade from exclusive to shared.\\nAlthough locks prevent serious data inconsistencies, they can lead to two major \\nproblems:\\n•\\n The resulting transaction schedule might not be serializable.\\n• The schedule might create deadlocks. A deadlock occurs when two transactions wait \\nindefinitely for each other to unlock data. A database deadlock, which is similar to traffic gridlock in a big city, is caused when two or more transactions wait for each other to unlock data.\\nFortunately, both problems can be managed: serializability is attained through a locking \\nprotocol known as two-phase locking, and deadlocks can be managed by using deadlock detection and prevention techniques. Those techniques are examined in the next two sections.\\n10-3c  Two-Phase Locking to Ensure Serializability\\nTwo-phase locking (2PL) defines how transactions acquire and relinquish locks. Two-phase locking guarantees serializability, but it does not prevent deadlocks. The two phases are:\\n1.\\n A growing phase, in which a transaction acquires all required locks without unlock-\\ning any data. Once all locks have been acquired, the transaction is in its locked point.\\n2. A shrinking phase, in which a transaction releases all locks and cannot obtain a new lock.\\nThe two-phase locking protocol is governed by the following rules:\\n• Two transactions cannot have conflicting locks.\\n• No unlock operation can precede a lock operation in the same transaction.\\n• No data is affected until all locks are obtained—that is, until the transaction is in its \\nlocked point.\\nFigure 10.7 depicts the two-phase locking protocol.In this example, the transaction first acquires the two locks it needs. When it has the \\ntwo locks, it reaches its locked point. Next, the data is modified to conform to the trans-action’s requirements. Finally, the transaction is completed as it releases all of the locks it acquired in the first phase. Two-phase locking increases the transaction processing cost and might cause additional undesirable effects, such as deadlocks.\\n10-3d  Deadlocks\\nA deadlock occurs when two transactions wait indefinitely for each other to unlock data. For example, a deadlock occurs when two transactions, T1 and T2, exist in the following mode:\\nT1 = access data items X and YT2 = access data items Y and X\\nIf T1 has not unlocked data item Y , T2 cannot begin; if T2 has not unlocked data item \\nX, T1 cannot continue. Consequently, T1 and T2 each wait for the other to unlock the deadlock\\nA condition in which \\ntwo or more transactions wait indefinitely for the other to release the lock on a previously locked data item. Also called deadly embrace.\\ntwo-phase locking (2PL)\\nA set of rules that governs how transactions acquire and relinquish locks. Two-phase locking guarantees serializability, but it does not prevent deadlocks. The two-phase locking protocol is divided into two phases: (1) A growing phase occurs when the transaction acquires the locks it needs without unlocking any existing data locks. Once all locks have been acquired, the transaction is in its locked point. (2) A shrinking phase occurs when the transaction releases all locks and cannot obtain a new lock.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ce781e20-2000-49a1-8226-b8ce7adaa7f6', embedding=None, metadata={'page_label': '501', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    501\\nrequired data item. Such a deadlock is also known as a deadly embrace . Table 10.13 \\ndemonstrates how a deadlock condition is created.\\nThe preceding example used only two concurrent transactions to demonstrate a dead -\\nlock condition. In a real-world DBMS, many more transactions can be executed simulta -\\nneously, thereby increasing the probability of generating deadlocks. Note that deadlocks \\nare possible only when one of the transactions wants to obtain an exclusive lock on a data \\nitem; no deadlock condition can exist among shared  locks.\\nTABLE 10.13\\nHOW A DEADLOCK CONDITION IS CREATED\\nTIME TRANSACTION REPLY LOCK STATUS\\nDATA X DATA Y\\n0 Unlocked Unlocked\\n1 T1:LOCK(X) OK Locked Unlocked\\n2 T2:LOCK(Y) OK Locked Locked\\n3 T1:LOCK(Y) WAIT Locked Locked\\n4 T2:LOCK(X) WAIT Locked Locked\\n5 T1:LOCK(Y) WAIT Locked Locked\\n6 T2:LOCK(X) WAIT Locked Locked\\n7 T1:LOCK(Y) WAIT Locked Locked\\n8 T2:LOCK(X) WAIT Locked Locked\\n9 T1:LOCK(Y) WAIT Locked Locked\\n... .............. ........ ......... ..........\\n... .............. ........ ......... ..........\\n... .............. ........ ......... ..........\\n... .............. ........ ......... .........deadly embrace\\nSee deadlock .FIGURE 10.7  TWO-PHASE LOCKING PROTOCOL  \\nLocked\\npoint\\nAcquire\\nlock\\nAcquire\\nlockRelease\\nlockRelease\\nlock\\nTime\\nStart Operations End\\nGrowing phaseLocked \\nphase Shrinking phase1 2 3 4 5 6 7 8\\nD\\ne\\na\\nd\\nl\\no\\nc\\nk\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='77e523c9-735d-4e22-b17f-c067127d25ab', embedding=None, metadata={'page_label': '502', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='502   Part 4    Advanced Database Concepts\\nThe three basic techniques to control deadlocks are:\\n• Deadlock prevention . A transaction requesting a new lock is aborted when there is \\nthe possibility that a deadlock can occur. If the transaction is aborted, all changes \\nmade by this transaction are rolled back and all locks obtained by the transaction are released. The transaction is then rescheduled for execution. Deadlock prevention works because it avoids the conditions that lead to deadlocking.\\n•\\n Deadlock detection . The DBMS periodically tests the database for deadlocks. If a dead-\\nlock is found, the “victim” transaction is aborted (rolled back and restarted) and the other transaction continues.\\n•\\n Deadlock avoidance . The transaction must obtain all of the locks it needs before it \\ncan be executed. This technique avoids the rolling back of conflicting transactions by requiring that locks be obtained in succession. However, the serial lock assignment required in deadlock avoidance increases action response times.\\nThe choice of which deadlock control method to use depends on the database envi-\\nronment. For example, if the probability of deadlocks is low, deadlock detection is rec-ommended. However, if the probability of deadlocks is high, deadlock prevention is recommended. If response time is not high on the system’s priority list, deadlock avoid-ance might be employed. All current DBMSs support deadlock detection in transac-tional databases, while some DBMSs use a blend of prevention and avoidance techniques for other types of data, such as data warehouses or XML data.\\n10-4   Concurrency Control with Time Stamping Methods\\nThe time stamping approach to scheduling concurrent transactions assigns a global, \\nunique time stamp to each transaction. The time stamp value produces an explicit order in which transactions are submitted to the DBMS. Time stamps must have two proper -\\nties: uniqueness and monotonicity. Uniqueness ensures that no equal time stamp values can exist, and monotonicity\\n1 ensures that time stamp values always increase.\\nAll database operations (read and write) within the same transaction must have \\nthe same time stamp. The DBMS executes conflicting operations in time stamp order, thereby ensuring serializability of the transactions. If two transactions conflict, one is stopped, rolled back, rescheduled, and assigned a new time stamp value.\\nThe disadvantage of the time stamping approach is that each value stored in the data-\\nbase requires two additional time stamp fields: one for the last time the field was read and one for the last update. Time stamping thus increases memory needs and the database’s processing overhead. Time stamping demands a lot of system resources because many transactions might have to be stopped, rescheduled, and restamped.\\n10-4a  Wait/Die and Wound/Wait Schemes\\nTime stamping methods are used to manage concurrent transaction execution. In this section, you will learn about two schemes used to decide which transaction is rolled back and which continues executing: the wait/die scheme and the wound/wait scheme.\\n2 An time stamping\\nIn transaction management, a technique used in scheduling concurrent transactions that assigns a global unique time stamp to each transaction.\\nuniqueness\\nIn concurrency control, a property of time stamping that ensures no equal time stamp values can exist.\\nmonotonicity\\nA quality that ensures that time stamp values always increase. (The time stamping approach to scheduling concurrent transactions assigns a global, unique time stamp to each transaction. The time stamp value produces an explicit order in which transactions are submitted to the DBMS.)\\n1 The term monotonicity  is part of the standard concurrency control vocabulary. The authors’ first introduction \\nto this term and its proper use was in an article written by W . H. Kohler, “ A survey of techniques for synchro -\\nnization and recovery in decentralized computer systems, ” Computer Surveys  3(2), June 1981, pp. 149–283.\\n2 The procedure was first described by R. E. Stearnes and P . M. Lewis II in “System-level concurrency control \\nfor distributed database systems, ” ACM Transactions on Database Systems, No. 2, June 1978, pp. 178–198.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e66a3dc3-9fff-4c56-89e6-4750379f3bee', embedding=None, metadata={'page_label': '503', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    503\\nexample illustrates the difference. Assume that you have two conflicting transactions: T1 \\nand T2, each with a unique time stamp. Suppose that T1 has a time stamp of 11548789 and T2 has a time stamp of 19562545. Y ou can deduce from the time stamps that T1 is the older transaction (the lower time stamp value), and T2 is the newer transaction. Given that scenario, the four possible outcomes are shown in Table 10.14.\\nUsing the wait/die scheme:\\n•\\n If the transaction requesting the lock is the older of the two transactions, it will wait  \\nuntil the other transaction is completed and the locks are released.\\n• If the transaction requesting the lock is the younger of the two transactions, it will die  \\n(roll back) and is rescheduled using the same time stamp.\\nIn short, in the wait/die scheme, the older transaction waits for the younger one to \\ncomplete and release its locks.\\nIn the wound/wait scheme:\\n• If the transaction requesting the lock is the older of the two transactions, it will preempt (wound ) the younger transaction by rolling it back. T1 preempts T2 when \\nT1 rolls back T2. The younger, preempted transaction is rescheduled using the same time stamp.\\n•\\n If the transaction requesting the lock is the younger of the two transactions, it will wait until the other transaction is completed and the locks are released.\\nIn short, in the wound/wait scheme, the older transaction rolls back the younger \\ntransaction and reschedules it.\\nIn both schemes, one of the transactions waits for the other transaction to finish and \\nrelease the locks. However, in many cases, a transaction requests multiple locks. How long does a transaction have to wait for each lock request? Obviously, that scenario can cause some transactions to wait indefinitely, causing a deadlock. To prevent a deadlock, each lock request has an associated time-out value. If the lock is not granted before the time-out expires, the transaction is rolled back.\\n10-5   Concurrency Control with  Optimistic Methods\\nThe optimistic approach is based on the assumption that the majority of database \\noperations do not conflict. The optimistic approach requires neither locking nor time stamping techniques. Instead, a transaction is executed without restrictions until it is wait/die\\nA concurrency control scheme in which an older transaction must wait for the younger transaction to complete and release the locks before requesting the locks itself. Otherwise, the newer transaction dies and is rescheduled.\\nwound/wait\\nA concurrency control scheme in which an older transaction can request the lock, preempt the younger transaction, and reschedule it. Otherwise, the newer transaction waits until the older transaction finishes.\\noptimistic approach\\nIn transaction management, a concurrency control technique based on the assumption that most database operations do not conflict.TABLE 10.14\\nWAIT/DIE AND WOUND/WAIT CONCURRENCY CONTROL SCHEMES\\nTRANSACTION  REQUESTING LOCKTRANSACTION OWNING LOCKWAIT/DIE SCHEME WOUND/WAIT SCHEME\\nT1 (11548789) T2 (19562545) • T1 waits until T2 is completed and T2 releases its locks. • T1 preempts (rolls back) T2.\\n• T2 is rescheduled using the same time stamp.\\nT2 (19562545) T1 (11548789)\\n• T2 dies (rolls back).\\n• T2 is rescheduled using the same time stamp.• T2 waits until T1 is completed and T1 releases its locks.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9086ba18-c18c-4f92-8394-add47a19b64e', embedding=None, metadata={'page_label': '504', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='504   Part 4    Advanced Database Concepts\\ncommitted. Using an optimistic approach, each transaction moves through two or three \\nphases, referred to as read , validation , and write .3\\n• During the read phase , the transaction reads the database, executes the needed com-\\nputations, and makes the updates to a private copy of the database values. All update operations of the transaction are recorded in a temporary update file, which is not accessed by the remaining transactions.\\n•\\n During the validation phase , the transaction is validated to ensure that the changes \\nmade will not affect the integrity and consistency of the database. If the validation test is positive, the transaction goes to the write phase. If the validation test is negative, the transaction is restarted and the changes are discarded.\\n•\\n During the write phase , the changes are permanently applied to the database.\\nThe optimistic approach is acceptable for most read or query database systems that \\nrequire few update transactions. In a heavily used DBMS environment, the manage-ment of deadlocks—their prevention and detection—constitutes an important DBMS function. The DBMS will use one or more of the techniques discussed here, as well as variations on those techniques. To further understand how transaction management is implemented in a database, it is important that you learn about the transaction isolation levels as defined in ANSI SQL 1992 standard.\\n10-6  ANSI Levels of Transaction Isolation\\nThe ANSI SQL standard (1992) defines transaction management based on transaction isolation levels. Transaction isolation levels refer to the degree to which transaction data is “protected or isolated” from other concurrent transactions. The isolation levels are described based on what data other transactions can see (read) during execution. More precisely, the transaction isolation levels are described by the type of “reads” that a trans-action allows or not. The types of read operations are:\\n•\\n Dirty read: a transaction can read data that is not yet committed.\\n• Nonrepeatable read: a transaction reads a given row at time t1, and then it reads \\nthe same row at time t2, yielding different results. The original row may have been updated or deleted.\\n•\\n Phantom read: a transaction executes a query at time t1, and then it runs the same query at time t2, yielding additional rows that satisfy the query.\\nBased on the above operations, ANSI defined four levels of transaction isolation: \\nRead Uncommitted, Read Committed, Repeatable Read, and Serializable. Table 10.15 shows the four ANSI transaction isolation levels. The table also shows an additional level of isolation provided by Oracle and MS SQL Server databases.\\nRead Uncommitted will read uncommitted data from other transactions. At this iso-\\nlation level, the database does not place any locks on the data, which increases transaction performance but at the cost of data consistency. Read Committed forces transactions to read only committed data. This is the default mode of operation for most databases (including Oracle and SQL Server). At this level, the database will use exclusive locks on data, causing other transactions to wait until the original transaction commits. The Repeatable Read isolation level ensures that queries return consistent results. This type of isolation level uses shared locks to ensure other transactions do not update a row after dirty read\\nIn transaction management, when a transaction reads data that is not yet committed.\\nnonrepeatable read\\nIn transaction management, when a transaction reads a given row at time t1, then reads the same row at time t2, yielding different results because the original row may have been updated or deleted.\\nphantom read\\nIn transaction management, when a transaction executes a query at time t1, then runs the same query at time t2, yielding additional rows that satisfy the query.\\nRead Uncommitted\\nAn ANSI SQL transaction isolation level that allows transactions to read uncommitted data from other transactions, and which allows nonrepeatable reads and phantom reads. The least restrictive level defined by ANSI SQL.\\nRead Committed\\nAn ANSI SQL transaction isolation level that allows transactions to read only committed data. This is the default mode of operations for most databases.\\nRepeatable Read\\nAn ANSI SQL transaction isolation level that uses shared locks to ensure that other transactions do not update a row after the original query updates it. However, phantom reads are allowed.\\n3 The optimistic approach to concurrency control is described in an article by H. T. King and J. T. Robinson, \\n“Optimistic methods for concurrency control, ” ACM Transactions on Database Systems 6(2), June 1981,  \\npp. 213–226. Even the most current software is built on conceptual standards that were developed more than \\ntwo decades ago.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='902206d2-8567-44ff-bbec-3d5ef936c823', embedding=None, metadata={'page_label': '505', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    505\\nthe original query reads it. However, new rows are read (phantom read) as these rows \\ndid not exist when the first query ran. The Serializable isolation level is the most restric-tive level defined by the ANSI SQL standard. However, it is important to note that even with a Serializable isolation level, deadlocks are always possible. Most databases use a deadlock detection approach to transaction management, and, therefore, they will detect  \\n“deadlocks” during the transaction validation phase and reschedule the transaction.\\nThe reason for the different levels of isolation is to increase transaction concurrency. \\nThe isolation levels go from the least restrictive (Read Uncommitted) to the more restric-tive (Serializable). The higher the isolation level the more locks (shared and exclusive) are required to improve data consistency, at the expense of transaction concurrency per -\\nformance. The isolation level of a transaction is defined in the transaction statement, for example using general ANSI SQL syntax:\\nBEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED\\n… SQL STATEMENTS….COMMIT TRANSACTION;\\nOracle and MS SQL Server use the SET TRANSACTION ISOLATION LEVEL state-\\nment to define the level of isolation. SQL Server supports all four ANSI isolation levels. Oracle by default provides consistent statement-level reads to ensure Read Committed and Repeatable Read transactions. MySQL uses START TRANSACTION WITH CON-SISTENT SNAPSHOT to provide transactions with consistent reads; that is, the transac-tion can only see the committed data at the time the transaction started.\\nAs you can see from the previous discussion, transaction management is a complex \\nsubject and databases make use of various techniques to manage the concurrent exe-cution of transactions. However, it may be necessary sometimes to employ database recovery techniques to restore the database to a consistent state.\\nSerializable\\nAn ANSI SQL transaction isolation level that does not allow dirty reads, nonrepeatable reads, or phantom reads; the most restrictive level defined by the ANSI SQL standard.TABLE 10.15\\nTRANSACTION ISOLATION LEVELS\\nISOLATION LEVELALLOWED COMMENT\\nDIRTY READNONREPEATABLE READPHANTOM READ\\nLess restrictive\\nMore restrictiveRead Uncommitted Y Y Y The transaction reads \\nuncommitted data, allows nonrepeatable reads, and phantom reads.\\nRead Committed N Y Y Does not allow uncommitted data reads but allows nonrepeatable reads and phantom reads.\\nRepeatable Read N N Y Only allows phantom reads.\\nSerializable N N N Does not allow dirty reads, nonrepeatable reads, or phantom reads.\\nOracle / SQL Server OnlyRead Only / SnapshotN N N Supported by Oracle and SQL Server. The transaction can only see the changes that were committed at the time the transaction started.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2738e232-fc83-4680-88c4-dbf3fd02a859', embedding=None, metadata={'page_label': '506', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='506   Part 4    Advanced Database Concepts\\n10-7  Database Recovery Management\\nDatabase recovery restores a database from a given state (usually inconsistent) to a previ-\\nously consistent state. Recovery techniques are based on the atomic transaction property: all portions of the transaction must be treated as a single, logical unit of work in which all operations are applied and completed to produce a consistent database. If a transaction oper -\\nation cannot be completed for some reason, the transaction must be aborted and any changes to the database must be rolled back (undone). In short, transaction recovery reverses all of the changes that the transaction made to the database before the transaction was aborted.\\nAlthough this chapter has emphasized the recovery of transactions , recovery tech-\\nniques also apply to the database  and to the system  after some type of critical error has \\noccurred. Critical events can cause a database to stop working and compromise the integrity of the data. Examples of critical events are:\\n•\\n Hardware/software failures . A failure of this type could be a hard disk media failure, \\na bad capacitor on a motherboard, or a failing memory bank. Other causes of errors \\nunder this category include application program or operating system errors that cause data to be overwritten, deleted, or lost. Some database administrators argue that this is one of the most common sources of database problems.\\n•\\n Human-caused incidents. This type of event can be categorized as unintentional or intentional.\\n –An unintentional failure is caused by a careless end user. Such errors include  \\ndeleting the wrong rows from a table, pressing the wrong key on the keyboard, or shutting down the main database server by accident.\\n –Intentional events are of a more severe nature and normally indicate that the company data is at serious risk. Under this category are security threats caused by hackers trying to gain unauthorized access to data resources and virus attacks caused by disgruntled employees trying to compromise the database operation and damage the company.\\n•\\n Natural disasters. This category includes fires, earthquakes, floods, and power failures.\\nWhatever the cause, a critical error can render the database into an inconsistent state. \\nThe following section introduces the various techniques used to recover the database from an inconsistent state to a consistent state.\\n10-7a  Transaction Recovery\\nIn Section 10-1d, you learned about the transaction log and how it contains data for database recovery purposes. Database transaction recovery uses data in the transaction log to recover a database from an inconsistent state to a consistent state.\\nBefore continuing, examine four important concepts that affect the recovery process:\\n•\\n The write-ahead-log protocol ensures that transaction logs are always written before  \\nany database data is actually updated. This protocol ensures that, in case of a failure, the database can later be recovered to a consistent state using the data in the transaction log.\\n•\\n Redundant transaction logs (several copies of the transaction log) ensure that a physical disk failure will not impair the DBMS’s ability to recover data.\\n•\\n Database buffers are temporary storage areas in primary memory used to speed up \\ndisk operations. To improve processing time, the DBMS software reads the data from the physical disk and stores a copy of it on a “buffer” in primary memory. When a transaction updates data, it actually updates the copy of the data in the buffer because that process is much faster than accessing the physical disk every time. Later, all buf-fers that contain updated data are written to a physical disk during a single operation, thereby saving significant processing time.database recovery\\nThe process of restoring a database to a previous consistent state.\\natomic transaction property\\nA property that requires all parts of a transaction to be treated as a single, logical unit of work in which all operations must be completed (committed) to produce a consistent database.\\nwrite-ahead-log protocol\\nIn concurrency control, a process that ensures transaction logs are written to permanent storage before any database data is  actually updated. Also called a write-ahead protocol.\\nredundant transaction logs\\nMultiple copies of the transaction log kept by database management systems to ensure that the physical failure of a disk will not impair the DBMS’s ability to recover data.\\nbuffer\\nTemporary storage area in primary memory used to speed up disk operations.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='329ed8d1-2893-4ff1-81fb-200a99e9d10e', embedding=None, metadata={'page_label': '507', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    507\\n• Database checkpoints are operations in which the DBMS writes all of its updated \\nbuffers in memory (also known as dirty buffers) to disk. While this is happening, \\nthe DBMS does not execute any other requests. A checkpoint operation is also reg-istered in the transaction log. As a result of this operation, the physical database and the transaction log will be in sync. This synchronization is required because update operations update the copy of the data in the buffers and not in the physical database. Checkpoints are automatically and periodically executed by the DBMS according to certain operational parameters (such a high watermark for the transaction log size or volume of outstanding transactions) but can also be executed explicitly (as part of a database transaction statement) or implicitly (as part of a database backup operation). Of course, checkpoints that are too frequent would affect transaction performance; checkpoints that are too infrequent would affect database recovery performance. In any case, checkpoints serve a very practical function. As you will see next, check-points also play an important role in transaction recovery.\\nThe database recovery process involves bringing the database to a consistent state \\nafter a failure. Transaction recovery procedures generally make use of deferred-write and write-through techniques.\\nWhen the recovery procedure uses a deferred-write technique (also called a \\ndeferred update), the transaction operations do not immediately update the physical database. Instead, only the transaction log is updated. The database is physically updated only with data from committed transactions, using information from the transaction log. If the transaction aborts before it reaches its commit point, no changes (no ROLLBACK or undo) need to be made to the database because it was never updated. The recovery process for all started and committed transactions (before the failure) follows these steps:\\n1.\\n Identify the last checkpoint in the transaction log. This is the last time transaction \\ndata was physically saved to disk.\\n2. For a transaction that started and was committed before the last checkpoint, nothing needs to be done because the data is already saved.\\n3.\\n For a transaction that performed a commit operation after the last checkpoint, the DBMS uses the transaction log records to redo the transaction and update the database, using the “after” values in the transaction log. The changes are made in ascending order, from oldest to newest.\\n4.\\n For any transaction that had a ROLLBACK operation after the last checkpoint or that was left active (with neither a COMMIT nor a ROLLBACK) before the failure occurred, nothing needs to be done because the database was never updated.\\nWhen the recovery procedure uses a write-through technique (also called an  \\nimmediate update), the database is immediately updated by transaction operations during the transaction’s execution, even before the transaction reaches its commit point. If the trans-action aborts before it reaches its commit point, a ROLLBACK or undo operation needs to be done to restore the database to a consistent state. In that case, the ROLLBACK operation will use the transaction log “before” values. The recovery process follows these steps:\\n1.\\n Identify the last checkpoint in the transaction log. This is the last time transaction \\ndata was physically saved to disk.\\n2. For a transaction that started and was committed before the last checkpoint, nothing needs to be done because the data is already saved.\\n3.\\n For a transaction that was committed after the last checkpoint, the DBMS re-does the transaction, using the “after” values of the transaction log. Changes are applied in ascending order, from oldest to newest.checkpoint\\nIn transaction management, an operation in which the database management system writes all of its updated buffers to disk.\\ndeferred write technique\\nSee deferred update.\\ndeferred update\\nIn transaction management, a condition in which transaction operations do not immediately update a physical database. Also called deferred write technique.\\nwrite-through technique\\nIn concurrency control, a process that ensures a database is immediately updated by operations during the transaction’s execution, even before the transaction reaches its commit point. Also called immediate update.\\nimmediate update\\nSee write-through technique.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2c80e07d-1832-411b-8ba6-4dce1d30403c', embedding=None, metadata={'page_label': '508', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='508   Part 4    Advanced Database Concepts\\n4. For any transaction that had a ROLLBACK operation after the last checkpoint or \\nthat was left active (with neither a COMMIT nor a ROLLBACK) before the failure occurred, the DBMS uses the transaction log records to ROLLBACK or undo the operations, using the “before” values in the transaction log. Changes are applied in reverse order, from newest to oldest.\\nUse the transaction log in Table 10.16 to trace a simple database recovery process. \\nTo make sure you understand the recovery process, the simple transaction log includes three transactions and one checkpoint. This transaction log includes the transaction components used earlier in the chapter, so you should already be familiar with the basic process. Given the transaction, the transaction log has the following characteristics:\\n•\\n Transaction 101 consists of two UPDATE statements that reduce the quantity on \\nhand for product 54778-2T and increase the customer balance for customer 10011 for a credit sale of two units of product 54778-2T.\\n•\\n Transaction 106 is the same credit sales event you saw in Section 10-1a. This transac-tion represents the credit sale of one unit of product 89-WRE-Q to customer 10016 for $277.55. This transaction consists of five SQL DML statements: three INSERT statements and two UPDATE statements.\\n•\\n Transaction 155 represents a simple inventory update. This transaction consists of one UPDATE statement that increases the quantity on hand of product 2232/QWE from 6 units to 26 units.\\n•\\n A database checkpoint writes all updated database buffers to disk. The checkpoint event writes only the changes for all previously committed transactions. In this case, the checkpoint applies all changes made by transaction 101 to the database data files.\\nUsing Table 10.16, you can now trace the database recovery process for a DBMS using \\nthe deferred update method as follows:\\n1.\\n Identify the last checkpoint—in this case, TRL ID 423. This was the last time database \\nbuffers were physically written to disk.\\n2. Note that transaction 101 started and finished before the last checkpoint. Therefore, all changes were already written to disk, and no additional action needs to be taken.\\n3.\\n For each transaction committed after the last checkpoint (TRL ID 423), the DBMS will use the transaction log data to write the changes to disk, using the “after” values. For example, for transaction 106:\\na. Find COMMIT (TRL ID 457).\\nb. Use the previous pointer values to locate the start of the transaction (TRL ID 397).\\nc.\\n Use the next pointer values to locate each DML statement, and apply the changes to disk using the “after” values. (Start with TRL ID 405, then 415, 419, 427, and 431.) Remember that TRL ID 457 was the COMMIT state-ment for this transaction.\\nd.\\n Repeat the process for transaction 155.\\n4. Any other transactions will be ignored. Therefore, for transactions that ended  \\nwith ROLLBACK or that were left active (those that do not end with a COMMIT or ROLLBACK), nothing is done because no changes were written to disk.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='65e25444-809b-4052-ad34-df0cdc314270', embedding=None, metadata={'page_label': '509', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    509TABLE 10.16\\nA TRANSACTION LOG FOR TRANSACTION RECOVERY EXAMPLES\\nTRL ID TRX \\nNUMPREV PTRNEXT PTROPERATION TABLE ROW ID ATTRIBUTE BEFORE \\nVALUEAFTER VALUE\\n341 101 Null 352 START ****Start Transaction\\n352 101 341 363 UPDATE PRODUCT 54778-2T PROD_QOH 45 43\\n363 101 352 365 UPDATE CUSTOMER 10011 CUST_BALANCE 615.73 675.62\\n365 101 363 Null COMMIT **** End of Transaction\\n397 106 Null 405 START ****Start Transaction\\n405 106 397 415 INSERT INVOICE 1009 1009,10016, …\\n415 106 405 419 INSERT LINE 1009,1 1009,1, 89-WRE-Q,1, …\\n419 106 415 427 UPDATE PRODUCT 89-WRE-Q PROD_QOH 12 11\\n423 CHECKPOINT\\n427 106 419 431 UPDATE CUSTOMER 10016 CUST_BALANCE 0.00 277.55\\n431 106 427 457 INSERT ACCT_TRANSACTION 10007 1007,18-JAN-2016, …\\n457 106 431 Null COMMIT **** End of Transaction521 155 Null 525 START ****Start Transaction\\n525 155 521 528 UPDATE PRODUCT 2232/QWE PROD_QOH 6 26\\n528 155 525 Null COMMIT **** End of Transaction\\n* * * * * C *R*A* S* H * * * *\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6f467a79-3f0e-4fde-9468-97e998abe147', embedding=None, metadata={'page_label': '510', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='510   Part 4    Advanced Database Concepts\\nSummary\\n• A transaction is a sequence of database operations that access the database. A trans-\\naction is a logical unit of work; that is, all parts are executed or the transaction is aborted. A transaction takes a database from one consistent state to another. A consis-tent database state is one in which all data integrity constraints are satisfied.\\n•\\n Transactions have four main properties: atomicity, consistency, isolation, and dura-bility. Atomicity means that all parts of the transaction must be executed; otherwise, the transaction is aborted. Consistency means that the database’s consistent state is maintained. Isolation means that data used by one transaction cannot be accessed by another transaction until the first one is completed. Durability means that changes made by a transaction cannot be rolled back once the transaction is committed. In addition, transaction schedules have the property of serializability—the result of the concurrent execution of transactions is the same as that of the transactions being executed in serial order.\\n•\\n SQL provides support for transactions through the use of two statements: COMMIT, which saves changes to disk, and ROLLBACK, which restores the previous database state. SQL transactions are formed by several SQL statements or database requests. Each database request originates several I/O database operations. The transaction log keeps track of all transactions that modify the database. The information stored in the transaction log is used for recovery (ROLLBACK) purposes.\\n•\\n Concurrency control coordinates the simultaneous execution of transactions. The concurrent execution of transactions can result in three main problems: lost updates, uncommitted data, and inconsistent retrievals. The scheduler is responsible for estab-lishing the order in which the concurrent transaction operations are executed. The transaction execution order is critical and ensures database integrity in multiuser database systems. The scheduler uses locking, time stamping, and optimistic methods to ensure the serializability of transactions.\\n•\\n A lock guarantees unique access to a data item by a transaction. The lock prevents one transaction from using the data item while another transaction is using it. There are several levels of locks: database, table, page, row, and field. Two types of locks can be used in database systems: binary locks and shared/exclusive locks. A binary lock can have only two states: locked (1) or unlocked (0). A shared lock is used when a transac-tion wants to read data from a database and no other transaction is updating the same data. Several shared or “read” locks can exist for a particular item. An exclusive lock is issued when a transaction wants to update (write to) the database and no other locks (shared or exclusive) are held on the data.\\n•\\n Serializability of schedules is guaranteed through the use of two-phase locking. The two-phase locking schema has a growing phase, in which the transaction acquires all of the locks that it needs without unlocking any data, and a shrinking phase, in which the transaction releases all of the locks without acquiring new locks. When two or more transactions wait indefinitely for each other to release a lock, they are in a deadlock, also called a deadly embrace. There are three deadlock control techniques: prevention, detection, and avoidance.\\n•\\n Concurrency control with time stamping methods assigns a unique time stamp to each transaction and schedules the execution of conflicting transactions in time stamp order. Two schemes are used to decide which transaction is rolled back and which continues executing: the wait/die scheme and the wound/wait scheme.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f0a2ac9-2a1b-4292-8b6e-c1708e85bbc1', embedding=None, metadata={'page_label': '511', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    511\\n• Concurrency control with optimistic methods assumes that the majority of database \\ntransactions do not conflict and that transactions are executed concurrently, using private, temporary copies of the data. At commit time, the private copies are updated to the database. The ANSI standard defines four transaction isolation levels: Read Uncommitted, Read Committed, Repeatable Read, and Serializable.\\n•\\n Database recovery restores the database from a given state to a previous consistent state. Database recovery is triggered when a critical event occurs, such as a hardware error or application error.\\natomicity\\natomic transaction propertybinary lockbuffercheckpointconcurrency controlconsistencyconsistent database statedatabase-level lockdatabase recoverydatabase requestdeadlockdeadly embracedeferred updatedeferred-write techniquedirty readdiskpagedurabilityexclusive lockfield-level lockimmediate updateinconsistent retrievalisolationlocklock granularitylock managerlost updatemonotonicitymutual exclusive rulenonrepeatable readoptimistic approachpagepage-level lockpessimistic lockingphantom readRead CommittedRead Uncommittedredundant transaction logRepeatable Readrow-level lockschedulerserializabilitySerializableserializable scheduleshared locktable-level locktime stampingtransactiontransaction logtwo-phase locking (2PL)uncommitted datauniquenesswait/diewound/waitwrite-ahead-log protocolwrite-through technique\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\n1. Explain the following statement: A transaction is a logical unit of work.\\n2. What is a consistent database state, and how is it achieved?\\n3. The DBMS does not guarantee that the semantic meaning of the transaction \\ntruly represents the real-world event. What are the possible consequences of that limitation? Give an example.\\n4.\\n List and discuss the four individual transaction properties.\\n5. What does serializability of transactions mean?\\n6. What is a transaction log, and what is its function?Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a4f9d4fc-fda5-428d-8fc7-4bdcf9545809', embedding=None, metadata={'page_label': '512', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='512   Part 4    Advanced Database Concepts\\n7. What is a scheduler, what does it do, and why is its activity important to concurrency \\ncontrol?\\n8. What is a lock, and how does it work in general?\\n9. What are the different levels of lock granularity?\\n10. Why might a page-level lock be preferred over a field-level lock?\\n11. What is concurrency control, and what is its objective?\\n12. What is an exclusive lock, and under what circumstances is it granted?\\n13. What is a deadlock, and how can it be avoided? Discuss several strategies for dealing with deadlocks.\\n14.\\n What are some disadvantages of time stamping methods for concurrency control?\\n15. Why might it take a long time to complete transactions when using an optimistic approach to concurrency control?\\n16.\\n What are the three types of database-critical events that can trigger the database recovery process? Give some examples for each one.\\n17.\\n What are the four ANSI transaction isolation levels? What type of reads does each level allow?\\n1. Suppose that you are a manufacturer of product ABC, which is composed of parts A, B, and C. Each time a new product ABC is created, it must be added to the product inventory, using the PROD_QOH in a table named PRODUCT. Also, each time the product is created, the parts inventory, using PART_QOH in a table named PART, must be reduced by one each of parts A, B, and C. The sample database contents are shown in Table P10.1.Problems\\nTABLE P10.1\\nTABLE NAME: PRODUCT TABLE NAME: PART\\nPROD_CODE PROD_QOH PART_CODE PART_QOH\\nABC 1,205 A 567\\nB 98\\nC 549\\nGiven the preceding information, answer Questions a through e.\\na. How many database requests can you identify for an inventory update for both PRODUCT and PART?\\nb.\\n Using SQL, write each database request you identified in Step a.\\nc. Write the complete transaction(s).\\nd. Write the transaction log, using Table 10.1 as your template.\\ne. Using the transaction log you created in Step d, trace its use in database recovery.\\n2. Describe the three most common problems with concurrent transaction execution. Explain how concurrency control can be used to avoid those problems.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c8de8b13-19f6-4500-891e-b608c31a0d5c', embedding=None, metadata={'page_label': '513', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 10    Transaction Management and Concurrency Control    513\\n3. What DBMS component is responsible for concurrency control? How is this \\nfeature used to resolve conflicts?\\n4. Using a simple example, explain the use of binary and shared/exclusive locks \\nin a DBMS.\\n5. Suppose that your database system has failed. Describe the database recovery \\nprocess and the use of deferred-write and write-through techniques.\\n6. ABC Markets sell products to customers. The relational diagram shown \\nin Figure P10.6 represents the main entities for ABC’s database. Note the  \\nfollowing important characteristics:\\n• A customer may make many purchases, each one represented by an invoice.\\n• The CUS_BALANCE is updated with each credit purchase or payment and \\nrepresents the amount the customer owes.\\n• The CUS_BALANCE is increased (+) with every credit purchase and decreased \\n(–) with every customer payment.\\n• The date of last purchase is updated with each new purchase made by the customer.\\n• The date of last payment is updated with each new payment made by the customer.\\n• An invoice represents a product purchase by a customer.\\n• An INVOICE can have many invoice LINEs, one for each product purchased.\\n• The INV_TOTAL represents the total cost of the invoice, including taxes.\\n• The INV_TERMS can be “30, ” “60, ” or “90” (representing the number of days \\nof credit) or “CASH, ” “CHECK, ” or “CC. ”\\n• The invoice status can be “OPEN, ” “PAID, ” or “CANCEL. ”\\n• A product’s quantity on hand (P_QTYOH) is updated (decreased) with each \\nproduct sale.The Ch10_ABC_Markets data -\\nbase is available at www.\\ncengagebrain.com . Use this \\ndatabase to provide solutions \\nfor Problems 6–11.Online \\nContent\\nFIGURE P10.6  THE ABC MARKETS RELATIONAL DIAGRAM  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='21c823c8-4edb-4762-bac4-244245c90df7', embedding=None, metadata={'page_label': '514', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='514   Part 4    Advanced Database Concepts\\n• A customer may make many payments. The payment type (PMT_TYPE) can be \\none of the following:\\n• “CASH” for cash payments.\\n• “CHECK” for check payments.\\n• “CC” for credit card payments.\\n• The payment details (PMT_DETAILS) are used to record data about check or \\ncredit card payments:\\n• The bank, account number, and check number for check payments.\\n• The issuer, credit card number, and expiration date for credit card payments.\\nNote : Not all entities and attributes are represented in this example. Use only the attri-\\nbutes indicated.\\n Using this database, write the SQL code to represent each of the following transac-\\ntions. Use BEGIN TRANSACTION and COMMIT to group the SQL statements in logical transactions.\\na.\\n On May 11, 2016, customer 10010 makes a credit purchase (30 days) of one unit of product 11QER/31 with a unit price of $110.00; the tax rate is 8 percent. The invoice number is 10983, and this invoice has only one product line.\\nb.\\n On June 3, 2016, customer 10010 makes a payment of $100 in cash. The payment ID is 3428.\\n7.\\n Create a simple transaction log (using the format shown in Table 10.14) to represent the actions of the transactions in Problems 6a and 6b.\\n8.\\n Assuming that pessimistic locking is being used but the two-phase locking proto-col is not, create a chronological list of the locking, unlocking, and data manipula-tion activities that would occur during the complete processing of the transaction described in Problem 6a.\\n9.\\n Assuming that pessimistic locking is being used with the two-phase locking protocol, create a chronological list of the locking, unlocking, and data manipulation activities that would occur during the complete processing of the transaction described in Problem 6a.\\n10.\\n Assuming that pessimistic locking is being used but the two-phase locking proto-col is not, create a chronological list of the locking, unlocking, and data manipula-tion activities that would occur during the complete processing of the transaction described in Problem 6b.\\n11.\\n Assuming that pessimistic locking with the two-phase locking protocol is being used with row-level lock granularity, create a chronological list of the locking, unlocking, and data manipulation activities that would occur during the complete processing of the transaction described in Problem 6b. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='206b81ba-19b8-4279-b91b-6d01834915fb', embedding=None, metadata={'page_label': '515', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11\\nDatabase Performance Tuning and Query Optimization\\nIn this chapter, you will learn:\\n• Basic database performance-tuning concepts\\n• How a DBMS processes SQL queries\\n• About the importance of indexes in query processing\\n• About the types of decisions the query optimizer has to make\\n• Some common practices used to write efficient SQL code\\n• How to formulate queries and tune the DBMS for optimal performance\\nPreviewDatabase performance tuning is a critical topic, yet it usually receives minimal coverage \\nin the database curriculum. Most databases used in classrooms have only a few records per table. As a result, the focus is often on making SQL queries perform an intended task, without considering the efficiency of the query process. In fact, even the most efficient query environment yields no visible performance improvements over the least efficient query environment when only 20 or 30 table rows (records) are queried. Unfortunately, that lack of attention to query efficiency can yield unacceptably slow results in the real world when queries are executed over tens of millions of records. In this chapter, you will learn what it takes to create a more efficient query environment.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH11_SaleCo              P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='244e0f17-7cd5-4099-a05c-23ac954d450a', embedding=None, metadata={'page_label': '516', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"516   Part 4    Advanced Database Concepts\\n11-1  Database Performance-Tuning Concepts\\nOne of the main functions of a database system is to provide timely answers to end users. \\nEnd users interact with the DBMS through the use of queries to generate information, using the following sequence:\\n1.\\n The end-user (client-end) application generates a query.\\n2. The query is sent to the DBMS (server end).\\n3. The DBMS (server end) executes the query.\\n4. The DBMS sends the resulting data set to the end-user (client-end) application.\\nEnd users expect their queries to return results as quickly as possible. How do you \\nknow that the performance of a database is good? Good database performance is hard \\nto evaluate. How do you know if a 1.06-second query response time is good enough? It is easier to identify bad database performance than good database performance—all it takes is end-user complaints about slow query results. Unfortunately, the same query might perform well one day and not so well two months later. Regardless of end-user \\n perceptions, the goal of database performance is to execute queries as fast as  possible. \\n Therefore, database performance must be closely monitored and regularly tuned. \\n Database performance tuning refers to a set of activities and procedures designed to \\nreduce the response time of the database system—that is, to ensure that an end-user query is processed by the DBMS in the minimum amount of time.\\nThe time required by a query to return a result set depends on many factors, which \\ntend to be wide-ranging and to vary among environments and among vendors. In gen-eral, the performance of a typical DBMS is constrained by three main factors: CPU processing power, available primary memory (RAM), and input/output (hard disk and network) throughput. Table 11.1 lists some system components and summarizes general guidelines for achieving better query performance.\\nNaturally, the system will perform best when its hardware and software resources are \\noptimized. However, in the real world, unlimited resources are not the norm; internal and external constraints always exist. Therefore, the system components should be opti-mized to obtain the best throughput possible with existing (and often limited) resources, which is why database performance tuning is important.\\nFine-tuning the performance of a system requires a holistic approach. That is, all  \\nfactors must be checked to ensure that each one operates at its optimum level and has sufficient resources to minimize the occurrence of bottlenecks. Because database design is such an important factor in determining the database system’s performance efficiency, it is worth repeating this book’s mantra:\\nGood database performance starts with good database design. No amount of \\nfine-tuning will make a poorly designed database perform as well as a well-designed database.  \\ndatabase performance tuning\\nA set of activities and procedures designed to reduce the response time of a database system—that is, to ensure that an end-user query is processed by the DBMS in the minimum amount of time.\\nBecause this book focuses on databases, this chapter covers only the factors that directly affect database performance. Also, because performance-tuning techniques can be \\nDBMS-specific, the material in this chapter might not be applicable under all circum-stances, nor will it necessarily pertain to all DBMS types. This chapter is designed to build a foundation for the general understanding of database performance-tuning issues and to help you choose appropriate performance-tuning strategies. (For the most current infor -\\nmation about tuning your database, consult the database vendor's documentation.)Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='75807ab0-9425-4240-a0ea-4873ab13d047', embedding=None, metadata={'page_label': '517', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    517\\nTABLE 11.1\\nGENERAL GUIDELINES FOR BETTER SYSTEM PERFORMANCE\\nSYSTEM RESOURCES CLIENT SERVER\\nHardware CPU The fastest possible\\nDual-core CPU or higherThe fastest possibleMultiple processors (quad-core \\n technology)Cluster of networked computers\\nRAM The maximum possible to avoid\\xa0OS memory to disk \\n swappingThe maximum possible to avoid OS memory to disk swapping\\nHard disk Fast SATA/EIDE hard disk with sufficient free hard disk spaceSolid State Drives (SSD) for faster speedMultiple high-speed, high-capacity disksFast disk interface (SAS / SCSI /  Firewire / Fibre ChannelRAID configuration optimized for throughputSolid State Drives (SSD) for faster speedSeparate disks for OS, DBMS, and  data spaces\\nNetwork High-speed connection High-speed connection\\nSoftware Operating System (OS) 64-bit OS for larger address spacesFine-tuned for best client  application performance64-bit OS for larger address spacesFine-tuned for best server application performance\\nNetwork Fine-tuned for best throughput Fine-tuned for best throughput\\nApplication Optimize SQL in client  applicationOptimize DBMS server for best  performance\\nThis is particularly true when redesigning existing databases, where the end user expects unrealistic performance gains from older databases.\\nWhat constitutes a good, efficient database design? From the performance-tuning \\npoint of view, the database designer must ensure that the design makes use of features in the DBMS that guarantee the integrity and optimal performance of the database. This chapter provides fundamental knowledge that will help you optimize database perfor -\\nmance by selecting the appropriate database server configuration, using indexes, under-standing table storage organization and data locations, and implementing the most efficient SQL query syntax.\\n11-1a  Performance Tuning: Client and Server\\nIn general, database performance-tuning activities can be divided into those on the  \\nclient side and those on the server side.\\n• On the client side, the objective is to generate a SQL query that returns the correct \\nanswer in the least amount of time, using the minimum amount of resources at the server end. The activities required to achieve that goal are commonly referred to as SQL performance tuning.\\n•\\n On the server side, the DBMS environment must be properly configured to respond to clients’ requests in the fastest way possible, while making optimum use of existing resources. The activities required to achieve that goal are commonly referred to as DBMS performance tuning.SQL performance tuning\\nActivities to help generate a SQL query that returns the correct answer in the least amount of time, using the minimum amount of resources at the server end.\\nDBMS performance tuning\\nActivities to ensure that clients’ requests are addressed as quickly as possible while making optimum use of existing resources.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3876cadf-7078-46f8-b03f-931eab5734b8', embedding=None, metadata={'page_label': '518', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"518   Part 4     Advanced Database Concepts\\nKeep in mind that DBMS implementations are typically more complex than just a \\ntwo-tier client/server configuration. The network component plays a critical role in deliv -\\nering messages between clients and servers; this is especially important in distributed \\ndatabases. In this chapter however, we assume a fully optimized network, and, therefore, \\nour focus is on the database components. Even in multi-tier client/server environments \\nthat consist of a client front end, application middleware, and database server back end, \\nperformance-tuning activities are frequently divided into subtasks to ensure the fastest \\npossible response time between any two component points. The database administrator \\nmust work closely with the network group to ensure that database traffic flows efficiently \\nin the network infrastructure. This is even more important when you consider that most \\ndatabase systems service geographically dispersed users.\\nThis chapter covers SQL performance-tuning practices on the client side and DBMS \\nperformance-tuning practices on the server side. However, before you start learning \\nabout the tuning processes, you must first learn more about the DBMS architectural \\ncomponents and processes, and how those processes interact to respond to end-users’ \\nrequests.\\n11-1b  DBMS Architecture\\nThe architecture of a DBMS is represented by the processes and structures (in  memory \\nand permanent storage) used to manage a database. Such processes collaborate with \\none another to perform specific functions. Figure 11.1 illustrates the basic DBMS \\narchitecture.\\nNote the following components and functions in Figure 11.1:\\n• All data in a database is stored in data files . A typical enterprise database is nor -\\nmally composed of several data files. A data file can contain rows from a single table, \\nor it can contain rows from many different tables. A database administrator (DBA) data file\\nA named physical \\nstorage space that \\nstores a database's \\ndata. It can reside in a \\ndifferent directory on a \\nhard disk or on one or \\nmore hard disks. All data \\nin a database is stored \\nin data files. A typical \\nenterprise database is \\nnormally composed of \\nseveral data files. A data \\nfile can contain rows \\nfrom one or more tables.\\nFIGURE 11.1  BASIC DBMS ARCHITECTURE  \\nDBMS server\\ncomputer\\nClient\\ncomputer\\nClient\\nprocess\\nResult set\\nis sent\\nback to\\nclientI/O\\noperations\\nData ﬁlesTable spacesDatabase\\nSchedulerLock\\nmanagerOptimizer\\nSQL cacheListenerUser\\nprocess\\nDBMS processes\\nrunning in primary\\nmemory (RAM)Database data ﬁles\\nstored in permanent\\nsecondary memory\\n(hard disk)Data cacheSQL\\nqueryOnline \\nContent\\nIf you want to learn \\nmore about clients and \\nservers, check Appendix \\nF, Client/Server Systems, \\nat www.cengagebrain.\\ncom .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='62344de6-6e80-41af-abdf-9ccfe1686838', embedding=None, metadata={'page_label': '519', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    519\\ndetermines the initial size of the data files that make up the database; however, the \\ndata files can automatically expand as required in predefined increments known as extents. For example, if more space is required, the DBA can define that each new extent will be in 10 KB or 10 MB increments.\\n•\\n Data files are generally grouped in file groups or table spaces. A table space or file group is a logical grouping of several data files that store data with similar charac-teristics. For example, you might have a system  table space where the data dictionary \\ntable data is stored, a user data table space to store the user-created tables, an index  \\ntable space to hold all indexes, and a temporary  table space to do temporary sorts, \\ngrouping, and so on. Each time you create a new database, the DBMS automatically creates a minimum set of table spaces.\\n•\\n The data cache, or buffer cache, is a shared, reserved memory area that stores the \\nmost recently accessed data blocks in RAM. The data read from the data files is stored in the data cache after the data has been read or before the data is written to the data files. The data cache also caches system catalog data and the contents of the indexes.\\n•\\n The SQL cache, or procedure cache, is a shared, reserved memory area that stores \\nthe most recently executed SQL statements or PL/SQL procedures, including triggers and functions. (To learn more about PL/SQL procedures, triggers, and SQL functions, study Chapter 8, Advanced SQL.) The SQL cache does not store the SQL written by the end user. Rather, the SQL cache stores a “processed” version of the SQL that is ready for execution by the DBMS.\\n•\\n To work with the data, the DBMS must retrieve the data from permanent storage and place it in RAM. In other words, the data is retrieved from the data files and placed in the data cache.\\n•\\n To move data from permanent storage (data files) to RAM (data cache), the DBMS issues I/O requests and waits for the replies. An input/output (I/O) request is a low-level data access operation that reads or writes data to and from computer devices, such as memory, hard disks, video, and printers. Note that an I/O disk read operation retrieves an entire physical disk block, generally containing multiple rows, from per -\\nmanent storage to the data cache, even if you will use only one attribute from only one row. The physical disk block size depends on the operating system and could be 4K, 8K, 16K, 32K, 64K, or even larger. Furthermore, depending on the circumstances,  \\na DBMS might issue a single-block read request or a multiblock read request.\\n•\\n Working with data in the data cache is many times faster than working with data in the data files because the DBMS does not have to wait for the hard disk to retrieve the data; no hard disk I/O operations are needed to work within the data cache.\\n•\\n Most performance-tuning activities focus on minimizing the number of I/O \\n operations because using I/O operations is many times slower than reading data from the data cache. For example, as of this writing, RAM access times range from 5 to 70 \\n nanoseconds, while hard disk access times range from 5 to 15 milliseconds. \\nThis\\xa0means that hard disks are about six orders of magnitude (a million times) slower than RAM.\\nFigure 11.1 also illustrates some typical DBMS processes. Although the number of \\nprocesses and their names vary from vendor to vendor, the functionality is similar. The following processes are represented in Figure 11.1:\\n•\\n Listener . The listener process listens for clients’ requests and handles the processing \\nof the SQL requests to other DBMS processes. Once a request is received, the listener \\npasses the request to the appropriate user process.extents\\nIn a DBMS environment, refers to the ability of data files to expand in size automatically using predefined increments.\\ntable space\\nIn a DBMS, a logical storage space used to group related data. Also known as a file group.\\nfile group\\nSee table space.\\ndata cache\\nA shared, reserved memory area that stores the most recently accessed data blocks in RAM. Also called buffer cache.\\nbuffer cache\\nSee data cache.\\nSQL cache\\nA shared, reserved memory area that stores the most recently executed SQL statements or PL/SQL procedures, including triggers and functions. Also called procedure cache.\\nprocedure cache\\nSee SQL cache.\\ninput/output (I/O) request\\nA low-level data access operation that reads or writes data to and from computer devices.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ca5de632-11ce-43c7-aa78-eea72d1d2cde', embedding=None, metadata={'page_label': '520', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='520   Part 4    Advanced Database Concepts\\n• User . The DBMS creates a user process to manage each client session. Therefore, when \\nyou log on to the DBMS, you are assigned a user process. This process handles all \\nrequests you submit to the server. There are many user processes—at least one per logged-in client.\\n•\\n Scheduler . The scheduler process organizes the concurrent execution of SQL requests. \\n(See Chapter 10, Transaction Management and Concurrency Control.)\\n• Lock manager. This process manages all locks placed on database objects, including disk pages. (See Chapter 10.)\\n•\\n Optimizer. The optimizer process analyzes SQL queries and finds the most efficient way to access the data. Y ou will learn more about this process later in the chapter.\\n11-1c  Database Query Optimization Modes\\nMost of the algorithms proposed for query optimization are based on two principles:\\n• The selection of the optimum execution order to achieve the fastest execution time\\n• The selection of sites to be accessed to minimize communication costs\\nWithin those two principles, a query optimization algorithm can be evaluated on the \\nbasis of its operation mode  or the timing of its optimization.\\nOperation modes can be classified as manual or automatic. Automatic query \\n optimization means that the DBMS finds the most cost-effective access path with-\\nout user intervention. Manual query optimization requires that the optimization be selected and scheduled by the end user or programmer. Automatic query optimization is clearly more desirable from the end user’s point of view, but the cost of such convenience is the increased overhead that it imposes on the DBMS.\\nQuery optimization algorithms can also be classified according to when the optimi-\\nzation is done. Within this timing classification, query optimization algorithms can be static or dynamic.\\n•\\n Static query optimization takes place at compilation time. In other words, the best \\noptimization strategy is selected when the query is compiled by the DBMS. This approach is common when SQL statements are embedded in procedural program-ming languages such as C# or Visual Basic .NET. When the program is submitted to the DBMS for compilation, it creates the plan necessary to access the database. When the program is executed, the DBMS uses that plan to access the database.\\n•\\n Dynamic query optimization takes place at execution time. Database access strategy is defined when the program is executed. Therefore, access strategy is dynamically determined by the DBMS at run time, using the most up-to-date information about the database. Although dynamic query optimization is efficient, its cost is measured by run-time processing overhead. The best strategy is determined every time the query is executed; this could happen several times in the same program.\\nFinally, query optimization techniques can be classified according to the type of \\n information that is used to optimize the query. For example, queries may be based on statistically based or rule-based algorithms.\\n•\\n A statistically based query optimization algorithm uses statistical information \\nabout the database. The statistics provide information about database characteristics \\nsuch as size, number of records, average access time, number of requests serviced, and number of users with access rights. These statistics are then used by the DBMS to determine the best access strategy. Within statistically based optimizers, some DBMSs allow setting a goal to specify that the optimizer should attempt to minimize automatic query optimization\\nA method by which a DBMS finds the most efficient access path for the execution of a query.\\nmanual query optimization\\nAn operation mode that requires the end user or programmer to define the access path for the execution of a query.\\nstatic query optimization\\nA query optimization mode in which the access path to a database is predetermined at compilation time.\\ndynamic query optimization\\nThe process of determining the SQL access strategy at run time, using the most up-to-date information about the database.\\nstatistically based query optimization algorithm\\nA query optimization technique that uses statistical information about a database. The DBMS then uses these statistics to determine the best access strategy.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6435c478-15fb-433c-8b6e-4d789b6355b2', embedding=None, metadata={'page_label': '521', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    521\\nthe time to retrieve the first row or the last row. Minimizing the time to retrieve the \\nfirst row is often used in transaction systems and interactive client environments. In these cases, the goal is to present the first several rows to the user as quickly as possi-ble. Then, while the DBMS waits for the user to scroll through the data, it can fetch the other rows for the query. Setting the optimizer goal to minimize retrieval of the last row is typically done in embedded SQL and inside stored procedures. In these cases, the control will not pass back to the calling application until all of the data has been retrieved; therefore, it is important to retrieve all of the data to the last row as quickly as possible so control can be returned.\\n•\\n The statistical information is managed by the DBMS and is generated in one of two different modes: dynamic or manual. In the dynamic statistical generation mode, the DBMS automatically evaluates and updates the statistics after each data access operation. In the manual statistical generation mode, the statistics must be updated periodically through a user-selected utility such as IBM’s RUNSTAT com-mand, which is used by DB2 DBMSs.\\n•\\n A rule-based query optimization algorithm is based on a set of user-defined rules \\nto determine the best query access strategy. The rules are entered by the end user or database administrator, and they are typically general in nature.\\nBecause database statistics play a crucial role in query optimization, this topic is \\nexplored in more detail in the next section.\\n11-1d  Database Statistics\\nAnother DBMS process that plays an important role in query optimization is gathering database statistics. The term database statistics refers to a number of measurements about database objects, such as number of processors used, processor speed, and tempo-rary space available. Such statistics provide a snapshot of database characteristics.\\nAs you will learn later in this chapter, the DBMS uses these statistics to make critical \\ndecisions about improving query processing efficiency. Database statistics can be gath-ered manually by the DBA or automatically by the DBMS. For example, many DBMS vendors support the ANALYZE command in SQL to gather statistics. In addition, many vendors have their own routines to gather statistics. For example, IBM’s DB2 uses the RUNSTATS procedure, while Microsoft’s SQL Server uses the UPDATE STATISTICS procedure and provides the Auto-Update and Auto-Create Statistics options in its initial-ization parameters. A sample of measurements that the DBMS may gather about various database objects is shown in Table 11.2.dynamic statistical generation mode\\nIn a DBMS, the capability to automatically evaluate and update the database access statistics after each data access operation.\\nmanual statistical generation mode\\nA mode of generating statistical data access information for query optimization. In this mode, the DBA must periodically run a routine to generate the data access statistics—for example, running the RUNSTAT command in an IBM DB2 database.\\nrule-based query optimization algorithm\\nA query optimization technique that uses preset rules and points to determine the best approach to executing a query.\\ndatabase statistics\\nIn query optimization, measurements about database objects, such as the number of rows in a table, number of disk blocks used, maximum and average row length, number of columns in each row, and number of distinct values in each column. Such statistics provide a snapshot of database characteristics.\\nTABLE 11.2\\nSAMPLE DATABASE STATISTICS MEASUREMENTS\\nDATABASE OBJECT SAMPLE MEASUREMENTS\\nTables Number of rows, number of disk blocks used, row length, number of columns in each row, number of distinct values in each column, maximum value in each column, minimum value in each column, and columns that have indexes\\nIndexes Number and name of columns in the index key, number of key values in the index, number of distinct key values in the index key, histogram of key values in an index, and number of disk pages used by the index\\nEnvironment Resources Logical and physical disk block size, location and size of data files, and number of extends \\nper data file\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ac42e3f1-63c8-4796-8104-2880c088d331', embedding=None, metadata={'page_label': '522', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='522   Part 4    Advanced Database Concepts\\nIf the object statistics exist, the DBMS will use them in query processing. Most newer \\nDBMSs (such as Oracle, MySQL, SQL Server, and DB2) automatically gather statistics; \\nothers require the DBA to gather statistics manually. To generate the database object statistics manually, each DBMS has its own commands. \\nIn Oracle, use ANALYZE <TABLE/INDEX> object_name COMPUTE STATISTICS; \\nIn MySQL, use ANALYZE TABLE <table_name>; In SQL Server, use UPDATE STATISTICS <object_name>, where object name refers \\nto a table or a view.\\nFor example, to generate statistics for the VENDOR table, you would use: In Oracle: ANALYZE TABLE VENDOR COMPUTE STATISTICS;\\nIn MySQL: ANALYZE TABLE VENDOR;In SQL Server: UPDATE STATISTICS VENDOR;\\nWhen you generate statistics for a table, all related indexes are also analyzed. How-\\never, you could generate statistics for a single index by using the following command, \\nwhere VEND_NDX is the name of the index: \\nANALYZE INDEX VEND_NDX COMPUTE STATISTICS;\\nIn SQL Server, use UPDATE STATISTICS <table_name> <index_name>. An exam-\\nple command would be UPDATE STATISTICS VENDOR VEND_NDX;.\\nDatabase statistics are stored in the system catalog in specially designated tables. \\nIt is common to periodically regenerate the statistics for database objects, especially \\ndatabase objects that are subject to frequent change. For example, if you have a video rental DBMS, your system will likely use a RENTAL table to store the daily video rent-als. That RENTAL table and its associated indexes would be subject to constant inserts and updates as you record daily rentals and returns. Therefore, the RENTAL table sta -\\ntistics you generated last week do not accurately depict the table as it exists today. The more current the statistics are, the better the chances that the DBMS will properly select the fastest way to execute a given query.\\nNow that you know the basic architecture of DBMS processes and memory struc-\\ntures, and the importance and timing of the database statistics gathered by the DBMS, you are ready to learn how the DBMS processes a SQL query request.\\n11-2  Query Processing\\nWhat happens at the DBMS server end when the client’s SQL statement is received? In\\xa0simple terms, the DBMS processes a query in three phases:\\n1.\\n Parsing . The DBMS parses the SQL query and chooses the most efficient access/  \\nexecution plan.\\n2. Execution . The DBMS executes the SQL query using the chosen execution plan.\\n3. Fetching . The DBMS fetches the data and sends the result set back to the client.\\nThe processing of SQL DDL statements (such as CREATE TABLE) is different from the \\nprocessing required by DML statements. The difference is that a DDL statement actually \\nupdates the data dictionary tables or system catalog, while a DML statement (SELECT, INSERT, UPDATE, or DELETE) mostly manipulates end-user data. \\n Figure\\xa011.2 shows \\nthe general steps required for query processing. Each step will be discussed in the \\n following sections.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2929b6b7-18d4-4d9b-bed2-e5f6d17acf8b', embedding=None, metadata={'page_label': '523', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    523\\nFIGURE 11.2  QUERY PROCESSING  \\nParsing\\nphaseFetching\\nphaseData ﬁles\\nSelect ....\\nFrom ...\\nWhere ...\\nData cache\\n• Syntax check\\n• Naming check\\n• Access rights check\\n• Decompose and analyze\\n• Generate access plan\\n• Store access plan in SQL cache• Execute I/O operations\\n• Add locks for transaction mgmt\\n• Retrieve data blocks from data ﬁles\\n• Place data blocks in data cache• Generate result setExecution\\nphaseSQL cache\\nAccess plan\\n11-2a  SQL Parsing Phase\\nThe optimization process includes breaking down—parsing—the query into smaller \\nunits and transforming the original SQL query into a slightly different version of the orig -\\ninal SQL code, but one that is fully equivalent and more efficient. Fully equivalent  means \\nthat the optimized query results are always the same as the original query. More efficient  \\nmeans that the optimized query will almost always execute faster than the original query. \\n(Note that it almost  always executes faster because many factors affect the  performance of \\na database, as explained earlier. Those factors include the network, the client computer’s \\nresources, and other queries running concurrently in the same  database.) To determine \\nthe most efficient way to execute the query, the DBMS may use the database statistics you \\nlearned about earlier.\\nThe SQL parsing activities are performed by the query optimizer , which analyzes the \\nSQL query and finds the most efficient way to access the data. This process is the most \\ntime-consuming phase in query processing. Parsing a SQL query requires several steps, \\nin which the SQL query is:\\n• Validated for syntax compliance\\n• Validated against the data dictionary to ensure that table names and column names \\nare correct\\n• Validated against the data dictionary to ensure that the user has proper access \\nrights\\n• Analyzed and decomposed into more atomic componentsquery optimizer\\nA DBMS process that \\nanalyzes SQL queries and \\nfinds the most efficient \\nway to access the data. \\nThe query optimizer \\ngenerates the access or \\nexecution plan for the \\nquery.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68005956-cda6-459e-94ce-00e6fdb0010b', embedding=None, metadata={'page_label': '524', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"524   Part 4    Advanced Database Concepts\\nIn Table 11.3, note that a table access using a row ID is the fastest method. A row ID \\nis a unique identification for every row saved in permanent storage; it can be used to \\naccess the row directly. Conceptually, a row ID is similar to a slip you get when you park your car in an airport parking lot. The parking slip contains the section number and lot number. Using that information, you can go directly to your car without searching every section and lot.\\n11-2b  SQL Execution Phase\\nIn this phase, all I/O operations indicated in the access plan are executed. When the exe-cution plan is run, the proper locks—if needed—are acquired for the data to be accessed, and the data is retrieved from the data files and placed in the DBMS’s data cache. All transaction management commands are processed during the parsing and execution phases of query processing.•\\n Optimized through transformation into a fully equivalent but more efficient SQL \\nquery\\n• Prepared for execution by determining the most efficient execution or access plan\\nOnce the SQL statement is transformed, the DBMS creates what is commonly \\nknown as an access plan or execution plan. An access plan is the result of parsing a SQL statement; it contains the series of steps a DBMS will use to execute the query and return the result set in the most efficient way. First, the DBMS checks to see if an access plan already exists for the query in the SQL cache. If it does, the DBMS reuses the access plan to save time. If it does not, the optimizer evaluates various plans and then decides which indexes to use and how to best perform join operations. The  \\nchosen access plan for the query is then placed in the SQL cache and made available for use and future reuse.\\nAccess plans are DBMS-specific and translate the client’s SQL query into the series \\nof complex I/O operations required to read the data from the physical data files and \\n generate the result set. Table 11.3 illustrates some I/O operations for an Oracle RDBMS. Most DBMSs perform similar types of operations when accessing and manipulating data\\xa0sets.\\naccess plan\\nA set of instructions generated at application compilation time that is created and managed by a DBMS. The access plan predetermines how an application's query will access the database at run time.TABLE 11.3\\nSAMPLE DBMS ACCESS PLAN I/O OPERATIONS\\nOPERATION DESCRIPTION\\nTable scan (full) Reads the entire table sequentially, from the first row to the last, one row at a time (slowest)\\nTable access (row ID) Reads a table row directly, using the row ID value (fastest)\\nIndex scan (range) Reads the index first to obtain the row IDs and then accesses the table rows directly (faster than a full table scan)\\nIndex access (unique) Used when a table has a unique index in a column\\nNested loop Reads and compares a set of values to another set of values, using a nested loop style (slow)\\nMerge Merges two data sets (slow)\\nSort Sorts a data set (slow)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3f958719-0c62-4400-b234-a370c5761e7d', embedding=None, metadata={'page_label': '525', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    525\\n11-2c  SQL Fetching Phase\\nAfter the parsing and execution phases are completed, all rows that match the  specified \\ncondition(s) are retrieved, sorted, grouped, and aggregated (if required). During the fetch-\\ning phase, the rows of the resulting query result set are returned to the client. The\\xa0DBMS might use temporary table space to store temporary data. In this stage, the \\n database \\nserver coordinates the movement of the result set rows from the server cache to the client cache. For example, a given query result set might contain 9,000 rows; the\\xa0server would send the first 100 rows to the client and then wait for the client to request the next set of rows, until the entire result set is sent to the client.\\n11-2d  Query Processing Bottlenecks\\nThe main objective of query processing is to execute a given query in the fastest way possible with the least amount of resources. As you have seen, the execution of a query requires the DBMS to break down the query into a series of interdependent I/O opera-tions to be executed in a collaborative manner. The more complex a query is, the more complex the operations are, which means that bottlenecks are more likely. A query \\n processing bottleneck is a delay introduced in the processing of an I/O operation that causes the overall system to slow down. In the same way, the more components a system has, the more interfacing is required among the components, increasing the likelihood of bottlenecks. Within a DBMS, five components typically cause bottlenecks:\\n•\\n CPU. The CPU processing power of the DBMS should match the system’s expected \\nwork load. A high CPU utilization might indicate that the processor speed is too slow for the amount of work performed. However, heavy CPU utilization can be caused by other factors, such as a defective component, not enough RAM (the CPU spends too much time swapping memory blocks), a badly written device driver, or a rogue process. A CPU bottleneck will affect not only the DBMS but all processes running in the system.\\n•\\n RAM. The DBMS allocates memory for specific usage, such as data cache and SQL cache. RAM must be shared among all running processes, including the operat-ing system and DBMS. If there is not enough RAM available, moving data among \\n components that are competing for scarce RAM can create a bottleneck.\\n• Hard disk . Other common causes of bottlenecks are hard disk speed and data transfer \\nrates. Current hard disk storage technology allows for greater storage capacity than in the past; however, hard disk space is used for more than just storing end-user data. Current operating systems also use the hard disk for virtual memory , which refers to \\ncopying areas of RAM to the hard disk as needed to make room in RAM for more urgent tasks. Therefore, more hard disk storage space and faster data transfer rates reduce the likelihood of bottlenecks.\\n•\\n Network . In a database environment, the database server and the clients are con-\\nnected via a network. All networks have a limited amount of bandwidth that is shared among all clients. When many network nodes access the network at the same time, \\n bottlenecks are likely.\\n• Application code . Not all bottlenecks are caused by limited hardware resources. Two \\nof the most common sources of bottlenecks are inferior application code and poorly designed databases. Inferior code can be improved with code optimization tech-niques, as long as the underlying database design is sound. However, no amount of coding will make a poorly designed database perform better.query processing bottleneck\\nIn query optimization, a delay introduced in the processing of an I/O operation that causes the overall system to slow down.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='df5c2493-e7a1-4421-a31d-e47b6a7b67dd', embedding=None, metadata={'page_label': '526', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"526   Part 4     Advanced Database Concepts\\nSuppose you submit the following query:\\nSELECT CUS_NAME, CUS_STATE\\nFROM CUSTOMER\\nWHERE CUS_STATE = 'FL';Bottlenecks are the result of multiple database transactions competing for the use of \\ndatabase resources (CPU, RAM, hard disk, indexes, locks, buffers, etc.). As you learned \\nearlier in this chapter, a DBMS uses many components and structures to perform its \\noperations, such as processes, buffers, locks, table spaces, indexes, and log files. These \\nresources are used by all transactions executing on the database, and, therefore, the \\ntransactions often compete for such resources. Because most (if not all) transactions \\nwork with data rows in tables, one of the most typical bottlenecks is caused by transac -\\ntions competing for the same data rows. Another common source of contention is for \\nshared memory resources, particularly shared buffers and locks. To speed up data update \\noperations, the DMBS uses buffers to cache the data. At the same time, to manage access \\nto data, the DBMS uses locks. Learning how to avoid these bottlenecks and optimize \\ndatabase performance is the main focus of this chapter.\\n11-3  Indexes and Query Optimization\\nIndexes are crucial in speeding up data access because they facilitate searching, sorting, \\nand using aggregate functions and even join operations. The improvement in data access \\nspeed occurs because an index is an ordered set of values that contains the index key \\nand pointers. The pointers are the row IDs for the actual table rows. Conceptually, a data \\nindex is similar to a book index. When you use a book index, you look up a word, which \\nis similar to the index key. The word is accompanied by one or more page numbers where \\nthe word is used; these numbers are similar to pointers.\\nAn index scan is more efficient than a full table scan because the index data is pre -\\nordered and the amount of data is usually much smaller. Therefore, when performing \\nsearches, it is almost always better for the DBMS to use the index to access a table than \\nto scan all rows in a table sequentially. For example, Figure 11.3 shows the index repre -\\nsentation of a CUSTOMER table with 14,786 rows and the index STATE_NDX on the \\nCUS_STATE attribute.\\nFIGURE 11.3  INDEX REPRESENTATION FOR THE CUSTOMER TABLE  \\nSTATE_NDX INDEXCUSTOMER TABLE\\n(14,786 rows)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e06659b3-d9e1-4d5a-bde8-fbf06feb154f', embedding=None, metadata={'page_label': '527', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    527\\nIf there is no index, the DBMS will perform a full-table scan and read all 14,786 cus-\\ntomer rows. Assuming that the index STATE_NDX is created (and analyzed), the DBMS \\nwill automatically use the index to locate the first customer with a state equal to \\'FL\\' and then proceed to read all subsequent CUSTOMER rows, using the row IDs in the index as a guide. Assuming that only five rows meet the condition CUS_STATE = \\'FL\\' there are five accesses to the index and five accesses to the data, for a total of 10 I/O accesses. The DBMS would be saved from reading approximately 14,776 I/O requests for customer rows that do not meet the criteria. That is a lot of CPU cycles!\\nIf indexes are so important, why not index every column in every table? The simple \\nanswer is that it is not practical to do so. Indexing every column in every table overtaxes the DBMS in terms of index-maintenance processing, especially if the table has many attributes and rows, or requires many inserts, updates, and deletes.\\nOne measure that determines the need for an index is the data sparsity  of the col-\\numn you want to index. Data sparsity refers to the number of different values a column could have. For example, a STU_SEX column in a STUDENT table can have only two possible values, M or F; therefore, that column is said to have low sparsity. In contrast, the STU_DOB column that stores the student date of birth can have many different date values; therefore, that column is said to have high sparsity. Knowing the sparsity helps you decide whether the use of an index is appropriate. For exam-ple, when you perform a search in a column with low sparsity, you are likely to read a high percentage of the table rows anyway; therefore, index processing might be unnecessary work. In Section 11-5, you learn how to determine when an index is recommended.\\nMost DBMSs implement indexes using one of the following data structures:\\n•\\n Hash index. A hash index is based on an ordered list of hash values. A hash algorithm is used to create a hash value from a key column. This value points to an entry in a hash table, which in turn points to the actual location of the data row. This type of index is good for simple and fast lookup operations based on equality conditions—for example, LNAME=\"Scott\" and FNAME=\"Shannon\".\\n•\\n B-tree index. The B-tree index is an ordered data structure organized as an upside-down tree. (See Figure 11.4.) The index tree is stored separately from the data. The lower-level leaves of the B-tree index contain the pointers to the actual data rows. B-tree indexes are “self-balanced, ” which means that it takes approximately the same amount of time to access any given row in the index. This is the default and most common type of index used in databases. The B-tree index is used mainly in tables in which column values repeat a relatively small number of times.\\n•\\n Bitmap index. A bitmap index uses a bit array (0s and 1s) to represent the exis-tence of a value or condition. These indexes are used mostly in data warehouse appli-cations in tables with a large number of rows in which a small number of column  \\nvalues repeat many times. (See Figure 11.4.) Bitmap indexes tend to use less space than B-tree indexes because they use bits instead of bytes to store their data.\\nUsing the preceding index characteristics, a database designer can determine the best \\ntype of index to use. For example, assume that a CUSTOMER table has several thousand rows. The CUSTOMER table has two columns that are used extensively for query pur -\\nposes: CUS_LNAME, which represents a customer’s last name, and REGION_CODE, which can have one of four values (NE, NW , SW , and SE). Based on this information, you could conclude that:\\n•\\n Because the CUS_LNAME column contains many different values that repeat a  \\nrelatively small number of times compared to the total number of rows in the table,  \\na B-tree index will be used.data sparsity\\nA column distribution \\nof values or the number of different values a column can have.\\nhash index\\nAn index based on an ordered list of hash values.\\nB-tree index\\nAn ordered data structure organized as an upside-down tree.\\nbitmap index\\nAn index that uses a bit array (0s and 1s) to represent the existence of a value or condition.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cb4a8588-3c8c-4804-abd8-a0f9b5bd03a0', embedding=None, metadata={'page_label': '528', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='528   Part 4     Advanced Database Concepts\\n• Because the REGION_CODE column contains only a few different values that repeat \\na relatively large number of times compared to the total number of rows in the table, \\na bitmap index will be used. Figure 11.4 shows the B-tree and bitmap representations \\nfor the CUSTOMER table used in the previous discussion.\\nCurrent-generation DBMSs are intelligent enough to determine the best type of \\nindex to use under certain circumstances, provided that the DBMS has updated data -\\nbase statistics. Regardless of which index is chosen, the DBMS determines the best \\nplan to execute a given query. The next section guides you through a simplified exam -\\nple of the type of choices the query optimizer must make.\\n11-4  Optimizer Choices\\nQuery optimization is the central activity during the parsing phase in query processing. \\nIn this phase, the DBMS must choose what indexes to use, how to perform join opera -\\ntions, which table to use first, and so on. Each DBMS has its own algorithms for deter -\\nmining the most efficient way to access the data. The query optimizer can operate in one \\nof two modes:\\n• A rule-based  optimizer  uses preset rules and points to determine the best approach \\nto execute a query. The rules assign a “fixed cost” to each SQL operation; the costs are \\nthen added to yield the cost of the execution plan. For example, a full table scan has  \\na set cost of 10, while a table access by row ID has a set cost of 3.\\n• A cost-based optimizer  uses sophisticated algorithms based on statistics about the \\nobjects being accessed to determine the best approach to execute a query. In\\xa0this rule-based optimizer\\nA query optimization \\nmode based on the \\nrule-based query \\noptimization algorithm.\\ncost-based optimizer\\nA query optimization \\nmode that uses an \\nalgorithm based on \\nstatistics about the \\nobjects being accessed, \\nincluding number of \\nrows, indexes available, \\nindex sparsity, and so on.FIGURE 11.4  B-TREE AND BITMAP INDEX REPRESENTATION  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='966e9e9b-f2fc-4dd4-885e-02b874a399b1', embedding=None, metadata={'page_label': '529', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 11    Database Performance Tuning and Query Optimization    529\\nTABLE 11.4\\nCOMPARING ACCESS PLANS AND I/O COSTS\\nPLAN STEP OPERATION I/O  \\nOPERATIONSI/O COST RESULTING SET ROWSTOTAL I/O COST\\nA A1 Cartesian product  \\n(PRODUCT, VENDOR)7,000 + 300 7,300 2,100,000 7,300\\nA2 Select rows in A1 with \\nmatching vendor codes2,100,000 2,100,000 7,000 2,107,300\\nA3 Select rows in A2 with  \\nV_STATE = 'FL'7,000 7,000 1,000 2,114,300\\nB B1 Select rows in VENDOR with \\nV_STATE = 'FL'300 300 10 300\\nB2 Cartesian Product  \\n(PRODUCT, B1)7,000 + 10 7,010 70,000 7,310\\nB3 Select rows in B2 with \\nmatching vendor codes70,000 70,000 1,000 77,310case, the optimizer process adds up the processing cost, the I/O costs, and the resource costs (RAM and temporary space) to determine the total cost of a given execution plan.\\nThe optimizer’s objective is to find alternative ways to execute a query—to evaluate the \\n“cost” of each alternative and then to choose the one with the lowest cost. To understand the function of the query optimizer, consider a simple example. Assume that you want to list all products provided by a vendor based in Florida. To acquire that \\n information, you \\ncould write the following query:\\nSELECT P_CODE, P_DESCRIPT, P_PRICE, V_NAME, V_STATE\\nFROM PRODUCT, VENDOR\\nWHERE PRODUCT.V_CODE = VENDOR.V_CODE\\nAND VENDOR.V_STATE = 'FL';\\nFurthermore, assume that the database statistics indicate the following:\\n• The PRODUCT table has 7,000 rows.\\n• The VENDOR table has 300 rows.\\n• Ten vendors are located in Florida.\\n• One thousand products come from vendors in Florida.\\nIt is important to point out that only the first two items are available to the optimizer. \\nThe second two items are assumed to illustrate the choices that the optimizer must make. \\nArmed with the information in the first two items, the optimizer would try to find the most efficient way to access the data. The primary factor in determining the most effi-cient access plan is the I/O cost. (Remember, the DBMS always tries to minimize I/O operations.) Table 11.4 shows two sample access plans for the previous query and their respective I/O costs.\\nTo make the example easier to understand, the I/O Operations and I/O Cost \\n columns \\nin Table 11.4 estimate only the number of I/O disk reads the DBMS must perform. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c06195e9-00b4-4935-bc8a-2963027e0813', embedding=None, metadata={'page_label': '530', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"530   Part 4    Advanced Database Concepts\\nFor\\xa0simplicity’s sake, it is assumed that there are no indexes and that each row read has an \\nI/O cost of 1. For example, in Step A1, the DBMS must calculate the Cartesian  product of \\nPRODUCT and VENDOR. To do that, the DBMS must read all rows from PRODUCT (7,000) and all rows from VENDOR (300), yielding a total of 7,300 I/O \\n operations. The \\nsame computation is done in all steps. In Table 11.4, you can see how Plan A has a total I/O cost that is almost 30 times higher than Plan B. In this case, the optimizer will choose Plan B to execute the SQL.\\nNot all DBMSs optimize SQL queries the same way. As a matter of fact, Oracle parses queries differently from the methods described in several sections in this chapter. Always read the documentation to examine the optimization requirements for your DBMS implementation.Note\\nGiven the right conditions, some queries could be answered entirely by using only \\nan index. For example, assume that you are using the PRODUCT table and the index P_QOH_NDX in the P_QOH attribute. Then a query such as SELECT MIN(P_QOH) FROM PRODUCT could be resolved by reading only the first entry in the P_QOH_NDX index, without the need to access any of the data blocks for the PRODUCT table. (Remember that the index defaults to ascending order.)\\nY ou learned in Section 11-3 that columns with low sparsity are not good candidates \\nfor index creation. However, in some cases an index in a low-sparsity column would be helpful. For example, assume that the EMPLOYEE table has 122,483 rows. If you want to find out how many female employees work at the company, you would write a query such as:\\nSELECT COUNT(EMP_SEX) FROM EMPLOYEE WHERE EMP_SEX = 'F';\\nIf you do not have an index for the EMP_SEX column, the query would have to \\nperform a full table scan to read all EMPLOYEE rows—and each full row includes \\nattributes you do not need. However, if you have an index on EMP_SEX, the query can be answered by reading only the index data, without the need to access the employee data at all.\\n11-4a  Using Hints to Affect Optimizer Choices\\nAlthough the optimizer generally performs very well under most circumstances, in some instances the optimizer might not choose the best execution plan. Remember, the \\n optimizer makes decisions based on the existing statistics. If the statistics are old, the optimizer might not do a good job in selecting the best execution plan. Even with current statistics, the optimizer’s choice might not be the most efficient one. Sometimes the end user would like to change the optimizer mode for the current SQL statement. To do that, you need to use hints. Optimizer hints are special instructions for the optimizer that are embedded inside the SQL command text. Table 11.5 summarizes a few of the most common optimizer hints used in standard SQL.\\nNow that you are familiar with the way the DBMS processes SQL queries, you can \\nturn your attention to some general SQL coding recommendations to facilitate the work of the query optimizer.\\noptimizer hints\\nSpecial instructions for the query optimizer that are embedded inside the SQL command text.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9174681f-462d-4a19-8475-d4abf7673536', embedding=None, metadata={'page_label': '531', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    531\\n11-5  SQL Performance Tuning\\nSQL performance tuning is evaluated from the client perspective. Therefore, the goal is \\nto illustrate some common practices used to write efficient SQL code. A few words of caution are appropriate:\\n•\\n Most current-generation relational DBMSs perform automatic query optimization at \\nthe server end.\\n• Most SQL performance optimization techniques are DBMS-specific and, therefore, are rarely portable, even across different versions of the same DBMS. Part of the  \\nreason for this behavior is the constant advancement in database technologies.\\nDoes this mean that you should not worry about how a SQL query is written because \\nthe DBMS will always optimize it? No, because there is considerable room for improve-ment. (The DBMS uses general optimization techniques rather than focusing on specific techniques dictated by the special circumstances of the query execution.) A poorly \\n written \\nSQL query can, and usually will , bring the database system to its knees from a perfor -\\nmance point of view. The majority of current database performance problems are related to poorly written SQL code. Therefore, although a DBMS provides general optimizing services, a carefully written query almost always outperforms a poorly written one.\\nAlthough SQL data manipulation statements include many different commands such \\nas INSERT, UPDATE, DELETE, and SELECT, most recommendations in this section are related to the use of the SELECT statement, and in particular, the use of indexes and how to write conditional expressions.\\n11-5a  Index Selectivity\\nIndexes are the most important technique used in SQL performance optimization. The key is to know when an index is used. As a general rule, indexes are likely to be used:\\n•\\n When an indexed column appears by itself in the search criteria of a WHERE or \\nHAVING clauseTABLE 11.5\\nOPTIMIZER HINTS\\nHINT USAGE\\nALL_ROWS Instructs the optimizer to minimize the overall execution time—that is, to minimize the time \\nneeded to return all rows in the query result set. This hint is generally used for batch mode \\n processes. For example:SELECT\\n /*+ ALL_ROWS */ *\\nFROM  PRODUCT\\nWHERE  P_QOH < 10;\\nFIRST_ROWS Instructs the optimizer to minimize the time needed to process the first set of rows—that is,  \\nto minimize the time needed to return only the first set of rows in the query result set. This hint  is generally used for interactive mode processes. For example:SELECT\\n /*+ FIRST_ROWS */ *\\nFROM  PRODUCT\\nWHERE  P_QOH < 10;\\nINDEX(name) Forces the optimizer to use the P_QOH_NDX index to process this query. For example:\\nSELECT  /*+ INDEX(P_QOH_NDX) */ *\\nFROM  PRODUCT\\nWHERE  P_QOH < 10\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fca639ec-adf3-4ec4-80bb-36608b5b547f', embedding=None, metadata={'page_label': '532', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='532   Part 4    Advanced Database Concepts\\n• When an indexed column appears by itself in a GROUP BY or ORDER BY clause\\n• When a MAX or MIN function is applied to an indexed column\\n• When the data sparsity on the indexed column is high\\nIndexes are very useful when you want to select a small subset of rows from a large \\ntable based on a given condition. If an index exists for the column used in the selection, \\nthe DBMS may choose to use it. The objective is to create indexes with high selectivity. Index selectivity is a measure of the likelihood that an index will be used in query  \\nprocessing. Here are some general guidelines for creating and using indexes:\\n•\\n Create indexes for each single attribute used in a WHERE, HA VING, ORDER BY, or \\nGROUP BY clause. If you create indexes in all single attributes used in search condi-tions , the DBMS will access the table using an index scan instead of a full table scan. \\nFor example, if you have an index for P_PRICE, the condition P_PRICE > 10.00 can be solved by accessing the index instead of sequentially scanning all table rows and evaluating P_PRICE for each row. Indexes are also used in join expressions, such as in CUSTOMER.CUS_CODE = INVOICE.CUS_CODE.\\n•\\n Do not use indexes in small tables or tables with low sparsity. Remember, small tables and low-sparsity tables are not the same thing. A search condition in a table with low sparsity may return a high percentage of table rows anyway, making the index opera-tion too costly and making the full table scan a viable option. Using the same logic, do not create indexes for tables with few rows and few attributes—unless you must ensure the existence of unique values in a column.\\n•\\n Declare primary and foreign keys so the optimizer can use the indexes in join opera-tions . All natural joins and old-style joins will benefit if you declare primary keys and \\n foreign keys because the optimizer will use the available indexes at join time. (The declaration of a PK or FK, primary key or foreign key, will automatically create an index for the declared column.) Also, for the same reason, it is better to write joins using the SQL JOIN syntax. (See Chapter 8, Advanced SQL.)\\n•\\n Declare indexes in join columns other than PK or FK. If you perform join operations on columns other than the primary and foreign keys, you might be better off declaring indexes in those columns.\\nY ou cannot always use an index to improve performance. For example, using the data \\nshown in Table 11.6 in the next section, the creation of an index for P_MIN will not help the search condition P_QOH > P_MIN * 1.10. The reason is that in some DBMSs, indexes are ignored when you use functions in the table attributes. However, major data-bases such as Oracle, SQL Server, and DB2 now support function-based indexes. A function-based index is an index based on a specific SQL function or expression. For example, you could create an index on YEAR(INV_DATE). Function-based indexes are especially useful when dealing with derived attributes. For example, you could create an index on EMP_SALARY + EMP_COMMISSION.\\nHow many indexes should you create? It bears repeating that you should not create an \\nindex for every column in a table. Too many indexes will slow down INSERT, UPDATE, and DELETE operations, especially if the table contains many thousands of rows. Fur -\\nthermore, some query optimizers will choose only one index to be the driving index for a query, even if your query uses conditions in many different indexed columns. Which index does the optimizer use? If you use the cost-based optimizer, the answer will change with time as new rows are added to or deleted from the tables. In any case, you should create indexes in all search columns and then let the optimizer choose. It is important  \\nto constantly evaluate the index usage—monitor, test, evaluate, and improve it if  \\nperformance is not adequate.\\nindex selectivity\\nA measure of how likely an index is to be used in query processing.\\nfunction-based index\\nA type of index based on a specific SQL function or expression.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c71508ca-42da-4cba-971b-96d5fcf94ef3', embedding=None, metadata={'page_label': '533', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 11    Database Performance Tuning and Query Optimization    533\\nIn Table 11.6, note that an operand can be:\\n• A simple column name such as P_PRICE or V_STATE\\n• A literal or a constant such as the value 10.00 or the text 'FL'\\n• An expression such as P_MIN * 1.10\\nMost of the query optimization techniques mentioned below are designed to make \\nthe optimizer’s work easier. The following common practices are used to write efficient \\nconditional expressions in SQL code.\\n• Use simple columns or literals as operands in a conditional expression—avoid the \\nuse of conditional expressions with functions whenever possible. Comparing the contents of a single column to a literal is faster than comparing to expressions. For example, P_PRICE > 10.00 is faster than P_QOH > P_MIN * 1.10 because the DBMS must evaluate the P_MIN * 1.10 expression first. The use of functions in expressions also adds to the total query execution time. For example, if your condition is UPPER (V_NAME) = 'JIM', try to use V_NAME = 'Jim' if all names in the V_NAME column are stored with proper capitalization.\\n•\\n Numeric field comparisons are faster than character, date, and NULL comparisons. In search conditions, comparing a numeric attribute to a numeric literal is faster than comparing a character attribute to a character literal. In general, the CPU handles numeric comparisons (integer and decimal) faster than character and date compari-sons. Because indexes do not store references to null values, NULL conditions involve additional processing, and therefore tend to be the slowest of all conditional operands.\\n•\\n Equality comparisons are generally faster than inequality comparisons. For example, P_PRICE = 10.00 is processed faster because the DBMS can do a direct search using the index in the column. If there are no exact matches, the condition is evaluated as false. However, if you use an inequality symbol (>, >=, <, <=), the DBMS must per -\\nform additional processing to complete the request, because there will almost always be more “greater than” or “less than” values in the index than “equal” values. With the exception of NULL, the slowest of all comparison operators is LIKE with wildcard symbols, as in V_CONTACT LIKE “%glo%” . Also, using the “not equal” symbol (< >) yields slower searches, especially when the sparsity of the data is high—that is, when there are many more different values than there are equal values.11-5b  Conditional Expressions\\nA conditional expression is normally placed within the WHERE or HAVING clauses of a SQL statement. Also known as conditional criteria, a conditional expression restricts the output of a query to only the rows that match the conditional criteria. Generally, the conditional criteria have the form shown in Table 11.6.\\nTABLE 11.6\\nCONDITIONAL CRITERIA\\nOPERAND1 CONDITIONAL OPERATOR OPERAND2\\nP_PRICE > 10.00\\nV_STATE = FL\\nV_CONTACT LIKE Smith%\\nP_QOH > P_MIN * 1.10\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bec5ce94-446d-450f-a526-8f83687317ec', embedding=None, metadata={'page_label': '534', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"534   Part 4    Advanced Database Concepts\\n11-6  Query Formulation\\nQueries are usually written to answer questions. For example, if an end user gives you a \\nsample output and tells you to match that output format, you must write the correspond-ing SQL. To get the job done, you must carefully evaluate what columns, tables, and •\\n Whenever possible, transform conditional expressions to use literals. For example, if \\nyour condition is P_PRICE − 10 = 7, change it to read P_PRICE = 17. Also, if you have a composite condition such as:\\n  P_QOH < P_MIN AND P_MIN = P_REORDER AND P_QOH = 10\\n  change it to read:\\n  P_QOH = 10 AND P_MIN = P_REORDER AND P_MIN > 10\\n• When using multiple conditional expressions, write the equality conditions first. Note that this was done in the previous example. Remember, equality conditions are faster to process than inequality conditions. Although most RDBMSs will automatically do this for you, paying attention to this detail lightens the load for the query optimizer. The optimizer will not have to do what you have already done.\\n•\\n If you use multiple AND conditions, write the condition most likely to be false first. If you use this technique, the DBMS will stop evaluating the rest of the conditions as soon as it finds a conditional expression that is evaluated as false. Remember, for multiple AND conditions to be found true, all conditions must be evaluated as true. If one of the conditions evaluates to false, the whole set of conditions will be evaluated as false. If you use this technique, the DBMS will not waste time unnecessarily evalu-ating additional conditions. Naturally, the use of this technique implies knowledge of the sparsity of the data set. For example, look at the following condition list:\\n  P_PRICE > 10 AND V_STATE = 'FL'\\n  If you know that only a few vendors are located in Florida, you could rewrite this condition as:\\n  V_STATE = 'FL' AND P_PRICE > 10\\n• When using multiple OR conditions, put the condition most likely to be true first. By doing this, the DBMS will stop evaluating the remaining conditions as soon as it finds a conditional expression that is evaluated as true. Remember, for multiple OR conditions to evaluate to true, only one of the conditions must be evaluated as true.\\n•\\n Whenever possible, try to avoid the use of the NOT logical operator. It is best to trans-form a SQL expression that contains a NOT logical operator into an equivalent expression. For example:\\n  NOT (P_PRICE > 10.00) can be written as P_PRICE <= 10.00.\\n  Also, NOT (EMP_SEX = 'M') can be written as EMP_SEX = 'F'.\\nOracle does not evaluate queries as described here. Instead, Oracle evaluates conditions from last to first.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4be0a010-1eea-4c6f-9eb5-0a41664ed533', embedding=None, metadata={'page_label': '535', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 11    Database Performance Tuning and Query Optimization    535\\ncomputations are required to generate the desired output. To do that, you must have a \\ngood understanding of the database environment and the database that will be the focus of your SQL code.\\nThis section focuses on SELECT queries because they are the queries you will find in \\nmost applications. To formulate a query, you would normally follow these steps:\\n1.\\n Identify what columns and computations are required. The first step is needed to clearly \\ndetermine what data values you want to return. Do you want to return just the names and addresses, or do you also want to include some computations? Remember that all columns in the SELECT statement should return single values.\\n  a.  Do you need simple expressions? For example, do you need to multiply the price by the quantity on hand to generate the total inventory cost? Y ou might need some single attribute functions such as DATE(), SYSDATE(), or ROUND().\\n  b.  Do you need aggregate functions? If you need to compute the total sales by prod-uct, you should use a GROUP BY clause. In some cases, you might need to use a subquery.\\n  c.  Determine the granularity of the raw data required for your output. Sometimes, you might need to summarize data that is not readily available in any table. In such cases, you might consider breaking the query into multiple subqueries and storing those subqueries as views. Then you could create a top-level query that joins those views and generates the final output.\\n2.\\n Identify the source tables. Once you know what columns are required, you can deter -\\nmine the source tables used in the query. Some attributes appear in more than one table. In those cases, try to use the least number of tables in your query to minimize the number of join operations.\\n3.\\n Determine how to join the tables. Once you know what tables you need in your query statement, you must properly identify how to join the tables. In most cases, you will use some type of natural join, but in some instances, you might need to use an outer join.\\n4.\\n Determine what selection criteria are needed. Most queries involve some type of selection criteria. In this case, you must determine what operands and operators are needed in your criteria. Ensure that the data type and granularity of the data in the comparison criteria are correct.\\n  a.  Simple comparison . In most cases, you will be comparing single values—for \\n example, P_PRICE > 10.\\n  b.  Single value to multiple values . If you are comparing a single value to multiple \\n values, you might need to use an IN comparison operator—for example, V_STATE IN ('FL', 'TN', 'GA').\\n  c.  Nested comparisons . In other cases, you might need to have some nested  selection \\ncriteria involving subqueries—for example, P_PRICE >= (SELECT AVG (P_PRICE) FROM PRODUCT).\\n  d.  Grouped data selection . On other occasions, the selection criteria might apply \\nnot to the raw data but to the aggregate data. In those cases, you need to use the \\n HAVING clause.\\n5. Determine the order in which to display the output. Finally, the required output might be ordered by one or more columns. In those cases, you need to use the ORDER BY clause. Remember that the ORDER BY clause is one of the most resource-intensive operations for the DBMS.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4f0c573f-7227-4288-8b58-b6e011b3d6e4', embedding=None, metadata={'page_label': '536', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='536   Part 4    Advanced Database Concepts\\n11-7  DBMS Performance Tuning\\nDBMS performance tuning includes global tasks such as managing the DBMS  processes \\nin primary memory (allocating memory for caching purposes) and managing the \\n structures in physical storage (allocating space for the data files).\\nFine-tuning the performance of the DBMS also includes applying several practices \\nexamined in the previous section. For example, the DBA must work with  developers to \\nensure that the queries perform as expected—creating the indexes to speed up query \\nresponse time and generating the database statistics required by cost-based optimizers.\\nDBMS performance tuning at the server end focuses on setting the parameters used for:\\n• Data cache . The data cache size must be set large enough to permit as many data \\nrequests as possible to be serviced from the cache. Each DBMS has settings that con-trol the size of the data cache; some DBMSs might require a restart. This cache is shared among all database users. The majority of primary memory resources will be allocated to the data cache.\\n•\\n SQL cache . The SQL cache stores the most recently executed SQL statements (after the \\nSQL statements have been parsed by the optimizer). Generally, if you have an applica-tion with multiple users accessing a database, the same  query will likely be submitted \\nby many different users. In those cases, the DBMS will parse the query only once and execute it many times, using the same access plan. In that way, the second and subse-quent SQL requests for the same query are served from the SQL cache, skipping the parsing phase.\\n•\\n Sort cache . The sort cache is used as a temporary storage area for ORDER BY or \\nGROUP BY operations, as well as for index-creation functions.\\n• Optimizer mode. Most DBMSs operate in one of two optimization modes: cost-based or rule-based. Others automatically determine the optimization mode based on whether database statistics are available. For example, the DBA is responsible for gen-erating the database statistics that are used by the cost-based optimizer. If the statistics are not available, the DBMS uses a rule-based optimizer.\\nFrom the performance point of view, it would be optimal to have the entire \\n database \\nstored in primary memory to minimize costly disk access. This is why several data-base vendors offer in-memory database options for their main products. In-memory \\n database systems are optimized to store large portions (if not all) of the database in primary (RAM) storage rather than secondary (disk) storage. These systems are becom-ing popular because increasing performance demands of modern database applications (such as Business Analytics and Big Data), diminishing costs, and technology advances of components (such as flash-memory and solid state drives.) Even though these type of databases “eliminate” disk access bottlenecks, they are still subject to query optimization and performance tuning rules, especially when faced with poorly designed databases or poorly written SQL statements.\\nAlthough in-memory databases are carving a niche in selected markets, most data-\\nbase implementations still rely on data stored on disk drives. That is why managing the physical storage details of the data files plays an important role in DBMS performance tuning. Note the following general recommendations for physical storage of databases:\\n•\\n Use I/O accelerators. This type of device uses flash solid-state drives (SSD) to store the \\ndatabase. A solid-state drive does not have any moving parts and, therefore  performs \\nI/O operations at a higher speed than traditional rotating disk drives. I/O  accelerators \\ndeliver high transaction performance rates and reduce contention caused by typical \\nstorage drives.in-memory database\\nA database optimized to store large portions (if not all) of the database in primary (RAM) storage rather than secondary (disk) storage.\\nI/O accelerator\\nA device used to improve throughput for input/output operations.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='294e35a4-5f87-4cbf-8dd3-4e405dca1666', embedding=None, metadata={'page_label': '537', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    537\\n• Minimize disk contention. Use multiple, independent storage volumes with indepen-\\ndent spindles (rotating disks) to minimize hard disk cycles. Remember, a database is composed of many table spaces, each with a particular function. In turn, each table space is composed of several data files in which the data is actually stored. A database should have at least the following table spaces:\\n  –  System table space . This is used to store the data dictionary tables. It is the most \\nfrequently accessed table space and should be stored in its own volume.\\n  –  User data table space. This is used to store end-user data. Y ou should create as many user data table spaces and data files as are required to balance performance and usability. For example, you can create and assign a different user data table space for each application and each distinct group of users, but this is not \\n necessary for \\neach user.\\n  –  Index table space . This is used to store indexes. Y ou can create and assign a  different \\nindex table space for each application and each group of users. The index table space data files should be stored on a storage volume that is separate from user data files or system data files.\\n  –  Temporary table space . This is used as a temporary storage area for merge, sort, \\nor set aggregate operations. Y ou can create and assign a different temporary table space for each application and each group of users.\\n  – Rollback segment table space . This is used for transaction-recovery purposes.\\n• Put high-usage tables in their own table spaces so the database minimizes conflict with other tables.•\\n Use RAID ( Redundant A rray of Independent D isks) to provide both performance \\nimprovement and fault tolerance, and a balance between them. Fault tolerance means that in case of failure, data can be reconstructed and retrieved. RAID systems use multiple disks to create virtual disks (storage volumes) formed by several individual disks. Table 11.7 describes the most common RAID configurations.\\nRAID\\nAn acronym for Redundant Array of Independent Disks. RAID systems use multiple disks to create virtual disks (storage volumes) from several individual disks. RAID systems provide performance improvement, fault tolerance, and a balance between the two.TABLE 11.7\\nCOMMON RAID LEVELS\\nRAID LEVEL DESCRIPTION\\n0 The data blocks are spread over separate drives. Also known as striped array. Provides increased performance but no fault tolerance. Requires a minimum of two drives.\\n1 The same data blocks are written (duplicated) to separate drives. Also referred to as mirroring or duplexing. Provides increased read performance and fault tolerance via data redundancy. \\n Requires\\xa0a minimum of two drives.\\n3 The data is striped across separate drives, and parity data is computed and stored in a  dedicated \\ndrive. (Parity data is specially generated data that permits the reconstruction of corrupted or missing data.) Provides good read performance and fault tolerance via parity data. Requires a minimum of three drives.\\n5 The data and the parity data is striped across separate drives. Provides good read performance and fault tolerance via parity data. Requires a minimum of three drives.\\n1+0 The data blocks are spread over separate drives and mirrored (duplicated). This arrangement provides both speed and fault tolerance. This is the recommended RAID configuration for most database installations (if cost is not an issue).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b620428f-326b-45a6-921f-9b0dc1b1e203', embedding=None, metadata={'page_label': '538', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='538   Part 4    Advanced Database Concepts\\n• Assign separate data files in separate storage volumes for the indexes, system, and \\nhigh-usage tables. This ensures that index operations will not conflict with end-user data or data dictionary table access operations. Another advantage of this approach is that you can use different disk block sizes in different volumes. For example, the data volume can use a 16 K block size, while the index volume can use an 8 K block size. Remember that the index record size is generally smaller, and by changing the block size you will reduce contention and minimize I/O operations. This is very important; many database administrators overlook indexes as a source of contention. By using separate storage volumes and different block sizes, the I/O operations on data and indexes will happen asynchronously (at different times); more importantly, the likelihood of write operations blocking read operations is reduced, as page locks tend to lock fewer records.\\n•\\n Take advantage of the various table storage organizations available in the database. For example, in Oracle consider the use of index-organized tables (IOT); in SQL Server, consider clustered index tables. An index-organized table (or clustered index table) is a table that stores the end-user data and the index data in \\n consecutive \\n locations on permanent storage. This type of storage organization provides a perfor -\\nmance advantage to tables that are commonly accessed through a given index order, because the index contains the index key as well as the data rows. Therefore, the DBMS tends to perform fewer I/O operations.\\n•\\n Partition tables based on usage. Some RDBMSs support the horizontal partitioning of tables based on attributes. (See Chapter 12, Distributed Database Management  \\nSystems.) By doing so, a single SQL request can be processed by multiple data  \\nprocessors. Put the table partitions closest to where they are used the most.\\n•\\n Use denormalized tables where appropriate. In other words, you might be able to improve performance by taking a table from a higher normal form to a lower normal form—typically, from third to second normal form. This technique adds data duplica-tion, but it minimizes join operations. (Denormalization was discussed in Chapter\\xa06, Normalization of Database Tables.)\\n•\\n Store computed and aggregate attributes in tables. In short, use derived attributes in your tables. For example, you might add the invoice subtotal, the amount of tax, and the total in the INVOICE table. Using derived attributes minimizes computations in queries and join operations, especially during the execution of aggregate queries.\\n11-8  Query Optimization Example\\nNow that you have learned the basis of query optimization, you are ready to test your new knowledge. A simple example illustrates how the query optimizer works and how you can help it work. The example is based on the QOVENDOR and QOPRODUCT tables, which are similar to tables you used in previous chapters. However, the QO prefix is used for the table name to ensure that you do not overwrite previous tables.\\nTo perform this query optimization example, you will use the Oracle SQL*Plus \\ninterface. Some preliminary work must be done before you can start testing query optimization, as explained in the following steps:\\n1.\\n Log in to Oracle SQL*Plus using the username and password provided by your instructor.\\n2. Create a fresh set of tables, using the QRYOPTDATA.SQL script file (available at \\nwww.cengagebrain.com). This step is necessary so that Oracle has a new set of tables and the new tables contain no statistics. At the SQL> prompt, type:\\n @path\\\\QRYOPTDATA.SQL\\n where path  is the location of the file in your computer.index organized table\\nIn a DBMS, a type of table storage organization that stores end-user data and index data in consecutive locations in permanent storage. Also known as cluster-indexed table.\\nclustered index table\\nSee index organized table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bb352b01-b3dd-4da3-ad72-2f6907a65068', embedding=None, metadata={'page_label': '539', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    539\\nTo see the access plan used by the DBMS to execute your query, use the EXPLAIN \\nPLAN and SELECT statements, as shown in Figure 11.5. Note that the first SQL state-\\nment generates the statistics for the QOVENDOR table. Also, the initial access plan in Figure 11.5 uses a full table scan on the QOVENDOR table, and the cost of the plan is 4.3.\\n Create the PLAN_TABLE, which is a special table used by Oracle to store the \\naccess plan information for a given query. End users can then query the PLAN_TABLE to see how Oracle will execute the query. To create the PLAN_TABLE, run the UTLXPLAN.SQL script file in the RDBMS\\\\ADMIN folder of your Oracle RDBMS installation. The UTLXPLAN.SQL script file is also available at www.cengagebrain.com. At the SQL prompt, type:\\n @path\\\\UTLXPLAN.SQL\\nY ou use the EXPLAIN PLAN command to store the execution plan of a SQL query \\nin the PLAN_TABLE. Then, you use the SELECT * FROM TABLE(DBMS_XPLAN.  \\nDISPLAY) command to display the access plan for a given SQL statement.\\nOracle 12c, MySQL, and SQL Server all default to cost-based optimization. In Oracle, if table statistics are not available, the DBMS will fall back to a rule-based optimizer.Note\\nFIGURE 11.5  INITIAL EXPLAIN PLAN  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9dd8e443-0c22-4865-a58c-a6333a31e634', embedding=None, metadata={'page_label': '540', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='540   Part 4    Advanced Database Concepts\\nNow create an index on V_AREACODE (note that V_AREACODE is used in the \\nORDER BY clause) and see how it affects the access plan generated by the cost-based \\noptimizer. The results are shown in Figure 11.6.\\nFIGURE 11.6  EXPLAIN PLAN AFTER INDEX ON V_AREACODE  \\nIn Figure 11.6, note that the new access plan cuts the cost of executing the query by \\n30 percent! Also note that this new plan scans the QOV_NDX1 index and accesses the QOVENDOR rows, using the index row ID. (Remember that access by row ID is one of the fastest access methods.) In this case, the creation of the QOV_NDX1 index had a positive impact on overall query optimization results.\\nAt other times, indexes do not necessarily help in query optimization, such as when \\nyou have indexes on small tables or when the query accesses a great percentage of table rows anyway. Note what happens when you create an index on V_NAME. The new access plan is shown in Figure 11.7. (Note that V_NAME is used on the WHERE clause as a conditional expression operand.)\\nAs you can see in Figure 11.7, creation of the second index did not help the query \\noptimization. However, on some occasions an index might be used by the optimizer, but it is not executed because of the way the query is written. For example, Figure 11.8 shows the access plan for a different query using the V_NAME column.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aa8e1f83-401f-4f84-abbe-d5d654d54f76', embedding=None, metadata={'page_label': '541', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    541\\nFIGURE 11.7  EXPLAIN PLAN AFTER INDEX ON V_NAME  \\nFIGURE 11.8  ACCESS PLAN USING INDEX ON V_NAME  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='23c2d58f-4a9d-4ecd-906d-b13fbad109ce', embedding=None, metadata={'page_label': '542', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='542   Part 4    Advanced Database Concepts\\nIn Figure 11.8, note that the access plan for this new query uses the QOV_NDX2 \\nindex on the V_NAME column. What would happen if you wrote the same query, using \\nthe UPPER function on V_NAME? The results are illustrated in Figure 11.9.\\nFIGURE 11.9  ACCESS PLAN USING FUNCTIONS ON INDEXED COLUMNS  \\nAs Figure 11.9 shows, the use of a function on an indexed column caused the DBMS \\nto perform additional operations that could potentially increase the cost of the query. The same query might produce different costs if your tables contain many more rows and if the index sparsity is different.\\nNow use the QOPRODUCT table to demonstrate how an index can help when aggre-\\ngate function queries are being run. For example, Figure 11.10 shows the access plan for a SELECT statement using the MAX(P_PRICE) aggregate function. This plan uses a full table scan with a total cost of 3.\\nA cost of 3 is very low already, but you could improve the previous query performance \\nby creating an index on P_PRICE. Figure 11.11 shows how the plan cost is reduced by two-thirds after the index is created and the QOPRODUCT table is analyzed. Also note that the second version of the access plan uses only the index QOP_NDX2 to answer the query; the QOPRODUCT table is never accessed.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61027164-c021-438a-9bd4-0a7e757c061d', embedding=None, metadata={'page_label': '543', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    543\\nFIGURE 11.11  SECOND EXPLAIN PLAN: AGGREGATE FUNCTION ON AN INDEXED COLUMN  \\nFIGURE 11.10  FIRST EXPLAIN PLAN: AGGREGATE FUNCTION ON A NON-INDEXED COLUMN  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c000a49a-2234-4c40-9bca-9e221a9d0e0f', embedding=None, metadata={'page_label': '544', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='544   Part 4    Advanced Database Concepts\\nFIGURE 11.12  ORACLE TOOLS FOR QUERY OPTIMIZATION  \\nAlthough the few examples in this section show the importance of proper index \\n selection for query optimization, you also saw examples in which index creation does \\nnot improve query performance. As a DBA, you should be aware that the main goal is to \\n optimize overall database performance—not just for a single query but for all requests and query types. Most database systems provide advanced graphical tools for \\n performance \\nmonitoring and testing. For example, Figures 11.12, 11.13, and 11.4 show the graphical representation of the access plan using Oracle, MySQL, and MS SQL Server tools.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4850fec2-976d-4dae-81d3-d7bca0149523', embedding=None, metadata={'page_label': '545', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    545\\nFIGURE 11.13  MYSQL TOOLS FOR QUERY OPTIMIZATION  \\nFIGURE 11.14  MICROSOFT SQL SERVER TOOLS FOR QUERY OPTIMIZATION  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f9f78ef-7247-4e4a-83f6-4e7dc8ca3df1', embedding=None, metadata={'page_label': '546', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='546   Part 4    Advanced Database Concepts\\nSummary\\n• Database performance tuning refers to a set of activities and procedures designed to \\nensure that an end-user query is processed by the DBMS in the least amount of time. SQL performance tuning refers to activities on the client side that are designed to gen-erate SQL code that returns the correct answer in the least amount of time, using the minimum amount of resources at the server end. DBMS performance tuning refers to activities on the server side that are oriented so the DBMS is properly configured to respond to clients’ requests in the fastest way possible while making optimum use of existing resources.\\n•\\n Database statistics refer to a number of measurements gathered by the DBMS that describe a snapshot of the database objects’ characteristics. The DBMS gathers statistics about objects such as tables, indexes, and available resources, which include the number of processors used, processor speed, and temporary space available. The DBMS uses the statistics to make critical decisions about improving query processing efficiency.\\n•\\n DBMSs process queries in three phases. In the parsing phase, the DBMS parses the SQL query and chooses the most efficient access/execution plan. In the \\n execution \\nphase,\\xa0the DBMS executes the SQL query using the chosen execution plan. In the fetching phase, the DBMS fetches the data and sends the result set back to the client.\\n•\\n Indexes are crucial in the process that speeds up data access. Indexes facilitate search-ing, sorting, and using aggregate functions and join operations. The improvement  \\nin data access speed occurs because an index is an ordered set of values that contains the index key and pointers. Data sparsity refers to the number of different values a column could have. Indexes are recommended in high-sparsity columns used in search conditions.\\n•\\n During query optimization, the DBMS must choose what indexes to use, how to  \\nperform join operations, which table to use first, and so on. Each DBMS has its own algorithms for determining the most efficient way to access the data. The two most common approaches are rule-based and cost-based optimization.\\n•\\n A rule-based optimizer uses preset rules and points to determine the best approach to execute a query. A cost-based optimizer uses sophisticated algorithms based on statistics about the objects being accessed to determine the best approach to execute a query. In this case, the optimizer process adds up the processing cost, the I/O costs, and the resource costs (RAM and temporary space) to determine the total cost of  \\na given execution plan.\\n•\\n SQL performance tuning deals with writing queries that make good use of the \\n statistics. In particular, queries should make good use of indexes. Indexes are very useful when you want to select a small subset of rows from a large table based on  \\na condition.\\n•\\n Query formulation deals with how to translate business questions into specific SQL code to generate the required results. To do this, you must carefully evaluate which columns, tables, and computations are required to generate the desired output.\\n•\\n DBMS performance tuning includes tasks such as managing the DBMS processes in primary memory (allocating memory for caching purposes) and managing the \\n structures in physical storage (allocating space for the data files).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dc816717-2fed-472e-b338-1290671f8c6b', embedding=None, metadata={'page_label': '547', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    547\\naccess plan\\nautomatic query \\noptimization\\nbitmap indexB-tree indexbuffer cacheclustered index tablecost-based optimizerdatabase performance \\ntuning\\ndatabase statisticsdata cachedata filesdata sparsityDBMS performance tuningdynamic query optimizationdynamic statistical \\n generation mode\\nextentsfile groupfunction-based indexhash indexin-memory databaseindex-organized tableindex selectivityinput/output (I/O) requestI/O acceleratormanual query optimizationmanual statistical \\n generation modeoptimizer hintsprocedure cachequery optimizerquery processing \\nbottleneck\\nRAIDrule-based optimizerrule-based query \\n optimization algorithm\\nstatic query optimizationstatistically based query \\noptimization algorithm\\nSQL cacheSQL performance tuningtable spaceKey Terms\\nFlashcards and crossword \\npuzzles for key term  practice are available at www.cengagebrain.com.Online \\nContent\\n1. What is SQL performance tuning?\\n2. What is database performance tuning?\\n3. What is the focus of most performance-tuning activities, and why does that focus exist?\\n4. What are database statistics, and why are they important?\\n5. How are database statistics obtained?\\n6. What database statistics measurements are typical of tables, indexes, and resources?\\n7. How is the processing of SQL DDL statements (such as CREATE TABLE) different \\nfrom the processing required by DML statements?\\n8. In simple terms, the DBMS processes a query in three phases. What are the phases, and what is accomplished in each phase?\\n9.\\n If indexes are so important, why not index every column in every table? (Include a brief discussion of the role played by data sparsity.)\\n10.\\n What is the difference between a rule-based optimizer and a cost-based optimizer?\\n11. What are optimizer hints, and how are they used?\\n12. What are some general guidelines for creating and using indexes?\\n13. Most query optimization techniques are designed to make the optimizer’s work \\n easier. What factors should you keep in mind if you intend to write conditional expressions in SQL code?Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e8e67d7-1e5c-4d28-b1b5-cb98c7e17812', embedding=None, metadata={'page_label': '548', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"548   Part 4    Advanced Database Concepts\\nProblems\\nProblems 1 and 2 are based on the following query:\\nSELECT EMP_LNAME, EMP_FNAME, EMP_AREACODE, EMP_SEX\\nFROM EMPLOYEE\\nWHERE EMP_SEX = 'F' AND EMP_AREACODE = '615'ORDER BY EMP_LNAME, EMP_FNAME;\\n1.\\n What is the likely data sparsity of the EMP_SEX column?\\n2. What indexes should you create? Write the required SQL commands.\\n3. Using Table 11.4 as an example, create two alternative access plans. Use the following \\nassumptions:\\n  a. There are 8,000 employees.\\n  b. There are 4,150 female employees.\\n  c. There are 370 employees in area code 615.\\n  d. There are 190 female employees in area code 615.\\nProblems 4−6 are based on the following query:\\nSELECT EMP_LNAME, EMP_FNAME, EMP_DOB, YEAR(EMP_DOB) AS YEAR\\nFROM EMPLOYEE\\nWHERE YEAR(EMP_DOB) = 1976;\\n4. What is the likely data sparsity of the EMP_DOB column?\\n5. Should you create an index on EMP_DOB? Why or why not?\\n6. What type of database I/O operations will likely be used by the query? (See Table 11.3.)\\nProblems 7−10 are based on the ER model shown in Figure P11.7 and on the query \\nshown after the figure.\\nSELECT P_CODE, P_PRICE\\nFROM PRODUCT\\nWHERE P_PRICE >= (SELECT AVG(P_PRICE) FROM PRODUCT);\\n7. Assuming there are no table statistics, what type of optimization will the DBMS use?\\n8. What type of database I/O operations will likely be used by the query? (See \\nTable\\xa011.3.)\\n9. What is the likely data sparsity of the P_PRICE column?\\n10. Should you create an index? Why or why not?14. What recommendations would you make for managing the data files in a DBMS with many tables and indexes?\\n15.\\n What does RAID stand for, and what are some commonly used RAID levels?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61fdafd8-8d83-4def-8abb-d31ccae167ad', embedding=None, metadata={'page_label': '549', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 11    Database Performance Tuning and Query Optimization    549\\nFIGURE P11.7  THE CH11_SALECO ER MODEL  \\nProblems 11−14 are based on the following query:\\nSELECT P_CODE, SUM(LINE_UNITS)\\nFROM LINE\\nGROUP BY P_CODE\\nHAVING SUM(LINE_UNITS) > (SELECT MAX(LINE_UNITS) FROM LINE);\\n11. What is the likely data sparsity of the LINE_UNITS column?\\n12. Should you create an index? If so, what would the index column(s) be, and why \\nwould you create the index? If not, explain your reasoning.\\n13. Should you create an index on P_CODE? If so, write the SQL command to create the \\nindex. If not, explain your reasoning.\\n14. Write the command to create statistics for this table.\\nProblems 15 and 16 are based on the following query:\\nSELECT P_CODE, P_QOH*P_PRICE\\nFROM PRODUCT\\nWHERE P_QOH*P_PRICE > (SELECT AVG(P_QOH*P_PRICE)  \\nFROM PRODUCT);\\n15. What is the likely data sparsity of the P_QOH and P_PRICE columns?\\n16. Should you create an index? If so, what would the index column(s) be, and why \\nshould you create the index?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='95c9ba3b-8874-4e59-a76e-56e5f10e6952', embedding=None, metadata={'page_label': '550', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"550   Part 4    Advanced Database Concepts\\nProblems 17−21 are based on the following query:\\nSELECT V_CODE, V_NAME, V_CONTACT, V_STATE\\nFROM VENDOR\\nWHERE V_STATE = 'TN'ORDER BY V_NAME;\\n17.\\n What indexes should you create and why? Write the SQL command to create the \\nindexes.\\n18. Assume that 10,000 vendors are distributed as shown in Table P11.18. What \\n percentage of rows will be returned by the query?\\nTABLE P11.18\\nSTATE NUMBER OF VENDORS STATE NUMBER OF VENDORS\\nAK 15 MS 47\\nAL 55 NC 358\\nAZ 100 NH 25\\nCA 3244 NJ 645\\nCO 345 NV 16\\nFL 995 OH 821\\nGA 75 OK 62\\nHI 68 PA 425\\nIL 89 RI 12\\nIN 12 SC 65\\nKS 19 SD 74\\nKY 45 TN 113\\nLA 29 TX 589\\nMD 208 UT 36\\nMI 745 VA 375\\nMO 35 WA 258\\n19. What type of I/O database operations would most likely be used to execute the query?\\n20.\\n Using Table 11.4 as an example, create two alternative access plans.\\n21. Assume that you have 10,000 different products stored in the PRODUCT table and that you are writing a web-based interface to list all products with a quantity on hand (P_QOH) that is less than or equal to the minimum quantity, P_MIN. What optimizer hint would you use to ensure that your query returns the result set to the web interface in the least time possible? Write the SQL code.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='14157f39-e3d6-4675-8c74-f91427b65fd6', embedding=None, metadata={'page_label': '551', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 11    Database Performance Tuning and Query Optimization    551\\nProblems 22−24 are based on the following query:\\nSELECT P_CODE, P_DESCRIPT, P_PRICE, P .V_CODE, V_STATE\\nFROM PRODUCT P , VENDOR V\\nWHERE P .V_CODE = V .V_CODE\\nAND V_STATE = 'NY'AND V_AREACODE = '212'\\nORDER BY P_PRICE;\\n22.\\n What indexes would you recommend?\\n23. Write the commands required to create the indexes you recommended in Problem 22.\\n24. Write the command(s) used to generate the statistics for the PRODUCT and \\n VENDOR tables.\\nProblems 25 and 26 are based on the following query:\\nSELECT P_CODE, P_DESCRIPT, P_QOH, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE V_CODE = '21344'ORDER BY P_CODE;\\n25.\\n What index would you recommend, and what command would you use?\\n26. How should you rewrite the query to ensure that it uses the index you created in \\nyour solution to Problem 25?\\nProblems 27 and 28 are based on the following query:\\nSELECT P_CODE, P_DESCRIPT, P_QOH, P_PRICE, V_CODE\\nFROM PRODUCT\\nWHERE P_QOH < P_MIN\\nAND P_MIN = P_REORDERAND P_REORDER = 50\\nORDER BY P_QOH;\\n27.\\n Use the recommendations given in Section 11-5b to rewrite the query and produce \\nthe required results more efficiently.\\n28. What indexes would you recommend? Write the commands to create those indexes.\\nProblems 29−32 are based on the following query:\\nSELECT CUS_CODE, MAX(LINE_UNITS*LINE_PRICE)\\nFROM CUSTOMER NATURAL JOIN INVOICE NATURAL JOIN LINE\\nWHERE CUS_AREACODE = '615'GROUP BY CUS_CODE;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5dac734a-b9a3-4c72-a80e-bebdebef8962', embedding=None, metadata={'page_label': '552', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='552   Part 4    Advanced Database Concepts\\n29. Assuming that you generate 15,000 invoices per month, what recommendation \\nwould you give the designer about the use of derived attributes?\\n30. Assuming that you follow the recommendations you gave in Problem 29, how would you rewrite the query?\\n31.\\n What indexes would you recommend for the query you wrote in Problem 30, and what SQL commands would you use?\\n32.\\n How would you rewrite the query to ensure that the index you created in Problem 31 is used?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dc7d1328-4f4a-42cf-8dfa-e9083af13743', embedding=None, metadata={'page_label': '553', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12\\nDistributed Database Management Systems\\nIn this chapter, you will learn:\\n• About distributed database management systems (DDBMSs) and their components\\n• How database implementation is affected by different levels of data and process distribution\\n• How transactions are managed in a distributed database environment\\n• How distributed database design draws on data partitioning and replication to balance \\n performance, scalability, and availability\\n• About the trade-offs of implementing a distributed data system\\nPreviewIn this chapter, you will learn that a single database can be divided into several fragments \\nstored on different computers within a geographically dispersed network. Processing also can be dispersed among several different network sites, or nodes.\\nThe growth of distributed database systems has been fostered by the increased global-\\nization of business operations, the accumulation of massive organizational data sets, and technological changes that have made distributed network-based services practical, more reliable, and cost-effective.\\nThe distributed database management system (DDBMS) treats a distributed database as \\na single logical database; therefore, the basic design concepts you learned in earlier chap-ters apply. However, the distribution of data among different sites in a computer network adds to the system’s complexity. For example, the design of a distributed database must consider the location of the data, partitioning the data into fragments, and replication of those fragments. Although a distributed database system requires a more sophisticated DBMS, the greater complexity of a distributed database system should be transparent to the end user.\\nIn today’s web-centric environment, any distributed data system must be highly scal-\\nable; in other words, it must grow dynamically as demand increases. To accommodate such dynamic growth, trade-offs must be made to achieve some desirable properties.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH12_Text              P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fc83b60b-bdd8-46d3-ba4f-77c9993ac152', embedding=None, metadata={'page_label': '554', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='554   Part 4     Advanced Database Concepts\\n12-1   The Evolution of Distributed Database \\nManagement Systems\\nA distributed database management system (DDBMS)  governs the storage and pro -\\ncessing of logically related data over interconnected computer systems in which both \\ndata and processing are distributed among several sites. To understand how and why the \\nDDBMS is different from the DBMS, it is useful to briefly examine the changes in the \\nbusiness environment that set the stage for the development of the DDBMS.\\nDuring the 1970s, corporations implemented centralized database management sys -\\ntems to meet their structured information needs. The use of a centralized database required \\nthat corporate data be stored in a single central site, usually a mainframe  computer. Data \\naccess was provided through dumb terminals. The centralized approach, illustrated in \\nFigure 12.1, worked well to fill the structured information needs of  corporations, but it \\nfell short when quickly moving events required faster response times and equally quick \\naccess to information. The slow progression from information request to approval to \\nspecialist to user simply did not serve decision makers well in a dynamic environment. \\nWhat was needed was quick, unstructured access to databases, using ad hoc queries to \\ngenerate on-the-spot information.\\ndistributed database \\nmanagement system \\n(DDBMS)\\nA DBMS that supports \\na database distributed \\nacross several different \\nsites; a DDBMS \\ngoverns the storage \\nand processing of \\nlogically related data \\nover interconnected \\ncomputer systems in \\nwhich both data and \\nprocessing functions \\nare distributed among \\nseveral sites.FIGURE 12.1  CENTRALIZED DATABASE MANAGEMENT SYSTEM  \\nLocal databaseDBMS\\nDataRequest\\nReplyReadEnd user\\nApplication issues a data \\nrequest to the DBMS\\nThe last two decades gave birth to a series of crucial social and technological changes \\nthat affected the nature of the systems and the data they use:\\n• Business operations became global; with this change, competition expanded from the \\nshop on the next corner to the web store in cyberspace.\\n• Customer demands and market needs favored an on-demand transaction style, \\nmostly based on web-based services.\\n• Rapid social and technological changes fueled by low-cost, smart mobile devices \\nincreased the demand for complex and fast networks to interconnect them. As a con -\\nsequence, corporations have increasingly adopted advanced network technologies as \\nthe platform for their computerized solutions. See Chapter 15, Database Connectivity \\nand Web Technologies, for a discussion of cloud-based services.\\n• Data realms are converging in the digital world more frequently. As a result, appli -\\ncations must manage multiple types of data, such as voice, video, music, and images. \\nSuch data tends to be geographically distributed and remotely accessed from diverse \\nlocations via location-aware mobile devices.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='36065aee-9e7a-4a4d-91fc-e928d724821b', embedding=None, metadata={'page_label': '555', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    555\\n• The advent of social media as a way to reach new customers and open new markets \\nhas fueled the need to store large amounts of digital data and created a revolution in the way data is managed and mined for knowledge. Businesses are looking for new ways to gain business intelligence through the analysis of vast stores of structured and unstructured data.\\nThese factors created a dynamic business environment in which companies had to \\nrespond quickly to competitive and technological pressures. As large business units restructured to form leaner, quickly reacting, dispersed operations, two database \\n requirements became obvious:\\n• Rapid ad hoc data access  became crucial in the quick-response decision-making \\nenvironment.\\n• Distributed data access  was needed to support geographically dispersed business \\nunits.\\nDuring recent years, these factors became even more firmly entrenched. However, the \\nway they were addressed was strongly influenced by the following factors:•\\n The growing acceptance of the Internet as the platform for data access and distribution. \\nThe web is effectively the repository for distributed data.\\n• The mobile wireless revolution . The widespread use of mobile wireless digital devices \\nincludes smartphones and tablets. These devices have created high demand for data access. They access data from geographically dispersed locations and require varied data exchanges in multiple formats, such as data, voice, video, music, and pictures. Although distributed data access does not necessarily imply distributed databases, per -\\nformance and failure tolerance requirements often lead to the use of data \\n replication \\ntechniques similar to those in distributed databases.\\n• The accelerated growth of companies using “applications as a service. ” This new type of service provides remote applications to companies that want to outsource their application development, maintenance, and operations. The company data is gener -\\nally stored on central servers and is not necessarily distributed. Just as with mobile data access, this type of service may not require fully distributed data functionality; however, other factors such as performance and failure tolerance often require the use of data replication techniques similar to those in distributed databases.\\n•\\n The increased focus on mobile business intelligence. More and more companies are embracing mobile technologies within their business plans. As companies use social networks to get closer to customers, the need for on-the-spot decision making increases. Although a data warehouse is not usually a distributed database, it does rely on techniques such as data replication and distributed queries that facilitate data extraction and integration. (Y ou will learn more about this topic in Chapter 13, \\n Business Intelligence and Data Warehouses.)\\n• Emphasis on Big Data analytics. The era of mobile communications unraveled an \\n avalanche of data from many sources and of many types. Today’s customers have significant influence on the spending habits of communities, and organizations are investing in ways to harvest such data to “discover” new ways to effectively and \\n efficiently reach customers.\\nAt this point, the long-term impact of the Internet and the mobile revolution on \\n distributed  database design and management is just starting to be felt. Perhaps the  success \\nof the Internet and mobile technologies will foster the use of distributed databases as bandwidth becomes a less troublesome bottleneck. Perhaps the resolution of bandwidth problems will simply confirm the centralized database standard. In any case, distributed To learn more about the Internet’s impact on data access and distribution, see Appendix I, Databases in Electronic Commerce,  \\nat www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ed5b953-4b63-4edd-a5d6-012fa97d8893', embedding=None, metadata={'page_label': '556', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='556   Part 4    Advanced Database Concepts\\ndatabase concepts and components are likely to find a place in future database develop-\\nment, particularly for specialized mobile and location-aware applications.\\nThe distributed database is especially desirable because centralized database manage-\\nment is subject to problems such as:\\n• Performance degradation  because of a growing number of remote locations over \\ngreater distances.\\n• High costs associated with maintaining and operating large central (mainframe) data-\\nbase systems and physical infrastructure.\\n• Reliability problems created by dependence on a central site (single point of failure syndrome) and the need for data replication.\\n•\\n Scalability problems associated with the physical limits imposed by a single location, such as physical space, temperature conditioning, and power consumption.\\n•\\n Organizational rigidity imposed by the database, which means it might not support the flexibility and agility required by modern global organizations.\\nThe dynamic business environment and the centralized database’s shortcomings \\nspawned a demand for applications based on accessing data from different sources at multiple locations. Such a multiple-source/multiple-location database environment is best managed by a DDBMS.\\n12-2  DDBMS Advantages and Disadvantages\\nDistributed database management systems deliver several advantages over traditional systems. At the same time, they are subject to some problems. Table 12.1 summarizes the advantages and disadvantages associated with a DDBMS.\\nDistributed databases are being used successfully in many web staples such as Google \\nand Amazon, but they still have a long way to go before they yield the full flexibility and power they theoretically possess.\\nThe remainder of this chapter explores the basic components and concepts of the \\ndistributed database. Because the distributed database is usually based on the relational database model, relational terminology is used to explain the basic concepts and com-ponents. Even though some of the most widely used distributed databases are part of the NoSQL movement (see Chapter 2, Data Models), the basic concepts and fundamentals of distributed data still apply to them.\\n12-3   Distributed Processing and  Distributed Databases\\nIn distributed processing, a database’s logical processing is shared among two or more \\nphysically independent sites that are connected through a network. For example, the data input/output (I/O), data selection, and data validation might be performed on one computer, and a report based on that data might be created on another computer.\\nA basic distributed processing environment is illustrated in Figure 12.2, which shows \\nthat a distributed processing system shares the database processing chores among three sites connected through a communications network. Although the database resides at only one site (Miami), each site can access the data and update the database. The data-base is located on Computer A, a network computer known as the database server.\\nA distributed database, on the other hand, stores a logically related database \\nover two or more physically independent sites. The sites are connected via a computer distributed processing\\nSharing the logical processing of a database over two or more sites connected by a network.\\ndistributed database\\nA logically related database that is stored in two or more physically independent sites.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f367fe92-08e7-4a55-86f2-02caf4b976ea', embedding=None, metadata={'page_label': '557', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    557\\nnetwork. In contrast, the distributed processing system uses only a single-site database \\nbut shares the processing chores among several sites. In a distributed database system, a database is composed of several parts known as database fragments. The database fragments are located at different sites and can be replicated among various sites. Each database fragment is, in turn, managed by its local database process. An example of  \\na distributed database environment is shown in Figure 12.3.\\nThe database in Figure 12.3 is divided into three database fragments (E1, E2, and E3) \\nlocated at different sites. The computers are connected through a network system. In  \\na fully distributed database, the users Alan, Betty, and Hernando do not need to know the name or location of each database fragment in order to access the database. Also, the database fragment\\nA subset of a distributed database. Although the fragments may be stored at different sites within a computer network, the set of all fragments is treated as a single database. See also horizontal fragmentation and vertical fragmentation.TABLE 12.1\\nDISTRIBUTED DBMS ADVANTAGES AND DISADVANTAGES\\nADVANTAGES DISADVANTAGES\\nData is located near the site of greatest demand. The data in a distributed database system is dispersed to match business requirements.Complexity of management and control. Applications must recognize data location, and they must be able to stitch together data from various sites. Database admin-istrators must have the ability to coordinate database activities to prevent database degradation due to data anomalies.\\nFaster data access. End users often work with only the nearest stored subset of the data.Technological difficulty. Data integrity, transaction management, concurrency control, security, backup, recovery, and query optimization must all be addressed and resolved.\\nFaster data processing. A distributed database system spreads out the system’s workload by processing data at several sites.Security. The probability of security lapses increases when data is located at multiple sites. The responsibility of data management will be shared by different people at several sites.\\nGrowth facilitation. New sites can be added to the net-work without affecting the operations of other sites.Lack of standards. There are no standard communication protocols at the database level. For example, different database vendors employ different and often incompat-ible techniques to manage the distribution of data and processing in a DDBMS environment.\\nImproved communications. Because local sites are smaller and located closer to customers, local sites foster \\n better \\ncommunication among departments and between \\n customers and company staff.Increased storage and infrastructure requirements. Multiple copies of data are required at different sites, thus requiring additional storage space.\\nReduced operating costs. It is more cost-effective to add nodes to a network than to update a mainframe system. Development work is done more cheaply and quickly on low-cost PCs than on mainframes.Increased training cost. Training costs are generally higher in a distributed model than they would be in a centralized model, sometimes even to the extent of offsetting opera-tional and hardware savings.\\nUser-friendly interface. PCs and workstations are usually equipped with an easy-to-use graphical user interface (GUI). The GUI simplifies training and use for end users.Costs. Distributed databases require duplicated infrastruc-ture to operate, such as physical location, environment, personnel, software, and licensing.\\nLess danger of a single-point failure. When one of the computers fails, the workload is picked up by other \\n workstations. Data is also distributed at multiple sites.\\nProcessor independence. The end user can access any \\navailable copy of the data, and an end user’s request is processed by any processor at the data location.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='171910ee-2200-40d8-befd-812661e4cd31', embedding=None, metadata={'page_label': '558', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='558   Part 4     Advanced Database Concepts\\nFIGURE 12.3  DISTRIBUTED DATABASE ENVIRONMENT  \\nE1\\nE3 E2\\nSite 2\\nNew York user BettySite 3\\nAtlanta user HernandoDBMSComputer A\\nSite 1\\nMiami user Alan\\nCommunications network\\nDBMSComputer B\\nDBMSComputer CFIGURE 12.2  DISTRIBUTED PROCESSING ENVIRONMENT  \\nEmployee databaseSite 2\\nNew York user Donna\\nComputer B\\nDatabase records are processed in different locationsSite 3\\nAtlanta user Victor\\nComputer C\\nGenerate\\npayroll reportDBMSComputer A\\nSite 1\\nMiami user Joe\\nCommunications network\\nUpdate\\npayroll data\\nusers might be at sites other than Miami, New Y ork, or Atlanta and still be able to access \\nthe database as a single logical unit.\\nAs you examine Figures 12.2 and 12.3, keep the following points in mind:\\n• Distributed processing does not require a distributed database, but a distributed data -\\nbase requires distributed processing. (Each database fragment is managed by its own \\nlocal database process.)\\n• Distributed processing may be based on a single database located on a single com -\\nputer. For the management of distributed data to occur, copies or parts of the database \\nprocessing functions must be distributed to all data storage sites.\\n• Both distributed processing and distributed databases require a network of intercon -\\nnected components.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='429121dd-7acc-49a6-904d-9f93c342eca7', embedding=None, metadata={'page_label': '559', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    559\\n12-4   Characteristics of Distributed Database \\nManagement Systems\\nA DDBMS governs the storage and processing of logically related data over intercon-nected computer systems in which both data and processing functions are distributed among several sites. A DBMS must have at least the following functions to be classified as distributed:\\n•\\n Application interface  to interact with the end user, application programs, and other \\nDBMSs within the distributed database\\n• Validation  to analyze data requests for syntax correctness\\n• Transformation  to decompose complex requests into atomic data request components\\n• Query optimization  to find the best access strategy (which database fragments must be \\naccessed by the query, and how must data updates, if any, be synchronized?)\\n• Mapping  to determine the data location of local and remote fragments\\n• I/O interface to read or write data from or to permanent local storage\\n• Formatting  to prepare the data for presentation to the end user or to an application \\nprogram\\n• Security to provide data privacy at both local and remote databases\\n• Backup and recovery  to ensure the availability and recoverability of the database in \\ncase of a failure\\n• DB administration features  for the database administrator\\n• Concurrency control  to manage simultaneous data access and to ensure data  consistency \\nacross database fragments in the DDBMS\\n• Transaction management to ensure that the data moves from one consistent state to \\nanother; this activity includes the synchronization of local and remote transactions as well as transactions across multiple distributed segments\\nA fully distributed database management system must perform all of the functions of \\na centralized DBMS, as follows:\\n1.\\n Receive the request of an application or end user.\\n2. Validate, analyze, and decompose the request. The request might include  mathematical \\nand logical operations such as the following: Select all customers with a balance \\ngreater than $1,000. The request might require data from only a single table, or it might require access to several tables.\\n3.\\n Map the request’s logical-to-physical data components.\\n4. Decompose the request into several disk I/O operations.\\n5. Search for, locate, read, and validate the data.\\n6. Ensure database consistency, security, and integrity.\\n7. Validate the data for the conditions, if any, specified by the request.\\n8. Present the selected data in the required format.\\nIn addition, a distributed DBMS must handle all necessary functions imposed by the \\ndistribution of data and processing, and it must perform those additional functions trans -\\nparently  to the end user. The DDBMS’s transparent data access features are  illustrated in \\nFigure 12.4.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8ceac686-eff9-40d9-9293-69bfca235a46', embedding=None, metadata={'page_label': '560', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='560   Part 4     Advanced Database Concepts\\nThe single logical database in Figure 12.4 consists of two database fragments, A1 and  \\nA2, located at Sites 1 and 2, respectively. Mary can query the database as if it were  \\na local database; so can Tom. Both users “see” only one logical database and do not need \\nto know the names of the fragments . In fact, the end users do not even need to know that \\nthe  database is divided into fragments, nor do they need to know where the fragments are \\nlocated .\\nTo better understand the different types of distributed database scenarios, first \\n consider the components of the distributed database system.\\n12-5  DDBMS Components\\nThe DDBMS must include at least the following components:\\n• Computer workstations or remote devices  (sites or nodes) that form the network \\n system. The distributed database system must be independent of the computer  system \\nhardware.\\n• Network hardware and software  components that reside in each workstation or \\ndevice.\\xa0The network components allow all sites to interact and exchange data. Because \\nthe components—computers, operating systems, network hardware, and so on—are \\nlikely to be supplied by different vendors, it is best to ensure that distributed data -\\nbase\\xa0functions can be run on multiple platforms.\\n• Communications media  that carry the data from one node to another. The DDBMS \\nmust be communications media-independent; that is, it must be able to support \\n several types of communications media.\\n• The transaction  processor (TP)  is the software component found in each computer \\nor device that requests data. The transaction processor receives and processes the \\napplication’s remote and local data requests. The TP is also known as the application \\nprocessor (AP)  or the transaction manager (TM) .\\n• The data processor (DP)  is the software component residing on each computer or \\ndevice that stores and retrieves data located at the site. The DP is also known as the \\ndata manager (DM) . A data processor may even be a centralized DBMS.transaction \\n processor (TP)\\nIn a DDBMS, the software \\ncomponent on each \\ncomputer that requests \\ndata. The TP is responsible \\nfor the execution and \\ncoordination of all \\ndatabase requests issued \\nby a local application that \\naccesses data on any DP . \\nAlso called transaction \\nmanager (TM)  or \\napplication processor (AP) .\\napplication \\n processor (AP)\\nSee transaction \\nprocessor  (TP).\\ntransaction \\nmanager\\xa0(TM)\\nSee transaction \\nprocessor  (TP).\\ndata processor (DP)\\nThe resident software \\ncomponent that stores \\nand retrieves data \\nthrough a DDBMS. The \\nDP is responsible for \\nmanaging the local data \\nin the computer and \\ncoordinating access to \\nthat data. Also known as \\ndata manager (DM) .\\ndata manager (DM)\\nSee data processor (DP) .FIGURE 12.4  A FULLY DISTRIBUTED DATABASE MANAGEMENT SYSTEM  \\nDatabase fragment\\nA1Database fragment\\nA2Distributed processingSite 1 Site 2\\nSingle logical databaseUser Mary User Tom\\nCommunications network\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84dd4235-4962-4332-a36a-aa28b1307953', embedding=None, metadata={'page_label': '561', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    561\\nFigure 12.5 illustrates the placement of the components and the interaction among \\nthem. The communication among TPs and DPs is made possible through a specific set of \\nrules, or protocols , used by the DDBMS.\\nFIGURE 12.5  DISTRIBUTED DATABASE SYSTEM COMPONENTS  \\nNote:  Each TP can access data on any DP , and each DP handles all requests for local data from any TP .José\\nTP TP DPPeter Mary Dedicated data processor\\nAmy Chantal Dedicated data processorDPTP\\nDPTP\\nDPTP\\nDP\\nCommunications network\\nThe protocols determine how the distributed database system will:\\n• Interface with the network to transport data and commands between DPs and TPs.\\n• Synchronize all data received from DPs (TP side) and route retrieved data to the \\nappropriate TPs (DP side).\\n• Ensure common database functions in a distributed system. Such functions include \\ndata security, transaction management and concurrency control, data partitioning \\nand synchronization, and data backup and recovery.\\nDPs and TPs should be added to the system transparently without affecting its operation. \\nA TP and a DP can reside on the same computer, allowing the end user to access both local \\nand remote data transparently. In theory, a DP can be an independent centralized DBMS with \\nproper interfaces to support remote access from other independent DBMSs in the network.\\n12-6  Levels of Data and Process Distribution\\nCurrent database systems can be classified on the basis of how process distribution and \\ndata distribution are supported. For example, a DBMS may store data in a single site \\n(using a centralized DB) or in multiple sites (using a distributed DB), and it may support \\ndata processing at one or more sites. Table 12.2 uses a simple matrix to classify data -\\nbase systems according to data and process distribution. These types of processes are \\n discussed in the sections that follow.\\n12-6a  Single-Site Processing, Single-Site Data\\nIn the single-site processing, single-site data (SPSD)  scenario, all processing is done \\non a single host computer, and all data is stored on the host computer’s local disk system. single-site  processing, \\n single-site data \\n(SPSD)\\nA scenario in which all \\nprocessing is done on \\na single host computer \\nand all data is stored \\non the host computer’s \\nlocal disk.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='852d7467-31c3-446e-959d-f3e9592d4e45', embedding=None, metadata={'page_label': '562', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='562   Part 4     Advanced Database Concepts\\nProcessing cannot be done on the end user’s side of the system. Such a scenario is typical \\nof most mainframe and midrange UNIX/Linux server DBMSs. The DBMS is on the host \\ncomputer, which is accessed by terminals connected to it (see Figure 12.6). This scenario \\nis also typical of the first generation of single-user microcomputer databases.TABLE 12.2\\nDATABASE SYSTEMS: LEVELS OF DATA AND PROCESS DISTRIBUTION\\nADVANTAGES SINGLE-SITE DATA MULTIPLE-SITE DATA\\nSingle-site process Host DBMS Not applicable  \\n(Requires multiple processes)\\nMultiple-site process File server\\nClient/server DBMS (LAN DBMS)Fully distributed\\nClient/server DDBMS\\nFIGURE 12.6  SINGLE-SITE PROCESSING, SINGLE-SITE DATA (CENTRALIZED)\\nDumb\\nterminals\\nRemote\\ndumb\\nterminalDBMS\\nHost computerFront-end\\nprocessorT1\\nT3T2\\nCommunication through \\nDSL or T-1 lineDatabase\\nUsing Figure 12.6 as an example, you can see that the functions of the TP and DP \\nare embedded within the DBMS on the host computer. The DBMS usually runs under \\na time-sharing, multitasking operating system, which allows several processes to run \\nconcurrently on a host computer accessing a single DP . All data storage and data pro -\\ncessing are handled by a single host computer.\\n12-6b  Multiple-Site Processing, Single-Site Data\\nUnder the multiple-site processing, single-site data (MPSD)  scenario, multiple pro -\\ncesses run on different computers that share a single data repository. Typically, the \\nMPSD scenario requires a network file server running conventional applications that are  \\naccessed through a network. Many multiuser accounting applications running under  \\na personal computer network fit such a description (see Figure 12.7).\\nAs you examine Figure 12.7, note that:\\n• The TP on each workstation acts only as a redirector to route all network data requests \\nto the file server.\\n• The end user sees the file server as just another hard disk. Because only the data \\n storage input/output (I/O) is handled by the file server’s computer, the MPSD offers \\nlimited capabilities for distributed processing.multiple-site \\n processing, single-  \\nsite data (MPSD)\\nA scenario in which \\nmultiple processes run \\non different computers \\nsharing a single data \\nrepository.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cca88cdc-3d23-49d9-b378-9f7c1ab37aea', embedding=None, metadata={'page_label': '563', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    563\\n• The end user must make a direct reference to the file server to access remote data. \\nAll\\xa0record- and file-locking activities are performed at the end-user location.\\n• All data selection, search, and update functions take place at the workstation, thus \\nrequiring that entire files travel through the network for processing at the  workstation. \\nSuch a requirement increases network traffic, slows response time, and increases \\ncommunication costs.\\nThe inefficiency of the last condition can be illustrated easily. For example, suppose that \\nthe file server computer stores a CUSTOMER table containing 100,000 data rows, 50 of \\nwhich have balances greater than $1,000. Suppose that Site A issues the following SQL query:\\nSELECT *\\nFROM CUSTOMER\\nWHERE CUS_BALANCE > 1000;\\nAll 100,000 CUSTOMER rows must travel through the network to be evaluated at \\nSite A. A variation of the multiple-site processing, single-site data approach is known as \\nclient/server architecture. Client/server architecture  is similar to that of the network \\nfile server except that all database processing is done at the server site, thus reducing net -\\nwork traffic . Although both the network file server and the client/server systems perform \\nmultiple-site processing, the client/server system’s processing is distributed. Note that \\nthe network file server approach requires the database to be located at a single site. In \\ncontrast, the client/server architecture is capable of supporting data at multiple sites.\\n12-6c  Multiple-Site Processing, Multiple-Site Data\\nThe multiple-site processing, multiple-site data (MPMD)  scenario describes a fully \\ndistributed DBMS with support for multiple data processors and transaction proces -\\nsors at multiple sites. Depending on the level of support for various types of databases, \\nDDBMSs are classified as either homogeneous or heterogeneous.\\nHomogeneous DDBMSs  integrate multiple instances of the same DBMS over a \\n network—for example, multiple instances of Oracle 11g running on different platforms. \\nIn contrast, heterogeneous DDBMSs  integrate different types of DBMSs over a  network, \\nbut all support the same data model. For example, Table 12.3 lists several relational data -\\nbase systems that could be integrated within a DDBMS. A fully  heterogeneous DDBMS  \\nwill support different DBMSs, each one supporting a different data model,  running under \\ndifferent computer systems.client/server \\narchitecture\\nA hardware and software \\nsystem composed of \\nclients, servers, and \\nmiddleware. Features \\na user of resources \\n(client) and a provider of \\nresources (server).\\nmultiple-site \\n processing, multiple-  \\nsite data (MPMD)\\nA scenario describing a \\nfully distributed database \\nmanagement system \\nwith support for multiple \\ndata processors and \\ntransaction processors at \\nmultiple sites.\\nhomogeneous \\nDDBMS\\nA system that integrates \\nonly one type of \\ncentralized database \\nmanagement system \\nover a network.\\nheterogeneous \\nDDBMS\\nA system that integrates \\ndifferent types of \\ncentralized database \\nmanagement systems \\nover a network.FIGURE 12.7  MULTIPLE-SITE PROCESSING, SINGLE-SITE DATA  \\nSite A\\nTPFile Server\\nDPSite B\\nTPSite C\\nTP\\nCommunications networkFor more information \\nabout client/server archi -\\ntecture, see  Appendix F, \\nClient/Server  Systems, \\navailable at www.  \\ncengagebrain.com .Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f73ea220-9da5-4bf8-8022-6e95f1b16382', embedding=None, metadata={'page_label': '564', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='564   Part 4    Advanced Database Concepts\\nDistributed database implementations are better understood as an abstraction layer \\non top of a DBMS. This abstraction layer provides additional functionality that enables \\n support for distributed database features, including straightforward data links, repli-\\ncation, advanced data fragmentation, synchronization, and integration. In fact, most database vendors provide for increasing levels of data fragmentation, replication, and integration. Therefore, the support for distributed databases can be better seen as a continuous spectrum that goes from homogeneous to fully heterogeneous distributed data management. Consequently, at any point on this spectrum, a DDBMS is subject to \\n certain restrictions. For example:\\n• Remote access is provided on a read-only basis and does not support write \\nprivileges.\\n• Restrictions are placed on the number of remote tables that may be accessed in  \\na single transaction.\\n• Restrictions are placed on the number of distinct databases that may be accessed.\\n• Restrictions are placed on the database model that may be accessed. Thus, access may be provided to relational databases but not to network or hierarchical databases.\\nThe preceding list of restrictions is by no means exhaustive. The DDBMS \\n technology \\ncontinues to change rapidly, and new features are added frequently. Managing data at multiple sites leads to a number of issues that must be addressed and understood. The next section examines several key features of distributed database management systems.\\n12-7   Distributed Database Transparency Features\\nA distributed database system should provide some desirable transparency features that make all the system’s complexities hidden to the end user. In other words, the end user should have the sense of working with a centralized DBMS. For this reason, the \\n minimum desirable DDBMS transparency features are:\\n• Distribution transparency allows a distributed database to be treated as a single \\n logical database. If a DDBMS exhibits distribution transparency, the user does not \\nneed to know:\\n– The data is partitioned—meaning the table’s rows and columns are split vertically \\nor horizontally and stored among multiple sites.\\n– The data is geographically dispersed among multiple sites.\\n– The data is replicated among multiple sites.TABLE 12.3\\nDATABASE SYSTEMS: LEVELS OF DATA AND PROCESS DISTRIBUTION\\nPLATFORM DBMS OPERATING SYSTEM NETWORK COMMUNICATIONS PROTOCOL\\nIBM 3090 DB2 MVS APPC LU 6.2\\nIBM AS/400 SQL/400 OS/400 3270\\nRISC computer Informix UNIX TCP/IP\\nIntel Xeon CPU Oracle Windows Server TCP/IP\\nfully  heterogeneous \\ndistributed  database \\nsystem (fully \\n heterogeneous DDBMS)\\nA system that integrates different types of database management systems (hierarchical, network, and relational) over a network. It supports different database management systems that may even support different data models running under different computer systems. See also heterogeneous DDBMS and homogeneous DDBMS.\\ndistribution transparency\\nA DDBMS feature that allows a distributed database to look like a single logical database to an end user.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='be1b56f7-b81f-4157-828d-55f9fe142811', embedding=None, metadata={'page_label': '565', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    565\\n• Transaction transparency allows a transaction to update data at more than one \\n network site. Transaction transparency ensures that the transaction will be either \\nentirely completed or aborted, thus maintaining database integrity.\\n• Failure transparency ensures that the system will continue to operate in the event of a node or network failure. Functions that were lost because of the failure will be picked up by another network node. This is a very important feature, particularly in organizations that depend on web presence as the backbone for maintaining trust in their business.\\n•\\n Performance transparency allows the system to perform as if it were a centralized DBMS. The system will not suffer any performance degradation due to its use on a network or because of the network’s platform differences. Performance transparency also ensures that the system will find the most cost-effective path to access remote data. The system should be able to “scale out” in a transparent manner or increase performance capacity by adding more transaction or data-processing nodes, without affecting the overall performance of the system.\\n•\\n Heterogeneity transparency allows the integration of several different local DBMSs (relational, network, and hierarchical) under a common, or global, schema. The DDBMS is responsible for translating the data requests from the global schema to the local DBMS schema.\\nThe following sections discuss each of these transparency features in greater detail.\\n12-8  Distribution Transparency\\nDistribution transparency allows a physically dispersed database to be managed as though it were a centralized database. The level of transparency supported by the DDBMS varies from system to system. Three levels of distribution transparency are recognized:\\n•\\n Fragmentation transparency is the highest level of distribution transparency. \\nThe\\xa0end user or programmer does not need to know that a database is partitioned. Therefore, neither fragment names nor fragment locations are specified prior to data access.\\n•\\n Location transparency exists when the end user or programmer must specify the database fragment names but does not need to specify where those fragments are located.\\n•\\n Local mapping transparency exists when the end user or programmer must specify both the fragment names and their locations.\\nTransparency features are summarized in Table 12.4.\\nTABLE 12.4\\nSUMMARY OF TRANSPARENCY FEATURES\\nIF THE SQL STATEMENT REQUIRES:\\nFRAGMENT \\nNAME?LOCATION NAME?THEN THE DBMS SUPPORTS LEVEL OF DISTRIBUTON TRANSPARENCY\\nYes Yes Local mapping transparency Low\\nYes No Location transparency Medium\\nNo No Fragmentation transparency Hightransaction transparency\\nA DDBMS property that ensures database transactions will maintain the distributed database’s integrity and consistency, and that a transaction will be completed only when all database sites involved complete their part of the transaction.\\nfailure transparency\\nA feature that allows continuous operation of a DDBMS, even if a network node fails.\\nperformance transparency\\nA DDBMS feature that allows a system to perform as though it were a centralized DBMS.\\nheterogeneity transparency\\nA feature that allows a system to integrate several centralized DBMSs into one logical DDBMS.\\nfragmentation transparency\\nA DDBMS feature that allows a system to treat a distributed database as a single database even though it is divided into two or more fragments.\\nlocation transparency\\nA property of a DDBMS in which database access requires the user to know only the name of the database fragments. (Fragment locations need not be known.)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='323146e2-a910-4dbb-9b7b-428f08da108a', embedding=None, metadata={'page_label': '566', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"566   Part 4     Advanced Database Concepts\\nTo illustrate the use of various transparency levels, suppose you have an EMPLOYEE \\ntable that contains the attributes EMP_NAME, EMP_DOB, EMP_ADDRESS, EMP_\\nDEPARTMENT, and EMP_SALARY . The EMPLOYEE data is distributed over three \\ndifferent locations: New Y ork, Atlanta, and Miami. The table is divided by location; that \\nis, New Y ork employee data is stored in fragment E1, Atlanta employee data is stored in \\nfragment E2, and Miami employee data is stored in fragment E3 (see Figure 12.8).\\nAs you examine Table 12.4, notice that there is no reference to a situation in which the \\nfragment name is “No” and the location name is “Yes. ” The reason is simple: you cannot  \\nhave a location name that fails to reference an existing fragment. If you don’t need to  \\nspecify a fragment name, its location is clearly irrelevant.Note\\nFIGURE 12.8  FRAGMENT LOCATIONS  \\nDistributed DBMS\\nFragment\\nLocationEMPLOYEE table\\nE1 E2 E3\\nNew York Atlanta Miami\\nNow suppose that the end user wants to list all employees born before January 1, \\n1960. To focus on the transparency issues, also suppose that the EMPLOYEE table is \\nfragmented and each fragment is unique. The unique fragment  condition indicates that \\neach row is unique, regardless of the fragment in which it is located. Finally, assume that \\nno portion of the database is replicated at any other site on the network.\\nDepending on the level of distribution transparency support, you may examine three \\nquery cases.\\nCase 1: The Database Supports Fragmentation Transparency\\nThe query conforms to a nondistributed database query format; that is, it does not  specify \\nfragment names or locations. The query reads:\\nSELECT  *\\nFROM   EMPLOYEE\\nWHERE  EMP_DOB < '01-JAN-1979';\\nCase 2: The Database Supports Location Transparency\\nFragment names must be specified in the query, but the fragment’s location is not \\n specified. The query reads:\\nSELECT  *\\nFROM   E1local mapping \\ntransparency\\nA property of a DDBMS \\nin which database \\naccess requires the user \\nto know both the name \\nand location of the \\nfragments.\\nunique fragment\\nIn a DDBMS, a condition \\nin which each row is \\nunique, regardless of \\nwhich fragment it is \\nlocated in.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e1fec82e-6bb1-4261-bbf1-61f78f5ffbde', embedding=None, metadata={'page_label': '567', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 12    Distributed Database Management Systems    567\\nWHERE  EMP_DOB < '01-JAN-1979'\\nUNION  \\nSELECT  *\\nFROM   E2\\nWHERE  EMP_DOB < '01-JAN-1979'\\nUNION  \\nSELECT  *\\nFROM   E3\\nWHERE  EMP_DOB < '01-JAN-1979'\\nCase 3: The Database Supports Local Mapping Transparency\\nBoth the fragment name and its location must be specified in the query. Using \\npseudo-SQL:\\nSELECT  *\\nFROM   El NODE NY\\nWHERE  EMP_DOB < '01-JAN-1979';\\nUNION  \\nSELECT  *\\nFROM   E2 NODE ATL\\nWHERE  EMP_DOB < '01-JAN-1979';\\nUNION  \\nSELECT  *\\nFROM   E3 NODE MIA\\nWHERE  EMP_DOB < '01-JAN-1979';\\nNODE indicates the location of the database fragment. NODE is used for illustration \\n purposes and is not part of the standard SQL syntax.Note\\nAs you examine the preceding query formats, you can see how distribution \\n transparency affects the way end users and programmers interact with the database.\\nDistribution transparency is supported by a distributed data dictionary (DDD)  \\nor a distributed data catalog (DDC). The DDC contains the description of the \\nentire database as seen by the database administrator. The database description, known as the \\n distributed global schema, is the common database schema used \\nby local TPs to translate user requests into subqueries (remote requests) that will be processed by \\n different DPs. The DDC is itself distributed, and it is replicated \\nat the network nodes. Therefore, the DDC must maintain consistency through updating at all sites.\\nKeep in mind that some of the current DDBMS implementations impose lim-\\nitations on the level of transparency support. For instance, you might be able to distribute a database, but not a table, across multiple sites. Such a condition indicates that the DDBMS supports location transparency but not fragmentation transparency.distributed data \\n dictionary (DDD)\\nSee distributed data catalog.\\ndistributed data \\n catalog (DDC)\\nA data dictionary that contains the description (fragment names and locations) of a distributed database. \\ndistributed global schema\\nThe database schema description of a distributed database as seen by the database administrator.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1fe121b1-6508-4409-b9dd-a10f0a73c760', embedding=None, metadata={'page_label': '568', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='568   Part 4     Advanced Database Concepts\\n12-9  Transaction Transparency\\nTransaction transparency is a DDBMS property that ensures database transactions \\nwill maintain the distributed database’s integrity and consistency. Remember that a \\nDDBMS database transaction can update data stored in many different computers \\n connected in a network. Transaction transparency ensures that the transaction will be \\ncompleted only when all database sites involved in the transaction complete their part \\nof the transaction.\\nDistributed database systems require complex mechanisms to manage transactions \\nand ensure the database’s consistency and integrity. To understand how the transactions \\nare managed, you should know the basic concepts governing remote requests, remote \\ntransactions, distributed transactions, and distributed requests.\\n12-9a   Distributed Requests and Distributed \\nTransactions1\\nWhether or not a transaction is distributed, it is formed by one or more database requests. \\nThe basic difference between a nondistributed transaction and a distributed transaction is \\nthat the distributed transaction can update or request data from several different remote \\nsites on a network. To better understand distributed transactions, begin by learning the \\ndifference between remote and distributed transactions, using the BEGIN WORK and \\nCOMMIT WORK transaction format. Assume the existence of location transparency to \\navoid having to specify the data location.\\nA remote request , illustrated in Figure 12.9, lets a single SQL statement access the \\ndata that are to be processed by a single remote database processor. In other words, the \\nSQL statement (or request) can reference data at only one remote site.\\nSimilarly, a remote transaction , composed of several requests, accesses data at  \\na  single remote site. A remote transaction is illustrated in Figure 12.10.\\nAs you examine Figure 12.10, note the following remote transaction features:\\n• The transaction updates the PRODUCT and INVOICE tables (located at Site B).\\n• The remote transaction is sent to the remote Site B and executed there.\\n1  The details of distributed requests and transactions were originally described by David McGoveran and \\nColin White, “Clarifying client/server, ” DBMS 3 (12), November 1990, pp. 78–89.FIGURE 12.9  A REMOTE REQUEST  \\nCUSTOMERNetwork\\nSELECT *\\n     FROM CUSTOMER\\n            WHERE CUS_STATE = ‘AL’;Comment: The request is \\ndirected to the CUSTOMER table at Site B.Site A Site B\\nTP DP\\nremote request\\nA DDBMS feature that \\nallows a single SQL \\nstatement to access data \\nin a single remote DP .\\nremote transaction\\nA DDBMS feature that \\nallows a transaction \\n(formed by several \\nrequests) to access data \\nin a single remote DP . \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='adbf2697-e6a4-448b-a23a-affdd000827c', embedding=None, metadata={'page_label': '569', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    569\\n• The transaction can reference only one remote DP .\\n• Each SQL statement (or request) can reference only one (the same) remote DP at a \\ntime, and the entire transaction can reference and be executed at only one remote \\nD P.\\nA distributed transaction  can reference several different local or remote DP sites. \\nAlthough each single request can reference only one local or remote DP site, the trans -\\naction as a whole can reference multiple DP sites because each request can reference  \\na different site. The distributed transaction process is illustrated in Figure 12.11.FIGURE 12.10  A REMOTE TRANSACTION  \\nINVOICE\\nPRODUCT\\nBEGIN WORK;\\nUPDATE PRODUCT\\n    SET PROD_QTY = PROD_QTY – 1\\n       WHERE PROD_NUM = ‘231785’;\\nINSERT IN TO INVOICE (CUS_NUM, INV_DATE, INV_TOTAL)\\n  VALUES ‘100’, ‘15-FE B-2016’, 120.00;\\nCOMMIT WORK;NetworkSite A Site B\\nTP DP\\nFIGURE 12.11  A DISTRIBUTED TRANSACTION  \\nINVOICE\\nPRODUCTBEGIN WORK;\\nUPDATE PRODUCT\\n SET PROD_QTY=PROD_QTY – 1\\n      WHERE PROD_NUM = ‘231785’;\\nINSERT IN TO INVOICE (CUS_NUM, INV_DATE, \\n  INV_ TOTAL)\\n VALUES (‘100’, ‘15-FE B-2016’, 120.00);\\nUPDATE CUSTOMER\\n SET CUS_BALANCE = CUS_BALANCE + 120\\n       WHERE CUS_NUM = ‘100’;\\nCOMMIT WORK;NetworkSite A Site B\\nTP DP\\nDPSite CCUSTOMER\\nNote the following features in Figure 12.11:\\n• The transaction references two remote sites, B and C.\\n• The first two requests, UPDATE PRODUCT and INSERT INTO INVOICE, are \\n processed by the DP at the remote Site C, and the last request (UPDATE CUSTOMER) \\nis processed by the DP at the remote Site B.\\n• Each request can access only one remote site at a time.distributed \\ntransaction\\nA database transaction \\nthat accesses data in \\nseveral remote data \\nprocessors (DPs) in a \\ndistributed database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76fe8121-bd38-4f97-b082-0ecd684d0bd8', embedding=None, metadata={'page_label': '570', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"570   Part 4     Advanced Database Concepts\\nThe distributed request feature also allows a single request to reference a physically \\npartitioned table. For example, suppose that a CUSTOMER table is divided into two \\nfragments, C1 and C2, located at Sites B and C, respectively. Further suppose that the \\nend user wants to obtain a list of all customers whose balances exceed $250. The request \\nis illustrated in Figure 12.13. Full-fragmentation transparency support is provided only \\nby a DDBMS that supports distributed requests.The third characteristic may create problems. For example, suppose the  PRODUCT \\ntable is divided into two fragments, PRODl and PROD2, located at Sites B and C, \\n respectively. Given that scenario, the preceding distributed transaction cannot \\nbe  executed because the following request cannot access data from more than one \\nremote\\xa0site:\\nSELECT  *\\nFROM   PRODUCT\\nWHERE  PROD_NUM = '231785';\\nTherefore, the DBMS must be able to support a distributed request.\\nA distributed  request  lets a single SQL statement reference data located at several \\ndifferent local or remote DP sites. Because each request (SQL statement) can access data \\nfrom more than one local or remote DP site, a transaction can access several sites. The \\nability to execute a distributed request provides fully distributed database processing \\nbecause you can:\\n• Partition a database table into several fragments.\\n• Reference one or more of those fragments with only one request. In other words, \\nthere is fragmentation transparency.\\nThe location and partition of the data should be transparent to the end user. \\n Figure\\xa012.12 illustrates a distributed request. As you examine the figure, note that the \\ntransaction uses a single SELECT statement to reference two tables, CUSTOMER and \\nINVOICE. The two tables are located at two different sites, B and C.\\ndistributed request\\nA database request \\nthat allows a single SQL \\nstatement to access data \\nin several remote data \\nprocessors (DPs) in a \\ndistributed database.FIGURE 12.12  A DISTRIBUTED REQUEST  \\nCUSTOMER\\nINVOICE\\nPRODUCTBEGIN WORK;\\n   SELECT CUS_NUM, INV_TOTAL\\n     FROM CUS TOMER, INVOICE\\n        WHERE CUS_NUM = ‘100’ AND\\n    INVOICE.CUS_NUM = CUS TOMER.CUS_NUM;\\nCOMMIT WORK;NetworkSite A Site B\\nTP DP\\nDPSite C\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4f165717-904d-4c6a-b8e4-ab94ed607723', embedding=None, metadata={'page_label': '571', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    571\\nFIGURE 12.13  ANOTHER DISTRIBUTED REQUEST  \\nC1\\nC2 SELECT *\\n FROM CUS TOMER\\n  WHERE CUS_BALANCE > 250;NetworkSite A Site B\\nTP DP\\nDPSite C\\nUnderstanding the different types of database requests in distributed database  systems \\nhelps you address the transaction transparency issue more effectively.  Transaction \\n transparency ensures that distributed transactions are treated as centralized  transactions, \\nensuring their serializability. (Review Chapter 10, Transaction Management and \\n Concurrency Control, if necessary.) That is, the execution of concurrent transactions, \\nwhether they are distributed or not, will take the database from one consistent state to \\nanother.\\n12-9b  Distributed Concurrency Control\\nConcurrency control becomes especially important in distributed databases because \\nmultisite, multiple-process operations are more likely to create data inconsistencies \\nand deadlocked transactions than single-site systems. For example, the TP component \\nof a DDBMS must ensure that all parts of the transaction are completed at all sites \\nbefore a final COMMIT is issued to record the transaction.\\nSuppose that a transaction updates data at three DP sites. The first two DP sites com -\\nplete the transaction and commit the data at each local DP; however, the third DP site \\ncannot commit the transaction. Such a scenario would yield an inconsistent database, \\nwith its inevitable integrity problems, because committed data cannot be uncommitted! \\nThis problem is illustrated in Figure 12.14.\\nThe solution to this problem is a two-phase commit protocol , which you will explore \\nnext.\\n12-9c  Two-Phase Commit Protocol\\nCentralized databases require only one DP . All database operations take place at only \\none site, and the consequences of database operations are immediately known to the \\nDBMS. In contrast, distributed databases make it possible for a transaction to access \\ndata at several sites. A final COMMIT must not be issued until all sites have  committed \\ntheir parts of the transaction. The two-phase commit protocol (2PC)  guarantees that \\nif a portion of a transaction operation cannot be committed, all changes made at the \\nother sites participating in the transaction will be undone to maintain a consistent \\n database state.two-phase commit \\nprotocol (2PC)\\nIn a DDBMS, an \\nalgorithm used to ensure \\natomicity of transactions \\nand database \\nconsistency as well as \\nintegrity in distributed \\ntransactions.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='572abaa8-4356-4679-be94-1a5eb3a10e30', embedding=None, metadata={'page_label': '572', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='572   Part 4     Advanced Database Concepts\\nEach DP maintains its own transaction log. The two-phase commit protocol requires \\nthat the transaction log entry for each DP be written before the database fragment is \\nactually updated (see Chapter 10). Therefore, the two-phase commit protocol requires  \\na DO-UNDO-REDO protocol and a write-ahead protocol.\\nThe DO-UNDO-REDO protocol  is used by the DP to roll transactions back and \\n forward with the help of the system’s transaction log entries. The DO-UNDO-REDO \\nprotocol defines three types of operations:\\n• DO performs the operation and records the “before” and “after” values in the \\n transaction log.\\n• UNDO reverses an operation, using the log entries written by the DO portion of the \\nsequence.\\n• REDO redoes an operation, using the log entries written by the DO portion of the \\nsequence.\\nTo ensure that the DO, UNDO, and REDO operations can survive a system crash \\nwhile they are being executed, a write-ahead protocol is used. The write-ahead  protocol  \\nforces the log entry to be written to permanent storage before the actual operation takes \\nplace.\\nThe two-phase commit protocol defines the operations between two types of nodes: \\nthe coordinator  and one or more subordinates , or cohorts . The participating nodes \\nagree on a coordinator. Generally, the coordinator role is assigned to the node that \\n initiates the transaction. However, different systems implement various, more sophisti -\\ncated election methods. The protocol is implemented in two phases, as illustrated in the \\n following sections.DO-UNDO-REDO \\nprotocol\\nA protocol used by a \\ndata processor (DP) to \\nroll back or roll forward \\ntransactions with the \\nhelp of a system’s \\ntransaction log entries.\\nwrite-ahead protocol\\nA protocol that ensures \\ntransaction logs are \\nwritten to permanent \\nstorage before any \\ndatabase data is actually \\nupdated.\\ncoordinator\\nThe transaction \\nprocessor (TP) node \\nthat coordinates the \\nexecution of a two-phase \\nCOMMIT in a DDBMS. \\nsubordinate\\nIn a DDBMS, a data \\nprocessor (DP) node \\nthat participates in a \\ndistributed transaction \\nusing the two-phase \\nCOMMIT protocol.FIGURE 12.14  THE EFFECT OF A PREMATURE COMMIT  \\nData is\\ncommitted\\nRollback at \\nSite CSite A\\nSite B\\nSite CCan’t roll back\\nSites A and BDP\\nDP\\nLOCK (Z)\\n...\\n...\\nROLLBACKDPLOCK (X)\\nWRITE (X)\\nCOMMIT\\nLOCK (Y)\\nWRITE (Y)\\nCOMMIT\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3bde563-e54e-4acc-9890-8d691693c970', embedding=None, metadata={'page_label': '573', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    573\\nPhase 1: Preparation\\nThe coordinator sends a PREPARE TO COMMIT message to all subordinates.\\n1. The subordinates receive the message, write the transaction log using the write-ahead \\nprotocol, and send an acknowledgment message (YES/PREPARED TO COMMIT or NO/NOT PREPARED) to the coordinator.\\n2.\\n The coordinator makes sure that all nodes are ready to commit, or it aborts the action.\\nIf all nodes are PREPARED TO COMMIT, the transaction goes to Phase 2. If one \\nor more nodes reply NO or NOT PREPARED, the coordinator broadcasts an ABORT message to all subordinates.\\nPhase 2: The Final COMMIT\\n1. The coordinator broadcasts a COMMIT message to all subordinates and waits for the replies.\\n2.\\n Each subordinate receives the COMMIT message and then updates the database using the DO protocol.\\n3.\\n The subordinates reply with a COMMITTED or NOT COMMITTED message to the coordinator.\\nIf one or more subordinates do not commit, the coordinator sends an ABORT message, thereby forcing them to UNDO all changes.\\nThe objective of the two-phase commit is to ensure that each node commits its part \\nof the transaction; otherwise, the transaction is aborted. If one of the nodes fails to com-mit, the information necessary to recover the database is in the transaction log, and the database can be recovered with the DO-UNDO-REDO protocol. (Remember that the log information was updated using the write-ahead protocol.)\\n12-10  Performance and Failure Transparency\\nOne of the most important functions of a database is its ability to make data  available. \\nWeb-based distributed data systems demand high availability, which means not only that data is accessible but that requests are processed in a timely manner. For \\n example, the average Google search has a subsecond response time. When was the last time you entered a Google query and waited more than a couple of seconds for the results?\\nPerformance transparency allows a DDBMS to perform as if it were a centralized \\ndatabase. In other words, no performance degradation should be incurred due to data distribution. Failure transparency ensures that the system will continue to operate in the case of a node or network failure. Although these are two separate issues, they are interrelated in that a failing node or congested network path could cause performance problems. Therefore, both issues are addressed in this section.\\nChapter 11, Database Performance Tuning and Query Optimization, provides additional details about query optimization.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='86b77d11-e925-410b-972f-5babac33403a', embedding=None, metadata={'page_label': '574', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='574   Part 4    Advanced Database Concepts\\nThe objective of query optimization is to minimize the total cost associated with the \\nexecution of a request. The costs associated with a request are a function of the following:\\n• Access time (I/O) cost involved in accessing the data from multiple remote sites\\n• Communication cost associated with data transmission among nodes in distributed \\ndatabase systems\\n• CPU time cost associated with the processing overhead of managing distributed transactions\\nAlthough costs are often classified either as communication or processing costs, it is \\ndifficult to separate the two. Not all query optimization algorithms use the same param-eters, and not all algorithms assign the same weight to each parameter. For example, some algorithms minimize total time, others minimize the communication time, and still others do not factor in the CPU time, considering its cost insignificant relative to other costs.\\nAs you learned in Chapter 11, a centralized database evaluates every data request to \\nfind the most-efficient way to access the data. This is a reasonable requirement, con-sidering that all data is locally stored and all active transactions working on the data are known to the central DBMS. In contrast, in a DDBMS, transactions are distributed among multiple nodes; therefore, determining what data is being used becomes more complex. Hence, resolving data requests in a distributed data environment must take the following points into consideration:\\n•\\n Data distribution . In a DDBMS, query translation is more complicated because the \\nDDBMS must decide which fragment to access. (Distribution transparency was \\nexplained earlier in this chapter.) In this case, a TP executing a query must choose what fragments to access, create multiple data requests to the chosen remote DPs, combine the DP responses, and present the data to the application.\\n•\\n Data replication . In addition, the data may also be replicated at several different sites. \\nThe data replication makes the access problem even more complex because the data-base must ensure that all copies of the data are consistent. Therefore, an important characteristic of query optimization in distributed database systems is that it must provide replica  transparency. Replica transparency refers to the DDBMS’s ability to \\nhide multiple copies of data from the user. This ability is particularly important with data update operations. If a read-only request is being processed, it can be satisfied by accessing any available remote DP . However, processing a write request also involves “synchronizing” all existing fragments to maintain data consistency. The two-phase commit protocol you learned about in Section 12-9c ensures that the transaction will complete successfully. However, if data is replicated at other sites, the DDBMSs must also ensure the consistency of all the fragments—that is, all fragments should be mutually consistent. To accomplish this, a DP captures all changes and pushes them to each remote replica. This introduces delays in the system and basically means that not all data changes are immediately seen by all replicas. (The implications of this issue are explained in Section 12-12, The CAP Theorem.)\\n•\\n Network and node availability . The response time associated with remote sites can-\\nnot be easily predetermined because some nodes finish their part of the query in less time than others and network path performance varies because of bandwidth and traffic loads. Hence, to achieve performance transparency, the DDBMS should consider issues such as network latency, the delay imposed by the amount of time required for a data packet to make a round trip from point A to point B, or network \\npartitioning, the delay imposed when nodes become suddenly unavailable due to  \\na network failure.replica transparency\\nThe DDBMS’s ability to hide the existence of multiple copies of data from the user.\\nnetwork latency\\nThe delay imposed by the amount of time required for a data packet to make a round trip from point A to point B.\\nnetwork partitioning\\nThe delay that occurs when nodes become suddenly unavailable due to a network failure. In distributed databases, the system must account for the possibility of this condition.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fdb9b2d2-fc20-438c-86fd-8f788ea7b8fd', embedding=None, metadata={'page_label': '575', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    575\\nCarefully planning how to partition a database and where to locate the database \\nfragments can help ensure the performance and consistency of a distributed database. \\nThe following section discusses issues for distributed database design.\\n12-11  Distributed Database Design\\nWhether the database is centralized or distributed, the design principles and concepts described in Chapters 3, 4, and 6 are still applicable. However, the design of a distributed database introduces three new issues:\\n•\\n How to partition the database into fragments\\n• Which fragments to replicate\\n• Where to locate those fragments and replicas\\nData fragmentation and data replication deal with the first two issues, and data \\nallocation deals with the third issue. Ideally, data in a distributed database should be \\nevenly distributed to maximize performance, increase availability (reduce bottlenecks), and provide location awareness, which is an ever-increasing requirement for mobile applications.\\n12-11a  Data Fragmentation\\nData fragmentation allows you to break a single object into two or more segments, or fragments. The object might be a user’s database, a system database, or a table. Each fragment can be stored at any site over a computer network. Information about data fragmentation is stored in the distributed data catalog (DDC), from which it is accessed by the TP to process user requests.\\nData fragmentation strategies, as discussed here, are based at the table level and \\n consist of dividing a table into logical fragments. Y ou will explore three types of data fragmentation strategies: horizontal, vertical, and mixed. (Keep in mind that a frag-mented table can always be re-created from its fragmented parts by a combination of unions and joins.)\\n•\\n Horizontal fragmentation refers to the division of a relation into subsets (fragments) \\nof tuples (rows). Each fragment is stored at a different node, and each fragment has unique rows. However, the unique rows all have the same attributes (columns). In short, each fragment represents the equivalent of a SELECT statement, with the WHERE clause on a single attribute.\\n•\\n Vertical fragmentation refers to the division of a relation into attribute (\\n column)\\xa0subsets. Each subset (fragment) is stored at a different node, and each \\nfragment has unique columns—with the exception of the key column, which is common to all fragments. This is the equivalent of the PROJECT statement  \\nin SQL.\\n•\\n Mixed fragmentation refers to a combination of horizontal and vertical strategies. In other words, a table may be divided into several horizontal subsets (rows), each one having a subset of the attributes (columns).\\nTo illustrate the fragmentation strategies, use the CUSTOMER table for the XYZ \\nCompany, as depicted in Figure 12.15. The table contains the attributes CUS_NUM, CUS_NAME, CUS_ADDRESS, CUS_STATE, CUS_LIMIT, CUS_BAL, CUS_RATING, and CUS_DUE.data fragmentation\\nA characteristic of a DDBMS that allows a single object to be broken into two or more segments or fragments. The object might be a user’s database, a system database, or a table. Each fragment can be stored at any site on a computer network.\\nhorizontal fragmentation\\nThe distributed database design process that breaks a table into subsets of unique rows.\\nvertical fragmentation\\nIn distributed database design, the process that breaks a table into a subset of columns from the original table. Fragments must share a common primary key. \\nmixed fragmentation\\nA combination of horizontal and vertical strategies for data fragmentation, in which a table may be divided into several rows and each row has a subset of the attributes (columns).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2650e8f0-90b6-4041-9a12-51638563c3fe', embedding=None, metadata={'page_label': '576', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='576   Part 4     Advanced Database Concepts\\nHorizontal Fragmentation  In this case, a table is divided into multiple subsets of \\nrows. There are various ways to partition a table horizontally:\\n• Round-robin partitioning . Rows are assigned to a given fragment in a round-robin \\nfashion (F1, F2, F3, … , F n) to ensure an even distribution of rows among all  fragments. \\nHowever, this is not a good strategy if you require “location awareness”—the ability \\nto determine which DP node will process a query based on the geospatial location \\nof the requester. For example, you would want all queries from Florida customers to \\nbe resolved from a fragment that stores only Florida customers. Of course, you also \\nwould like this fragment to be located in a node close to Florida.\\n• Range partitioning based on a partition key . A partition key is one or more attributes \\nin a table that determine the fragment in which a row will be stored. For example, if \\nyou want to provide location awareness, a good partition key would be the customer \\nstate field. This is the most common and useful data partitioning strategy.\\nTake a closer look at how to use a partition key to partition a table. Suppose that \\nthe XYZ Company’s corporate management requires information about its customers \\nin all three states, but company locations in each state (TN, FL, and GA) require data \\nregarding local customers only. Based on such requirements, you decide to distribute the \\ndata by state. Therefore, you define the horizontal fragments to conform to the structure \\nshown in Table 12.5.\\npartition key\\nIn partitioned databases, \\none or more attributes \\nin a table that determine \\nthe fragment in which a \\nrow will be stored.FIGURE 12.15  A SAMPLE CUSTOMER TABLE  \\nTable name: CUSTOMER Database name: Ch12_Text\\nTABLE 12.5\\nHORIZONTAL FRAGMENTATION OF THE CUSTOMER TABLE BY STATE\\nFRAGMENT \\nNAMELOCATION CONDITION NODE NAME CUSTOMER \\nNUMBERSNUMBER OF ROWS\\nCUST_H1 Tennessee CUS_STATE = ‘TN’ NAS 10, 12 2\\nCUST_H2 Georgia CUS_STATE = ‘GA’ ATL 15 1\\nCUST_H3 Florida CUS_STATE = ‘FL’ TAM 11, 13, 14 3\\nThe partition key will be the CUS_STATE field. Each horizontal fragment may have  \\na different number of rows, but each fragment must  have the same attributes. The resulting  \\nfragments yield the three tables depicted in Figure 12.16.\\nVertical Fragmentation  Y ou may also divide the CUSTOMER relation into vertical \\nfragments that are composed of a collection of attributes. For example, suppose that the \\ncompany is divided into two departments: the service department and the collections \\ndepartment. Each department is located in a separate building, and each has an interest \\nin only a few of the CUSTOMER table’s attributes. In this case, the fragments are defined \\nas shown in Table 12.6.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='40b3d455-c423-4cfd-b498-6be1f0e545cd', embedding=None, metadata={'page_label': '577', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    577\\nEach vertical fragment must have the same number of rows, but the inclusion of the \\ndifferent attributes depends on the key column. The vertical fragmentation results are \\ndisplayed in Figure 12.17. Note that the key attribute (CUS_NUM) is common to both \\nfragments CUST_V1 and CUST_V2.TABLE 12.6\\nVERTICAL FRAGMENTATION OF THE CUSTOMER TABLE\\nFRAGMENT NAME LOCATION NODE NAME ATTRIBUTE NAMES\\nCUST_V1 Service Bldg SVC CUS_NUM, CUS_NAME, CUS_ADDRESS, CUS_STATE\\nCUST_V2 Collection Bldg. ARC CUS_NUM, CUS_LIMIT, CUS_BAL, CUS_RATING, CUS_DUEFIGURE 12.16  TABLE FRAGMENTS IN THREE LOCATIONS  \\nTable name: CUST_H1\\nTable name: CUST_H2\\nTable name: CUST_H3Location: Tennessee\\nLocation: Georgia\\nLocation: FloridaNode: NAS\\nNode: ATL\\nNode: TAMDatabase name: Ch12_Text\\nFIGURE 12.17  VERTICALLY FRAGMENTED TABLE CONTENTS  \\nTable name: CUST_V1\\nTable name: CUST_V2Location: Service BuildingDatabase name: Ch12_Text\\nLocation: Collection BuildingNode: SVC\\nNode: ARC\\nMixed Fragmentation  The XYZ Company’s structure requires that the CUSTOMER \\ndata be fragmented horizontally to accommodate the various company locations; \\nwithin the locations, the data must be fragmented vertically to accommodate the two \\ndepartments (service and collection). In short, the CUSTOMER table requires mixed \\nfragmentation.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e84b852e-73ab-4537-a6ff-06b33e22168d', embedding=None, metadata={'page_label': '578', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='578   Part 4    Advanced Database Concepts\\nMixed fragmentation requires a two-step procedure. First, horizontal fragmenta-\\ntion is introduced for each site based on the location within a state (CUS_STATE). The \\nhorizontal fragmentation yields the subsets of customer tuples (horizontal fragments) that are located at each site. Because the departments are located in different buildings, vertical fragmentation is used within each horizontal fragment to divide the attributes, thus meeting each department’s information needs at each subsite. Mixed fragmentation yields the results displayed in Table 12.7.\\nTABLE 12.7\\nMIXED FRAGMENTATION OF THE CUSTOMER TABLE\\nFRAGMENT NAMELOCATION HORIZONTAL \\nCRITERIANODE NAMERESULTING ROWS AT SITEVERTICAL CRITERIA ATTRIBUTES AT EACH FRAGMENT\\nCUST_M1 TN-Service CUS_STATE = TN NAS-S 10, 12 CUS_NUM, CUS_NAMECUS_ADDRESS, CUS_STATE\\nCUST_M2 TN-Collection CUS_STATE = TN NAS-C 10, 12 CUS_NUM, CUS_LIMIT, CUS_BAL,  CUS_RATING, CUS_DUE\\nCUST_M3 GA-Service CUS_STATE = GA ATL-S 15 CUS_NUM, CUS_NAMECUS_ADDRESS, CUS_STATE\\nCUST_M4 GA-Collection CUS_STATE = GA ATL-C 15 CUS_NUM, CUS_LIMIT, CUS_BAL,  CUS_RATING, CUS_DUE\\nCUST_M5 FL-Service CUS_STATE = FL TAM-S 11, 13, 14 CUS_NUM, CUS_NAME\\nCUS_ADDRESS, CUS_STATE\\nCUST_M6 FL-Collection CUS_STATE = FL TAM-C 11, 13, 14 CUS_NUM, CUS_LIMIT, CUS_BAL,  \\nCUS_RATING, CUS_DUE\\nEach fragment displayed in Table 12.7 contains customer data by state and, within \\neach state, by department location to fit each department’s data requirements. The tables corresponding to the fragments listed in Table 12.7 are shown in Figure 12.18.\\n12-11b  Data Replication\\nData replication refers to the storage of data copies at multiple sites served by a \\n computer network. Fragment copies can be stored at several sites to serve specific information requirements. Because the existence of fragment copies can enhance data availability and response time, data copies can help to reduce communication and total query costs.\\nSuppose database A is divided into two fragments, A1 and A2. Within a replicated \\ndistributed database, the scenario depicted in Figure 12.19 is possible: fragment A1 is stored at Sites S1 and S2, while fragment A2 is stored at Sites S2 and S3.\\nReplicated data is subject to the mutual consistency rule, which requires that all \\ncopies of data fragments be identical. Therefore, to maintain data consistency among the replicas, the DDBMS must ensure that a database update is performed at all sites where replicas exist.\\nThere are basically two styles of replication:\\n•\\n Push replication . After a data update, the originating DP node sends the changes to \\nthe replica nodes to ensure that data is immediately updated. This type of replication focuses on maintaining data consistency. However, it decreases data availability due to the latency involved in ensuring data consistency at all nodes.data replication\\nThe storage of duplicated database fragments at multiple sites on a DDBMS. Duplication of the fragments is transparent to the end user. Data replication provides fault tolerance and performance enhancements.\\nmutual consistency rule\\nA data replication rule that requires all copies of data fragments to be identical.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a06e4bce-9a06-476a-b032-ccc8e209e61f', embedding=None, metadata={'page_label': '579', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    579\\n• Pull replication . After a data update, the originating DP node sends “messages” to the \\nreplica nodes to notify them of the update. The replica nodes decide when to apply \\nthe updates to their local fragment. In this type of replication, data updates propagate \\nmore slowly to the replicas. The focus is on maintaining data availability. However, \\nthis style of replication allows for temporary data inconsistencies.\\nAlthough replication has some benefits, such as improved data availability, better load \\ndistribution, improved data failure tolerance, and reduced query costs, it also imposes \\nadditional DDBMS processing overhead because each data copy must be maintained by \\nthe system. Furthermore, because the data is replicated at another site, there are associ -\\nated storage costs and increased transaction times (as data must be updated at several FIGURE 12.18  TABLE CONTENTS AFTER THE MIXED FRAGMENTATION PROCESS\\nTable name: CUST_M1\\nTable name: CUST_M2\\nTable name: CUST_M3Location: TN -Service\\nLocation: TN -CollectionDatabase name: Ch12_Text\\nLocation: GA-ServiceNode: NAS-S\\nNode: NAS-C\\nNode: ATL-S\\nTable name: CUST_M4\\nTable name: CUST_M5\\nTable name: CUST_M6Location: GA-Collection\\nLocation: FL-Service\\nLocation: FL-CollectionNode: ATL-C\\nNode: TAM-S\\nNode: TAM-C\\nFIGURE 12.19  DATA REPLICATION  \\nA 1 A 2 A 1 A 2Site S1 Site S3 Site S2\\nDP DP DP\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0cc34ee1-5c40-4acf-bccf-148623602631', embedding=None, metadata={'page_label': '580', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='580   Part 4    Advanced Database Concepts\\nsites concurrently to comply with the mutual consistency rule). To illustrate the replica \\noverhead imposed on a DDBMS, consider the processes that the DDBMS must perform to use the database:\\n•\\n If the database is fragmented, the DDBMS must decompose a query into subqueries \\nto access the appropriate fragments.\\n• If the database is replicated, the DDBMS must decide which copy to access. A READ operation selects the nearest copy  to satisfy the transaction. A WRITE operation \\nrequires that all copies  be selected and updated to satisfy the mutual consistency rule.\\n•\\n The TP sends a data request to each selected DP for execution.\\n• The DP receives and executes each request and sends the data back to the TP .\\n• The TP assembles the DP responses.\\nThe problem becomes more complex when you consider additional factors such as \\nnetwork topology and communication throughputs.\\nThree replication scenarios exist: a database can be fully replicated, partially \\n replicated, or unreplicated.\\n• A fully replicated database stores multiple copies of each database fragment \\nat\\xa0 multiple sites. In this case, all database fragments are replicated. A fully replicated \\ndatabase can be impractical due to the amount of overhead it imposes on the system.\\n• A partially replicated database stores multiple copies of some database fragments at \\nmultiple sites. Most DDBMSs are able to handle the partially replicated database well.\\n• An unreplicated database stores each database fragment at a single site. Therefore, \\nthere are no duplicate database fragments.\\nSeveral factors influence the decision to use data replication:•\\n Database size. The amount of data replicated will have an impact on the storage require-\\nments and the data transmission costs. Replicating large amounts of data requires  \\na window of time and higher network bandwidth that could affect other applications.\\n• Usage frequency. The frequency of data usage determines how frequently the data needs to be updated. Frequently used data should be updated more often, for \\n example, \\nthan large data sets that are used only every quarter.\\n• Costs . Costs include those for performance, software overhead, and management \\n associated with synchronizing transactions and their components versus fault-  \\ntolerance benefits that are associated with replicated data.\\nWhen the usage frequency of remotely located data is high and the database is large, \\ndata replication can reduce the cost of data requests. Data replication information is stored in the DDC, whose contents are used by the TP to decide which copy of a database fragment to access. The data replication makes it possible to restore lost data.\\n12-11c  Data Allocation\\nData allocation describes the process of deciding where to locate data. Data allocation strategies are as follows:\\n•\\n With centralized data allocation, the entire database is stored at one site.\\n• With partitioned data allocation, the database is divided into two or more \\n disjointed parts (fragments) and stored at two or more sites.\\n• With replicated data allocation, copies of one or more database fragments are \\nstored at several sites.fully replicated \\ndatabase\\nIn a DDBMS, the distributed database that stores multiple copies of each database fragment at multiple sites.\\npartially replicated database\\nA distributed database in which copies of only some database fragments are stored at multiple sites.\\nunreplicated database\\nA distributed database in which each database fragment is stored at a single site.\\ndata allocation\\nIn a distributed DBMS, the process of deciding where to locate data fragments.\\ncentralized data allocation\\nA data allocation strategy in which the entire database is stored at one site. Also known as a centralized database.\\npartitioned data allocation\\nA data allocation strategy of dividing a database into two or more fragments that are stored at two or more sites.\\nreplicated data allocation\\nA data allocation strategy in which copies of one or more database fragments are stored at several sites.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ff60f282-294f-4b81-b621-f25ad6c4a617', embedding=None, metadata={'page_label': '581', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    581\\nData distribution over a computer network is achieved through data partitioning, \\nthrough data replication, or through a combination of both. Data allocation is closely \\nrelated to the way a database is divided or fragmented. Most data allocation studies focus on one issue: which data to locate where.\\nData allocation algorithms consider a variety of factors, including:\\n•\\n Performance and data availability goals\\n• Size, number of rows, and number of relations that an entity maintains with other entities\\n•\\n Types of transactions to be applied to the database and the attributes accessed by each of those transactions\\n•\\n Disconnected operation for mobile users\\nIn some cases, the design might consider the use of loosely disconnected fragments \\nfor mobile users, particularly for read-only data that does not require frequent updates and for which the replica update windows may be longer. (A replica update window is the amount of time available to perform a data-processing task that cannot be executed concurrently with other tasks.)\\nMost algorithms include information such as network topology, network \\n bandwidth \\nand throughput, data size, and location. No optimal or universally accepted algorithm exists yet, and each database vendor implements its own version to showcase the strengths of its respective products.\\n12-12  The CAP Theorem\\nIn a 2000 symposium on distributed computing, Dr. Eric Brewer stated in his presen-tation that “in any highly distributed data system there are three commonly desirable properties: consistency, availability, and partition tolerance. However, it is impossible for a system to provide all three properties at the same time. ”\\n2 The initials CAP stand for the \\nthree desirable properties. Consider these three properties in more detail:\\n• Consistency . In a distributed database, consistency takes a bigger role. All nodes should \\nsee the same data at the same time, which means that the replicas should be immedi-\\nately updated. However, this involves dealing with latency and network  partitioning \\ndelays, as you learned in Section 12-10.\\n• Availability . Simply speaking, a request is always fulfilled by the system. No received \\nrequest is ever lost. If you are buying tickets online, you do not want the system to stop in the \\n middle of the operation. This is a paramount requirement of all web-centric \\norganizations.\\n• Partition tolerance . The system continues to operate even in the event of a node \\n failure. This is the equivalent of failure transparency in distributed databases (see \\n Section\\xa012-7). The system will fail only if all nodes fail.\\nDo not mistake transaction management consistency (which you learned in \\n Chapter\\xa010) with CAP consistency. Transaction management consistency refers to the result when executing a transaction yields a database that complies with all integrity con-straints. Consistency in CAP is based on the assumption that all transaction operations \\n2   Eric A. Brewer, “Towards robust distributed systems, ” University of California at Berkeley and Inktomi \\nCorporation, presentation at the Principles of Distributed Computing, ACM Symposium, July 2000. This theorem was later proven by Seth Gilbert and Nancy Lynch of MIT in their paper, “Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services, ” ACM SIGACT News, 33(2), 2002, pp. 51–59.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7adb1b84-5b61-477d-b276-2c20d7e21089', embedding=None, metadata={'page_label': '582', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='582   Part 4    Advanced Database Concepts\\ntake place at the same time in all nodes, as if they were executing in a single-node  \\ndatabase. (“ All nodes see the same data at the same time. ”)\\nAlthough the CAP theorem focuses on highly distributed web-based systems, its \\nimplications are widespread for all distributed systems, including databases.\\nIn Chapter 10, you learned that there are four database transaction properties: \\n atomicity, consistency, isolation, and durability. The ACID properties ensure that all \\n successful transactions result in a consistent database state—one in which all data \\noperations always return the same results. For centralized and small  distributed \\ndatabases, latency is not an issue. As the business grows and the need for  availability \\nincreases, database latency becomes a bigger problem. It is more  difficult for a \\nhighly\\xa0 distributed database to ensure ACID transactions without paying a high price in network latency or data contention (delays imposed by concurrent data access).\\nFor example, imagine that you are using Amazon.com to buy tickets for a Manches-\\nter United–Barcelona soccer game in Washington, D.C. Y ou may spend a few minutes browsing through the available tickets and checking the stadium website to see which seats have the best view. At the same time, other users from all over the world may be doing exactly the same thing. By the time you click the checkout button, the tickets you selected may already have been purchased by someone else! In this case, you will start again and select other tickets until you get the ones you want. The website is designed to work this way because Amazon prefers the small probability of having a few customers restart their transactions to having to lock the database to ensure consistency and leaving thousands of customers waiting for their webpages to refresh. If you have noticed the small countdown clock when using Ticketmaster to buy concert tickets, you have seen the same principle at work.\\nAs this example shows, when dealing with highly distributed systems, some \\n companies tend to forfeit the consistency and isolation components of the ACID proper -\\nties to achieve higher availability. This trade-off between consistency and availability has \\n generated a new type of distributed data systems in which data is basically available, soft state, eventually consistent (BASE). BASE refers to a data consistency model in which data changes are not immediate but propagate slowly through the system until all replicas are eventually consistent. For example, NoSQL databases provide a highly \\n distributed database with eventual consistency (see Chapter 2, Data Models). In practice, the emergence of NoSQL distributed databases now provides a spectrum of consistency that ranges from the highly consistent (ACID) to the eventually consistent (BASE), as shown in Table 12.8.basically available, soft state, eventually consistent (BASE)\\nA data consistency model in which data changes are not immediate but propagate slowly through the system until all replicas are eventually consistent.\\nTABLE 12.8\\nDISTRIBUTED DATABASE SPECTRUM\\nDBMS TYPE CONSISTENCY AVAILABILITY PARTITION \\nTOLERANCETRANSACTION MODELTRADE-OFF\\nCentralized DBMSHigh High N/A ACID No distributed data \\n processing\\nRelational DBMSHigh Relaxed High ACID (2PC) Sacrifices availability to \\nensure consistency and isolation.\\nNoSQL DDBMSRelaxed High High BASE Sacrifices consistency to ensure availability\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b152a6d-beb1-4481-b919-1cafb5237afa', embedding=None, metadata={'page_label': '583', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    583\\n12-13   C. J. Date’s 12 Commandments for \\nDistributed Databases\\nThe notion of distributed databases has been around for over 20 years. With the rise of relational databases, most vendors implemented their own versions of distributed  \\ndatabases, generally highlighting their respective product’s strengths. To make compar -\\nisons easier, C. J. Date formulated 12 “commandments” or basic principles of distrib-uted databases.\\n3 Although no current DDBMS conforms to all of them, they constitute  \\na useful target. The 12 rules are shown in Table 12.9.\\n3 C. J. Date, “Twelve rules for a distributed database, ” Computerworld 2 (23), June 8, 1987, pp. 77–81.TABLE 12.9\\nC. J. DATE’S 12 COMMANDMENTS FOR DISTRIBUTED DATABASES\\nRULE NUMBER RULE NAME RULE EXPLANATION\\n1 Local-site \\n independenceEach local site can act as an independent, autonomous, centralized DBMS.Each site is responsible for security, concurrency control, backup, and \\n recovery.\\n2 Central-site \\n independenceNo site in the network relies on a central site or any other site. All sites have the same capabilities.\\n3 Failure \\n independenceThe system is not affected by node failures. The system is in continuous \\n operation even in the case of a node failure or an expansion of the network.\\n4 Location \\n transparencyThe user does not need to know the location of data to retrieve that data.\\n5 Fragmentation transparencyData fragmentation is transparent to the user, who sees only one \\n logical \\n database. The user does not need to know the name of the database \\n fragments to retrieve them.\\n6 Replication \\n transparencyThe user sees only one logical database. The DDBMS transparently selects the database fragment to access. To the user, the DDBMS manages all fragments transparently.\\n7 Distributed query processingA distributed query may be executed at several different DP sites. Query \\n optimization is performed transparently by the DDBMS.\\n8 Distributed transac-tion processingA transaction may update data at several different sites, and the transaction is\\xa0executed transparently.\\n9 Hardware \\n independenceThe system must run on any hardware platform.\\n10 Operating system independenceThe system must run on any operating system platform.\\n11 Network \\n independenceThe system must run on any network platform.\\n12 Database \\n independenceThe system must support any vendor’s database product.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='250468d4-3d7c-4d5e-b968-77e1b43ca3c0', embedding=None, metadata={'page_label': '584', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='584   Part 4    Advanced Database Concepts\\nSummary\\n• A distributed database stores logically related data in two or more physically indepen-\\ndent sites connected via a computer network. The database is divided into fragments, which can be a horizontal set of rows or a vertical set of attributes. Each fragment can be allocated to a different network node.\\n•\\n Distributed processing is the division of logical database processing among two or more network nodes. Distributed databases require distributed processing. A distrib-uted database management system (DDBMS) governs the processing and storage of logically related data through interconnected computer systems.\\n•\\n The main components of a DDBMS are the transaction processor (TP) and the data processor (DP). The transaction processor component is the resident software on each computer node that requests data. The data processor component is the resident software on each computer that stores and retrieves data.\\n•\\n Current database systems can be classified by the extent to which they support pro-cessing and data distribution. Three major categories are used to classify distributed \\n database systems: single-site processing, single-site data (SPSD); multiple-site process-ing, single-site data (MPSD); and multiple-site processing, multiple-site data (MPMD).\\n•\\n A homogeneous distributed database system integrates only one particular type of DBMS over a computer network. A heterogeneous distributed database system inte-grates several different types of DBMSs over a computer network.\\n•\\n DDBMS characteristics are best described as a set of transparencies: distribution, transaction, performance, failure, and heterogeneity. All transparencies share the common objective of making the distributed database behave as though it were a cen-tralized database system; that is, the end user sees the data as part of a single, logical centralized database and is unaware of the system’s complexities.\\n•\\n A transaction is formed by one or more database requests. An undistributed transac-tion updates or requests data from a single site. A distributed transaction can update or request data from multiple sites.\\n•\\n Distributed concurrency control is required in a network of distributed databases. A two-phase COMMIT protocol is used to ensure that all parts of a transaction are completed.\\n•\\n A distributed DBMS evaluates every data request to find the optimum access path in a distributed database. The DDBMS must optimize the query to reduce associated access costs, communication costs, and CPU costs.\\n•\\n The design of a distributed database must consider the fragmentation and replication of data. The designer must also decide how to allocate each fragment or replica to obtain better overall response time and to ensure data availability to the end user. \\n Ideally, a distributed database should evenly distribute data to maximize  performance, \\navailability, and location awareness.\\n• A database can be replicated over several different sites on a computer network. The \\n replication of the database fragments has the objective of improving data availability, thus decreasing access time. A database can be partially, fully, or not replicated. Data allocation strategies are designed to determine the location of the database fragments or replicas.\\n•\\n The CAP theorem states that a highly distributed data system has some desirable properties of consistency, availability, and partition tolerance. However, a system can only provide two of these properties at a time.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f9b8ebb0-daac-4477-b46f-271d7c50f581', embedding=None, metadata={'page_label': '585', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 12    Distributed Database Management Systems    585\\napplication processor (AP)\\nbasically available, soft \\nstate, eventually \\n consistent (BASE)\\ncentralized data allocationclient/server architecturecoordinatordata allocationdata fragmentationdata manager (DM)data processor (DP)data replicationdatabase fragmentsdistributed databasedistributed database man-\\nagement system (DDBMS)\\ndistributed data catalog \\n(DDC)\\ndistributed data dictionary \\n(DDD)\\ndistributed global schemadistributed processingdistributed requestdistributed transactiondistribution transparencyDO-UNDO-REDO protocolfailure transparencyfragmentation transparencyfully heterogeneous DDBMSfully replicated databaseheterogeneity transparencyheterogeneous DDBMShomogeneous DDBMShorizontal fragmentationlocal mapping transparencylocation transparencymixed fragmentationmultiple-site processing,  \\nmultiple-site data \\n(MPMD)\\nmultiple-site processing, \\nsingle-site data (MPSD)\\nmutual consistency rule\\nnetwork latencynetwork partitioningpartially replicated  \\ndatabase\\npartitioned data  \\nallocation\\npartition keyperformance  \\ntransparency\\nremote requestremote transactionreplica transparencyreplicated data allocationsingle-site processing, \\n single-site data (SPSD)\\nsubordinatestransaction manager (TM)transaction processor (TP)transaction transparencytwo-phase commit protocol \\n(2PC)\\nunique fragmentunreplicated databasevertical fragmentationwrite-ahead protocolKey Terms\\nFlashcards and crossword \\npuzzle for key term  practice \\nare available at www.  \\ncengagebrain.com.Online \\nContent\\n1. Describe the evolution from centralized DBMSs to distributed DBMSs.\\n2. List and discuss some of the factors that influenced the evolution of the DDBMS.\\n3. What are the advantages of the DDBMS?\\n4. What are the disadvantages of the DDBMS?\\n5. Explain the difference between a distributed database and distributed processing.\\n6. What is a fully distributed database management system?\\n7. What are the components of a DDBMS?\\n8. List and explain the transparency features of a DDBMS.\\n9. Define and explain the different types of distribution transparency.\\n10. Describe the different types of database requests and transactions.\\n11. Explain the need for the two-phase commit protocol. Then describe the two phases.\\nReview Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fff90754-2e31-4bd3-8d47-a5c407caf86e', embedding=None, metadata={'page_label': '586', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='586   Part 4     Advanced Database Concepts\\n12. What is the objective of query optimization functions?\\n13. To which transparency feature are the query optimization functions related?\\n14. What issues should be considered when resolving data requests in a distributed data \\nenvironment?\\n15. Describe the three data fragmentation strategies. Give some examples of each.\\n16. What is data replication, and what are the three replication strategies?\\n17. What are the two basic styles of data replication?\\n18. What trade-offs are involved in building highly distributed data environments?\\n19. How does a BASE system differ from a traditional distributed database system?\\nFIGURE P12.1  THE DDBMS SCENARIO FOR PROBLEM 1  \\nTABLES LOCATION FRAGMENTS\\nCUSTOMER\\nPRODUCT\\nINVOICE\\nINV_LINEN/A\\nPROD_A\\nPROD_B\\nN/A\\nN/AA\\nA\\nB\\nB\\nB\\nSite CSite A Site BProblems\\nProblem 1 is based on the DDBMS scenario in Figure P12.1.\\n1. Specify the minimum types of operations the database must support to perform the \\nfollowing operations. These operations include remote requests, remote  transactions, \\ndistributed transactions, and distributed requests.\\nAt Site C\\na. SELECT *\\nFROM CUSTOMER;\\nb.SELECT *\\nFROM INVOICE\\nWHERE INV_TOT < 1000;\\nc. SELECT *\\nFROM PRODUCT\\nWHERE PROD_ QOH < 10;\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f4393318-1219-4be9-be08-103100e68ebd', embedding=None, metadata={'page_label': '587', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Chapter 12    Distributed Database Management Systems    587\\nd.BEGIN WORK;\\nUPDATE CUSTOMER\\nSET CUS_BAL = CUS_BAL + 100\\nWHERE CUS_NUM = '10936';\\nINSERT INTO INVOICE(INV_NUM, CUS_NUM, INV_\\nDATE, INV_TOTAL)\\nV ALUES ('986391', '10936', '15-FEB-2016', 100);\\nINSERT INTO LINE(INV_NUM, PROD_NUM, LINE_PRICE)V ALUES('986391', '1023', 100);\\nUPDATE PRODUCT\\nSET PROD_QOH = PROD_ QOH –1\\nWHERE PROD_NUM = '1023';\\nCOMMIT WORK;\\ne.BEGIN WORK;INSERT INTO CUSTOMER(CUS_NUM, CUS_NAME, CUS_\\nADDRESS, CUS_BAL)\\nV ALUES ('34210', 'Victor Ephanor', '123 Main St.', 0.00);\\nINSERT INTO INVOICE(INV_NUM, CUS_NUM, INV_\\nDATE, INV_TOTAL)\\nV ALUES ('986434', '34210', '10-AUG-2016', 2.00);\\nCOMMIT WORK;\\nAt Site A\\nf.SELECT CUS_NUM, CUS_NAME, INV_TOTAL\\nFROM CUSTOMER, INVOICE\\nWHERE CUSTOMER.CUS_NUM = INVOICE.CUS_NUM;\\ng.SELECT *\\nFROM INVOICE\\nWHERE INV_TOTAL > 1000;\\nh. SELECT *\\nFROM PRODUCT\\nWHERE PROD_QOH < 10;\\nAt Site B\\ni.SELECT *\\nFROM CUSTOMER;\\nj.SELECT CUS_NAME, INV_TOTAL\\nFROM CUSTOMER, INVOICE\\nWHERE INV_TOTAL > 1000 AND CUSTOMER.CUS_NUM = \\nINVOICE.CUS_NUM;\\nk. SELECT *\\nFROM PRODUCT\\nWHERE PROD_QOH < 10;\\n2.\\n The following data structure and constraints exist for a magazine publishing company:\\n  a.  The company publishes one regional magazine in each of four states:  Florida\\xa0(FL), \\nSouth Carolina (SC), Georgia (GA), and Tennessee (TN).\\n  b.  The company has 300,000 customers (subscribers) distributed throughout the four states listed in Problem 2a.\\n  c.  On the first day of each month, an annual subscription INVOICE is printed and sent to each customer whose subscription is due for renewal. The INVOICE entity contains a REGION attribute to indicate the customer’s state of residence (FL, SC, GA, TN):\\n  CUSTOMER (CUS_NUM, CUS_NAME, CUS_ADDRESS, CUS_CITY , CUS_ZIP , CUS_SUBSDATE)\\n  INVOICE (INV_NUM, INV_REGION, CUS_NUM, INV_DATE, INV_TOTAL)\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba72d341-6124-46b7-84e4-d5f83b99a1bb', embedding=None, metadata={'page_label': '588', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='588   Part 4    Advanced Database Concepts\\n     The company is aware of the problems associated with centralized manage-\\nment and has decided to decentralize management of the  subscriptions into the \\n company’s four regional subsidiaries. Each subscription site will handle its own customer and invoice data. The management at company headquarters, \\n however, \\nwill have access to  customer and invoice data to generate annual reports and to \\nissue ad hoc queries such as:\\n   • Listing all current customers by region\\n   • Listing all new customers by region\\n   • Reporting all invoices by customer and by region\\n    Given these requirements, how must you partition the database?\\n3. Given the scenario and requirements in Problem 2, answer the following questions:\\n  a.  What recommendations will you make regarding the type and characteristics of the required database system?\\n  b. What type of data fragmentation is needed for each table?\\n  c. What criteria must be used to partition each database?\\n  d.  Design the database fragments. Show an example with node names, location, fragment names, attribute names, and demonstration data.\\n  e.  What type of distributed database operations must be supported at each remote\\xa0site?\\n   f.  What type of distributed database operations must be supported at the \\n headquarters site?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='277b0937-2e65-4d1d-85ec-ac16bf99cb2b', embedding=None, metadata={'page_label': '589', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13\\nBusiness Intelligence and Data Warehouses\\nIn this chapter, you will learn:\\n• How business intelligence provides a comprehensive business decision support framework\\n• About business intelligence architecture, its evolution, and reporting styles\\n• About the relationship and differences between operational data and decision support data\\n• What a data warehouse is and how to prepare data for one\\n• What star schemas are and how they are constructed\\n• About data analytics\\n• About online analytical processing (OLAP)\\n• How SQL extensions are used to support OLAP-type data manipulations\\nPreviewBusiness intelligence (BI) is the collection of best practices and software tools developed \\nto support business decision making in this age of globalization, emerging markets, rapid change, and increasing regulation. The complexity and range of information required to support business decisions has increased, and operational database structures were unable to support all of these requirements. Therefore, a new data storage facility, called a data warehouse , developed. The data warehouse extracts its data from operational databases as \\nwell as from external sources, providing a more comprehensive data pool.\\nAdditionally, new ways to analyze and present decision support data were developed. \\nOnline analytical processing (OLAP) provides advanced data analysis and visualization tools, including multidimensional data analysis. This chapter explores the main concepts and components of business intelligence and decision support systems that gather, gener -\\nate, and present information for business decision makers, focusing especially on the use of data warehouses.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH13_Text              P\\t P\\t P\\t P CH13_PI  P\\t P\\t P\\t P\\nCH13_P3  P\\t P\\t P\\t P\\nCH13_P4  P\\t P\\t P\\t P\\nCH13_SaleCo_DW  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f2eb8d5c-7cf3-4265-95c0-38bcf9d7ff98', embedding=None, metadata={'page_label': '590', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='590   Part 4    Advanced Database Concepts\\n13-1  The Need for Data Analysis\\nOrganizations tend to grow and prosper as they gain a better understanding of their \\nenvironment. Most managers need to track daily transactions to evaluate how the busi-ness is performing. By tapping into the operational database, management can develop an understanding of how the company is performing and evaluate whether the current strategies meet organizational goals. In addition, analyzing the company data can pro-vide insightful information about short-term tactical evaluations and strategic questions, such as: Are our sales promotions working? What market percentage are we controlling? Are we attracting new customers? Tactical and strategic decisions are also shaped by constant pressure from external and internal forces, including globalization, the cultural and legal environment, and technology.\\nOrganizations are always looking for a competitive advantage through product devel-\\nopment, market positioning, sales promotions, and customer service. Thanks to the Internet, customers are more informed than ever about the products they want and the prices they are willing to pay. Technology advances allow customers to place orders using their smart phones while they commute to work in the morning. Decision makers can no longer wait a couple of days for a report to be generated; they are compelled to make quick decisions if they want to remain competitive. Every day, TV ads offer low-price warranties, instant price matching, and so on. How can companies survive on lower margins and still make a profit? The key is in having the right data at the right time to support the decision-making process.\\nThis process takes place at all levels of an organization. For example, transaction-\\n \\nprocessing systems, based on operational databases, are tailored to serve the information needs of people who deal with short-term inventory, accounts payable, and purchasing. Middle-level managers, general managers, vice presidents, and presidents focus on stra-tegic and tactical decision making. Those managers require summarized information designed to help them make decisions in a complex business environment.\\nCompanies and software vendors addressed these multilevel decision support needs \\nby creating autonomous applications for particular groups of users, such as those in finance, customer management, human resources, and product support. Applications were also tailored to different industries such as education, retail, health care, and finance. This approach worked well for some time, but changes in the business world, such as \\n globalization, expanding markets, mergers and acquisitions, increased  regulation, and \\nnew technologies, called for new ways of integrating and managing decision support across levels, sectors, and geographic locations. This more comprehensive and integrated decision support framework within organizations became known as business intelligence.\\n13-2  Business Intelligence\\nBusiness intelligence (BI)1 is a term that describes a comprehensive, cohesive, and \\n integrated set of tools and processes used to capture, collect, integrate, store, and  analyze \\ndata with the purpose of generating and presenting information to support business decision making. This intelligence is based on learning and understanding the facts about the business environment. BI is a framework that allows a business to transform data into information, information into knowledge, and knowledge into wisdom. BI has the potential to positively affect a company’s culture by creating continuous business per -\\nformance improvement through active decision support at all levels in an organization. \\n1 In 1989, while working at Gartner, Inc., Howard Dresner popularized BI as an umbrella term to describe \\na set of concepts and methods to improve business decision making by using fact-based support systems \\n(www.computerworld.com/s/article/266298/BI_at_age_17).business \\nintelligence\\xa0(BI)\\nA comprehensive, cohesive, and integrated set of tools and processes used to capture, collect, integrate, store, and analyze data with the purpose of generating and presenting information to support business decision making.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3b313b2-e766-4cfd-b5f2-6976361ff33e', embedding=None, metadata={'page_label': '591', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    591\\nThis business insight empowers users to make sound decisions based on the accumu-\\nlated knowledge of the business.\\nBI’s initial adopters were high-volume industries such as financial services, insurance, and \\nhealthcare companies. As BI technology evolved, its usage spread to other industries such as telecommunications, retail/merchandising, manufacturing, media, government, and even education. Table 13.1 lists some companies that have implemented BI tools and shows how the tools benefited the companies. Y ou will learn about these tools later in the chapter.\\nTABLE 13.1\\nSOLVING BUSINESS PROBLEMS AND ADDING VALUE WITH BI TOOLS\\nCOMPANY PROBLEM BENEFIT\\nCiCi’s EnterprisesEighth-largest pizza chain in the United States; \\n operates 650 pizza \\n restaurants in 30 statesSource: Cognos Corp. www.cognos.com•\\n Information access was cumbersome and time-consuming\\n•\\n Needed to increase accuracy in the creation of marketing budgets\\n•\\n Needed an easy, reliable, and efficient way to access daily data•\\n Provided accurate, timely budgets in less time\\n•\\n Provided analysts with access to data for decision-making purposes\\n•\\n Received in-depth view of product \\n performance by store to reduce waste and\\xa0increase profits\\nNASDAQLargest U.S. electronic stock market trading \\n organizationSource: Oracle Corp. www.oracle.com•\\n Inability to provide real-time, ad hoc query and standard reporting for executives, business analysts, and other users\\n•\\n Excessive storage costs for many terabytes of data•\\n Reduced storage costs by moving to a \\n multitier storage solution\\n• Implemented new data warehouse \\n center with support for ad hoc query and \\n reporting, and near real-time data access for end users\\nPfizerGlobal pharmaceutical companySource: Oracle Corp.  www.oracle.com•\\n Needed a way to control costs and adjust to tougher market \\n conditions, \\ninternational competition, and \\n increasing government regulations\\n• Needed better analytical  capabilities and \\nflexible decision-making  framework• Ability to get and integrate financial data from multiple sources in a reliable way\\n•\\n Streamlined, standards-based financial analysis to improve forecasting process\\n•\\n Faster and smarter decision making for business strategy formulation\\nSwisscomSwitzerland’s leading \\n telecommunications providerSource: Microsoft Corp. www.microsoft.com•\\n Needed a tool to help employees monitor service-level compliance\\n•\\n Had a time-consuming process to generate performance reports\\n•\\n Needed a way to integrate data from 200 different systems•\\n Ability to monitor performance using \\n dashboard technology\\n• Quick and easy access to real-time \\n performance data\\n• Managers have closer and better control over costs\\nImplementing BI in an organization involves capturing not only internal and external \\nbusiness data, but also the metadata, or knowledge about the data. In practice, BI is a complex proposition that requires a deep understanding and alignment of the business processes, business data, and information needs of users at all levels in an organization. (See Appendix O, Data Warehouse Implementation Factors.)\\nBI is not a product by itself, but a framework of concepts, practices, tools, and tech-\\nnologies that help a business better understand its core capabilities, provide snapshots of the company situation, and identify key opportunities to create competitive advantage. In general, BI provides a framework for:\\n•\\n Collecting and storing operational data\\n• Aggregating the operational data into decision support data\\n• Analyzing decision support data to generate information\\n• Presenting such information to the end user to support business decisions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f44ebfd-2aa4-47a4-a84c-935fe6f6c51d', embedding=None, metadata={'page_label': '592', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='592   Part 4     Advanced Database Concepts\\n• Making business decisions, which in turn generate more data that is collected, stored, \\nand so on (restarting the process)\\n• Monitoring results to evaluate outcomes of the business decisions, which again \\n provides more data to be collected, stored, and so on\\n• Predicting future behaviors and outcomes with a high degree of accuracy\\nThe preceding points represent a system-wide view of the flow of data, processes, \\nand outcomes within the BI framework. In practice, the first point, collecting and stor -\\ning operational data, does not fall into the realm of a BI system per se; rather, it is the \\nfunction of an operational system. However, the BI system will use the operational data \\nas input material from which information will be derived. The rest of the processes and \\noutcomes explained in the preceding points are oriented toward generating knowledge, \\nand they are the focus of the BI system. In the following section, you will learn about the \\nbasic BI architecture.\\n13-2a  Business Intelligence Architecture\\nBI covers a range of technologies and applications to manage the entire data life cycle \\nfrom acquisition to storage, transformation, integration, presentation, analysis, monitor -\\ning, and archiving. BI functionality ranges from simple data gathering and transforma -\\ntion to very complex data analysis and presentation. BI architecture ranges from highly \\nintegrated single-vendor systems to loosely integrated, multivendor environments. \\nHowever, some common functions are expected in most BI implementations.\\nLike any critical business IT infrastructure, the BI architecture is composed of many \\ninterconnected parts: people, processes, data, and technology working together to facil -\\nitate and enhance a business’s management and governance. Figure 13.1 depicts how  \\nall these components fit together within the BI framework.\\nFIGURE 13.1  BUSINESS INTELLIGENCE FRAMEWORK  \\nBusiness Intelligence FrameworkProcesses\\nManagement GovernanceData visualization\\nMonitoring\\nand alertingData\\nanalytics\\nQuery & reportingPeople\\nExtraction,\\ntransformation,\\nand loadingExternal\\ndataOperational\\ndata\\nData\\nwarehouseData store\\nDatamartETL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e6e30c7e-3fef-4cc6-bd50-75067289a6e2', embedding=None, metadata={'page_label': '593', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    593\\nTABLE 13.2\\nBASIC BI ARCHITECTURAL COMPONENTS\\nCOMPONENT DESCRIPTION\\nETL tools Data extraction, transformation, and loading (ETL)  tools collect, \\nfilter, integrate, and  aggregate internal and external data to be saved \\ninto a data store optimized for decision  support.\\xa0Internal data is \\ngenerated by the company during its day-to-day operations, such \\nas  product sales history, invoicing, and payments. The external data \\nsources provide data that cannot be found within the company but is relevant to the business, such as stock prices, market \\n indicators, \\n marketing information (such as demographics), and competitors’  data. Such data is generally \\n located in external databases provided  \\nby industry groups or companies that market the\\xa0data.\\nData store The data store is optimized for decision support and is generally \\nrepresented by a data  warehouse\\xa0or a data mart. The data is stored  \\nin structures that are optimized for data analysis and\\xa0query speed.\\nQuery and \\n reportingThis component performs data selection and retrieval, and it is used by the data analyst to create queries that access the database and create the required reports. Depending on the \\n implementation, the \\nquery and reporting tool accesses the operational database, or more \\n commonly, the data store.\\nData visualization This component presents data to the end user in a variety of \\nmeaningful and innovative ways. This tool helps the end user select the most appropriate presentation format, such as summary reports, maps, pie or bar graphs, mixed graphs, and static or interactive dashboards.\\nData monitoring and alertingThis component allows real-time monitoring of business activities. The BI system will present the concise information in a single integrated view for the data analyst. This integrated view could \\n include specific \\nmetrics about the system performance or activities, such as number of orders placed in the last four hours, number of customer complaints by product by month, and total revenue by region. Alerts can be placed on a given metric; once the value of a metric goes below or above a certain baseline, the system will perform a given action, such as emailing shop floor managers, presenting visual alerts, or starting an application.\\nData analytics This component performs data analysis and data-mining tasks using \\nthe data in the data store. This tool advises the user as to which data analysis tool to select and how to build a reliable business data model. Business models are generated by special algorithms that identify and enhance the understanding of business situations and problems. Data analysis can be either explanatory or predictive. Explanatory analysis uses the existing data in the data store to discover relationships and their types, and predictive analysis creates statistical models of the data that allow \\n predictions of future values and events. Chapter 14, \\nBig Data Analytics and NoSQL, covers these topics in more\\xa0detail.extraction, \\n transformation, and loading (ETL)\\nIn a data warehousing environment, the integrated processes of getting data from original sources into the data warehouse. ETL includes retrieving data from original data sources (extraction), manipulating the data into an appropriate form (transformation), and storing the data in the data warehouse (loading).The general BI framework depicted in Figure 13.1 has six basic components that \\nencompass the functionality required on most current-generation BI systems. Y ou will learn more about these components later in this and future chapters. The components are briefly described in Table 13.2.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e74bbe4a-2138-4b70-a92d-ce547aa8f3c0', embedding=None, metadata={'page_label': '594', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='594   Part 4    Advanced Database Concepts\\nEach BI component shown in Table 13.2 has generated a fast-growing market for \\nspecialized tools. Thanks to technological advancements, the components can interact \\nwith other components to form a truly open architecture. As a matter of fact, you can integrate multiple tools from different vendors into a single BI framework. Table 13.3 shows a sample of common BI tools and vendors.\\nTABLE 13.3\\nSAMPLE OF BUSINESS INTELLIGENCE TOOLS\\nTOOL DESCRIPTION SAMPLE VENDORS\\nDashboards and business activity monitoring Dashboards  use web-based \\n technologies to present key business performance indicators or information in a single integrated view, generally using graphics that are clear, concise, and easy to understand.SalesforceIBM/CognosBusinessObjectsInformation BuildersiDashboards\\nPortals\\nPortals  provide a unified, single point of \\nentry for information distribution. Portals are a web-based technology that use a web browser to integrate data from multiple sources into a single webpage. Many different types of BI functionality can be accessed through a portal.Oracle PortalActuateMicrosoftSAP\\nData analysis and reporting toolsThese advanced tools are used to \\n query multiple and diverse data \\n sources to create integrated reports.Microsoft Reporting ServicesMicroStrategySAS WebReportStudio\\nData-mining tools These tools provide advanced \\n statistical analysis to uncover \\n problems and opportunities hidden within business data. Chapter 14 \\n covers data mining in more detail.SAPTeradataMicroStrategyMS Analytics Services\\nData warehouses (DW)The data warehouse is the foundation of a BI infrastructure. Data is captured from the production system and placed in the DW on a near real-time basis. BI provides company-wide \\n integration of \\ndata and the capability to respond to business issues in a timely manner.MicrosoftOracleIBM/CognosTeradata\\nOLAP tools Online analytical processing provides \\nmultidimensional data analysis.IBM/CognosBusinessObjectsOracleMicrosoft\\nData visualization These tools provide advanced visual \\nanalysis and techniques to enhance understanding and create additional insight of business data and its true meaning.DundasTableauQlikViewActuatedashboard\\nIn business intelligence, a web-based system that presents key business performance indicators or information in a single, integrated view with clear and concise graphics.\\nportal\\nIn terms of business intelligence, a unified, single point of entry for information distribution.\\nYou will learn about data warehouses and OLAP tools later in this chapter, and learn about data mining in Chapter 14.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f67ee269-c2ed-4275-8269-3b5fe3d7d636', embedding=None, metadata={'page_label': '595', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    595\\nAs depicted in Figure 13.1, BI integrates people and processes using technology at all \\nlevels of the organization. A sound BI strategy adds value to an organization by provid-\\ning the right data, in the right format, to the right people, at the right time. Such value is derived from how end users apply such information in their daily activities, and partic-ularly in their daily business decision making.\\nThe focus of traditional information systems was on operational automation and \\nreporting; in contrast, BI tools focus on the strategic and tactical use of information. To achieve this goal, BI recognizes that technology alone is not enough. Therefore, BI uses an arrangement of best management practices to manage data as a corporate asset. One of the most recent developments in this area is the use of master data management techniques. Master data management (MDM) is a collection of concepts, techniques, \\nand processes for the proper identification, definition, and management of data elements within an organization. MDM’s main goal is to provide a comprehensive and consistent definition of all data within an organization. MDM ensures that all company resources (people, procedures, and IT systems) that work with data have uniform and consistent views of the company’s data.\\nAn added benefit of this meticulous approach to data management and decision \\nmaking is that it provides a framework for business governance. Governance is a method or process of government. In this case, BI provides a method for controlling and \\n monitoring business health and for consistent decision making. Furthermore, hav-\\ning such  governance creates accountability for business decisions. In the present age of \\nbusiness flux, accountability is increasingly important. Had governance been as pivotal to business operations a few years back, crises precipitated by Enron, WorldCom, Arthur Andersen, and the 2008 financial meltdown might have been avoided.\\nMonitoring a business’s health is crucial to understanding where the company is and \\nwhere it is headed. To do this, BI makes extensive use of a special type of metrics known as key performance indicators. Key performance indicators (KPIs) are quantifiable numeric or scale-based measurements that assess the company’s effectiveness or success in reaching its strategic and operational goals. Many different KPIs are used by different industries. Some examples of KPIs are:\\n•\\n General. Y ear-to-year measurements of profit by line of business, same-store sales, \\nproduct turnovers, product recalls, sales by promotion, and sales by employee\\n• Finance . Earnings per share, profit margin, revenue per employee, percentage of sales \\nto account receivables, and assets to sales\\n• Human resources . Applicants to job openings, employee turnover, and employee \\nlongevity\\n• Education . Graduation rates, number of incoming freshmen, student retention rates, \\npublication rates, and teaching evaluation scores\\nKPIs are determined after the main strategic, tactical, and operational goals are \\ndefined for a business. To tie the KPI to the strategic master plan of an organization, a KPI is compared to a desired goal within a specific time frame. For example, if you are in an academic environment, you might be interested in ways to measure student satisfaction or retention. In this case, a sample goal would be to increase the final exam grades of graduating high school seniors by Fall 2019. Another sample KPI would be to increase the returning student rate from freshman year to sophomore year from 60\\xa0\\n percent to 75 percent by 2019. In this case, such performance indicators would be \\nmeasured and monitored on a year-to-year basis, and plans to achieve such goals would be set in place.\\nAlthough BI has an unquestionably important role in modern business operations, the \\nmanager must initiate the decision support process by asking the appropriate questions. master data \\n management (MDM)\\nIn business intelligence, a collection of concepts, techniques, and processes for the proper identification, definition, and management of data elements within an organization.\\ngovernance\\nIn business intelligence, the methods for controlling and monitoring business health and promoting consistent decision making.\\nkey performance indicators (KPIs)\\nIn business intelligence, quantifiable numeric or scale-based measurements that assess a company’s effectiveness or success in reaching strategic and operational goals. Examples of KPIs are product turnovers, sales by promotion, sales by employee, and earnings per share.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aa8a8b1a-dd36-4fc5-ae2a-b10781af8f22', embedding=None, metadata={'page_label': '596', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='596   Part 4     Advanced Database Concepts\\nThe BI environment exists to support the manager; it does not replace the management \\nfunction. If the manager fails to ask the appropriate questions, problems will not be \\n identified and solved, and opportunities will be missed. In spite of the very powerful  \\nBI presence, the human component is still at the center of business technology.\\nHaving a well-implemented BI environment (people, processes, technology, manage -\\nment, and governance) positions a company to react quickly to changes in the environ -\\nment. Today’s customers are more connected than ever with other customers (current or \\npotential), companies, and organizations. In certain industries, social media plays a key \\nrole in marketing, brand recognition, and development. A simple tweet could generate \\nmillions of dollars in new sales or could cost a company millions of dollars in revenue. \\nCompanies monitor social media data to identify trends and quickly react to current or \\nfuture threats or opportunities.\\nData visualization  is abstracting data to provide information in a visual format that \\nenhances the user’s ability to effectively comprehend the meaning of the data. The goal of \\ndata visualization is to allow the user to see the big picture in the most efficient way pos -\\nsible. Tables with hundreds, thousands, or millions of rows of data cannot be processed \\nby the human mind. Providing summarized tabular data to managers does not give them \\nthe insight into the meaning of the data that they need to make informed decisions. \\nData visualization aggregates the data into a format that provides at-a-glance insight into \\noverall trends and patterns.\\nData visualization techniques can range from simple to very complex, and many \\nare familiar. Techniques include: pie charts, line graphs, bar charts, scatter plots, Gantt \\ncharts, heat maps, and more.\\nAn example of a heat map is shown in Figure 13.2. This heat map was created using \\nTableau ( www.tableau.com ), a data visualization tool, to analyze sales for a company. data visualization\\nAbstracting data to \\nprovide information \\nin a visual format that \\nenhances the user’s \\nability to effectively \\ncomprehend the \\nmeaning of the data.\\nFIGURE 13.2  VISUALIZING SALES TOTAL BY zip CODE\\nCourtesy of Tableau\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c9e2b54e-690d-4613-8b33-e6c7edc964dd', embedding=None, metadata={'page_label': '597', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    597\\nThe size of the circles is determined by the dollar value of the sales summed for all sales \\nin each zip code, such that larger total sales produce a larger circle. The circles are then mapped against a geographical map of the United States based on the zip code. The figure makes it easy for a manager to quickly see the region of the northeastern United States that has the greatest sale penetration.\\nIn addition to specialized data visualization software such as Tableau, R, and \\nGephi, common productivity tools such as Microsoft Excel can often provide surpris-ingly \\n powerful data visualization. Excel has long provided basic charting abilities and \\n PivotTable and PivotChart capabilities for visualizing spreadsheet data. More recently, the introduction of the PowerPivot add-in has eliminated row and column data \\n limitations \\nand allows for the integration of data from multiple sources. This puts powerful data visualization capabilities on the desktop of most business users.\\nData visualization plays an important role in discovering and understanding the \\n meaning\\xa0of\\xa0data. New ways to present data are being constantly developed. Good data \\n visualizations can be used in any discipline. For example, see the video from Dr. Hans \\n Rosling, (www.youtube.com/watch?v=jbkSRLYSojo) in which he uses public health data  \\nto visualize the history of the world in the last 200 years.Note\\nThe main BI architectural components were illustrated in Figure 13.1 and further \\nexplained in Tables 13.2 and 13.3. However, the heart of the BI system is its advanced information generation and decision support capabilities. A BI system’s advanced deci-sion support functions come to life via its intuitive and informational user interface, and particularly its reporting capabilities. A modern BI system provides three distinctive reporting styles:\\n•\\n Advanced reporting . A BI system presents insightful information about the organiza-\\ntion in a variety of presentation formats. Furthermore, the reports provide interactive \\nfeatures that allow the end user to study the data from multiple points of view—from highly summarized to very detailed data. The reports present key actionable informa-tion used to support decision making.\\n•\\n Monitoring and alerting . After a decision has been made, the BI system offers ways \\nto monitor the decision’s outcome. The BI system provides the end user with ways\\xa0to define metrics and other key performance indicators to evaluate different aspects of an organization. In addition, exceptions and alerts can be set to warn managers promptly about deviations or problem areas.\\n•\\n Advanced data analytics . A BI system provides tools to help the end user discover \\nrelationships, patterns, and trends hidden within the organization’s data. These tools are used to create two types of data analysis: explanatory and predictive. Explanatory analysis provides ways to discover relationships, trends, and patterns among data, while predictive analysis provides the end user with ways to create models that predict future outcomes.\\nUnderstanding the architectural components of a BI framework is the first step in \\nproperly implementing BI in an organization. A good BI infrastructure promises many benefits to an organization, as outlined in the next section.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd822c1f-238b-423e-8351-838694d2494b', embedding=None, metadata={'page_label': '598', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='598   Part 4    Advanced Database Concepts\\n13-2b  Business Intelligence Benefits\\nAs you have learned in previous sections, a properly implemented BI architecture could \\nprovide a framework for continuous performance improvements and business decision making. Improved decision making is the main goal of BI, but BI provides other benefits:\\n•\\n Integrating architecture . Like any other IT project, BI has the potential of becoming \\nthe integrating umbrella for a disparate mix of IT systems within an organization. \\nThis architecture could support all types of company-generated data from operational to executive, as well as diverse hardware such as mainframes, servers, desktops for managers and executives, and mobile devices on the shop floor.\\n•\\n Common user interface for data reporting and analysis. BI front ends can provide up-to-the-minute consolidated information using a common interface for all com-pany users. IT departments no longer have to provide multiple training options for diverse interfaces. End users benefit from similar or common interfaces in different devices that use multiple clever and insightful presentation formats.\\n•\\n Common data repository fosters single version of company data . In the past, multiple \\nIT systems supported different aspects of an organization’s operations. Such systems collected and stored data in separate data stores. Keeping the data synchronized and up to date has always been difficult. BI provides a framework to integrate such data under a common environment and present a single version of the data.\\n•\\n Improved organizational performance . BI can provide competitive advantages in many \\ndifferent areas, from customer support to manufacturing processes. Such advantages can be reflected in added efficiency, reduced waste, increased sales, reduced employee and customer turnover, and most importantly, an increased bottom line for the business.\\nAchieving all these benefits takes a lot of human, financial, and technological \\nresources, not to mention time. BI benefits are not achieved overnight, but are the result of a focused company-wide effort that could take a long time. As a matter of fact, as you will learn in the next section, the BI field has evolved over a long period of time itself.\\n13-2c  Business Intelligence Evolution\\nProviding useful information to end users has been a priority of IT systems since main-frame computing became an integral part of corporations. Business decision support has evolved over many decades. Following computer technology advances, business \\n intelligence started with centralized reporting systems and evolved into today’s highly integrated BI environments. Table 13.4 summarizes the evolution of BI systems.\\nUsing Table 13.4 as a guide, you can trace business intelligence from the mainframe  \\nenvironment to the desktop and then to the more current, cloud-based, mobile BI environments. (Chapter 15, Database Connectivity and Web Technologies, provides  \\na detailed discussion of cloud-based systems.)\\nThe precursor of the modern BI environment was the first-generation decision sup-\\nport system. A decision support system (DSS) is an arrangement of computerized tools used to assist managerial decision making. A DSS typically has a much narrower focus and reach than a BI solution. At first, decision support systems were the realm of a few selected managers in an organization. Over time, and with the introduction of the desktop computer, decision support systems migrated to more agile platforms, such as midrange computers, high-end servers, commodity servers, appliances, and cloud-based offerings. This evolution effectively changed the reach of decision support systems; BI is no longer limited to a small group of top-level managers with training in statistical \\ndecision support system (DSS)\\nAn arrangement of computerized tools used to assist managerial decision making within a business.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='897f50b1-bd38-42cf-bd9f-8871d46ecf50', embedding=None, metadata={'page_label': '599', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    599\\nTABLE 13.4\\nBUSINESS INTELLIGENCE EVOLUTION\\nSYSTEM TYPE DATA SOURCE DATA EXTRACTION/\\nINTEGRATION \\n PROCESSDATA STORE END-USER QUERY TOOLEND USER PRESENTATION TOOL\\nTraditional \\n mainframe-based online \\n transaction \\n processing (OLTP)Operational data None\\nReports read and \\n summarized data \\n directly from \\n operational dataNoneTemporary files used for \\n reporting \\n purposesVery basicPredefined reporting formatsBasic sorting, totaling, and averagingVery basicMenu-driven, \\n predefined reports, text and numbers only\\nManagerial \\n information \\n system (MIS)Operational data Basic extraction and \\naggregationRead, filter, and \\n summarize operational data into intermediate data storeLightly \\n aggregated data in RDBMSSame as above, in addition to some ad hoc reporting using SQLSame as above, in addition to some ad hoc columnar report definitions\\nFirst-generation departmental decision support system (DSS)Operational data External dataData extraction and integration process populates DSS data storeRun periodicallyFirst DSS \\n database \\n generationUsually RDBMSQuery tool with some \\n analytical \\n capabilities and predefined reportsSpreadsheet styleAdvanced \\n presentation tools with plotting and graphics \\n capabilities\\nFirst-generation BIOperational dataExternal dataAdvanced data \\n extraction and \\n integrationAccess diverse data sources, \\n filters, \\n aggregations, \\n classifications, \\n scheduling, and \\n conflict resolutionData  warehouse \\nRDBMS \\n technologyOptimized for query purposesStar schema modelSame as above Same as above, \\nin addition to multidimensional presentation tools with drill-down capabilities\\nSecond-\\n \\ngeneration BIOnline \\n analytical \\nprocessing (OLAP)Same as above Same as above Data warehouse \\nstores data in MDBMSCubes with \\n multiple \\n dimensionsAdds support for end-user-based data analyticsSame as above, but uses cubes and \\n multidimensional matrixes; limited by cube sizeDashboardsScorecardsPortals\\nThird-generationMobile, cloud-based, and Big DataSame as aboveIncludes \\n social \\n media and \\n machine- generated dataSame as above  Cloud-basedSame as aboveCloud-basedHadoop and NoSQL \\n databasesAdvanced \\n analyticsLimited ad hoc interactionsMobile devices: smartphones and tablets\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd9e4f1d-3349-4930-b668-4f7bcb74c82b', embedding=None, metadata={'page_label': '600', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='600   Part 4     Advanced Database Concepts\\nmodeling. Instead, BI is now available to all users in an organization, from line managers \\nto the shop floor to mobile agents in the field.\\nY ou can also use Table 13.4 to track the evolution of information dissemination styles \\nused in business intelligence.\\n• Starting in the late 1970s, the need for information distribution was filled by central -\\nized reports running on mainframes, minicomputers, or even central server environ -\\nments. Such reports were predefined and took considerable time to process.\\n• With the introduction of desktop computers in the 1980s, a new style of information \\ndistribution, the spreadsheet, emerged as the dominant format for decision support \\nsystems. In this environment, managers downloaded information from centralized \\ndata stores and manipulated the data in desktop spreadsheets.\\n• As the use of spreadsheets multiplied, IT departments tried to manage the flow of \\ndata in a more formal way using enterprise reporting systems. These systems were \\ndeveloped in the early 1990s and basically integrated all data into an IT umbrella that \\nstarted with the first-generation DSS. The systems still used spreadsheet-like features \\nwith which end users were familiar.\\n• Once DSSs were established, the evolution of business intelligence flourished with the \\nintroduction of the data warehouse and online analytical processing systems (OLAPs) \\nin the mid-1990s.\\n• Rapid changes in information technology and the Internet revolution led to the \\n introduction of advanced BI systems such as web-based dashboards in the early and \\nmid 2000s and mobile BI later in the decade. With mobile BI, end users access BI \\nreports via native applications that run on a mobile smart device, such as a smart -\\nphone or tablet.\\n• More recently, the social media revolution has generated large amounts of data. At \\nthe same time sensor-generated data is being collected and stored. Companies are \\nusing Big Data analytics tools to leverage such data and obtain critical information \\notherwise unavailable to them.\\nFigure 13.3 depicts the evolution of BI information dissemination.\\nFIGURE 13.3  EVOLUTION OF BI INFORMATION DISSEMINATION FORMATS  \\nOLAP Mobile BIBig Data\\nanalytics/Hadoop\\n/NoSQLSpreadsheets Dashboards Enterprise\\nreporting2010s+ 1970s 1980s 1990s 2000s\\nCentralized\\nreporting\\n© Antun Hirsman/Shutterstock.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fefcdf12-727d-434e-b5ee-8b77fa34f7b0', embedding=None, metadata={'page_label': '601', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    601\\nMobile BI technology is poised to have a significant impact on the way BI information \\nis disseminated and processed. If the number of students using smartphones to com-\\nmunicate with friends, update their Facebook status, and send tweets on Twitter is any indicator, you can expect the next generation of consumers and workers to be highly mobile. Leading corporations are therefore starting to push decision making to agents in the field to facilitate customer relationships, sales and ordering, and product support.  \\nSuch mobile technologies are so portable and interactive that some users call them  \\n“disruptive” technologies.\\nBI information technology has evolved from centralized reporting styles to the cur -\\nrent, mobile BI and Big Data analytics style in the span of just a few years. The rate of technological change is not slowing down; to the contrary, technology advancements are accelerating the adoption of BI to new levels. The next section illustrates some BI technology trends.\\n13-2d  Business Intelligence Technology Trends\\nSeveral technological advances are driving the growth of business intelligence technol-ogies. These advances create new generations of more affordable products and services that are faster and easier to use. In turn, such products and services open new markets and work as driving forces in the increasing adoption of business intelligence technolo-gies within organizations. Some of the more remarkable technological trends are:\\n•\\n Data storage improvements. Newer data storage technologies, such as solid state drives \\n(SSD) and Serial Advanced Technology Attachment (SATA) drives, offer increased performance and larger capacity that make data storage faster and more affordable. Currently you can buy single drives with a capacity approaching 4 terabytes.\\n•\\n Business intelligence appliances . Vendors now offer plug-and-play appliances opti-\\nmized for data warehouse and BI applications. These new appliances offer improved price-performance ratios, simplified administration, rapid installation, scalability, and fast integration. Some of these vendors include IBM, Netezza, Greenplum, and AsterData.\\n•\\n Business intelligence as a service. Vendors now offer data warehouses and BI as  \\na service. These cloud-based services allow any corporation to rapidly develop a data warehouse store without the need for hardware, software, or extra personnel. These prepackaged services offer “pay-as-you-go” models for specific industries and capaci-ties, and they provide an opportunity for organizations to pilot-test a BI project with-out incurring large time or cost commitments. Such services are offered by Netezza, AppNexus, AsterData, MicroStrategy, and Kognitio.\\n•\\n Big Data analytics. The Big Data phenomenon is creating a new market for data analytics. Organizations are turning to social media as the new source for informa-tion and knowledge to gain competitive advantages. Examples of Big Data analytics vendors include Vertica, AsterData, and Netezza. Y ou’ll learn more about Big Data analytics in Chapter 14.\\n•\\n Personal analytics. OLAP brought data analytics to the desktop of every end user in an organization. Mobile BI is extending business decision making outside the walls \\nThe OLAP environment is covered in Section 13-6 of this chapter.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5f9f4763-6a7d-4ef5-adbd-cd83585e1f4a', embedding=None, metadata={'page_label': '602', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='602   Part 4    Advanced Database Concepts\\nof the organization. BI can now be deployed to mobile users who are closer to cus-\\ntomers. The main requirement is for the BI end user to have a key understanding of the business. Some personal analytics vendors include MicroStrategy, QlikView, and Actuate. There is a growing trend toward self-service, personalized data analytics. It is not so far-fetched to imagine that in a few years, end users will have smart data ana-lytics agents on their smartphones tailored to their personal interests. Such personal agents will provide users with up-to-the-minute “intelligent knowledge” about their personal interests.\\nOne constant in this relentless technological evolution is the need for better decision \\nsupport data and the importance of understanding the difference between decision sup-port data and operational data.\\n13-3  Decision Support Data\\nAlthough BI is used at strategic and tactical managerial levels within organizations, its effectiveness depends on the quality of data gathered at the operational level. Y et, opera-tional data is seldom well suited to the decision support tasks. The differences between operational data and decision support data are examined in the next section.\\n13-3a  Operational Data Versus Decision Support Data\\nOperational data and decision support data serve different purposes. Therefore, it is not surprising to learn that their formats and structures differ. Most operational data is stored in a relational database in which the structures (tables) tend to be highly normalized. Operational data storage is optimized to support transactions that rep-resent daily operations. For example, each time an item is sold, it must be accounted for. Customer data, inventory data, and other similar data need frequent updating. To provide effective update performance, operational systems store data in many tables, each with a minimum number of fields. Thus, a simple sales transaction might be rep-resented by five or more different tables, such as INVOICE, INVOICE LINE, DIS-COUNT, STORE, and DEPARTMENT. Although such an arrangement is excellent in an operational database, it is not efficient for query processing. For example, to extract a simple invoice, you would have to join several tables. Whereas operational data is useful for capturing daily business transactions, decision support data gives tactical and strategic business meaning to the operational data. From the data analyst’s point of view, decision support data differs from operational data in three main areas: time span, granularity, and dimensionality.\\n•\\n Time span . Operational data covers a short time frame. In contrast, decision support \\ndata tends to cover a longer time frame. Managers are seldom interested in a specific \\nsales invoice to Customer X; rather, they tend to focus on sales generated during the last month, the last year, or the last five years.\\n•\\n Granularity (level of aggregation). Decision support data must be presented at \\n different levels of aggregation, from highly summarized to nearly atomic. For exam-ple, if managers analyze regional sales, they must be able to access data showing the sales by region, by city within the region, by store within the city within the region, and so on. In that case, summarized data to compare the regions is required, along with data in a structure that enables a manager to drill down, or decompose, the data into more atomic components—that is, finer-grained data at lower levels of aggregation. In contrast, when you roll up the data, you are aggregating the data to a higher level.drill down\\nTo decompose data into more atomic components—that is, data at lower levels of aggregation. This approach is used primarily in a decision support system to focus on specific geographic areas, business types, and so on.\\nroll up\\n(1) To aggregate data into summarized components, that is, higher levels of aggregation. (2) In SQL, an OLAP extension used with the GROUP BY clause to aggregate data by different dimensions. Rolling up the data is the exact opposite of drilling down the data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='51f431cc-64c4-415a-a1f0-1c672b544521', embedding=None, metadata={'page_label': '603', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    603\\n• Dimensionality . Operational data focuses on representing individual transactions \\nrather than the effects of the transactions over time. In contrast, data analysts tend to \\ninclude many data dimensions and are interested in how the data relates over those \\ndimensions. For example, an analyst might want to know how Product X fared rela -\\ntive to Product Z during the past six months by region, state, city, store, and customer. \\nIn that case, both place and time are part of the picture.\\nFigure 13.4 shows how decision support data can be examined from multiple  dimensions \\nsuch as product, region, and year, using a variety of filters to produce each dimension. \\nThe\\xa0ability to analyze, extract, and present information in meaningful ways is one of the \\ndifferences between decision support data and transaction-at-a-time  operational data.\\nThe decision support data in Figure 13.4 shows the output for the solution to Problem 2  \\nat the end of this chapter.NoteFIGURE 13.4  TRANSFORMING OPERATIONAL DATA INTO DECISION SUPPORT DATA  \\nOperational Data\\nDecision Support Data\\nOperational data has a narrow time span, low\\ngranularity, and single focus. Such data is usually\\nrepresented in tabular format, in which each row\\nrepresents a single transaction. This format often\\nmakes it difﬁcult to derive useful information.Decision support system (DSS) data focuses on a broader\\ntime span, tends to have high levels of granularity, and can be\\nexamined in multiple dimensions. For example, note these\\npossible aggregations:\\n• Sales by product, region, agent, and so on\\n• Sales for all years or only a few selected years\\n• Sales for all products or only a few selected products\\nSalesRegion\\nAgentProductTime\\nFrom the designer’s point of view, the differences between operational and decision \\nsupport data are as follows:\\n• Operational data represents transactions as they happen in real time. Decision sup -\\nport data is a snapshot of the operational data at a given point in time. Therefore, \\ndecision support data is historic, representing a time slice of the operational data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8647ab02-7afe-4422-8535-ad19d8e45345', embedding=None, metadata={'page_label': '604', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='604   Part 4    Advanced Database Concepts\\n• Operational and decision support data are different in terms of transaction type  and \\ntransaction volume . Whereas operational data is characterized by update transac-\\ntions, decision support data is mainly characterized by read-only transactions. Deci-\\nsion support data also requires periodic  updates to load new data that is summarized \\nfrom the operational data. Finally, the concurrent transaction volume in operational data tends to be very high compared with the low to medium levels in decision  \\nsupport data.\\n•\\n Operational data is commonly stored in many tables, and the stored data rep-resents information about a given transaction only. Decision support data is gener -\\nally stored in a few tables derived from the operational data. The decision support data does not include the details of each operational transaction. Instead, decision \\n support data\\xa0 represents transaction summaries ; therefore, the decision support \\ndatabase stores data that is integrated, aggregated, and summarized for decision support purposes.\\n•\\n The degree to which decision support data is summarized is very high when con-trasted with operational data. Therefore, you will see a great deal of derived data in decision support databases. For example, rather than storing all 10,000 sales trans-actions for a given store on a given day, the decision support database might simply store the total number of units sold and the total sales dollars generated during that day. Decision support data might be collected to monitor such aggregates as total sales for each store or for each product. The purpose of the summaries is simple: they are used to establish and evaluate sales trends and product sales comparisons and to provide other data that serves decision needs. (How well are items selling? Should this product be discontinued? Has the advertising been effective as measured by increased sales?)\\n•\\n The data models that govern operational data and decision support data are differ -\\nent. The operational database’s frequent and rapid data updates make data anoma-lies a potentially devastating problem. Therefore, the data in a relational transaction (operational) system generally requires normalized structures that yield many tables, each of which contains the minimum number of attributes. In contrast, the decision support database is not subject to such transaction updates, and the focus is on query-ing capability. Therefore, decision support databases tend to be non-normalized and include few tables, each of which contains a large number of attributes.\\n•\\n The frequency and complexity of query activity in the operational database tends to be low to allow additional processing cycles for the more crucial update trans-actions. Therefore, queries against operational data typically are narrow in scope and low in complexity, and high speed is critical. In contrast, decision support data exists for the sole purpose of serving query requirements. Queries against decision support data typically are broad in scope and high in complexity, and less speed  \\nis needed.\\n•\\n Finally, decision support data is characterized by very large amounts of data. The large data volume is the result of two factors. First, data is stored in non-normalized struc-tures that are likely to display many data redundancies and duplications. Second, the same data can be categorized in many different ways to represent different snapshots. For example, sales data might be stored in relation to product, store, customer, region, and manager.\\nTable 13.5 summarizes the differences between operational and decision support data \\nfrom the database designer’s point of view.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f0085fd-6c12-4699-86ca-61bc453e6787', embedding=None, metadata={'page_label': '605', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    605\\nThe many differences between operational data and decision support data are good \\nindicators of decision support database requirements, which are described in the next \\nsection.\\n13-3b  Decision Support Database Requirements\\nA decision support database is a specialized DBMS tailored to provide fast answers to complex queries. There are three main requirements for a decision support database: the database schema, data extraction and filtering, and database size.\\nDatabase Schema  The decision support database schema must support complex \\n(non-normalized) data representations. As noted earlier, the decision support database must contain data that is aggregated and summarized. In addition to meeting those requirements, the queries must be able to extract multidimensional time slices. If you are using an RDBMS, the conditions suggest using non-normalized and even duplicated data. To see why this must be true, take a look at the 10-year sales history for a single store containing a single department. At this point, the data is fully normalized within the single table, as shown in Table 13.6.\\nThis structure works well when you have only one store with only one department. \\nHowever, it is very unlikely that such a simple environment has much need for a decision support database. A decision support database becomes a factor when you are dealing with more than one store, each of which has more than one department. To support all of the decision support requirements, the database must contain data for all of the stores and all of their departments—and the database must be able to support multi-dimensional queries that track sales by stores, by departments, and over time. For sim-plicity, suppose that there are only two stores (A and B) and two departments (1 and 2) within each store. Also, change the time dimension to include yearly data. Table 13.7 shows the sales figures under the specified conditions. Only 2006, 2012, and 2015 are shown; ellipses (…) are used to indicate that data values were omitted. Y ou can see in TABLE 13.5\\nCONTRASTING OPERATIONAL AND DECISION SUPPORT DATA CHARACTERISTICS\\nCHARACTERISTIC OPERATIONAL DATA DECISION SUPPORT DATA\\nData currency Current operationsReal-time dataHistoric dataSnapshot of company dataTime component (week/month/year)\\nGranularity Atomic-detailed data Summarized data\\nSummarization level Low; some aggregate yields High; many aggregation levels\\nData model Highly normalized\\nMostly relational DBMSsNon-normalizedComplex structuresSome relational, but mostly multidimensional DBMSs\\nTransaction type Mostly updates Mostly query\\nTransaction volumes High-update volumes Periodic loads and summary calculations\\nTransaction speed Updates are critical Retrievals are critical\\nQuery activity Low to medium High\\nQuery scope Narrow range Broad range\\nQuery complexity Simple to medium Very complex\\nData volumes Hundreds of gigabytes Terabytes to petabytes\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='255c75a5-d70b-40e0-8e0d-9bc85d131bae', embedding=None, metadata={'page_label': '606', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='606   Part 4    Advanced Database Concepts\\nTable\\xa013.7 that the number of rows and attributes already multiplies quickly and that the \\ntable exhibits multiple redundancies.\\nNow suppose that the company has 10 departments per store and 20 stores nation-\\nwide, and suppose that you want to access yearly sales summaries. Now you are dealing with 200 rows and 12 monthly sales attributes per row. (Actually, there are 13 attributes per row if you add each store’s sales total for each year.)\\nThe decision support database schema must also be optimized for query (read-only) \\nretrievals. To optimize query speed, the DBMS must support features such as bitmap indexes and data partitioning. In addition, the DBMS query optimizer must be enhanced to support the non-normalized and complex structures in decision support databases.TABLE 13.6\\nTEN-YEAR SALES HISTORY FOR A SINGLE DEPARTMENT,  \\nIN MILLIONS OF DOLLARS\\nYEAR SALES\\n2006 8,227\\n2007 9,109\\n2008 10,104\\n2009 11,553\\n2010 10,018\\n2011 11,875\\n2012 12,699\\n2013 14,875\\n2014 16,301\\n2015 19,986\\nTABLE 13.7\\nYEARLY SALES SUMMARIES, TWO STORES AND TWO DEPARTMENTS PER STORE, IN MILLIONS OF DOLLARS\\nYEAR STORE DEPARTMENT SALES\\n2006 A 1 1,985\\n2006 A 2 2,401\\n2006 B 1 1,879\\n2006 B 2 1,962\\n… … … …\\n2012 A 1 3,912\\n2012 A 2 4,158\\n2012 B 1 3,426\\n2012 B 2 1,203\\n… … … …\\n2015 A 1 7,683\\n2015 A 2 6,912\\n2015 B 1 3,768\\n2015 B 2 1,623\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='88ad4563-daf0-483d-ab67-4dfbde176043', embedding=None, metadata={'page_label': '607', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    607\\nData Extraction and Filtering  The decision support database is created largely by \\nextracting data from the operational database and by importing additional data from \\nexternal sources. Thus, the DBMS must support advanced data extraction and data-  \\nfiltering tools. To minimize the impact on the operational database, the data extraction capabilities should allow batch and scheduled data extraction, and should support differ -\\nent data sources: flat files and hierarchical, network, and relational databases, as well as multiple vendors. Data-filtering capabilities must include the ability to check for incon-sistent data or data validation rules. Finally, to filter and integrate the operational data into the decision support database, the DBMS must support advanced data integration, aggregation, and classification.\\nUsing data from multiple external sources also usually means having to solve data-\\n \\nformatting conflicts. For example, data such as Social Security numbers and dates can occur in different formats; measurements can be based on different scales, and the same data elements can have different names. In short, data must be filtered and purified to ensure that only the pertinent decision support data is stored in the database and that it is stored in a standard format.\\nDatabase Size  Decision support databases tend to be very large; gigabyte and tera-\\nbyte ranges are not unusual. For example, Walmart has more than 4 petabytes of data in its data warehouses. Therefore, the DBMS must be capable of supporting very large databases (VLDBs). To support a VLDB adequately, the DBMS might be required to support advanced storage technologies, and even more importantly, to support multiple-processor technologies, such as a symmetric multiprocessor (SMP) or a massively parallel processor (MPP).\\nThe complex information requirements and the ever-growing demand for sophisti-\\ncated data analysis sparked the creation of a new type of data repository. This repository, called a data warehouse, contains data in formats that facilitate data extraction, data analysis, and decision making. It has become the foundation for a new generation of decision support systems.\\n13-4  The Data Warehouse\\nBill Inmon, the acknowledged “father” of the data warehouse, defines the term as  \\n“an integrated , subject-oriented , time-variant , nonvolatile  collection of data that provides \\nsupport for decision making. ”2 (Italics were added for emphasis.) To understand that \\ndefinition, take a more detailed look at its components.\\n• Integrated . The data warehouse is a centralized, consolidated database that inte-\\ngrates data derived from the entire organization and from multiple sources with \\ndiverse formats. Data integration implies that all business entities, data elements, data characteristics, and business metrics are described in the same way throughout the enterprise. Although this requirement sounds logical, you would be amazed to discover how many different measurements for “sales performance” can exist within an organization; the same scenario can be true for any other business element. For instance, the status of an order might be indicated with text labels such as “open, ” “received, ” “\\n canceled, ” and “closed” in one department and as “1, ” “2, ” “3, ” and “4” in \\nanother department. A student’s status might be defined as “freshman, ” “sophomore, ” “junior, ” or “senior” in the accounting department and as “FR, ” “SO, ” “JR, ” or “SR” in the computer information systems department. To avoid the potential format tangle, \\n2 Bill Inmon and Chuck Kelley, “The twelve rules of data warehouse for a client/server world, ” Data \\n Management Review 4(5), May 1994, pp. 6–16.very large database (VLDB)\\nDatabase that contains huge amounts of data—gigabyte, terabyte, and petabyte ranges are not unusual.\\ndata warehouse\\n An integrated, subject-oriented, time-variant, nonvolatile collection of data that provides support for decision making.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='121ff9db-70f4-4e41-97af-f940f0c72a54', embedding=None, metadata={'page_label': '608', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='608   Part 4    Advanced Database Concepts\\nthe data in the data warehouse must conform to a common format that is accept-\\nable throughout the organization. This integration can be time-consuming, but once accomplished, it enhances decision making and helps managers better understand the company’s operations. This understanding can be translated into recognition of strategic business opportunities.\\n•\\n Subject-oriented. Data warehouse data is arranged and optimized to provide answers to questions from diverse functional areas within a company. Data warehouse data is organized and summarized by topic, such as sales, marketing, finance, distribution, and transportation. For each topic, the data warehouse con-tains specific subjects of interest—products, customers, departments, regions, promotions, and so on. This form of data organization is quite different from the more functional or process-oriented organization of typical transaction systems. For example, an invoicing system designer concentrates on designing normalized data structures to support the business process by storing invoice components in two tables: INVOICE and INVLINE. In contrast, the data warehouse has a subject  \\norientation. Data warehouse designers focus specifically on the data rather than on the processes that modify the data. (After all, data warehouse data is not sub-ject to numerous real-time data updates!) Therefore, instead of storing an invoice, the data warehouse stores its “sales by product” and “sales by customer” compo-nents because decision support activities require the retrieval of sales summaries by product or customer.\\n•\\n Time-variant . In contrast to operational data, which focuses on current transactions, \\nwarehouse data represents the flow of data through time. The data warehouse can even contain projected data generated through statistical and other models. It is also time-variant in the sense that when data is periodically uploaded to the data ware-house, all time-dependent aggregations are recomputed. For example, when data for previous weekly sales is uploaded to the data warehouse, the weekly, monthly, yearly, and other time-dependent aggregates for products, customers, stores, and other vari-ables are also updated. Because data in a data warehouse constitutes a snapshot of the company history as measured by its variables, the time component is crucial. The data warehouse contains a time ID that is used to generate summaries and aggregations by week, month, quarter, year, and so on. Once the data enters the data warehouse, the time ID assigned to the data cannot be changed.\\n•\\n Nonvolatile . Once data enters the data warehouse, it is never removed. Because the \\ndata in the warehouse represents the company’s history, the operational data, which represents the near-term history, is always added to it. Because data is never deleted and new data is continually added, the data warehouse is always growing. Therefore, the DBMS must be able to support multiterabyte or greater databases operating on multiprocessor hardware.\\nTable 13.8 summarizes the differences between data warehouses and operational \\ndatabases.\\nIn summary, the data warehouse is a read-only database optimized for data \\n analysis and query processing. Typically, data is extracted from various sources and are then transformed and integrated—in other words, passed through a data \\n filter—\\nbefore being loaded into the data warehouse. As mentioned, this process is known as ETL. Figure 13.5 illustrates the ETL process to create a data warehouse from operational data.\\nAlthough the centralized and integrated data warehouse can be an attractive prop-\\nosition that yields many benefits, managers may be reluctant to embrace this strategy. Creating a data warehouse requires time, money, and considerable managerial effort. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98a701dc-fe71-4dc1-9d5f-786ac96db298', embedding=None, metadata={'page_label': '609', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    609\\nTherefore, it is not surprising that many companies begin their foray into data ware -\\nhousing by focusing on more manageable data sets that are targeted to meet the special \\nneeds of small groups within the organization. These smaller data stores are called  \\ndata marts.TABLE 13.8\\nCHARACTERISTICS OF DATA WAREHOUSE DATA AND OPERATIONAL DATABASE DATA\\nCHARACTERISTIC OPERATIONAL DATABASE DATA DATA WAREHOUSE DATA\\nIntegrated Similar data can have different representations \\nor meanings. For example, Social Security \\nnumbers may be stored as ###-##-#### or \\nas #########, and a given condition may be \\nlabeled as T/F or 0/1 or Y/N. A sales value may \\nbe shown in thousands or in millions.Provide a unified view of all data elements with \\na common definition and representation for  \\nall business units.\\nSubject-oriented Data is stored with a functional, or process, \\norientation. For example, data may be stored \\nfor invoices, payments, and credit amounts.Data is stored with a subject orientation that \\n facilitates multiple views of the data and  decision \\nmaking. For example, sales may be  recorded by \\nproduct, division, manager, or region.\\nTime-variant Data is recorded as current transactions. For \\nexample, the sales data may be the sale of a \\nproduct on a given date, such as $342.78 on \\n12-MAY-2016.Data is recorded with a historical perspective \\nin mind. Therefore, a time dimension is  added \\nto  facilitate data analysis and various time \\n comparisons.\\nNonvolatile Data updates are frequent and common. For \\nexample, an inventory amount changes with \\neach sale. Therefore, the data environment \\nis fluid.Data cannot be changed. Data is added only \\n periodically from historical systems. Once the \\ndata is properly stored, no changes are allowed. \\n Therefore, the data environment is relatively static.\\nFIGURE 13.5  THE ETL PROCESS  \\nTransformationData warehouseOperational data\\n• Filter\\n• Transform\\n• Integrate\\n• Classify\\n• Aggregate\\n• Summarize• Integrated\\n• Subject-oriented\\n• Time-variant\\n• NonvolatileExtraction Loading\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3ccdc6f-89df-4733-9529-824ade52f25d', embedding=None, metadata={'page_label': '610', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='610   Part 4    Advanced Database Concepts\\n13-4a  Data Marts\\nA data mart is a small, single-subject data warehouse subset that provides decision sup-\\nport to a small group of people. In addition, a data mart could be created from data \\nextracted from a larger data warehouse for the specific purpose of supporting faster data access to a target group or function. That is, data marts and data warehouses can coexist within a business intelligence environment.\\nSome organizations choose to implement data marts not only because of the lower \\ncost and shorter implementation time but because of the technological advances and inevitable “people issues” that make data marts attractive. Powerful computers can pro-vide a customized decision support system to small groups in ways that might not be possible with a centralized system. Also, a company’s culture may predispose its employ-ees to resist major changes, but they might quickly embrace relatively minor changes that lead to demonstrably improved decision support. In addition, people at different organizational levels are likely to require data with different summarization, aggregation, and presentation formats. Data marts can serve as a test vehicle for companies exploring the potential benefits of data warehouses. By gradually migrating from data marts to data warehouses, a specific department’s decision support needs can be addressed within six months to one year, as opposed to the one- to three-year time frame usually required to implement a data warehouse. Information technology (IT) departments also benefit from this approach because their personnel can learn the issues and develop the skills required to create a data warehouse.\\nThe only difference between a data mart and a data warehouse is the size and scope of \\nthe problem being solved. The problem definitions and data requirements are essentially the same for both. To be useful, the data warehouse must conform to uniform structures and formats to avoid data conflicts and support decision making.\\n13-4b  Twelve Rules That Define a Data Warehouse\\nIn 1994, Bill Inmon and Chuck Kelley created a set of rules to define a data warehouse. These rules summarize many of the points made in this chapter about data warehouses.\\n3 \\nThe 12 rules for a data warehouse are shown in Table 13.9.\\nNote how the 12 rules capture the complete data warehouse life cycle—from its \\nintroduction as an entity separate from the operational data store to its components, \\n functionality, and management processes.\\nMost data warehouse implementations are based on the relational database model, and \\ntheir market share suggests that their popularity will not fade anytime soon.  Relational \\ndata warehouses use the star schema design technique to handle multidimensional data.\\n13-5  Star Schemas\\nThe star schema is a data-modeling technique used to map multidimensional deci-\\nsion support data into a relational database. In effect, the star schema creates the near equivalent of a multidimensional database schema from the existing relational \\n database. Star schemas yield an easily implemented model for multidimensional data analysis while preserving the relational structures on which the operational database is built. The basic star schema has four components: facts, dimensions, attributes, and attribute hierarchies.\\n3 Bill Inmon, and Chuck Kelley, “The twelve rules of data warehouse for a client/server world, ” Data Manage -\\nment Review 4(5), May 1994, pp. 6–16.data mart\\nA small, single-subject data warehouse subset that provides decision support to a small group of people.\\nstar schema\\nA data modeling technique used to map multidimensional decision support data into a relational database. The star schema represents data using a central table known as a fact table in a 1:M relationship with one or more dimension tables.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2210cc99-a9a2-4007-9896-98bbd5428f46', embedding=None, metadata={'page_label': '611', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    611\\n13-5a  Facts\\nFacts are numeric measurements (values) that represent a specific business aspect or activity. \\nFor example, sales figures are numeric measurements that represent product and service sales. Facts commonly used in business data analysis are units, costs, prices, and revenues. Facts are normally stored in a fact table that is the center of the star schema. The fact table contains \\nfacts that are linked through their dimensions, which are explained in the next section.\\nFacts can also be computed or derived at run time. Such computed or derived facts \\nare sometimes called metrics to differentiate them from stored facts. The fact table is updated periodically with data from operational databases.\\n13-5b  Dimensions\\nDimensions are qualifying characteristics that provide additional perspectives to a given fact. Recall that dimensions are of interest because decision support data is almost always viewed in relation to other data. For instance, sales might be compared by product from region to region and from one time period to the next. The kind of problem typically addressed by a BI system might be to compare the sales of unit X by region for the first quarters of 2006 through 2016. In that example, sales have product, location, and time dimensions. In effect, dimensions are the magnifying glass through which you study the facts. Such dimensions are normally stored in dimension tables. Figure 13.6 depicts  \\na star schema for sales with product, location, and time dimensions.TABLE 13.9\\nTWELVE RULES FOR A DATA WAREHOUSE\\nRULE NO. DESCRIPTION\\n1 The data warehouse and operational environments are separated.\\n2 The data warehouse data is integrated.\\n3 The data warehouse contains historical data over a long time.\\n4 The data warehouse data is snapshot data captured at a given point in time.\\n5 The data warehouse data is subject oriented.\\n6 The data warehouse data is mainly read-only with periodic batch updates from operational data. No\\xa0online updates are allowed.\\n7 The data warehouse development life cycle differs from classical systems development. Data warehouse development is data-driven; the classical approach is process-driven.\\n8 The data warehouse contains data with several levels of detail: current detail data, old detail data, lightly summarized data, and highly summarized data.\\n9 The data warehouse environment is characterized by read-only \\n transactions \\nto very large data sets. The\\xa0operational environment is  characterized by \\nnumerous update transactions to a few data entities at\\xa0a time.\\n10 The data warehouse environment has a system that traces data sources, transformations, and storage.\\n11 The data warehouse’s metadata is a critical component of this \\n environment. \\nThe metadata identifies and defines all data elements. The  metadata \\n provides the source, transformation, integration, storage, usage, \\n relationships, and history of each data element.\\n12 The data warehouse contains a chargeback mechanism for resource usage that enforces optimal use of the data by end users.facts\\nIn a data warehouse, the measurements (values) that measure a specific business aspect or activity. For example, sales figures are numeric measurements that represent product or service sales. Facts commonly used in business data analysis include units, costs, prices, and revenues.\\nfact table\\nIn a data warehouse, the star schema table that contains facts linked and classified through their common dimensions. A fact table is in a one-to-many relationship with each associated dimension table.\\nmetrics\\nIn a data warehouse, numeric facts that measure a business characteristic of interest to the end user.\\ndimensions\\nIn a star schema design, qualifying characteristics that provide additional perspectives to a given fact.\\ndimension tables\\nIn a data warehouse, tables used to search, filter, or classify facts within a star schema.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dfe21781-b0d0-41c4-a472-907bd6b95254', embedding=None, metadata={'page_label': '612', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='612   Part 4     Advanced Database Concepts\\n13-5c  Attributes\\nEach dimension table contains attributes. Attributes are often used to search, filter, or \\nclassify facts. Dimensions provide descriptive characteristics about the facts through their \\nattributes . Therefore, the data warehouse designer must define common business attri -\\nbutes that will be used by the data analyst to narrow a search, group information, or \\ndescribe dimensions. Using a sales example, some possible attributes for each dimension \\nare illustrated in Table 13.10.FIGURE 13.6  SIMPLE STAR SCHEMA  \\nProduct\\ndimension\\nTime\\ndimension\\nLocation\\ndimensionHP calculator\\nSales2016\\nfact\\n$125,000\\nTABLE 13.10\\nPOSSIBLE ATTRIBUTES FOR SALES DIMENSIONS\\nDIMENSION NAME DESCRIPTION POSSIBLE ATTRIBUTES\\nLocation Anything that provides a description of the location—\\nfor example, Nashville, Store 101, South Region, and TNRegion, state, city, store, and so on\\nProduct Anything that provides a description of the  product \\nsold—for example, hair care product, shampoo, \\n Natural Essence brand, 5.5-oz. bottle, and blue liquidProduct type, product ID, brand, \\n package, presentation, color, size, \\nand\\xa0so on\\nTime Anything that provides a time frame for the sales \\nfact—for example, the year 2016, the month of July, \\nthe date 07/29/2016, and the time 4:46 p.m.Year, quarter, month, week, day, time \\nof day, and so on\\nThese product, location, and time dimensions add a business perspective to the sales \\nfacts. The data analyst can now group the sales figures for a given product, in a given \\nregion, and at a given time. The star schema, through its facts and dimensions, can pro -\\nvide the data in a format suited for data analysis. Also, it can do so without imposing \\nthe burden of additional and unnecessary data, such as order number, purchase order \\nnumber, and status that commonly exists in operational databases.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3f46139d-e24b-4cb6-bd92-77b79612a89f', embedding=None, metadata={'page_label': '613', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    613\\nConceptually, the sales example’s multidimensional data model is best represented by \\na three-dimensional cube. Of course, this does not imply that there is a limit on the num -\\nber of dimensions you can associate to a fact table. There is no mathematical limit to the \\nnumber of dimensions used. However, using a three-dimensional model makes it easy to \\nvisualize the problem. The three-dimensional cube illustrated in Figure 13.7 represents a \\nview of sales with product, location, and time dimensions.\\nFIGURE 13.7  THREE-DIMENSIONAL VIEW OF SALES  \\nSales facts are stored in\\nthe intersection of each\\nproduct, time, and location\\ndimension.Conceptual three -dimensional\\ncube of sales by product,\\nlocation, and timeLocationProduct\\nTime\\nFIGURE 13.8  SLICE-AND-DICE VIEW OF SALES  \\nProduct manager’s\\nview of sales dataSales manager ’s\\nview of sales dataLocationProduct\\nTimeKeep in mind that this cube is only a conceptual  representation of multidimensional \\ndata; it does not show how the data is physically stored in a data warehouse.\\nWhatever the underlying database technology, one of the main features of multidi -\\nmensional analysis is its ability to focus on specific “slices” of the cube. For example, the \\nproduct manager may be interested in examining the sales of a product while the store \\nmanager is interested in examining the sales made by a particular store. In multidimen -\\nsional terms, the ability to focus on slices of the cube to perform a more detailed anal -\\nysis is known as slice and dice . Figure 13.8 illustrates the slice-and-dice concept; note \\nthat each cut across the cube yields a slice. Intersecting slices produce small cubes that \\n constitute the “dice” part of the slice-and-dice operation.\\nslice and dice\\nThe ability to focus on \\nslices of a data cube \\n(drill down or roll up) to \\nperform a more detailed \\nanalysis.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b1c775cd-d418-45b3-bbb9-95418890b28a', embedding=None, metadata={'page_label': '614', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='614   Part 4     Advanced Database Concepts\\nTo slice and dice, it must be possible to identify each slice of the cube. To do so, you \\nuse the values of each attribute in a given dimension. For example, to use the location \\ndimension, you might need to define a STORE_ID attribute to focus on a particular store.\\nGiven the requirement for attribute values in a slice-and-dice environment, re-exam -\\nine Table 13.10. Note that each attribute adds perspective to the sales facts, thus setting \\nthe stage for finding new ways to search, classify, and possibly aggregate information. For \\nexample, the location dimension adds a geographic perspective of where the sales took \\nplace: in which region, state, city, store, and so on. All of the attributes are selected with \\nthe objective of providing decision support data to end users so they can study sales by \\neach of the dimension’s attributes.\\nTime is an especially important dimension; it provides a framework from which \\nsales patterns can be analyzed and possibly predicted. Also, the time dimension plays an \\nimportant role when the data analyst is interested in studying sales aggregates by quarter, \\nmonth, week, and so on. Given the importance and universality of the time dimension \\nfrom a data analysis perspective, many vendors have added automatic time dimension \\nmanagement features to their data-warehousing products.\\n13-5d  Attribute Hierarchies\\nAttributes within dimensions can be ordered in a well-defined attribute hierarchy. The \\nattribute hierarchy  provides a top-down data organization that is used for two main \\npurposes: aggregation and drill-down/roll-up data analysis. For example, Figure 13.9 \\nshows how the location dimension attributes can be organized in a hierarchy by region, \\nstate, city, and store.\\nattribute hierarchy\\nA top-down data \\norganization that is used \\nfor two main purposes: \\naggregation and drill-\\ndown/roll-up data \\nanalysis.FIGURE 13.9  LOCATION ATTRIBUTE HIERARCHY  \\nThe attribute\\nhierarchy\\nallows the end\\nuser to\\nperform drill-dow n\\nand roll-up\\nsearches.Region\\nState\\nCity\\nStore\\nThe attribute hierarchy provides the capability to perform drill-down and roll-up \\nsearches in a data warehouse. For example, suppose a data analyst looks at the answers \\nto the following query: How does the 2015 month-to-date sales performance compare to \\nthe 2016 month-to-date sales performance? The data analyst spots a sharp sales decline \\nfor March 2016, and thus might decide to drill down inside the month of March to see \\nhow sales by regions compared to the previous year. By doing that, the analyst can deter -\\nmine whether the low March sales were reflected in all regions or in only a particular \\nregion. This type of drill-down operation can even be extended until the data analyst \\nidentifies the store that is performing below the norm.\\nThe March sales scenario is possible because the attribute hierarchy allows the \\ndata warehouse and BI systems to have a defined path that identifies how data is to be \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b058f1e4-ff93-47a5-9ab4-eb7862a8f4e1', embedding=None, metadata={'page_label': '615', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    615\\ndecomposed and aggregated for drill-down and roll-up operations. It is not necessary for \\nall attributes to be part of an attribute hierarchy; some attributes exist merely to provide \\nnarrative descriptions of the dimensions. However, keep in mind that the attributes from \\ndifferent dimensions can be grouped to form a hierarchy. For example, after you drill \\ndown from city to store, you might want to drill down using the product dimension so \\nthe manager can identify slow-selling products in the store. The product dimension can \\nbe based on the product group (dairy, meat, and so on) or the product brand (Brand A, \\nBrand B, and so on).\\nFigure 13.10 illustrates a scenario in which the data analyst studies sales facts using \\nthe product, time, and location dimensions. In this example, the product dimension is \\nset to “ All products, ” meaning that the data analyst will see all products on the y-axis. The \\ntime dimension ( x-axis) is set to “Quarter, ” meaning that the data is aggregated by quar -\\nters—for example, total sales of products A, B, and C in Q1, Q2, Q3, and Q4. Finally, the \\nlocation dimension is initially set to “Region, ” thus ensuring that each cell contains the \\ntotal regional sales for a given product in a given quarter.\\nFIGURE 13.10  ATTRIBUTE HIERARCHIES IN MULTIDIMENSIONAL ANALYSIS  \\nYear Quarter Month WeekTime dimension\\nProduct\\ndimensionAll products\\nBy product type\\nOne productQ1\\nProduct A\\nProduct B\\nProduct C\\n........\\n........\\n........\\nTotal of\\nquartersQ2Q3 Q4Total of\\nproduct\\nRegion\\nState\\nCity\\nStoreLocation hierarchy\\nThe simple scenario illustrated in Figure 13.10 provides the data analyst with three \\ndifferent information paths. On the product dimension (the y-axis), the data analyst can \\nrequest to see all products, products grouped by type, or just one product. On the time \\ndimension (the x-axis), the data analyst can request time–variant data at different levels \\nof aggregation: year, quarter, month, or week. Each sales value initially shows the total \\nsales, by region, of each product. When a GUI is used, clicking on the region cell enables \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4d0f09ff-b3f1-4e22-9310-050d0f9d468d', embedding=None, metadata={'page_label': '616', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='616   Part 4     Advanced Database Concepts\\nthe data analyst to drill down to see sales by states within the region. Clicking again on \\none of the state values yields the sales for each city in the state, and so forth.\\nAs the preceding examples illustrate, attribute hierarchies determine how the data in \\nthe data warehouse is extracted and presented. The attribute hierarchy information is \\nstored in the DBMS’s data dictionary and is used by the BI tool to access the data ware -\\nhouse properly. Once such access is ensured, query tools must be closely integrated with \\nthe data warehouse’s metadata, and they must support powerful analytical capabilities.\\n13-5e  Star Schema Representation\\nFacts and dimensions are normally represented by physical tables in the data warehouse \\ndatabase. The fact table is related to each dimension table in a many-to-one (M:1) relation -\\nship. In other words, many fact rows are related to each dimension row. Using the sales \\nexample, you can conclude that each product appears many times in the SALES fact table.\\nFact and dimension tables are related by foreign keys and are subject to the familiar \\nprimary key and foreign key constraints. The primary key on the “1” side, the dimension \\ntable, is stored as part of the primary key on the “many” side, the fact table. Because the \\nfact table is related to many dimension tables, the primary key of the fact table is a com -\\nposite primary key . Figure 13.11 illustrates the relationships among the sales fact table \\nand the product, location, and time dimension tables. To show you how easily the star \\nschema can be expanded, a customer dimension has been added to the mix. Adding the \\ncustomer dimension merely required including the CUST_ID in the SALES fact table \\nand adding the CUSTOMER table to the database.\\nFIGURE 13.11  STAR SCHEMA FOR SALES  \\n365 recordsLOCATION\\nSALES\\nCUSTOMERTIME\\nPRODUCTLOC_ID\\nLOC_DESCRIPTION\\nREGION_ID\\nLOC_S TATE\\nLOC_CITY\\nCUST_ID\\nCUST_LNAME\\nCUST_FNAME\\nCUST_INITIAL\\nCUST_DOBTIME_ID\\nLOC_ID\\nCUST_ID\\nPROD_ID\\nSALES_QUANTITY\\nSALES_PRICE\\nSALES_ TOTALTIME_ID\\nTIME_YEAR\\nTIME_QUARTER\\nTIME_MONTH\\nTIME_ DAY\\nTIME_CLOCKTIME\\nPROD_ID\\nPROD_DESCRIPTION\\nPROD_TYPE_ID\\nPROD_BRAND\\nPROD_COLOR\\nPROD_SIZE\\nPROD_PACKAGE\\nPROD_PRICE\\n3,000 records125 records25 records\\n3,000,000 records\\nDaily sales aggregates\\nby store, customer, and\\nproductMM1\\n1 MM1\\n1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c19e975a-44bb-4fc7-b034-b3ac70e5c50f', embedding=None, metadata={'page_label': '617', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    617\\nThe composite primary key for the SALES fact table is composed of TIME_ID, LOC_\\nID, CUST_ID, and PROD_ID. Each record in the SALES fact table is uniquely iden-\\ntified by the combination of values for each of the fact table’s foreign keys. By default, \\nthe fact table’s primary key is always formed by combining the foreign keys pointing to the dimension tables to which they are related. In this case, each sales record represents each product sold to a specific customer, at a specific time, and in a specific location. In this schema, the TIME dimension table represents daily periods, so the SALES fact table represents daily sales aggregates by product and by customer. Because fact tables contain the actual values used in the decision support process, those values are repeated many times in the fact tables. Therefore, the fact tables are always the largest tables in the star schema. Because the dimension tables contain only nonrepetitive information, such as all unique salespersons and all unique products, the dimension tables are always smaller than the fact tables.\\nIn a typical star schema, each dimension record is related to thousands of fact records. \\nFor example, “widget” appears only once in the product dimension, but it has thousands of corresponding records in the SALES fact table. This characteristic of the star schema facilitates data retrieval because the data analyst usually looks at the facts through the dimension’s attributes. Therefore, a data warehouse DBMS that is optimized for decision support first searches the smaller dimension tables before accessing the larger fact tables.\\nData warehouses usually have many fact tables. Each fact table is designed to answer \\nspecific decision support questions. For example, suppose that you develop a new inter -\\nest in orders while maintaining your original interest in sales. In that scenario, you should maintain an ORDERS fact table and a SALES fact table in the same data ware -\\nhouse. If orders are considered to be an organization’s key interest, the ORDERS fact table should be the center of a star schema that might have vendor, product, and time dimensions. In that case, an interest in vendors yields a new vendor dimension, repre-sented by a new VENDOR table in the database. The product dimension is represented by the same product table used in the initial sales star schema. However, given the interest in orders as well as sales, the time dimension now requires special attention. If the orders department uses the same time periods as the sales department, time can be represented by the same time table. If different time periods are used, you must create another table, perhaps named ORDER_TIME, to represent the time periods used by the orders department. In \\n Figure\\xa013.12, the ORDERS star schema shares the product, \\nvendor, and time dimensions.\\nMultiple fact tables can also be created for performance and semantic reasons. The \\nfollowing section explains several performance-enhancing techniques that can be used within the star schema.\\n13-5f   Performance-Improving Techniques  \\nfor the Star Schema\\nCreating a database that provides fast and accurate answers to data analysis queries is the prime objective of data warehouse design. Therefore, performance enhancement might target query speed through the facilitation of SQL code and through better semantic representation of business dimensions. The following four techniques are often used to optimize data warehouse design:\\n•\\n Normalizing dimensional tables\\n• Maintaining multiple fact tables to represent different aggregation levels\\n• Denormalizing fact tables\\n• Partitioning and replicating tables\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2b3c49a8-1c3a-4fff-adc7-c3b1a85f3dde', embedding=None, metadata={'page_label': '618', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='618   Part 4     Advanced Database Concepts\\nNormalizing Dimensional Tables  Dimensional tables are normalized to achieve \\nsemantic simplicity and facilitate end-user navigation through the dimensions. For \\nexample, if the location dimension table contains transitive dependencies among region, \\nstate, and city, you can revise those relationships to the 3NF (third normal form), as \\nshown in Figure 13.13. (If necessary, review the normalization techniques in Chapter 6, \\nNormalization of Database Tables.) The star schema shown in Figure 13.13 is known as \\na snowflake  schema , which is a type of star schema in which the dimension tables can \\nhave their own dimension tables. The snowflake schema is usually the result of normal -\\nizing dimension tables.\\nBy normalizing the dimension tables, you simplify the data-filtering operations \\nrelated to the dimensions. In this example, the region, state, city, and location contain \\nvery few records compared to the SALES fact table. Only the location table is directly \\nrelated to the SALES fact table.snowflake schema\\nA type of star schema \\nin which dimension \\ntables can have their \\nown dimension tables. \\nThe snowflake schema \\nis usually the result of \\nnormalizing dimension \\ntables.FIGURE 13.12  ORDERS STAR SCHEMA  \\n365 recordsPRODUCT\\nORDER\\nVENDORTIMEPROD_ID\\nPROD_DESCRIPTION\\nPROD_TYPE_ID\\nPROD_BRAND\\nPROD_COLOR\\nVEND_ID\\nVEND_NAME\\nVEND_AREACODE\\nVEND_PHONE\\nVEND_EMAILTIME_ID\\nPROD_ID\\nVEND_ID\\nORDER_QUANTITY\\nORDER_PRICE\\nORDER_AMOUNTTIME_ID\\nTIME_YEAR\\nTIME_QUARTER\\nTIME_MONTH\\nTIME_ DAY\\nTIME_CLOCKTIME\\n50 records3,000 records\\n85,000 records\\nDaily sales aggregates\\nby product and vendorMM1\\n1M 1\\nPROD_SIZE\\nPROD_PACKAGE\\nPROD_PRICE\\nAlthough using the dimension tables shown in Figure 13.13 provides structural simplicity, \\nthere is a price to pay for that simplicity. For example, if you want to aggregate the data \\nby region, you must use a four-table join, thus increasing the complexity of the SQL state -\\nments. The star schema in Figure 13.11 uses a LOCATION dimension table that greatly facil -\\nitates data retrieval by eliminating multiple join operations. This is yet another example of \\nthe trade-offs that designers must consider.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a89b51c3-a082-4d82-8899-7b1d72d81f7d', embedding=None, metadata={'page_label': '619', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    619\\nMaintaining Multiple Fact Tables that Represent Different Aggregation Levels   \\nY ou can also speed up query operations by creating and maintaining multiple fact tables \\nrelated to each level of aggregation (region, state, and city) in the location dimension. \\nThese aggregate tables are precomputed at the data-loading phase rather than at run time. \\nThe purpose of this technique is to save processor cycles at run time, thereby speeding \\nup data analysis. An end-user query tool optimized for decision analysis then properly \\naccesses the summarized fact tables instead of computing the values by accessing a fact \\ntable at a lower level of detail. This technique is illustrated in Figure 13.14, which adds \\naggregate fact tables for region, state, and city to the initial sales example.\\nThe data warehouse designer must identify which levels of aggregation to precompute \\nand store in the database. These multiple aggregate fact tables are updated during each \\nload cycle in batch mode. Also, because the objective is to minimize access according to \\nthe expected frequency of use and to minimize the processing time required to calculate \\na given aggregation level at run time, the data warehouse designer must select which \\naggregation fact tables to create.\\nDenormalizing Fact Tables  Denormalizing fact tables improves data access perfor -\\nmance and saves data storage space. The latter objective, however, is becoming less of an \\nissue. Data storage costs decrease almost daily, and DBMS limitations on database and \\ntable size, record size, and the maximum number of records in a single table have far \\nmore negative effects than raw storage space costs.\\nDenormalization improves performance by using a single record to store data that \\nnormally takes many records. For example, to compute the total sales for all products in \\nall regions, you might have to access the region sales aggregates and summarize all of the \\nrecords in this table. If you have 300,000 product sales, you could be summarizing at least \\n300,000 rows. Although this might not be a taxing operation for a DBMS, a comparison FIGURE 13.13  NORMALIZED DIMENSION TABLES  \\nREGION\\nLOCATION STATESALESREGION_ID\\nREGION_NAME\\nSTATE_ID\\nSTATE_NAME\\nREGION_IDLOC_ID\\nLOC_DESCRIPTION\\nCITY_IDTIME_ID\\nLOC_ID\\nCUST_ID\\nPROD_ID\\nSALES_QUANTITY\\nSALES_PRICE MM1\\n1\\nM1\\nCITY\\nCITY_ID\\nCITY_NAME\\nSTATE_IDSALES_ TOTALM\\n1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3d828d82-fd64-477e-8ddf-5adce5bb9c20', embedding=None, metadata={'page_label': '620', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='620   Part 4     Advanced Database Concepts\\nof 10 years’ worth of previous sales begins to bog down the system. In such cases, it is \\nuseful to have special aggregate tables that are denormalized. For example, a YEAR_\\nTOTALS table might contain the following fields: YEAR_ID, MONTH_1, MONTH_2 \\n… MONTH_12, and each year’s total. Such tables can easily be used to serve as a basis \\nfor year-to-year comparisons at the top month level, the quarter level, or the year level. \\nHere again, design criteria such as frequency of use and performance requirements are \\nevaluated against the possible overload placed on the DBMS to manage the denormal -\\nized relations.\\nPartitioning and Replicating Tables  Because table partitioning and replication were \\ncovered in detail in Chapter 12, Distributed Database Management Systems, those tech -\\nniques are discussed here only as they specifically relate to the data warehouse. Table \\npartitioning and replication are particularly important when a BI system is imple -\\nmented in dispersed geographic areas. Partitioning  splits a table into subsets of rows or \\n columns and places the subsets close to the client computer to improve data access time. \\n Replication  makes a copy of a table or partition and places it in a different location, also \\nto improve access time.\\nNo matter which performance-enhancement scheme is used, time is the most com -\\nmon dimension used in business data analysis. Therefore, it is very common to have \\none fact table for each level of aggregation defined within the time dimension. In the \\nsales example, you might have five aggregate sales fact tables: daily, weekly, monthly, partitioning\\nThe process of splitting \\na table into subsets of \\nrows or columns.\\nreplication\\nThe process of creating \\nand managing duplicate \\nversions of a database. \\nReplication is used to \\nplace copies in different \\nlocations and to improve \\naccess time and fault \\ntolerance.FIGURE 13.14  MULTIPLE FACT TABLES  \\nSALES_REGION REGION SALES_CITY\\nTIME_ID\\nREGION_IDREGION_ID\\nREGION_NAMETIME_ID\\nCITY_ID\\nCUST_ID\\nPROD_ID\\nSLSCIT_QUANTITY\\nSLSCIT_PRICE\\nSLSCIT_AMOUNTM1\\nCUST_ID\\nPROD_ID\\nSLSREG_QUANTITY\\nSLSREG_PRICE\\nSLSREG_AMOUNT\\nSALES_S TATE\\nTIME_ID\\nSTATE_ID\\nCUST_ID\\nPROD_ID\\nSLSSTA_QUANTITY\\nSLSSTA_PRICE\\nSLSSTA_AMOUNTSTATE\\nSTATE_ID\\nSTATE_NAME\\nREGION_ID\\nCITY\\nCITY_ID\\nCITY_NAME\\nLOCATION\\nLOC_ID\\nLOC_DESCRIPTION\\nCITY_IDSTATE_IDSALES_LOCATION\\nTIME_ID\\nLOC_ID\\nCUST_ID\\nPROD_ID\\nSLSLOC_QUANTITY\\nSLSLOC_PRICE\\nSLSLOC_AMOUNTM1\\n1\\nM1\\nM1\\nMM\\n1M\\n1\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1497b490-5135-49a2-b551-f7a671275ed5', embedding=None, metadata={'page_label': '621', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    621\\nquarterly, and yearly. These fact tables must have an implicit or explicit periodicity \\ndefined.  Periodicity, which is usually expressed as current year only, previous years, or \\nall years, provides information about the time span of the data stored in the table.\\nAt the end of each year, daily sales for the current year are moved to another table \\nthat contains previous years’ daily sales only. This table actually contains all sales records from the beginning of operations, with the exception of the current year. The data in the current year and previous years’ tables thus represents the complete sales history of the company. The previous years’ sales table can be replicated at several locations to avoid having to remotely access the historic sales data, which can cause a slow response time. The possible size of this table is enough to intimidate all but the bravest of query \\n optimizers. Here is one case in which denormalization would be of value!\\nIn this section you learned how the star schema design technique allows you to model \\ndata optimized for business decision making. A BI system uses all the previously men-tioned components to provide decision support to all organizational users. In the next section you will learn about a widely used BI style known as online analytical processing .\\n13-6  Online Analytical Processing\\nOnline analytical processing (OLAP) is a BI style whose systems share three main characteristics:\\n•\\n Multidimensional data analysis techniques\\n• Advanced database support\\n• Easy-to-use end-user interfaces\\nThis section examines each characteristic.\\n13-6a  Multidimensional Data Analysis Techniques\\nThe most distinctive characteristic of modern OLAP tools is their capacity for multidi-\\nmensional analysis, in which data is processed and viewed as part of a multidimensional structure. This type of data analysis is particularly attractive to business decision makers because they tend to view business data as being related to other business data.\\nTo better understand this view, you can examine how a business data analyst might \\ninvestigate sales figures. In this case, the analyst is probably interested in the sales figures as they relate to other business variables such as customers and time. In other words, cus-tomers and time are viewed as different dimensions of sales. Figure 13.15 illustrates how the operational (one-dimensional) view differs from the multidimensional view of sales.\\nNote in Figure 13.15 that the operational (tabular) view of sales data is not well suited \\nto decision support because the relationship between INVOICE and LINE does not pro-vide a business perspective of the sales data. On the other hand, the end user’s view of sales data from a business perspective  is more closely represented by the multidimen-\\nsional view of sales than by the tabular view of separate tables. Note also that the multidi-mensional view allows end users to consolidate or aggregate data at different levels: total sales figures by customers and by date. Finally, the multidimensional view of data allows a business data analyst to easily switch business perspectives (dimensions) from sales by customer to sales by division, by region, and so on.\\nMultidimensional data analysis techniques are augmented by the following functions:\\n•\\n Advanced data presentation functions . These functions include 3D graphics, pivot \\ntables, crosstabs, data rotation, and three-dimensional cubes. Such tools are \\n compatible with desktop spreadsheets, statistical packages, and query and report packages.periodicity\\nInformation about the time span of data stored in a table, usually expressed as current year only, previous years, or all years.\\nonline analytical processing (OLAP)\\nDecision support system (DSS) tools that use multidimensional data analysis techniques. OLAP creates an advanced data analysis environment that supports decision making, business modeling, and operations research.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='105da183-b866-4e59-96ea-b3f413fe7a16', embedding=None, metadata={'page_label': '622', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='622   Part 4    Advanced Database Concepts\\n• Advanced data aggregation, consolidation, and classification functions. These allow \\nthe data analyst to create multiple data aggregation levels, slice and dice data (see \\n Section\\xa013-5c), and drill down and roll up data across different dimensions and aggre-gation levels. For example, aggregating data by week, month, quarter, and year allows the data analyst to drill down and roll up across time dimensions.\\n•\\n Advanced computational functions . These include business-oriented variables such as \\nmarket share, period comparisons, sales margins, product margins, and percentage changes; financial and accounting ratios, including profitability, overhead, cost allo-cations, and returns; and statistical and forecasting functions. These functions are provided automatically, so the end user does not need to redefine the components each time they are accessed.\\n•\\n Advanced data-modeling functions . These provide support for what-if scenarios, \\nvariable assessment, contributions to outcome, linear programming, and predictive FIGURE 13.15  OPERATIONAL VS. MULTIDIMENSIONAL VIEW OF SALES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8d8272d0-d701-449e-9b58-722bea535ebb', embedding=None, metadata={'page_label': '623', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    623\\nmodeling tools. Predictive modeling allows the system to build advanced statisti-\\ncal models to predict future values (business outcomes) with a high percentage of accuracy.\\n13-6b  Advanced Database Support\\nTo deliver efficient decision support, OLAP tools must have the following advanced data access features:\\n•\\n Access to many different kinds of DBMSs, flat files, and internal and external data sources\\n• Access to aggregated data warehouse data as well as to the detail data found in \\n operational databases\\n• Advanced data navigation features such as drill-down and roll-up\\n• Rapid and consistent query response times\\n• The ability to map end-user requests, expressed in either business or model terms, to \\nthe appropriate data source and then to the proper data access language (usually SQL). The query code must be optimized to match the data source, regardless of whether the source is operational or data warehouse data.\\n•\\n Support for very large databases. As explained earlier, the data warehouse could easily and quickly grow to multiple terabytes in size.\\nTo provide a seamless interface, OLAP tools map the data elements from the data \\nwarehouse and the operational database to their own data dictionaries. This metadata is used to translate end-user data analysis requests into the proper (optimized) query codes, which are then directed to the appropriate data sources.\\n13-6c  Easy-to-Use End-User Interfaces\\nThe end-user analytical interface is one of the most critical OLAP components. When properly implemented, an analytical interface permits the user to navigate the data in a way that simplifies and accelerates decision making or data analysis.\\nAdvanced OLAP features become more useful when access to them is kept simple. \\nOLAP tool vendors learned this lesson early and have equipped their sophisticated data extraction and analysis tools with easy-to-use graphical interfaces. Many of the interface features are “borrowed” from previous generations of data analysis tools that are already familiar to end users.\\nBecause many analysis and presentation functions are common to desktop \\n spreadsheet \\npackages, most OLAP vendors have closely integrated their systems with spreadsheets such as Microsoft Excel. Using the features available in graphical end-user interfaces, OLAP sim -\\nply becomes another option within the spreadsheet menu bar, as shown in Figure\\xa013.16. This seamless integration is an advantage for OLAP systems and spreadsheet vendors because end users gain access to advanced data analysis features by using familiar pro -\\ngrams and interfaces. Therefore, additional training and development costs are minimized.\\n13-6d  OLAP Architecture\\nThe OLAP architecture is designed to meet ease-of-use requirements while keeping the system flexible. An OLAP system has three main architectural components:\\n•\\n Graphical user interface (GUI)\\n• Analytical processing logic\\n• Data-processing logic\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='69efc026-73d5-4e59-8813-e67f0344bbe5', embedding=None, metadata={'page_label': '624', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='624   Part 4     Advanced Database Concepts\\nThese three components can exist on the same computer or be distributed among \\nseveral computers. Figure 13.17 illustrates OLAP’s architectural components.FIGURE 13.16  INTEGRATION OF OLAP WITH A SPREADSHEET PROGRAM  \\nFIGURE 13.17  OLAP ARCHITECTURE  \\nAnalytical\\nprocessing logic\\nData-processing\\nlogic\\nAlternate direct access\\nof operational and data\\nwarehouse dataMultiple interfaces\\nand application\\nplug-insOLAP “engine” provides a front end to\\nthe data warehouse.\\nAccess\\nplug-inAdvanced\\nreporting\\nSpreadsheet\\nreports\\nOLAP\\nreports\\nDashboards\\nMobile Bl\\nETL\\nExtraction,\\ntransformation, and loadingData\\nWarehouseExcel\\nplug-in External\\ndataOperational\\ndata\\nOLAP\\nGUI\\nSource: Microsoft LLC (Excel screenshot); Oracle OCBC (Oracle windows)\\n© Antun Hirsman/Shutterstock.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3d6f8d1c-4389-4e32-8d5c-f3842d4a7f57', embedding=None, metadata={'page_label': '625', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    625\\nAs Figure 13.17 illustrates, OLAP systems are designed to use both operational and \\ndata warehouse data. The figure shows the OLAP system components on a single com -\\nputer, but this single-user scenario is only one of many. In fact, one problem with the \\ninstallation shown here is that each data analyst must have a powerful computer to store \\nthe OLAP system and perform all data processing locally.\\nA more common and practical architecture is one in which the OLAP GUI runs on \\nclient workstations while the OLAP data-processing logic (or OLAP “server”) runs on \\na shared server computer. The OLAP analytical processing logic could be located on \\na client workstation, the OLAP server, or be split between the two sides. In any case, \\nthe OLAP server component acts as an intermediary between the OLAP GUI and the \\ndata warehouse. This middle layer accepts and handles the data-processing requests gen -\\nerated by the many end-user OLAP workstations. This flexible architecture allows for \\nmany different OLAP configurations. Figure 13.18 illustrates an OLAP server with local \\nminiature data marts.\\nFIGURE 13.18  OLAP SERVER WITH LOCAL MINI DATA MARTS  \\nAnalytical\\nprocessing\\nlogic\\nData\\nprocessing\\nlogicOLAP GUI\\nOLAP GUI\\nOLAP GUI\\nOLAP GUI\\nData\\nWarehouseOLAP  “server”Local data marts Sales Dept.\\nMarketing Dept.\\nManufacturing Dept.\\nProcurement Dept.Multiple OLAP clients\\naccessing the OLAP serverCustomers\\nMarketing\\nProduction\\nVendors\\nOperational\\ndataData extracted from the data \\nwarehouse to local data marts,  \\nwhich provides faster processing\\nAs illustrated in Figure 13.18, the OLAP system could merge the data warehouse and \\ndata mart approaches by storing extracts of the data warehouse at end-user workstations. \\nThe objective is to increase the speed of data access and data visualization (the graphic \\nrepresentations of data trends and characteristics). The logic behind this approach is the \\nassumption that most end users usually work with fairly small, stable data warehouse \\nsubsets. For example, a sales analyst is most likely to work with sales data, whereas a \\ncustomer representative is likely to work with customer data.\\nWhatever the arrangement of the OLAP components, one thing is certain: multi -\\ndimensional data must be used. But how is multidimensional data best stored and \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4ebf554-4f8c-4340-a964-86dca8cb33af', embedding=None, metadata={'page_label': '626', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='626   Part 4    Advanced Database Concepts\\nmanaged? OLAP proponents are sharply divided. Some favor the use of relational data-\\nbases to store multidimensional data; others argue that specialized multidimensional databases are superior. The basic characteristics of each approach are examined next.\\n13-6e  Relational OLAP\\nRelational online analytical processing (ROLAP) provides OLAP functionality by using relational databases and familiar relational query tools to store and analyze multidi-mensional data. This approach builds on existing relational technologies and represents a natural extension to companies that already use relational database management systems within their organizations. ROLAP adds the following extensions to traditional RDBMS technology:\\n•\\n Multidimensional data schema support within the RDBMS\\n• Data access language and query performance optimized for multidimensional data\\n• Support for very large databases (VLDBs)\\nMultidimensional Data Schema Support within the RDBMS  Relational technol-\\nogy uses normalized tables to store data. The reliance on normalization as the design \\nmethodology for relational databases is seen as a stumbling block to its use in OLAP systems. Normalization divides business entities into smaller pieces to produce the nor -\\nmalized tables. For example, sales data components might be stored in four or five dif-ferent tables. The reason for using normalized tables is to reduce redundancies, thereby eliminating data anomalies, and to facilitate data updates. Unfortunately, for decision support purposes, it is easier to understand data when it is seen with respect to other data. (See the example in Figure 13.15.) Given that view of the data environment, this text has emphasized that decision support data tends to be non-normalized, duplicated, and preaggregated. Those characteristics seem to preclude the use of standard relational design techniques and RDBMSs as the foundation for multidimensional data.\\nFortunately for companies heavily invested in relational technology, ROLAP uses a \\nspecial design technique that enables RDBMS technology to support multidimensional data representations. This special design technique is known as a star schema, which is covered in detail in Section 13-5.\\nThe star schema is designed to optimize data query operations rather than data \\nupdate operations. Naturally, changing the data design foundation means that the tools used to access such data will have to change. End users who are familiar with traditional relational query tools will discover that those tools do not work efficiently with the star schema. However, ROLAP saves the day by adding support for the star schema when familiar query tools are used. ROLAP provides advanced data analysis functions and improves query optimization and data visualization methods.\\nData Access Language and Query Performance Optimized for  Multidimensional \\nData  Another criticism of relational databases is that SQL is not suited for performing \\nadvanced data analysis. Most decision support data requests require the use of multi -\\nple-pass SQL queries or multiple nested SQL statements. To answer this criticism, ROLAP extends SQL so that it can differentiate between access requirements for data warehouse data (based on the star schema) and operational data (normalized tables). A ROLAP \\n system \\ntherefore can generate the SQL code required to access the star schema data.\\nQuery performance is also improved because the query optimizer is modified to iden-\\ntify the SQL code’s intended query targets. For example, if the query target is the data warehouse, the optimizer passes the requests to the data warehouse. However, if the end user performs drill-down queries against operational data, the query optimizer identifies relational online analytical \\n processing \\n(ROLAP)\\nAnalytical processing functions that use relational databases and familiar relational query tools to store and analyze multidimensional data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e61fb39f-06c3-4cb6-aaea-996133809d79', embedding=None, metadata={'page_label': '627', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    627\\nthat operation and properly optimizes the SQL requests before passing them to the oper -\\national DBMS.\\nAnother source of improved query performance is the use of advanced indexing tech-\\nniques such as bitmapped indexes within relational databases. As the name suggests, a \\nbitmapped index is based on 0 and 1 bits to represent a given condition. For example, if the REGION attribute in Figure 13.4 has only four outcomes—North, South, East, and West—those outcomes may be represented as shown in Table 13.11. Only the first 10 rows from Figure 13.4 are represented in the table. The “1” represents “bit on, ” and the “0” represents “bit off. ” For example, to represent a row with a REGION attribute = “East, ” only the “East” bit would be on. Note that each row must be represented in the index table.\\nNote that the index in Table 13.11 takes a minimal amount of space. Therefore, bit-\\nmapped indexes are more efficient at handling large amounts of data than the indexes typically found in many relational databases. However, keep in mind that bitmapped indexes are primarily used when the number of possible values for an attribute is fairly small. For example, REGION has only four outcomes in this example. Marital status—married, single, widowed, or divorced—would be another good bitmapped index candi-date, as would gender—M or F.\\nTABLE 13.11\\nBITMAP REPRESENTATION OF REGION VALUES\\nNORTH SOUTH EAST WEST\\n0 0 1 0\\n0 0 1 0\\n1 0 0 0\\n1 0 0 0\\n1 0 0 0\\n0 1 0 0\\n0 1 0 0\\n0 1 0 0\\n0 0 0 1\\n0 0 0 1\\nSupport for Very Large Databases  Recall that support for VLDBs is a requirement \\nfor decision support databases. Therefore, when the relational database is used in a \\n decision support role, it also must be able to store very large amounts of data. Both the storage capability and the process of loading data into the database are crucial. Therefore, the RDBMS must have the proper tools to import, integrate, and populate the data ware-house with data. Decision support data is normally loaded in bulk (batch) mode from the operational data. However, batch operations require that both the source and the destination databases be reserved (locked). The speed of the data-loading operations is important, especially when you realize that most operational systems run 24 hours a day, 7 days a week. Therefore, the window of opportunity for maintenance and batch loading is open only briefly, typically during slack periods.\\nClearly, ROLAP is a logical choice for companies that already use relational databases \\nfor their operational data. Given the size of the relational database market, it is hardly surprising that most current RDBMS vendors have extended their products to support data warehouses and OLAP capabilities.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9288ec91-dd70-48c8-969b-db2c918704e1', embedding=None, metadata={'page_label': '628', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='628   Part 4    Advanced Database Concepts\\n13-6f  Multidimensional OLAP\\nMultidimensional online analytical processing (MOLAP) extends OLAP functional-\\nity to multidimensional database management systems (MDBMSs). An MDBMS \\nuses proprietary techniques to store data in matrix-like n-dimensional arrays. MOLAP’s premise is that multidimensional databases are best suited to manage, store, and analyze multidimensional data. Most of the proprietary techniques used in MDBMSs are derived from engineering fields such as computer-aided design/computer-aided manufacturing (CAD/CAM) and geographic information systems (GIS). MOLAP tools store data using multidimensional arrays, row stores, or column stores. (If necessary, review the NoSQL data model in Chapter 2, Data Models.)\\nConceptually, MDBMS end users visualize the stored data as a three-dimensional \\ncube known as a data cube. The location of each data value in the data cube is a func-tion of the x-, y-, and z-axes in a three-dimensional space. The three axes represent the \\ndimensions of the data value. The data cubes can grow to n number of dimensions, thus \\nbecoming hypercubes . Data cubes are created by extracting data from the operational \\ndatabases or from the data warehouse. One important characteristic of data cubes is that they are static; that is, they are not subject to change and must be created before they can be used. Data cubes cannot be created by ad hoc queries. Instead, you query precreated cubes with defined axes; for example, a cube for sales will have the product, location, and time dimensions, and you can query only those dimensions. Therefore, the data cube creation process is critical and requires in-depth front-end design work. This design work may be well justified because MOLAP databases are known to be much faster than their ROLAP counterparts, especially when dealing with large data sets. To speed data access, data cubes are normally held in memory in the cube cache. (A data cube is only a window to a predefined subset of data in the database. A data cube and a database are not the same thing.) Because MOLAP also benefits from a client/server infrastructure, the cube cache can be located at the MOLAP server, the MOLAP client, or both.\\nBecause the data cube is predefined with a set number of dimensions, the addition \\nof a new dimension requires that the entire data cube be re-created, which is time-con-suming. Therefore, when data cubes are created too often, the MDBMS loses some of its speed advantage over the relational database. In addition, the MDBMS uses proprietary data storage techniques that in turn require proprietary data access methods using a multidimensional query language.\\nMultidimensional data analysis is also affected by how the database system handles \\nsparsity. Sparsity measures the density of the data held in the data cube; it is computed \\nby dividing the total number of actual values in the cube by its total number of cells. Because the data cube’s dimensions are predefined, not all cells are populated. In other words, some cells are empty. Returning to the sales example, many products might not be sold during a given time period in a given location. In fact, you will often find that less than 50 percent of the data cube’s cells are populated. In any case, multidimensional databases must handle sparsity effectively to reduce processing overhead and resource requirements.\\n13-6g  Relational versus Multidimensional OLAP\\nTable 13.12 summarizes some pros and cons of ROLAP and MOLAP . Keep in mind that the selection of one or the other often depends on the evaluator’s vantage point. For example, a proper evaluation of OLAP must include price, supported hardware plat-forms, compatibility with the existing DBMS, programming requirements, performance, and availability of administrative tools. The summary in Table 13.12 provides a useful starting point for comparison.multidimensional online analytical processing (MOLAP)\\nAn extension of online analytical processing to multidimensional database management systems.\\n multidimensional database \\n management system (MDBMS)\\nA database management system that uses proprietary techniques to store data in matrixlike arrays of n dimensions known as cubes.\\ndata cube\\nThe multidimensional data structure used to store and manipulate data in a multidimensional DBMS. The location of each data value in the data cube is based on its x-, y-, and z-axes. Data cubes are static, meaning they must be created before they are used, so they cannot be created by an ad hoc query.\\ncube cache\\nIn multidimensional OLAP , the shared, reserved memory area where data cubes are held. Using the cube cache assists in speeding up data access.\\nsparsity\\nIn multidimensional data analysis, a measurement of the data density held in the data cube.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='37c6cc53-9a64-44a9-8598-3714bca65f99', embedding=None, metadata={'page_label': '629', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    629\\nROLAP and MOLAP vendors are working to integrate their respective solutions \\nwithin a unified decision support framework. Many OLAP products can handle tabular \\nand multidimensional data with the same ease. For example, if you use Excel OLAP \\nfunctionality, as shown earlier in Figure 13.16, you can access relational OLAP data in a \\nSQL server as well as cube (multidimensional) data in the local computer. In the mean -\\ntime, relational databases have successfully extended SQL to support many OLAP tools.\\n13-7  SQL Extensions for OLAP\\nThe proliferation of OLAP tools has fostered the development of SQL extensions to sup -\\nport multidimensional data analysis. Most SQL innovations are the result of vendor-  \\ncentric product enhancements. However, many of the innovations have made their way \\ninto standard SQL. This section introduces some of the new SQL extensions that have \\nbeen created to support OLAP-type data manipulations.\\nThe SaleCo snowflake schema shown in Figure 13.19 demonstrates the use of the \\nSQL extensions. Note that this snowflake schema has a central DWSALESFACT fact TABLE 13.12\\nRELATIONAL VS. MUL TIDIMENSIONAL OLAP\\nCHARACTERISTIC ROLAP MOLAP\\nSchema Uses star schema\\nAdditional dimensions can be added \\ndynamicallyUses data cubes\\nMultidimensional arrays, row stores, column stores\\nAdditional dimensions require re-creation of the \\ndata cube\\nDatabase size Medium to large Large\\nArchitecture Client/server\\nStandards-basedClient/server\\nOpen or proprietary, depending on vendor\\nAccess Supports ad hoc requests\\nUnlimited dimensionsLimited to predefined dimensions\\nProprietary access languages\\nSpeed Good with small data sets; average for \\nmedium-sized to large data setsFaster for large data sets with predefined dimensions\\nFIGURE 13.19  SALECO SNOWFLAKE SCHEMA  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='579f7bde-87b8-4212-922d-69d17e989056', embedding=None, metadata={'page_label': '630', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='630   Part 4    Advanced Database Concepts\\n13-7a  The ROLLUP Extension\\nThe ROLLUP extension is used with the GROUP BY clause to generate aggregates by \\ndifferent dimensions. As you know, the GROUP BY clause will generate only one aggre-gate for each new value combination of attributes listed in the GROUP BY clause. The ROLLUP extension goes one step further; it enables you to get a subtotal for each column listed except for the last one, which gets a grand total instead. The syntax of the GROUP BY ROLLUP command sequence is as follows:\\nSELECT column1 [, column2, …], aggregate_function(expression)\\nFROM table1 [, table2, …][WHERE condition]GROUP BY ROLLUP (column1 [, column2, …])[HAVING condition][ORDER BY column1 [, column2, …]]\\nThis section uses the Oracle RDBMS to demonstrate the use of SQL extensions to  support \\nOLAP functionality. If you use a different DBMS, consult the documentation to verify whether the vendor supports similar functionality and what the proper syntax is for your DBMS.Note\\nMS SQL Server and MySQL both support ROLLUP functionality. Other than the GROUP BY clause, the same syntax used for working with aggregate functions in these DBMSs applies. The GROUP BY clause is written:\\nGROUP BY column1 [, column2, …] WITH ROLLUPIn MySQL, if the ROLLUP option is specified, then an ORDER BY clause is not allowed. Access \\ndoes not support the ROLLUP extension.Notetable and three dimension tables: DWCUSTOMER, DWPRODUCT, and DWTIME. The central fact table represents daily sales by product and customer. However, as you examine the schema shown in Figure 13.19, you will see that the DWCUSTOMER and DWPRODUCT dimension tables have their own dimension tables: DWREGION and DWVENDOR.\\nKeep in mind that a database is at the core of all data warehouses. Therefore, all SQL \\ncommands (such as CREATE, INSERT, UPDATE, DELETE, and SELECT) will work in the data warehouse as expected. However, most queries you run in a data warehouse tend to include a lot of data groupings and aggregations over multiple columns. \\n Therefore, \\nthis section introduces two extensions to the GROUP BY clause that are particularly useful: ROLLUP and CUBE. In addition, you will learn about using materialized views to store preaggregated rows in the database.Online \\nContent\\nThe script files used to \\npopulate the database and run the SQL com-mands are available at www.cengagebrain.com.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b595e95c-edf7-4a76-b27b-acf4d580406d', embedding=None, metadata={'page_label': '631', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    631\\nThe order of the column list within GROUP BY ROLLUP is very important. The last \\ncolumn in the list will generate a grand total, and all other columns will generate sub -\\ntotals. For example, Figure 13.20 shows the use of the ROLLUP extension to generate \\nsubtotals by vendor and product.\\nFIGURE 13.20  ROLLUP EXTENSION  \\nSubtotals by V_CODE\\nGrand total for all P_CODE values\\nFigure 13.20 shows the subtotals by vendor code and a grand total for all product \\ncodes. Contrast that with the normal GROUP BY clause that generates only the subtotals \\nfor each vendor and product combination. The ROLLUP extension is particularly useful \\nwhen you want to obtain multiple nested subtotals for a dimension hierarchy. For exam -\\nple, within a location hierarchy, you can use ROLLUP to generate subtotals by region, \\nstate, city, and store.\\n13-7b  The CUBE Extension\\nThe CUBE extension is also used with the GROUP BY clause to generate aggregates \\nby the listed columns, including the last one. The CUBE extension enables you to get \\na subtotal for each column listed in the expression, in addition to a grand total for \\nthe last column listed. The syntax of the GROUP BY CUBE command sequence is as \\nfollows:\\nSELECT column1 [, column2, …], aggregate_function(expression)\\nFROM table1 [, table2, …]\\n[WHERE condition]\\nGROUP BY CUBE (column1 [, column2, …])\\n[HAVING condition]\\n[ORDER BY column1 [, column2, …]]\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='799cf145-fe78-4687-90db-478639e29633', embedding=None, metadata={'page_label': '632', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='632   Part 4     Advanced Database Concepts\\nFor example, Figure 13.21 shows the use of the CUBE extension to compute the sales \\nsubtotals by month and by product, as well as a grand total.\\nMS SQL Server supports CUBE functionality, too. Other than the GROUP BY clause, the \\nsame syntax used for working with aggregate functions applies. The GROUP BY clause is \\nwritten similarly to the ROLLUP extension:\\nGROUP BY column1 [, column2, …] WITH CUBE\\nMySQL and Access do not support the CUBE extension.Note\\nFIGURE 13.21  CUBE EXTENSION  \\nSubtotals by month\\nSubtotals by product\\nGrand total for all products and months\\nIn Figure 13.21, the CUBE extension also generates subtotals for each combination \\nof month and product. The CUBE extension is particularly useful when you want to \\ncompute all possible subtotals within groupings based on multiple dimensions. Cross-  \\ntabulations are especially good candidates for application of the CUBE extension.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7a9eff93-8cce-487b-9543-84cbcb66fcee', embedding=None, metadata={'page_label': '633', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    633\\n13-7c  Materialized Views\\nThe data warehouse normally contains fact tables that store specific measurements \\nof interest to an organization. Such measurements are organized by different dimen-sions. The vast majority of OLAP business analysis of everyday activity is based on data \\n comparisons that are aggregated at different levels, such as totals by vendor, by product, and by store.\\nBecause businesses normally use a predefined set of summaries for benchmark-\\ning, it is reasonable to predefine such summaries for future use by creating summary fact tables. (See Section 13-5f for a discussion of additional performance-\\n improving \\ntechniques.) However, creating multiple summary fact tables that use GROUP BY queries with multiple table joins could become resource-intensive. In addition, data warehouses must be able to maintain up-to-date summarized data at all times. So what happens with the summary fact tables after new sales data has been added to the base fact tables? Under normal circumstances, the summary fact tables are re-created. This operation requires that the SQL code be run again to re-create all summary rows, even when only a few rows need updating. Clearly, this is a time-\\n \\nconsuming process.\\nTo save query processing time, most database vendors have implemented  additional \\nfunctions to manage aggregate summaries more efficiently. This new functionality resembles the standard SQL views for which the SQL code is predefined in the data-base. However, the added difference is that the views also store the preaggregated rows, \\n something like a summary table. For example, Microsoft SQL Server provides \\nindexed views, while Oracle provides materialized views. This section explains the use of \\n materialized views.\\nA materialized view is a dynamic table that not only contains the SQL query \\n command to generate the rows, it stores the actual rows. The materialized view is cre-ated the first time the query is run, and the summary rows are stored in the table. The materialized view rows are automatically updated when the base tables are updated. That way, the data warehouse administrator will create the view but will not have to worry about updating the view. The use of materialized views is totally transparent to the end user. The OLAP end user can create OLAP queries using the standard fact tables, and the DBMS query optimization feature will automatically use the materialized views if they provide better performance.\\nThe basic syntax for the materialized view is:\\nCREATE MATERIALIZED VIEW view_nameBUILD {IMMEDIATE | DEFERRED}REFRESH {[FAST | COMPLETE | FORCE]} ON COMMIT[ENABLE QUERY REWRITE]AS select_query;\\nThe BUILD clause indicates when the materialized view rows are actually popu-\\nlated. IMMEDIATE indicates that the materialized view rows are populated right after the command is entered. DEFERRED indicates that the materialized view rows will be \\n populated later. Until then, the materialized view is in an unusable state. The DBMS \\n provides a special routine that an administrator runs to populate materialized views.\\nThe REFRESH clause lets you indicate when and how to update the materialized \\nview when new rows are added to the base tables. FAST indicates that whenever a change is made in the base tables, the materialized view updates only the affected rows. \\n COMPLETE indicates that a complete update will be made for all rows in the materialized view when you rerun the SELECT query on which the view is based. FORCE indicates  materialized view\\nA dynamic table that not only contains the SQL query command to generate rows but stores the actual rows. The materialized view is created the first time the query is run and the summary rows are stored in the table. The materialized view rows are automatically updated when the base tables are updated.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c16a58f1-ef93-49a5-9f33-ed680523f880', embedding=None, metadata={'page_label': '634', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='634   Part 4    Advanced Database Concepts\\nthat the DBMS will first try to do a FAST update; otherwise, it will do a  COMPLETE \\nupdate. The\\xa0ON COMMIT clause indicates that the updates to the materialized view \\nwill take place as part of the commit process of the underlying DML statement—that is, as part of the commitment of the DML transaction that updated the base tables. The ENABLE QUERY REWRITE option allows the DBMS to use the materialized views in query optimization.\\nTo create materialized views, you must have specified privileges and you must com-\\nplete specified prerequisite steps. As always, you must consult the DBMS documentation for the latest updates. In the case of Oracle, you must create materialized view logs on the base tables of the materialized view. Figure 13.22 shows the steps required to create the SALES_MONTH_MV materialized view in the Oracle RDBMS.\\nFIGURE 13.22  CREATING A MATERIALIZED VIEW  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c049cc55-a145-4656-b70c-6c6a7447e78a', embedding=None, metadata={'page_label': '635', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    635\\nFIGURE 13.23  REFRESHING A MATERIALIZED VIEW  \\nThe materialized view in Figure 13.22 computes the monthly total units sold and \\nthe total sales aggregated by product. The SALES_MONTH_MV materialized view is \\nconfigured to automatically update after each change in the base tables. The last row of SALES_MONTH_MV indicates that during October, three units of product “WR3/TT3” were sold for a total of $359.85. Figure 13.23 shows the effects of updating the DWDAYSALESFACT base table.\\nFigure 13.23 shows how the materialized view was automatically updated after the \\ninsertion of a new row in the DWDAYSALESFACT table. The last row of SALES_MONTH_MV now shows that in October, four units of product “WR3/TT3” were sold for a total of $466.84.\\nAlthough all of the examples in this section focus on SQL extensions to support \\nOLAP reporting in an Oracle DBMS, you have seen just a small fraction of the many business intelligence features currently provided by most DBMS vendors. For example, most vendors provide rich graphical user interfaces to manipulate, analyze, and present the data in multiple formats. Figure 13.24 shows two sample screens, one for Oracle and one for Microsoft SQL Server.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9875c87-2514-4135-a9ed-8ac49aca54f7', embedding=None, metadata={'page_label': '636', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='636   Part 4     Advanced Database Concepts\\nFIGURE 13.24  SAMPLE OLAP APPLICATIONS  \\nOracle DBMS\\nOLAP Services\\nMicrosoft SQL Server\\nAnalysis Services\\nSummary\\n• Business intelligence (BI) is a term for a comprehensive, cohesive, and integrated \\nset of applications used to capture, collect, integrate, store, and analyze data with \\nthe  purpose of generating and presenting information to support business decision \\nmaking.\\n• Decision support systems (DSSs) refer to an arrangement of computerized tools \\nused to assist managerial decision making within a business. DSSs were the original \\n precursor of current-generation BI systems.\\n• Operational data is not well suited for decision support. From the end user’s point of \\nview, decision support data differs from operational data in three main areas: time \\nspan, granularity, and dimensionality.\\n• The data warehouse is an integrated, subject-oriented, time-variant, nonvolatile \\n collection of data that provides support for decision making. The data warehouse is \\nusually a read-only database optimized for data analysis and query processing. A data \\nmart is a small, single-subject data warehouse subset that provides decision support \\nto a small group of people.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='19a9d19e-b89a-4813-98fe-109134c5b56f', embedding=None, metadata={'page_label': '637', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    637\\n• The star schema is a data-modeling technique used to map multidimensional deci-\\nsion support data into a relational database for advanced data analysis. The basic star schema has four components: facts, dimensions, attributes, and attribute hierarchies. Facts are numeric measurements or values that represent a specific business aspect or activity. Dimensions are general qualifying categories that provide additional per -\\nspectives to facts. Conceptually, the multidimensional data model is best represented by a three-dimensional cube. Attributes can be ordered in well-defined hierarchies, which provide a top-down organization that is used for two main purposes: to permit aggregation and provide drill-down and roll-up data analysis.\\n•\\n Online analytical processing (OLAP) refers to an advanced data analysis environment that supports decision making, business modeling, and operations research.\\n•\\n SQL has been enhanced with extensions that support OLAP-type processing and data generation.\\nattribute hierarchy\\nbusiness intelligence (BI)cube cachedashboarddata cubedata martdata visualizationdata warehousedecision support system \\n(DSS)\\ndimension tablesdimensionsdrill downextraction, transformation, \\nand loading (ETL)fact tablefactsgovernancekey performance indicator \\n(KPI)\\nmaster data management \\n(MDM)\\nmaterialized viewmetricsmultidimensional database \\nmanagement system \\n(MDBMS)\\nmultidimensional online \\nanalytical processing (MOLAP)online analytical  \\nprocessing (OLAP)\\npartitioning\\nperiodicityportalrelational online  \\nanalytical processing \\n(ROLAP)\\nreplication\\nroll upslice and dicesnowflake schemasparsitystar schemavery large database (VLDB)\\nKey Terms\\nFlashcards and  crossword \\npuzzles for key term \\n practice\\xa0are available at \\nwww.cengagebrain.com.Online \\nContent\\n1. What is business intelligence? Give some recent examples of BI usage, using the \\nInternet for assistance. What BI benefits have companies found?\\n2. Describe the BI framework. Illustrate the evolution of BI.\\n3. What are decision support systems, and what role do they play in the business environment?\\n4.\\n Explain how the main components of the BI architecture interact to form a system. Describe the evolution of BI information dissemination formats.\\nReview Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3c787125-3ee6-4804-a61a-8cda22803438', embedding=None, metadata={'page_label': '638', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='638   Part 4    Advanced Database Concepts\\n5. What are the most relevant differences between operational data and decision sup-\\nport data?\\n6. What is a data warehouse, and what are its main characteristics? How does it differ from a data mart?\\n7.\\n Give three examples of likely problems when operational data is integrated into the data warehouse.\\n  Use the following scenario to answer Questions 8–14.\\n  While working as a database analyst for a national sales organization, you are asked to be part of its data warehouse project team.\\n8.\\n Prepare a high-level summary of the main requirements for evaluating DBMS prod-ucts for data warehousing.\\n9.\\n Y our data warehousing project group is debating whether to create a prototype of a data warehouse before its implementation. The project group members are espe-cially concerned about the need to acquire some data warehousing skills before implementing the enterprise-wide data warehouse. What would you recommend? Explain your recommendations.\\n10.\\n Suppose that you are selling the data warehouse idea to your users. How would you define multidimensional data analysis for them? How would you explain its advan-tages to them?\\n11.\\n The data warehousing project group has invited you to provide an OLAP overview. The group’s members are particularly concerned about the OLAP client/server archi-tecture requirements and how OLAP will fit the existing environment. Y our job is to explain the main OLAP client/server components and architectures.\\n12.\\n One of your vendors recommends using an MDBMS. How would you explain this recommendation to your project leader?\\n13.\\n The project group is ready to make a final decision, choosing between ROLAP and MOLAP . What should be the basis for this decision? Why?\\n14.\\n The data warehouse project is in the design phase. Explain to your fellow designers how you would use a star schema in the design.\\n15.\\n Briefly discuss the OLAP architectural styles with and without data marts.\\n16. What is OLAP , and what are its main characteristics?\\n17. Explain ROLAP , and list the reasons you would recommend its use in the relational database environment.\\n18.\\n Explain the use of facts, dimensions, and attributes in the star schema.\\n19. Explain multidimensional cubes, and describe how the slice-and-dice technique fits into this model.\\n20.\\n In the star schema context, what are attribute hierarchies and aggregation levels, and what is their purpose?\\n21.\\n Discuss the most common performance improvement techniques used in star schemas.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='996b683a-7d5e-4307-a103-6d1bd4560ae2', embedding=None, metadata={'page_label': '639', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    639\\n1. The university computer lab’s director keeps track of lab usage, as measured by \\nthe number of students using the lab. This function is important for budgeting purposes. The computer lab director assigns you the task of developing a data warehouse to keep track of the lab usage statistics. The main requirements for this database are to:\\n  • Show the total number of users by different time periods.\\n  • Show usage numbers by time period, by major, and by student classification.\\n  • Compare usage for different majors and different semesters.\\n  Use the Ch13_P1.mdb database, which includes the following tables:\\n   • USELOG contains the student lab access data.\\n  • STUDENT is a dimension table that contains student data.\\n  Given the three preceding requirements, and using the Ch13_P1.mdb data, \\n complete the following problems:\\n  a.  Define the main facts to be analyzed. (Hint : These facts become the source for \\nthe design of the fact table.)\\n  b.  Define and describe the appropriate dimensions. (Hint : These dimensions \\nbecome the source for the design of the dimension tables.)\\n  c.  Draw the lab usage star schema, using the fact and dimension structures you defined in Problems 1a and 1b.\\n  d.  Define the attributes for each of the dimensions in Problem 1b.\\n  e. Recommend the appropriate attribute hierarchies.\\n  f.  Implement your data warehouse design, using the star schema you created in Problem 1c and the attributes you defined in Problem 1d.\\n  g.  Create the reports that will meet the requirements listed in this problem’s introduction.\\n2.\\n Victoria Ephanor manages a small product distribution company. Because the business is growing fast, she recognizes that it is time to manage the vast infor -\\nmation pool to help guide the accelerating growth. Ephanor, who is familiar with spreadsheet software, currently employs a sales force of four people. She asks you to develop a data warehouse application prototype that will enable her to study sales figures by year, region, salesperson, and product. (This prototype will be used as the basis for a future data warehouse database.)\\n  Using the data supplied in the Ch13_P2.xls file, complete the following seven problems:\\n  a. Identify the appropriate fact table components.\\n  b. Identify the appropriate dimension tables.\\n  c. Draw a star schema diagram for this data warehouse.\\n  d.  Identify the attributes for the dimension tables that will be required to solve this problem.\\n  e.  Using Microsoft Excel or any other spreadsheet program that can produce pivot tables, generate a pivot table to show the sales by product and by region. The end user must be able to specify the display of sales for any given year. The sample output is shown in the first pivot table in Figure P13.2E.Problems\\nThe databases used for the following problems are avail-able at www.cengagebrain.com  (see the list of data files \\nat the beginning of the chap -\\nter). The data for Problem 2 is stored in Microsoft Excel for -\\nmat at www.cengagebrain.com . The spreadsheet file -\\nname is Ch13_P2.xls.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='44473190-e22a-4804-b5e1-d9c2e98783e3', embedding=None, metadata={'page_label': '640', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='640   Part 4     Advanced Database Concepts\\n  f.  Using Problem 2e as your base, add a second pivot table (see Figure P13.2E) to \\nshow the sales by salesperson and by region. The end user must be able to specify \\nsales for a given year or for all years, and for a given product or for all products.\\n  g.  Create a 3D bar graph to show sales by salesperson, by product, and by region. \\n(See the sample output in Figure P13.2G.)FIGURE P13.2E  USING A PIVOT TABLE  \\nFIGURE P13.2G   3D BAR GRAPH SHOWING THE RELATIONSHIPS AMONG AGENT,  \\nPRODUCT, AND REGION\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5c9691f-f4c7-4452-80ef-31b6e87651fa', embedding=None, metadata={'page_label': '641', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    641\\n3. David Suker, the inventory manager for a marketing research company, wants to \\nstudy the use of supplies within the different company departments. Suker has heard that his friend, Victoria Ephanor, has developed a spreadsheet-based data ware-house model that she uses to analyze sales data (see Problem 2). Suker is interested in developing a data warehouse model like Ephanor’s so he can analyze orders by department and by product. He will use Microsoft Access as the data warehouse DBMS and Microsoft Excel as the analysis tool.\\n  a. Develop the order star schema.\\n  b. Identify the appropriate dimension attributes.\\n  c. Identify the attribute hierarchies required to support the model.\\n  d.  Develop a crosstab report in Microsoft Access, using a 3D bar graph to show orders by product and by department. (The sample output is shown in Figure\\xa0P13.3.)\\nFIGURE P13.3  CROSSTAB REPORT: ORDERS BY PRODUCT AND DEPARTMENT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29385aaa-1cdc-4060-916d-323e29771c6c', embedding=None, metadata={'page_label': '642', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='642   Part 4     Advanced Database Concepts\\n4. ROBCOR, whose sample data is contained in the database named Ch13_P4.mdb , \\nprovides “on-demand” aviation charters using a mix of different aircraft and  aircraft \\ntypes. Because ROBCOR has grown rapidly, its owner has hired you as its first \\n database manager. The company’s database, developed by an outside consulting \\nteam, is already in place to help manage all company operations. Y our first criti -\\ncal assignment is to develop a decision support system to analyze the charter data. \\n(Review the company’s operations in Problems 24–31 of Chapter 3, The Relational \\nDatabase Model.) The charter operations manager wants to be able to analyze  charter \\ndata such as cost, hours flown, fuel used, and revenue. She also wants to be able to \\ndrill down by pilot, type of airplane, and time periods.\\n  Given those requirements, complete the following:\\n  a. Create a star schema for the charter data.\\n  b. Define the dimensions and attributes for the charter operation’s star schema.\\n  c. Define the necessary attribute hierarchies.\\n  d.  Implement the data warehouse design using the design components you devel -\\noped in Problems 4a–4c.\\n  e.  Generate the reports to illustrate that your data warehouse meets the  specified \\ninformation requirements.\\n  Using the data provided in the Ch13-SaleCo-DW  database, solve the following \\nproblems. ( Hint : In Problems 5–11, use the ROLLUP command.)\\n5. What is the SQL command to list the total sales by customer and by product, with \\nsubtotals by customer and a grand total for all product sales? Figure P13.5 shows the \\nabbreviated results of the query.\\n6. What is the SQL command to list the total sales by customer, month, and product, \\nwith subtotals by customer and by month and a grand total for all product sales? \\nFigure P13.6 shows the abbreviated results of the query.Online \\nContent\\nThe script files used to \\npopulate the Ch13-Sale -\\nCo-DW database are \\navailable at www.  \\ncengagebrain.com . The \\nscript files are available \\nin Oracle, MySQL, and \\nSQL Server formats. \\nMS Access does not \\nhave SQL support for \\nthe complex grouping \\nrequired.\\nFIGURE P13.5  PROBLEM 5 ABBREVIATED RESULT  \\nSome records omitted\\nin output shown\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='194a9974-4cb7-48c0-a8ed-63347ea605b3', embedding=None, metadata={'page_label': '643', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    643\\nFIGURE P13.6  PROBLEM 6 ABBREVIATED RESULT  \\nSome records omitted\\nin output shown\\n7. What is the SQL command to list the total sales by region and customer, with \\n subtotals by region and a grand total for all sales? Figure P13.7 shows the result of \\nthe query.\\nFIGURE P13.7  PROBLEM 7 RESULT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c9051496-7ca8-4c26-b5a2-dda5ca6f79cc', embedding=None, metadata={'page_label': '644', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='644   Part 4     Advanced Database Concepts\\n8. What is the SQL command to list the total sales by month and product category, \\nwith subtotals by month and a grand total for all sales? Figure P13.8 shows the result \\nof the query.\\nFIGURE P13.8  PROBLEM 8 RESULT  \\nFIGURE P13.9  PROBLEM 9 RESULT  \\n9. What is the SQL command to list the number of product sales (number of rows) \\nand total sales by month, with subtotals by month and a grand total for all sales? \\nFigure\\xa0P13.9 shows the result of the query.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='082245cb-019b-4d4a-ad47-dcc32abf8745', embedding=None, metadata={'page_label': '645', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    645\\nFIGURE P13.10  PROBLEM 10 RESULT  \\n10. What is the SQL command to list the number of product sales (number of rows) and \\ntotal sales by month and product category, with subtotals by month and product \\ncategory and a grand total for all sales? Figure P13.10 shows the result of the query.\\n11. What is the SQL command to list the number of product sales (number of rows) and \\ntotal sales by month, product category, and product, with subtotals by month and prod -\\nuct category and a grand total for all sales? Figure P13.11 shows the result of the query.\\nFIGURE P13.11  PROBLEM 11 RESULT  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='10aa85a6-1a51-41c3-8203-1e302d6bc999', embedding=None, metadata={'page_label': '646', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='646   Part 4     Advanced Database Concepts\\nFIGURE P13.12  PROBLEM 12 RESULT  \\n12. Using the answer to Problem 10 as your base, what command would you need to \\ngenerate the same output but with subtotals in all columns? ( Hint : Use the CUBE \\ncommand.) Figure P13.12 shows the result of the query.\\n13. Create your own data analysis and visualization presentation. The purpose of this \\nproject is for you to search for a publicly available data set using the Internet and \\ncreate your own presentation using what you have learned in this chapter.\\n  a.  Search for a data set that may interest you and download it. Some examples of \\npublic data sets sources are:\\n    • http://www.data.gov\\n    • http://data.worldbank.org\\n    • http://aws.amazon.com/datasets\\n    • http://usgovxml.com/\\n    • https://data.medicare.gov/\\n    • http://www.faa.gov/data_research/\\n  b.  Use any tool available to you to analyze the data. Y ou can use tools such as MS \\nExcel Pivot Tables, Pivot Charts, or other free tools, such as Google Fusion tables, \\nTableau free trial, IBM Many Eyes, etc.\\n  c.  Create a short presentation to explain some of your findings (what the data \\nsources are, where the data comes from, what the data represents, etc.)\\nThe visualization in Figure P13.13 was created using a data set downloaded from one of \\nthe public sources listed above. A trial version of Tableau was used to create the visualiza -\\ntions. This simple example illustrates the type of quick analysis you can do for this project.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='11a47d90-1d08-40cd-a8bc-a6274ca6e05c', embedding=None, metadata={'page_label': '647', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 13    Business Intelligence and Data Warehouses    647\\nFIGURE P13.13  VISUALIZATION EXAMPLE USING TABLEAU  \\nSource: Tableau\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76ceb76b-2ef1-4278-a3f8-f127554ec3c3', embedding=None, metadata={'page_label': '648', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Big Data Analytics and NoSQL\\nPreviewIn Chapter 2, Data Models, you were introduced to the emerging NoSQL data model and \\nthe Big Data problem that has led to NoSQL ’s development. In this chapter, you learn about these issues in much greater detail. Y ou will find that there is more to Big Data and the problem that it represents to modern businesses than just the volume, velocity, and variety (“3 V”) characteristics introduced in Chapter 2. In fact, you will find that these characteristics themselves are more complex than previously discussed.\\nAfter learning about Big Data issues, you learn about the technologies that have devel-\\noped, and continue to be developed, to address Big Data. First, you learn about the low-level technologies in the Hadoop framework. Hadoop has become a standard component in organizations’ efforts to address Big Data. Next, you learn about the higher-level approaches of the NoSQL data model to develop nonrelational databases such as key-value databases, document databases, column-oriented databases, and graph databases.\\nFinally, you learn about the important area of data analytics and how statistical tech-\\nniques are being used to help organizations turn the vast stores of data that are being collected into actionable information. Analytics are helping organizations understand not only what has happened in the business, but also to predict what is likely to happen.\\nData Files Available on cengagebrain.com\\nBecause it is purely conceptual, this chapter does not reference any data files.NoteIn this chapter, you will learn:\\n• What Big Data is and why it is important in modern business\\n• The primary characteristics of Big Data and how these go beyond the traditional “3 Vs”\\n• How the core components of the Hadoop framework, HDFS and MapReduce, operate\\n• What the major components of the Hadoop ecosystem are\\n• The four major approaches of the NoSQL data model and how they differ from the relational model\\n• About data analytics, including data mining and predictive analytics\\nChapter 14\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4e8c0833-755a-4c74-8ae5-1f3ecba79969', embedding=None, metadata={'page_label': '649', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    649\\nThe relational database model has been dominant for decades, and during that time \\nit has faced challenges such as object-oriented databases and the development of data \\nwarehouses. The relational model, and the tools based on it, have evolved to adapt to these challenges and remain dominant in the data management arena. In each case, the challenge arose because technological advances changed business’s perceptions of what is possible and created new opportunities for organizations to create value from increased data leverage. The latest of these challenges is Big Data. Big Data is an ill-defined term that describes a new wave of data storage and manipulation possibilities and requirements. Organizations’ efforts to store, manipulate, and analyze this new wave of data represent one of the most urgent emerging trends in the database field. The challenges of dealing with the wave of Big Data have led to the development of NoSQL databases that reject many of the underlying assumptions of the relational model. Although the term Big Data  \\nlacks a consistent definition, there is a set of characteristics generally associated with it.\\n14-1  Big Data\\nBig Data generally refers to a set of data that displays the characteristics of volume, velocity,  \\nand variety (the “3 Vs”) to an extent that makes the data unsuitable for management by  \\na relational database management system. These characteristics can be defined as follows:\\n• Volume—the quantity of data to be stored\\n• Velocity—the speed at which data is entering the system\\n• Variety—the variations in the structure of the data to be stored\\nNotice the lack of specific values associated with these characteristics. This lack of spec-\\nificity is what leads to the ambiguity in defining Big Data. What was Big Data five years ago might not be considered Big Data now. Similarly, something considered Big Data now might not be considered Big Data five years from now. The key is that the charac-teristics are present to an extent that the current relational database technology struggles with managing the data.\\nFurther adding to the problem of defining Big Data is that there is some disagreement \\namong pundits about which of the 3 Vs must be present for a data set to be considered Big Data. Originally, Big Data was conceived as shown in Figure 14.1 as a combination of the 3 Vs. Web data, a combination of text, graphics, video, and audio sources combined \\nvolume\\nA characteristic of Big Data that describes the quantity of data to be stored.\\nvelocity\\nA characteristic of Big Data that describes the speed at which data enters the system and must be processed.\\nvariety\\nA characteristic of Big Data that describes the variations in the structure of data to be stored.FIGURE 14.1  ORIGINAL VIEW OF BIG DATA\\nVolume\\nVarietyVelocity\\nBig\\nData\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d8ad75d7-4330-4302-b3cc-eece14323609', embedding=None, metadata={'page_label': '650', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='650   Part 4    Advanced Database Concepts\\ninto complex structures, is often cited as creating the new challenges for data manage-\\nment that involve all three characteristics. After the dot-com bubble burst in the 1990s, many startup web-based companies failed, but the companies that survived experienced significant growth as web commerce consolidated into a smaller set of businesses. As a result, companies like Google and Amazon experienced significant growth and were among the first to feel the pressure of managing Big Data. The success of social media giant Facebook quickly followed, and these companies became pioneers in creating  \\nnew technologies to address Big Data problems. Google created the BigTable data store, Amazon created Dynamo, and Facebook created Cassandra to deal with the growing need to store and manage large sets of data that had the characteristics of the 3 Vs.\\nAlthough social media and web data have been at the forefront of perceptions of Big \\nData issues, other organizations have Big Data issues, too. More recently, changes in technology have increased the opportunities for businesses to generate and track data so that Big Data has been redefined as involving any, but not necessarily all, of the 3 Vs, as shown in Figure 14.2. Advances in technology have led to a vast array of user-generated data and machine-generated data that can spur growth in specific areas.\\nFIGURE 14.2  CURRENT VIEW OF BIG DATA\\nVolume\\nVarietyVelocity\\nBig\\nData\\nFor example, Disney World has introduced “Magic Bands” for park visitors to wear on \\ntheir wrists. Each visitor’s Magic Band is connected to much of the data that Disney stores about that individual. These bands use RFID and near-field communications (NFC) to act as tickets for rides, hotel room keys, and even credit cards within the park. The bands can be tracked so the Disney systems can track individuals as they move through the park, record with which Disney characters (who are also tracked) they interact, pur -\\nchases made, wait time in lines, and more. Visitors can make reservations at a restaurant and order meals through a Disney app on their smartphones, and by tracking the Magic Bands, the restaurant staff knows when the visitor arrives for their reservation, can track at which table they are seated, and deliver their meals within minutes of the guests sitting down. With the many cameras mounted throughout the park, Disney can also capture pictures and short videos of the visitor throughout their stay in the park to produce a personalized movie of their vacation experience, which can then be sold to the visitor as a souvenir. All of this involves the capture of a constant stream of data from each band, pro-cessed in real time. Considering the thousands of visitors in Disney World each day, each with their own Magic Band, the volume, velocity, and variety of the data is enormous.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4251f706-3547-460a-baf1-30dc1e940568', embedding=None, metadata={'page_label': '651', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    651\\n14-1a  Volume\\nVolume, the quantity of data to be stored, is a key characteristic of Big Data. The storage \\ncapacities associated with Big Data are extremely large. Table 14.1 provides definitions for units of data storage capacity.\\nTABLE 14.1\\nSTORAGE CAPACITY UNITS\\nTERM CAPACITY ABBREVIATION\\nBit 0 or 1 value b\\nByte 8 bits B\\nKilobyte 1024* bytes KB\\nMegabyte 1024 KB MB\\nGigabyte 1024 MB GB\\nTerabyte 1024 GB TB\\nPetabyte 1024 TB PB\\nExabyte 1024 PB EB\\nZettabyte 1024 EB ZB\\nYottabyte 1024 ZB YB\\n*  Note that because bits are binary in nature and are the basis on which all other storage values are based, all values  for data storage units are defined in terms of powers of 2. For example, the prefix kilo typically means 1000; however, in data storage, a kilobyte = 2\\n10 = 1024 bytes.\\nNaturally, as the quantity of data needing to be stored increases, the need for larger \\nstorage devices increases as well. When this occurs, systems can either scale up or scale out. Scaling up is keeping the same number of systems, but migrating each system to \\na larger system: for example, changing from a server with 16 CPU cores and a 1 TB storage system to a server with 64 CPU cores and a 100 TB storage system. Scaling up involves moving to larger and faster systems. However, there are limits to how large and fast a single system can be. Further, the costs of these high-powered systems increase at a dramatic rate. On the other hand, scaling out means that when the workload exceeds the capacity of a server, the workload is spread out across a number of servers. This is also referred to as clustering —creating a cluster of low-cost servers to share a workload. \\nThis can help to reduce the overall cost of the computing resources since it is cheaper to buy ten 100 TB storage systems than it is to buy a single 1 PB storage system. Make no mistake, organizations need storage capacities in these extreme sizes. The eBay singu-larity system, which collects clickstream data among other things, is over 40 PB. This is in addition to the eBay enterprise data warehouse, which is over 14 PB and spread over hundreds of thousands of nodes.\\n1\\n1 Cliff Saran, “Case study: How big data powers the eBay customer journey, ” ComputerWeekly.com , TechTarget, \\n2015, www.computerweekly.com/news/2240219736/Case-Study-How-big-data-powers-the-eBay-customer-\\njourney, August 18, 2015.scaling up\\nA method for dealing \\nwith data growth that involves migrating the same structure to more powerful systems.\\nscaling out\\nA method for dealing with data growth that involves distributing data storage structures across a cluster of commodity servers.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b1d678e9-d219-45ed-9797-23b24e0b9f2c', embedding=None, metadata={'page_label': '652', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='652   Part 4    Advanced Database Concepts\\nAlthough some RDBMS products, such as SQL Server and Oracle Real-Application Clusters \\n(RAC), legitimately claim to support clusters, these clusters are limited in scope and gener -\\nally rely on a single, shared data storage subsystem, such as a storage area network (SAN).NoteRecall from Chapter 3 that one of the greatest advances represented by the relational \\nmodel was the development of an RDBMS—a sophisticated database management system that could hide the complexity of the underlying data storage and manipulation from the user so that the data always appears to be in tables. To carry out these functions, the DBMS acts as the “brain” of the database system and must maintain control over all of the data within the database. As discussed in Chapter 12, it is possible to distribute a relational database over multiple servers using replication and fragmentation. However, because the DBMS must act as a single point of control for all of the data in the database, distributing the database across multiple systems requires a high degree of communication and coordination across the systems. There are significant limits associated with the ability to distribute the DBMS due to the increased performance costs of communication and coordination as the number of nodes grows. This limits the degree to which a relational database to be scaled out as data volume grows, and it makes RDBMSs ill-suited for clusters.\\n14-1b  Velocity\\nVelocity, another key characteristic of Big Data, refers to the rate at which new data enters the system as well as the rate at which the data must be processed. In many ways, the issues of velocity mirror those of volume. For example, consider a web retailer such as Amazon. In the past, a retail store might capture only the data about the final transac-tion of a customer making a purchase. A retailer like Amazon captures not only the final transaction, but every click of the mouse in the searching, browsing, comparing, and purchase process. Instead of capturing one event (the final sale) in a 20-minute shopping experience, it might capture data on 30 events during that 20-minute time frame—a 30× increase in the velocity of the data. Other advances in technology, such as RFID, GPS, and NFC, add new layers of data-gathering opportunities that often generate large amounts of data that must be stored in real-time. For example, RFID tags can be used to track items for inventory and warehouse management. The tags do not require line-of-sight between the tag and the reader, and the reader can read hundreds of tags simulta-neously while the products are still in boxes. This means that instead of a single record for tracking a given quantity of a product being produced, each individual product is tracked, creating an increase of several orders of magnitude in the amount of data being delivered to the system at any one time.\\nIn addition to the speed with which data is entering the system, for Big Data to be \\nactionable, that data must be processed at a very rapid pace. The velocity of processing can be broken down into two categories.\\n•\\n Stream processing\\n• Feedback loop processing\\nStream processing focuses on input processing, and it requires analysis of the data \\nstream as it enters the system. In some situations, large volumes of data can enter the \\nsystem at such a rapid pace that it is not feasible to try to store all of the data. The data must be processed and filtered as it enters the system to determine which data to keep stream processing\\nThe processing of data inputs in order to make decisions about which data to keep and which data to discard before storage.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ec43711c-d75f-4e82-a4ff-347d6422e12c', embedding=None, metadata={'page_label': '653', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    653\\nand which data to discard. For example, at the CERN Large Hadron Collider, the largest \\nand most powerful particle accelerator in the world, experiments produce about 600 TB per second of raw data. Scientists have created algorithms to decide ahead of time which data will be kept. These algorithms are applied in a two-step process to filter the data down to only about 1 GB per second of data that will actually be stored.\\n2\\nFeedback loop processing refers to the analysis of the data to produce actionable \\nresults. While stream processing could be thought of as focused on inputs, feedback loop processing can be thought of as focused on outputs. The process of capturing the data, processing it into usable information, and then acting on that information is a feedback loop. Figure 14.3 shows a feedback loop for providing recommendations for book pur -\\nchases. Feedback loop processing to provide immediate results requires analyzing large amounts of data within just a few seconds so that the results of the analysis can become a part of the product delivered to the user in real time. Not all feedback loops are used for inclusion of results within immediate data products. Feedback loop processing is also used to help organizations sift through terabytes and petabytes of data to inform decision makers to help them make faster strategic and tactical decisions, and it is a key component in data analytics.\\n14-1c  Variety\\nIn a Big Data context, variety refers to the vast array of formats and structures in which the data may be captured. Data can be considered to be structured, unstructured, or semistructured. Structured data  is data that has been organized to fit a predefined data \\nmodel. Unstructured data is data that is not organized to fit into a predefined data \\nmodel. Semistructured data combines elements of both—some parts of the data fit a pre-defined model while other parts do not. Relational databases rely on structured data. A data model is created by the database designer based on the business rules, as discussed in Chapter 4. As data enters the database, the data is decomposed and routed for storage in the corresponding tables and columns as defined in the data model. Although much of the transactional data that organizations use works well in a structured environment, \\n2 CERN, “Processing: What to record?” http://home.web.cern.ch/about/computing/processing-what-record, \\nAugust 20, 2015.algorithm\\nA process or set of operations in a calculation.\\nfeedback loop processing\\nAnalyzing stored data to produce actionable results.\\nstructured data\\nData that conforms to a predefined data model.\\nunstructured data\\nData that does not conform to a predefined data model.FIGURE 14.3  FEEDBACK LOOP PROCESSING\\nData is analyzed to\\ndetermine other books\\nand products the user\\nmay likeList of\\nrecommended\\nitems added to the\\nuser request\\nData is captured\\nabout the user and\\nabout the book requested\\nUser clicks on a link for a bookInformation requested by user plus\\ninformation on recommendations are\\nreturned\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='52da5cf0-48ae-4692-ae37-ef50c5c047cb', embedding=None, metadata={'page_label': '654', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='654   Part 4    Advanced Database Concepts\\nmost of the data in the world is semistructured or unstructured. Unstructured data \\nincludes maps, satellite images, emails, texts, tweets, videos, transcripts, and a whole host of other data forms. Over the decades that the relational model has been dominant, relational databases have evolved to address some forms of unstructured data. For exam-ple, most large-scale RDBMSs support a binary large object (BLOB) data type that allows the storage of unstructured objects like audio, video, and graphic data as a single, atomic value. One problem with BLOB data is that the semantic value of the data, the meaning that the object conveys, is inaccessible and uninterpretable by data processing.\\nBig Data requires that the data be captured in whatever format it naturally exists, \\nwithout any attempt to impose a data model or structure to the data. This is one of the key differences between processing data in a relational database and Big Data process-ing. Relational databases impose a structure on the data when the data is captured and stored. Big Data processing imposes a structure on the data as needed for applications as a part of retrieval and processing. One advantage to providing structure during retrieval and processing is the flexibility of being able to structure the data in different ways for different applications.\\n14-1d  Other Characteristics\\nCharacterizing Big Data with the 3 Vs is fairly standard. However, as the industry matures, other characteristics have been put forward as being equally important. Keep-ing with the spirit of the 3 Vs, these additional characteristics are typically presented as additional Vs. Variability refers to the changes in the meaning of the data based on con-\\ntext. While variety  and variability  are similar terms, they mean distinctly different things \\nin Big Data. Variety is about differences in structure. Variability is about differences in meaning. Variability is especially relevant in areas such as sentiment analysis that attempt to understand the meanings of words. Sentiment analysis is a method of text analysis that attempts to determine if a statement conveys a positive, negative, or neutral attitude about a topic. For example, the statements, “I just bought a new smartphone—I love it!” and “The screen on my new smartphone shattered the first time I dropped it—I love it!” In the first statement the presence of the phrase “I love it” might help an algorithm correctly interpret the statement as expressing a positive attitude. However, the second statement uses sarcasm to express a negative attitude so the presence of the phrase “I love it” may cause the analysis to interpret the meaning of the phrase incorrectly.\\nVeracity refers to the trustworthiness of the data. Can decision makers reasonably \\nrely on the accuracy of the data and the information generated from it? This is espe-cially pertinent given the automation of data capture and some of the analysis. Uncer -\\ntainty about the data can arise from several causes, such as having to capture only selected portions of the data due to high velocity. Also, in terms of sentiment analysis, customers’ opinions and preferences can change over time, so comments at one point in time might not be suitable for action at another point in time.\\nIncreasingly, value is being touted as an important characteristic for Big Data. Value, \\nalso called viability , refers to the degree to which the data can be analyzed to provide \\nmeaningful information that can add value to the organization. Just because a set of data can be captured does not mean that it should  be captured. Only data that can form \\nthe basis for analysis that has the potential to impact organizational behavior should be included in a company’s Big Data efforts.\\nThe final characteristic of Big Data is visualization. Visualization is the ability to \\ngraphically present the data in such a way as to make it understandable. Volumes of data can leave decision makers awash in facts but with little understanding of what the facts mean. Visualization is a way of presenting the facts so that decision makers can compre-hend the meaning of the information to gain insights.variability\\nThe characteristic of Big Data for the same data values to vary in meaning over time.\\nsentiment analysis\\nA method of text analysis that attempts to determine if a statement conveys a positive, negative, or neutral attitude.\\nveracity\\nThe trustworthiness of a set of data.\\nvalue\\nThe degree to which data can be analyzed to provide meaningful insights.\\nvisualization\\nThe ability to graphically present data in such a way as to make it understandable to users.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6065e276-8b01-43b3-acbf-836e6e6f1c65', embedding=None, metadata={'page_label': '655', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    655\\nAn argument could be made that these additional Vs are not necessarily characteris-\\ntics of Big Data; or, perhaps more accurately, they are not characteristics of only Big Data. \\nVeracity of data is an issue with even the smallest data store, which is why data manage-\\nment is so important in relational databases. Value of data also applies to traditional, structured data in a relational database. One of the keys to data modeling is that only the data that is of interest to the users should be included in the data model. Data that is not of value should not be recorded in any data store—Big Data or not. Visualization was dis-cussed and illustrated at length in Chapter 13 as an important tool in working with data warehouses, which are often maintained as structured data stores in RDBMS products. The important thing to remember is that these characteristics that play an important part in working with data in the relational model are universal and also apply to Big Data.\\nBig Data represents a new wave in data management challenges, but it does not mean \\nthat relational database technology is going away. Structured data that depends on ACID transactions, as discussed in Chapter 10, will always be critical to business operations. Relational databases are still the best way for storing and managing this type of data. What has changed is that now, for the first time in decades, relational databases are not necessarily the best way for storing and managing all  of an organization’s data. Since the \\nrise of the relational model, the decision for data managers when faced with new storage requirements was not whether to use a relational database, but rather which relational DBMS to use. Now, the decision of whether to use a relational database at all is a real question. This has led to polyglot persistence—the coexistence of a variety of data stor -\\nage and management technologies within an organization’s infrastructure. Scaling up, as discussed, is often considered a viable option as relational databases grow. However, it has practical limits and cost considerations that make it infeasible for many Big Data  \\ninstallations. Scaling out into clusters based on low-cost, commodity servers is the  \\ndominant approach that organizations are currently pursuing for Big Data management. As a result, new technologies not based on the relational model have been developed.\\n14-2  Hadoop\\nBig Data requires a different approach to distributed data storage that is designed for large-scale clusters. Although other implementation technologies are possible, Hadoop has become the de facto standard for most Big Data storage and processing. Hadoop is not a database. Hadoop is a Java-based framework for distributing and processing very large data sets across clusters of computers. While the Hadoop framework includes many parts, the two most important components are the Hadoop Distributed File System (HDFS) and MapReduce. HDFS is a low-level distributed file processing system, which means that it can be used directly for data storage. MapReduce is a programming model that supports processing large data sets in a highly parallel, distributed manner. While it is possible to use HDFS and MapReduce separately, the two technologies complement each other so that they work better together as a Hadoop system. Hadoop was engineered specifically to distribute and process enormous amounts of data across vast clusters of servers.\\n14-2a  HDFS\\nThe Hadoop Distributed File System (HDFS) approach to distributing data is based on \\nseveral key assumptions:\\n• High volume . The volume of data in Big Data applications is expected to be in tera-\\nbytes, petabytes, or larger. Hadoop assumes that files in the HDFS will be extremely \\nlarge. Data in the HDFS is organized into physical blocks, just as in other file storage. For example, on a typical personal computer, file storage is organized into blocks that polyglot persistence\\nThe coexistence of a variety of data storage and data management technologies within an organization’s infrastructure.\\nHadoop Distributed File System (HDFS)\\nA highly distributed, fault-tolerant file storage system designed to manage large amounts of data at high speeds.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eb6f442f-3834-4546-b4b9-2ab0a189987e', embedding=None, metadata={'page_label': '656', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='656   Part 4    Advanced Database Concepts\\nFIGURE 14.4  HADOOP DISTRIBUTED FILE SYSTEM (HDFS)\\nMetadata:\\nFile1: Blocks 1,3,4: r3\\nFile2: Blocks 2,5,6: r3\\nBlock 1\\nBlock 3Block 2Block 6Block 2 Block 3\\nBlock 4 Block 5Block 1\\nBlock 5 Block 4\\nBlock 6Block\\n3Block 1\\nBlock 4 Block 5\\nBlock 6Block 2Name Node Client Node\\nData Node 1 Data Node 2 Data Node 3 Data Node 4are often 512 bytes in size, depending on the hardware and operating system involved. \\nRelational databases often aggregate these into database blocks. By default, Oracle organizes data into 8-KB physical blocks. Hadoop, on the other hand, has a default block size of 64 MB (8,000 times the size of an Oracle block!), and it can be configured to even larger values. As a result, the number of blocks per file is greatly reduced, sim-plifying the metadata overhead of tracking the blocks in each file.\\n•\\n Write-once, read-many. Using a write-once, read-many model simplifies concurrency issues and improves overall data throughput. Using this model, a file is created, writ-ten to the file system, and then closed. Once the file is closed, changes cannot be made to its contents. This improves overall system performance and works well for the types of tasks performed by many Big Data applications. Although existing contents of the file cannot be changed, recent advancements in the HDFS allow for files to have new data appended to the end of the file. This is a key advancement for NoSQL databases because it allows for database logs to be updated.\\n•\\n Streaming access . Unlike transaction processing systems where queries often retrieve small \\npieces of data from several different tables, Big Data applications typically process entire files. Instead of optimizing the file system to randomly access individual data elements, Hadoop is optimized for batch processing of entire files as a continuous stream of data.\\n•\\n Fault tolerance . Hadoop is designed to be distributed across thousands of low-cost, \\ncommodity computers. It is assumed that with thousands of such devices, at any point in time, some will experience hardware errors. Therefore, the HDFS is designed to replicate data across many different devices so that when one device fails, the data is still available from another device. By default, Hadoop uses a replication factor of three, meaning that each block of data is stored on three different devices. Different replication factors can be specified for each file, if desired.\\nHadoop uses several types of nodes. A node  is just a computer that performs one or \\nmore types of tasks within the system. Within the HDFS, there are three types of nodes: the client node, the name node, and one or more data nodes, as depicted in Figure 14.4.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9965d8b1-76fb-4b6d-8dec-25547b1c7c4a', embedding=None, metadata={'page_label': '657', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    657\\nData nodes store the actual file data within the HDFS. Recall that files in HDFS are \\nbroken into blocks and are replicated to ensure fault tolerance. As a result, each block is \\nduplicated on more than one data node. Figure 14.4 shows the default replication factor of three, so each block appears on three data nodes.\\nThe name node contains the metadata for the file system. There is typically only one \\nname node within a HDFS cluster. The metadata is designed to be small, simple, and easily recoverable. Keeping the metadata small allows the name node to hold all of the metadata in memory to reduce disk accesses and improve system performance. This is important because there is only one name node so contention for the name node is min-imized. The metadata is composed primarily of the name of each file, the block numbers that comprise each file, and the desired replication factor for each file. The client node makes requests to the file system, either to read files or to write new files, as needed to support the user application.\\nWhen a client node needs to create a new file, it communicates with the name node. \\nThe name node:\\n•\\n Adds the new file name to the metadata.\\n• Determines a new block number for the file.\\n• Determines a list of which data nodes the block will be stored.\\n• Passes that information back to the client node.\\nThe client node contacts the first data node specified by the name node and begins \\nwriting the file on that data node. At the same time, the client node sends the data node \\nthe list of other data nodes that will be replicating the block. As the data is received from the client node, the data node contacts the next data node in the list and begins sending the data to this node for replication. This second data node then contacts the next data node in the list and the process continues with the data being streamed across all of the data nodes that are storing the block. Once the first block is written, the client node can get another block number and list of data nodes from the name node for the next block. When the entire file has been written, the client node informs the name node that the file is closed. It is important to note that at no time was any of the data file actually transmitted to the name node. This helps to reduce the data flow to the name node to avoid congestion that could slow system performance.\\nSimilarly, if a client node needs to read a file, it contacts the name node to request the \\nlist of blocks associated with that file and the data nodes that hold them. Given that each block may appear in many data nodes, for each block, the client attempts to retrieve the block from the data node that is closest to it on the network. Using this information, the client node reads the data directly from each of those nodes.\\nPeriodically, each data node communicates with the name node. The data nodes \\nsend block reports and heartbeats. A block report is sent every 6 hours and informs the name node of which blocks are on that data node. Heartbeats are sent every 3 seconds.  \\nA heartbeat is used to let the name node know that the data node is still available. If a data \\nnode experiences a fault, due to hardware failure, power outage, etc., then the name node will not receive a heartbeat from that data node. As a result, the name node knows not  \\nto include that data node in lists to client nodes for reading or writing files. If the lack  \\nof a heartbeat from a data node causes a block to have fewer than the desired number of replicas, the name node can have a “live” data node initiate replicating the block on another data node.\\nTaken together, the components of the HDFS produce a powerful, yet highly special-\\nized distributed file system that works well for the specialized processing requirements of Big Data applications. Next, we will consider how MapReduce provides data processing to complement data storage of HDFS.\\nblock report\\nIn the Hadoop Distributed File System (HDFS), a report sent every 6 hours by the data node to the name node informing the name node which blocks are on that data node.\\nheartbeat\\nIn the Hadoop Distributed File System (HDFS), a signal sent every 3 seconds from the data node to the name node to notify the name node that the data node is still available.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e2012a9b-338d-495e-ac09-82747289b398', embedding=None, metadata={'page_label': '658', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='658   Part 4    Advanced Database Concepts\\nFIGURE 14.5  MAPREDUCE\\n14-2b  MapReduce\\nMapReduce  is the computing framework used to process large data sets across clusters. \\nConceptually, MapReduce is easy to understand and follows the principle of divide and \\nconquer . MapReduce takes a complex task, breaks it down into a collection of smaller \\nsubtasks, performs the subtasks all at the same time, and then combines the result of \\neach subtask to produce a final result for the original task. As the name implies, it is a \\ncombination of a map function and a reduce function. A map  function takes a collection \\nof data and sorts and filters the data into a set of key-value pairs. The map function is  \\nperformed by a program called a mapper . A reduce  function takes a collection of  \\nkey-value pairs, all with the same key value, and summarizes them into a single result. \\nThe reduce function is performed by a program called a reducer . Recall that Hadoop \\nis a Java-based platform, therefore map and reduce functions are written as detailed,  \\nprocedure-oriented Java programs.\\nFigure 14.5 provides a simple, conceptual illustration of MapReduce that determines the \\ntotal number of units of each product that has been sold. The original data in Figure 14.5  \\nis stored as key-value pairs, with the invoice number as the key and the remainder of the \\ninvoice data as a value. Remember, the data in Hadoop data storage is not a relational data -\\nbase so the data is not separated into tables and there is no form of normalization that \\nensures that each fact is stored only once. Therefore, there is a great deal of duplication of \\ndata in the original data store. Note that even in the very small subset of data that is shown \\nin Figure 14.5, redundant data is kept for customer 10011, Leona Dunne. In the figure, map \\nfunctions parse each invoice to find data about the products sold on that invoice. The result \\nof the map function is a new list of key-value pairs in which the product code is the key and \\nthe line units are the value. The reduce function then takes that list of key-value pairs and \\ncombines them by summing the values associated with each key (product code) to produce \\nthe summary result.MapReduce\\nAn open-source \\napplication \\nprogramming interface \\n(API) that provides fast \\ndata analytics services; \\none of the main Big Data \\ntechnologies that allows \\norganizations to process \\nmassive data stores.\\nmap\\nThe function in a \\nMapReduce job that sorts \\nand filters data into a set \\nof key-value pairs as a \\nsubtask within a larger job.\\nmapper\\nA program that performs \\na map function.\\nAs previously stated, the data sets used in Big Data applications are extremely large. \\nTransferring entire files from multiple nodes to a central node for processing would \\nrequire a tremendous amount of network bandwidth, and place an incredible processing \\nburden on the central node. Therefore, instead of the computational program retrieving \\nthe data for processing in a central location, copies of the program are “pushed” to the \\nnodes containing the data to be processed. Each copy of the program produces results \\nthat are then aggregated across nodes and sent back to the client. This mirrors the distri -\\nbution of data in the HDFS. Typically, the Hadoop framework will distribute a mapper reduce\\nThe function in a \\nMapReduce job that \\ncollects and summarizes \\nthe results of map \\nfunctions to produce a \\nsingle result.\\nreducer\\nA program that performs \\na reduce function.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='042c5a74-66a8-41ce-a5fa-2f75aacb6889', embedding=None, metadata={'page_label': '659', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    659\\nfor each block on each data node that must be processed. This can lead to a very large \\nnumber of mappers. For example, if 1 TB of data is to be processed and the HDFS is using 64-MB blocks, that yields over 15,000 mapper programs. The number of reducers is configurable by the user, but best practices suggest about one reducer per data node.\\nBest practices suggest that the number of mappers on a given node should be kept to 100 or less. However, there are cases of applications with simple map functions running as many as 300 mappers on a given node with satisfactory performance. Clearly, much depends on the computing resources available at each node.Note\\nThe implementation of MapReduce complements the structure of the HDFS, which is \\nan important reason why they work so well together. Just as the HDFS structure is com-posed of a name node and several data nodes, MapReduce uses a job tracker (the actual name of the program is JobTracker) and several task trackers (the programs are named TaskTrackers). The job tracker acts as a central control for MapReduce processing and it normally exists on the same server that is acting as the name node. Task tracker pro-grams reside on the data nodes. One important feature of the MapReduce framework is that the user must write the Java code for the map and reduce functions, and must spec-ify the input and output files to be read and written for the job that is being submitted. However, the job tracker will take care of locating the data, determining which nodes to use, dividing the job into tasks for the nodes, and managing failures of the nodes. All of this is done automatically without user intervention. When a user submits a MapReduce job for processing, the general process is as follows:\\n1.\\n A client node (client application) submits a MapReduce job to the job tracker.\\n2. The job tracker communicates with the name node to determine which data nodes \\ncontain the blocks that should be processed for this job.\\n3. The job tracker determines which task trackers are available for work. Each task tracker can handle a set number of tasks. Remember, many MapReduce jobs from dif-ferent users can be running on the Hadoop system simultaneously, so a data node may contain data that is being processed by multiple mappers from different jobs all at the same time. Therefore, the task tracker on that node might be busy running mappers for other jobs when this new request arrives. Because the data is replicated on multiple nodes, the job tracker may be able to select from multiple nodes for the same data.\\n4.\\n The job tracker then contacts the task trackers on each of those nodes to begin  \\nmappers and reducers to complete that node’s portion of the task.\\n5. The task tracker creates a new JVM (Java virtual machine) to run the map and reduce functions. This way, if a function fails or crashes, the entire task tracker is not halted.\\n6.\\n The task tracker sends heartbeat messages to the job tracker to let the job tracker know that the  task tracker is still working on the job (and about the nodes availability \\nfor more jobs).\\n7.\\n The job tracker monitors the heartbeat messages to determine if a task manager has failed. If so, the job tracker can reassign that portion of the task to another node.\\n8.\\n When the entire job is finished, the job tracker changes status to indicate that the job is completed.\\n9.\\n The client node periodically queries the job tracker until the job status is completed.job tracker\\nA central control program used to accept, distribute, monitor, and report on MapReduce processing jobs in a Hadoop environment.\\ntask tracker\\nA program in the MapReduce framework responsible to running map and reduce tasks on a node.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f4943285-09fb-4e28-9333-0524e6667209', embedding=None, metadata={'page_label': '660', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='660   Part 4    Advanced Database Concepts\\nFIGURE 14.6  A SAMPLE OF THE HADOOP ECOSYSTEM\\nMapReduceMapReduce simpliﬁcation applications\\nHBaseHive Pig\\nImpalaFlume\\nSqoop\\nData ingestion applications Core Hadoop components Direct query applicationsHadoop Distributed File System (HDFS)The Hadoop system uses batch processing. Batch processing is when a program \\nruns from beginning to end, either completing the task or halting with an error, without \\nany interaction with the user. Batch processing is often used when the computing task requires an extended period of time or a large portion of the system’s processing capacity. Businesses often use batch processing to run year-end financial reports in the evenings when systems are often idle, and universities might use batch processing for student fee payment processing. Batch processing is not bad, but it has limitations. As a result, a number of complementary programs have been developed to improve the integration of Hadoop within the larger IT infrastructure. The next section discusses some of these programs.\\n14-2c  Hadoop Ecosystem\\nHadoop is widely used by organizations tapping into the potential of analyzing extremely large data sets. Unfortunately, because Hadoop is a very low-level tool requiring consid-erable effort to create, manage, and use, it presents quite a few obstacles. As a result, a host of related applications have grown up around Hadoop to attempt to make it easier to use and more accessible to users who are not skilled at complex Java programming. Figure 14.6 shows examples of some of these types of applications. Most organizations that use Hadoop also use a set of other related products that interact and complement each other to produce an entire ecosystem of applications and tools. Like any ecosystem, the interconnected pieces are constantly evolving and their relationships are changing, so it is a rather fluid situation. The following are some of the more popular components in a Hadoop ecosystem and how they relate to each other.\\nbatch processing\\nA data processing method that runs data processing tasks from beginning to end without any user interaction.MapReduce Simplification Applications  Creating MapReduce jobs requires signif-\\nicant programming skills. As the mapper and reducer programs become more complex, the skill requirements increase and the time to produce the programs becomes signifi-cant. These skills are beyond the capabilities of most data users. Therefore, applications to simplify the process of creating MapReduce jobs have been developed. Two of the most popular are Hive and Pig.\\nHive  is a data warehousing system that sits on top of HDFS. It is not a relational \\ndatabase, but it supports its own SQL-like language, called HiveQL, that mimics SQL commands to run ad hoc queries. HiveQL commands are processed by the Hive query engine into sets of MapReduce jobs. As a result, the underlying processing tends to be batch-oriented, producing jobs that are very scalable over extremely large sets of data. However, the batch nature of the jobs makes Hive a poor choice for jobs that only require a small subset of data to be returned very quickly.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='de5c40aa-bf84-401e-b7d7-3cd90656694b', embedding=None, metadata={'page_label': '661', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    661\\nPig is a tool for compiling a high-level scripting language, named Pig Latin, into \\nMapReduce jobs for executing in Hadoop. In concept it is similar to Hive in that it  \\nprovides a means of producing MapReduce jobs without the burden of low-level Java \\nprogramming. The primary difference is that Pig Latin is a scripting language, which means it is procedural, while HiveQL, like SQL, is declarative. Declarative languages allow the user to specify what they want, not how to get it. This is very useful for query processing. Procedural languages require the user to specify how the data is to be manip-ulated. This is very useful for performing data transformations. As a result, Pig is often used for producing data pipeline tasks that transform data in a series of steps. This is often seen in ETL processes as described in Chapter 13.\\nData Ingestion Applications  One challenge faced by organizations that are taking \\nadvantage of Hadoop’s massive data storage and data processing capabilities is the issue of actually getting data from their existing systems into the Hadoop cluster. To simplify this task, applications have been developed to “ingest” or gather this data into Hadoop.\\nFlume  is a component for ingesting data into Hadoop. It is designed primarily for \\nharvesting large sets of data from server log files, like clickstream data from web server logs. It can be configured to import the data on a regular schedule or based on specified events. In addition to simply bringing the data into Hadoop, Flume contains a simple query processing component so the possibility exists of performing some transforma-tions on the data as it is being harvested. Typically, Flume would move the data into the HDFS, but it can also be configured to input the data directly into another component of the Hadoop ecosystem named HBase.\\nSqoop  is a more recent addition to the Hadoop ecosystem. It is a tool for convert-\\ning data back and forth between a relational database and the HDFS. The name Sqoop (pronounced, “scoop, ” as in a scoop of ice cream) is an amalgam of “SQL-to-Hadoop. ” In concept, Sqoop is similar to Flume in that it provides a way of bringing data into the HDFS. However, while Flume works primarily with log files, Sqoop works with relational databases such as Oracle, MySQL, and SQL Server. Further, while Flume operates in one direction only, Sqoop can transfer data in both directions—into and out of HDFS. When transferring data from a relational database into HDFS, the data is imported one table at a time with the process reading the table row-by-row. This is done in a highly parallelized manner using MapReduce, so the contents of the table will usually be distributed into several files with the rows stored in a delimited format. Once the data has been imported into HDFS, it can be processed by MapReduce jobs or using Hive. The resulting data can then be exported from HDFS back to the relational database, most often a traditional data warehouse.\\nDirect Query Applications  Direct query applications attempt to provide faster query \\naccess than is possible through MapReduce. These applications interact with HDFS directly, instead of going through the MapReduce processing layer.\\nHBase is a column-oriented NoSQL database designed to sit on top of the HDFS. One \\nof HBase’s primary characteristics is that it is highly distributed and designed to scale out easily. It does not support SQL or SQL-like languages, relying instead on lower-level languages such as Java for interaction. The system does not rely on MapReduce jobs, so it avoids the delays caused by batch processing, making it more suitable for fast processing involving smaller subsets of the data. HBase is very good at quickly processing sparse data sets. HBase is one of the more popular components of the Hadoop ecosystem, and is used by Facebook for its messaging system. Column-oriented databases will be  \\ndiscussed in more detail in the next section.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eddfecf2-ee6b-4fd6-91dc-69f5d250647c', embedding=None, metadata={'page_label': '662', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='662   Part 4    Advanced Database Concepts\\nOther than Impala, each of the components of the Hadoop ecosystem described in this \\nsection are all open-source, top-level projects of the Apache Software Foundation. More information on each of these projects and many others is available at www.apache.org.NoteImpala  was the first SQL-on-Hadoop application. It was produced by Cloudera as \\na query engine that supports SQL queries that pull data directly from HDFS. Prior to Impala, if an organization needed to make data from Hadoop available to analysts through an SQL interface, data would be extracted from HDFS and imported into a relational database. With Impala, analysts can write SQL queries directly against the data while it is still in HDFS. Impala makes heavy use of in-memory caching on data nodes. It is generally considered an appropriate tool for processing large amounts of data into  \\na relatively small result set.\\n14-3  NoSQL\\nNoSQL is the unfortunate name given to a broad array of nonrelational database technol-ogies that have developed to address the challenges represented by Big Data. The name is unfortunate in that it does not describe what the NoSQL technologies are, but rather what they are not. In fact, the name also does a poor job of explaining what the technologies are not! The name was chosen as a Twitter hashtag to simplify coordinating a meeting of developers to discuss ideas about the nonrelational database technologies that were being developed by organizations like Google, Amazon, and Facebook to deal with the problems they were encountering as their data sets reached enormous sizes. The term “NoSQL ” was never meant to imply that products in this category should never include support for SQL. In fact, many such products support query languages that mimic SQL in important ways. Although no one has yet produced a NoSQL system that implements standard SQL, given the large base of SQL users, the appeal of creating such a product is obvious. More recently, some industry observers have tried to interject that “NoSQL ” could stand for “Not Only SQL. ” In fact, if the requirement to be considered a NoSQL product were sim-ply that languages beyond SQL are supported, then all of the traditional RDBMS products such as Oracle, SQL Server, MySQL, and MS Access would all qualify. Regardless, you are better off focusing on understanding the array of technologies to which the term refers than worrying about the name itself.\\nThere are literally hundreds of products that can be considered as being under the \\nbroadly defined term NoSQL. Most of these fit roughly into one of four categories: key-value data stores, document databases, column-oriented databases, and graph data-bases. Table 14.2 shows some popular NoSQL databases of each type. Although not all NoSQL databases have been produced as open-source software, most have been. As a result, NoSQL databases are generally perceived as a part of the open-source movement. Accordingly, they also tend to be associated with the Linux operating system. It makes sense from a cost standpoint that, if an organization is going to create a cluster con-taining tens of thousands of nodes, the organization does not want to purchase licenses for Windows or Mac OS for all of those nodes. The preference is to use a platform, like Linux, that is freely available and highly customizable. Therefore, most of the NoSQL products run only in a Linux or Unix environment. The following sections discuss each of the major NoSQL approaches.\\nNoSQL\\nA new generation of database management systems that is not based on the traditional relational database model.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='614c3874-7b1e-41bb-bc25-6f611692074e', embedding=None, metadata={'page_label': '663', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    663\\n14-3a  Key-Value Databases\\nKey-value (KV) databases are conceptually the simplest of the NoSQL data models. A \\nKV database is a NoSQL database that stores data as a collection of key-value pairs. The key acts as an identifier for the value. The value can be anything such as text, an XML document, or an image. The database does not attempt to understand the contents of the value component or its meaning—the database simply stores whatever value is provided for the key. It is the job of the applications that use the data to understand the meaning of the data in the value component. There are no foreign keys; in fact, relationships can-not be tracked among keys at all. This greatly simplifies the work that the DBMS must  \\nperform, making KV databases extremely fast and scalable for basic processing.\\nKey-value pairs are typically organized into “buckets. ” A bucket can roughly be \\nthought of as the KV database equivalent of a table. A bucket is a logical grouping of keys. Key values must be unique within a bucket, but they can be duplicated across buckets. All data operations are based on the bucket plus the key. In other words, it is not possible to query the data based on anything in the value component of the key-value pair. All queries are performed by specifying the bucket and key. Operations on KV databases are rather simple—only get , store , and delete  operations are used. Get or fetch  is used \\nto retrieve the value component of the pair. Store  is used to place a value in a key. If the \\nbucket + key combination does not exist, then it is added as a new key-value pair. If the bucket + key combination does exist, then the existing value component is replaced with the new value. Delete  is used to remove a key-value pair. Figure 14.7 shows a customer \\nbucket with three key-value pairs. Since the KV model does not allow queries based on data in the value component, it is not possible to query for a key-value pair based on customer last name, for example. In fact, the KV DBMS does not even know that there is such a thing as a customer last name because it does not understand the content of the value component. An application could issue a get  command to have the KV DBMS \\nreturn the key-value pair for bucket customer and key 10011, but it would be up to the application to know how to parse the value component to find the customer’s last name, first name, and other characteristics. (One important note about Figure 14.7: Be aware that although key-value pairs appear in tabular form in the figure, the tabular format is just a convenience to help visually distinguish the components. Actual key-value pairs are not stored in a table-like structure.)\\nkey-value (KV) database\\nA NoSQL database model that stores data as a collection of key-value pairs in which the value component is unintelligible to the DBMS.\\nbucket\\nIn a key-value database, a logical collection of related key-value pairs.TABLE 14.2\\nNoSQL DATABASES\\nNoSQL CATEGORY EXAMPLE DATABASES\\nKey-value database DynamoRiakRedisVoldemort\\nDocument databases MongoDBCouchDBOrientDBRavenDB\\nColumn-oriented databases HBaseCassandraHypertable\\nGraph databases Neo4JArangoDBGraphBase\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='70bdf81e-21be-4512-bb8b-94f94bb18fe2', embedding=None, metadata={'page_label': '664', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='664   Part 4    Advanced Database Concepts\\nFIGURE 14.7  KEY-VALUE DATABASE STORAGE\\nBucket = Customer\\nKey Value\\n“LName Ramas FName Alfred Initial A Areacode\\n615 Phone 844-2573 Balance 0”\\n“LName Dunne FName Leona Initial K Areacode\\n713 Phone 894-1238 Balance 0”\\n“LName Orlando FName Myron Areacode 615\\nPhone 222-1672 Balance 0”10010\\n10011\\n10014\\nFIGURE 14.8  DOCUMENT DATABASE TAGGED FORMAT\\nCollection = Customer\\nKey Document\\n{LName: “Ramas”, FName: “Alfred”, Initial: “A”,\\nAreacode: “615”, Phone: “844-2573”, Balance:“0”}\\n{LName: “Dunne”, FName: “Leona”, Initial: “K”,\\nAreacode: “713”, Phone: “894-1238”, Balance:“0”}\\n{LName: “Orlando”, FName: “Myron”, Areacode:\\n“615”, Phone: “222-1672”, Balance: “0”}10010\\n10011\\n1001414-3b  Document Databases\\nDocument databases are conceptually similar to key-value databases, and they can \\nalmost be considered a subtype of KV databases. A document database is a NoSQL data-base that stores data in tagged documents in key-value pairs. Unlike a KV database where the value component can contain any type of data, a document database always stores a document in the value component. The document can be in any encoded format, such as XML, JSON (JavaScript Object Notation), or BSON (Binary JSON). Another import-\\nant difference is that while KV databases do not attempt to understand the content of the value component, document databases do. Tags are named portions of a document. For example, a document may have tags to identify which text in the document represents the title, author, and body of the document. Within the body of the document, there may be additional tags to indicate chapters and sections. Despite the use of tags in documents, document databases are considered schema-less, that is, they do not impose a predefined structure on the data that is stored. For a document database, being schema-less means that although all documents have tags, not all documents are required to have the same tags, so each document can have its own structure. The tags in a document database are extremely important because they are the basis for most of the additional capabilities that document databases have over KV databases. Tags inside the document are accessi-ble to the DBMS, which makes sophisticated querying possible.\\nJust as KV databases group key-value pairs into logical groups called buckets , \\ndocument databases group documents into logical groups called collections . While a \\ndocument may be retrieved by specifying the collection and key, it is also possible to query based on the contents of tags. For example, Figure 14.8 represents the same data from Figure 14.7, but in a tagged format for a document database. Because the DBMS is aware of the tags within the documents, it is possible to write queries that retrieve all of \\ndocument database\\nA NoSQL database model that stores data in key-value pairs in which the value component is composed of a tag-encoded document.\\nJSON (JavaScript Object Notation)\\nA human-readable text format for data interchange that defines attributes and values in a document.\\nBSON (Binary JSON)\\nA computer-readable format for data interchange that expands the JSON format to include additional data types including binary objects.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cd5a7ba4-fc0f-477a-a5f7-84534ca7b6e5', embedding=None, metadata={'page_label': '665', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    665\\nthe documents where the Balance tag has the value 0. Document databases even support \\nsome aggregate functions such as summing or averaging balances in queries.\\nDocument databases tend to operate on an implied assumption that a document is rel-\\natively self-contained, not a fragment of the data about a given topic. Relational databases decompose complex data in the business environment into a set of related tables. For example data about orders may be decomposed into customer, invoice, line, and product tables. A document database would expect all of the data related to an order to be in a single order document. Therefore, each order document in an Orders  collection would \\ncontain data on the customer, the order itself, and the products purchased in that order all as a single self-contained document. Document databases do not store relationships as perceived in the relational model and generally have no support for join operations.\\n14-3c  Column-Oriented Databases\\nThe term column-oriented database can refer to two different sets of technologies that are often confused with each other. In one sense, column-oriented database or columnar database can refer to traditional, relational database technologies that use  \\ncolumn-centric storage instead of row-centric storage. Relational databases present data in logical tables; however, the data is actually stored in data blocks containing rows of data. All of the data for a given row is stored together in sequence with many rows in the same data block. If a table has many rows of data, the rows will be spread across many data blocks. Figure 14.9 illustrates a relational table with 10 rows of data that is physically stored across five data blocks. Row-centric storage minimizes the number of disk reads necessary to retrieve a row of data. Retrieving one row of data requires accessing just column-centric storage\\nA physical data storage technique in which data is stored in blocks, which hold data from a single column across many rows.\\nrow-centric storage\\nA physical data storage technique in which data is stored in blocks, which hold data from all columns of a given set of rows.\\nFIGURE 14.9  COMPARISON OF ROW-CENTRIC AND COLUMN-CENTRIC STORAGE\\nCUSTOMER relational table\\nRow-centric storage Column-centric storage\\nBlock 1\\n10010,Ramas,Alfred,Nashville,TN\\n10011,Dunne,Leona,Miami,FLCus_Code\\n10010 Ramas Alfred Nashville TN\\nFL\\nMATN\\nTNFL\\nAL\\nALNashville\\nNashvilleMiami\\nMiami\\nMobile\\nOppBostonLeona\\nKathyPaulMyronAmyJamesGeorgeAnneOletteDunneSmithOlowskiOrlandoO’BrianBrownWilliamsFarrissSmith100111001210013100141001510016100171001810019Cus_LName Cus_FName Cus_City Cus_State\\nBlock 4\\n10016,Brown,James,NULL,NULL\\n10017,Williams,George,Mobile,AL\\nBlock 5\\n10018,Farriss,Anne,OPP,AL\\n10019,Smith,Olette,Nashville,TNBlock 2\\n10012,Smith,Kathy,Boston,MA\\n10013,Olowski,Paul,Nashville,TN\\nBlock 3\\n10014,Orlando,Myron,NULL,NULL\\n10015,O’Brian,Amy,Miami,FLBlock 1\\n10010,10011,10012,10013,10014\\n10015,10016,10017,10018,10019Block 4\\nNashville,Miami,Boston,Nashville,NULL\\nMiami,NULL,Mobile,Opp,Nashville\\nBlock 5\\nTN,FL,MA,TN,NULL,\\nFL,NULL,AL,AL,TNBlock 2\\nRamas,Dunne,Smith,Olowski,Orlando\\nO’Brian,Brown,Williams,Farriss,Smith\\nBlock 3\\nAlfred,Leona,Kathy,Paul,Myron\\nAmy,James,George,Anne,Olette\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='764f9df8-83a0-4fff-9935-ed615ed0c31b', embedding=None, metadata={'page_label': '666', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='666   Part 4    Advanced Database Concepts\\none data block, as shown in Figure 14.9. Remember, in transactional systems, normal-\\nization is used to decompose complex data into related tables to reduce redundancy and to improve the speed of rapid manipulation of small sets of data. These manipulations tend to be row-oriented, so row-oriented storage works very well. However, in queries that retrieve a small set of columns across a large set of rows, a large number of disk accesses is required. For example, a query that wants to retrieve only the city and state of every customer will have to access every data block that contains a customer row to retrieve that data. In Figure 14.9, that would mean accessing five data blocks to get the city and state of every customer. A column-oriented or columnar database stores the data in blocks by column instead of by row. A single customer’s data will be spread across several blocks, but all of the data from a single column will be in just a few blocks. In Figure 14.9, all of the city data for customers will be stored together, just as all of the state data will be stored together. In that case, retrieving the city and state for every customer might require accessing only two data blocks. This type of column-centric storage works very well for databases that are primarily used to run queries over few columns but many rows, as is done in many reporting systems and data warehouses. Though Figure 14.9 shows only a few rows and data blocks, it is easy to imagine that the gains would be significant if the table size grew to millions or billions of rows across hundreds of thou-sands of data blocks. At the same time, column-centric storage would be very inefficient for processing transactions since insert, update, and delete activities would be very disk intensive. It is worth noting that column-centric storage can be achieved within rela-tional database technology, meaning that it still requires structured data and has the advantage of supporting SQL for queries.\\nThe other use of the term column-oriented database, also called column family data-\\nbase, is to describe a type of NoSQL database that takes the concept of column-centric storage beyond the confines of the relational model. As NoSQL databases, these prod-ucts do not require the data to conform to predefined structures nor do they support SQL for queries. This database model originated with Google’s BigTable product. Other column-oriented database products include HBase, described earlier, and Cassandra. Cassandra began as a project at Facebook, but Facebook released it to the open-source community, which has continued to develop Cassandra into one of the most popular column-oriented databases. A column family database is a NoSQL database that orga-nizes data in key-value pairs with keys mapped to a set of columns in the value compo-nent. While column family databases use many of the same terms as relational databases, the terms don’t mean quite the same things. Fortunately, the column family databases are conceptually simple and are conceptually close enough to the relational model that your understanding of the relational model can help you understand the column family model. A column is a key-value pair that is similar to a cell of data in a relational database. The key is the name of the column, and the value component is the data that is stored in that column. Therefore, “cus_lname: Ramas” is a column; cus_lname is the name of the column, and Ramas  is the data value in the column. Similarly, “cus_city: Nashville” is \\nanother column, with cus_city as the column name and Nashville  as the data value.\\ncolumn family database\\nA NoSQL database model that organizes data into key-value pairs, in which the value component is composed of a set of columns that vary by row.\\nEven though column family databases do not (yet) support standard SQL, Cassandra devel-opers have created a Cassandra query language (CQL). It is similar to SQL in many respects and is one of the more compelling reasons for adopting Cassandra.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6368a56e-938d-4a96-80a7-b6830d5b50ab', embedding=None, metadata={'page_label': '667', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    667\\nAs more columns are added, it becomes clear that some columns form natural groups, \\nsuch as cus_fname, cus_lname, and cus_initial which would logically group together to \\nform a customer’s name. Similarly, cus_street, cus_city, cus_state, and cus_zip would logically group together to form a customer’s address. These groupings are used to cre-ate super columns. A super column is a group of columns that are logically related. Recall the discussion in Chapter 4 about simple and composite attributes in the entity relationship model. In many cases, super columns can be thought of as the composite attribute and the columns that compose the super column as the simple attributes. Just as all simple attributes do not have to belong to a composite attribute, not all columns have to belong to a super column. Although this analogy is helpful in many contexts, it is not perfect. It is possible to group columns into a super column that logically belongs together for application processing reasons but does not conform to the relational idea of a composite attribute.\\nRow keys are created to identify objects in the environment. All of the columns or \\nsuper columns that describe these objects are grouped together to create a column family;  therefore, a column family is conceptually similar to a table in the relational model. While a column family is similar in concept to a relational table, Figure 14.10 shows that it is structurally very different. Notice in Figure 14.10 that each row key in the column family can have different columns.\\nsuper column\\nIn a column family database, a column that is composed of a group of other related columns.\\ncolumn family\\nIn a column family database, a collection of columns or super columns related to a collection of rows.\\nA column family can be composed of columns or super columns, but it cannot contain both.Note\\nFIGURE 14.10  COLUMN FAMILY DATABASE\\nColumn Family Name\\nKey Rowkey 1\\nRowkey 2\\nRowkey 3Columns\\nKey\\nColumns\\nKey\\nColumnsCity\\nBalance\\nCompany345.86\\nKathy\\nSmithFnameNashville\\nAlfredRamas\\nTNFname\\nLname\\nLname\\nLname DunneLocal Markets, Inc.StateCUSTOMERS\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ae08df9a-7f1b-474d-9b90-4e00428bd3b1', embedding=None, metadata={'page_label': '668', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='668   Part 4    Advanced Database Concepts\\n14-3d  Graph Databases\\nA graph database is a NoSQL database based on graph theory to store data about \\nrelationship-rich environments. Graph theory is a mathematical and computer science \\nfield that models relationships, or edges, between objects called nodes. Modeling and storing data about relationships is the focus of graph databases. Graph theory is a  \\nwell-established field of study going back hundreds of years. As a result, creating a database model based on graph theory immediately provides a rich source for algorithms and applications that have helped graph databases gain in sophistication very quickly. Since it also happens that much of the data explosion over the last decade has involved data that is relationship-rich, graph databases have been poised to experience significant interest in the business environment.\\nInterest in graph databases originated in the area of social networks. Social networks \\ninclude a wide range of applications beyond the typical Facebook, Twitter, and Instagram that immediately come to mind. Dating websites, knowledge management, logistics and routing, master data management, and identity and access management are all areas that rely heavily on tracking complex relationships among objects. Of course, relational data-bases support relationships too. One of the great advances of the relational model was that relationships are easy to maintain. A relationship between a customer and an agent is as easy to implement in the relational model as adding a foreign key to create a com-mon attribute, and the customer and agent rows are related by having the same value in the common attributes. If the customer changes to a different agent, then simply chang-ing the value in the foreign key will change the relationship between the rows to maintain the integrity of the data. The relational model does all of these things very well. However, what if we want a “like” option so customers can “like” agents on our website? This would require a structural change to the database to add a new foreign key to support this sec-ond relationship. Next, what if the company wants to allow customers on its website to “friend” each other so a customer can see which agents their friends like, or the friends of their friends? In social networking data, there can be dozens of different relationships among individuals that need to be tracked, and often the relationships are tracked many layers deep (e.g., friends, friends of friends, friends of friends of friends, etc.). This results in a situation where the relationships become just as important as the data itself. This is the area where graph databases shine.\\nThe primary components of graph databases are nodes, edges, and properties, as \\nshown in Figure 14.11. A node corresponds to the idea of a relational entity instance. The node is a specific instance of something we want to keep data about. Each node \\n(circle) in Figure 14.10 represents a single agent. Properties are like attributes; they are the data that we need to store about the node. All agent nodes might have properties like first name and last name, but all nodes are not required to have the same properties. An edge is a relationship between nodes. Edges (shown as arrows in Figure 14.10) can be in one direction, or they can be bidirectional. For example, in Figure 14.11, the friends  \\nrelationships are bidirectional, but the likes  relationships are not. Note that edges can \\nalso have properties. In Figure 14.11 the date on which customer Alfred Ramas liked  \\nagent Alex Alby is recorded in the graph database. A query in a graph database is called a traversal. Instead of querying the database, the correct terminology would be traversing the graph . Graph databases excel at traversals that focus on relationships between nodes, \\nsuch as shortest path and degree of connectedness.\\nGraph database share some characteristics with other NoSQL databases in that graph \\ndatabases do not force data to fit predefined structures, do not support SQL, and are opti-mized to provide velocity of processing, at least for relationship-intensive data. However, other key characteristics do not apply to graph databases. Graph databases do not scale \\ngraph database\\nA NoSQL database model based on graph theory that stores data on relationship-rich data as a collection of nodes and edges.\\nnode\\nIn a graph database, the representation of a single entity instance.\\nedge\\nIn a graph database, the representation of a relationship between nodes.\\nproperties\\nIn a graph database, the attributes or characteristics of a node or edge that are of interest to the users.\\ntraversal\\nA query in a graph database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='de09e025-dead-4a44-b9ae-281f5b2ca11e', embedding=None, metadata={'page_label': '669', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    669\\nout very well to clusters. The other NoSQL database models achieve clustering efficiency \\nby making each piece of data relatively independent. That allows a key-value pair to be stored on one node in the cluster without the DBMS needing to associate it with another key-value pair that may be on a different node on the cluster. The greater the number of nodes involved in a data operation, the greater the need for coordination and centralized control of resources. Separating independent pieces of data, often called shards , across \\nnodes in the cluster is what allows NoSQL databases to scale out so effectively. Graph databases specialize in highly related data, not independent pieces of data. As a result, graph databases tend to perform best in centralized or lightly clustered environments, similar to relational databases.\\n14-3e  NewSQL Databases\\nRelational databases are the mainstay of organizational data, and NoSQL databases do not attempt to replace them for supporting line-of-business transactions. These trans-actions that support the day-to-day operations of business rely on ACID-compliant transactions and concurrency control, as discussed in Chapter 10. NoSQL databases (except graph databases that focus on specific relationship-rich domains) are concerned with the distribution of user-generated and machine-generated data over massive clus-ters. NewSQL databases try to bridge the gap between RDBMS and NoSQL. NewSQL databases attempt to provide ACID-compliant transactions over a highly distributed infrastructure. NewSQL databases are the latest technologies to appear in the data man-agement arena to address Big Data problems. As a new category of data management products, NewSQL databases have not yet developed a track record of success and have been adopted by relatively few organizations.\\nNewSQL products, such as ClusterixDB and NuoDB, are designed from scratch as \\nhybrid products that incorporate features of relational databases and NoSQL databases.\\nNewSQL\\nA database model that attempts to provide ACID-compliant transactions across a highly distributed infrastructure.FIGURE 14.11  GRAPH DATABASE REPRESENTATION\\nID: 102\\nLabel: likesDate: 8/15/2012ID: 101\\nLabel: likes\\nDate: 9/15/2015\\nID: 107Label: likesDate: 3/20/2016 ID: 104Label: likesDate: 10/11/2014ID: 100Label: assists\\nID: 111Label: assistsID: 120Label: assists\\nID: 103Label: friendsID: 105Label: friends\\nID: 108\\nLabel: friendsID: 109Label: likesDate: 1/07/2016ID: 106Label: likesDate: 9/15/2015ID: 1\\nType: agent\\nFname: Alex\\nLname: Alby\\nPhone: 228-1249\\nID: 4\\nType: customer\\nFname: Alfred\\nLname: Ramas\\nAmt: 100\\nRenew:\\n04/05/2017ID: 2\\nType: agent\\nFname: Leah\\nLname: Hahn\\nID: 6\\nType: customer\\nFname: KathyLname: SmithID: 5\\nType: customer\\nFname: Leona\\nLname: Dunne\\nID: 7\\nType: customer\\nFname: Paul\\nLname: Olowski\\nPhone: 894-2180\\nID: 3\\nType: agent\\nFname: John\\nLname: Okon\\nPhone: 123-5589\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='187f8e08-728e-4407-9171-31eddec06004', embedding=None, metadata={'page_label': '670', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='670   Part 4    Advanced Database Concepts\\nLike RDBMS, NewSQL databases support:\\n• SQL as the primary interface\\n• ACID-compliant transactions\\nSimilar to NoSQL, NewSQL databases also support:\\n• Highly distributed clusters\\n• Key-value or column-oriented data stores\\nAs expected, no technology can perfectly provide the advantages of both RDBMS and \\nNoSQL, so NewSQL has disadvantages (the CAP theorem still applies!). Principally, the \\ndisadvantages that have been discovered center around NewSQL ’s heavy use of in-memory storage. Critics point to the fact that this can jeopardize the “durability” component of ACID. Further, the ability to handle vast data sets can be impacted by the reliance on in-memory  \\nstructures because there are practical limits to the amount of data that can be held in mem -\\nory. Although in theory NewSQL databases should be able to scale out significantly, in prac -\\ntice little has been done to scale beyond a few dozen data nodes. While this is a marked improvement over traditional RDBMS distribution, it is far from the hundreds of nodes used by NoSQL databases.\\nCapturing data, in and of itself, is not the goal of data management. As discussed \\nearlier, the data must add value to the organization. The data must help the organization to meet the needs of customers and provide value to shareholders. Data analysis is the process of turning the data into information that adds insights that enable data-based decisions. The next section will describe the complexity of that process.\\n14-4  Data Analytics\\nData analytics is a subset of business intelligence (BI) functionality that encompasses a wide range of mathematical, statistical, and modeling techniques with the purpose of extracting knowledge from data. Data analytics is used at all levels within the BI frame-work, including queries and reporting, monitoring and alerting, and data visualization. Hence, data analytics is a “shared” service that is crucial to what BI adds to an organiza-tion. Data analytics represents what business managers really want from BI: the ability to extract actionable business insight from current events and foresee future problems or opportunities.\\nData analytics discovers characteristics, relationships, dependencies, or trends in the \\norganization’s data, and then explains the discoveries and predicts future events based on the discoveries. In practice, data analytics is better understood as a continuous spec-trum of knowledge acquisition that goes from discovery  to explanation  to prediction . The \\noutcomes of data analytics then become part of the information framework on which decisions are built. Data analytics tools can be grouped into two separate (but closely related and often overlapping) areas:\\n•\\n Explanatory analytics focuses on discovering and explaining data characteristics \\nand relationships based on existing data. Explanatory analytics uses statistical tools to formulate hypotheses, test them, and answer the how  and why  of such relationships—\\nfor example, how do past sales relate to previous customer promotions?\\n•\\n Predictive analytics focuses on predicting future data outcomes  with a high degree of \\naccuracy. Predictive analytics uses sophisticated statistical tools to help the end user create advanced models that answer questions about future data occurrences—for example, what would next month’s sales be based on a given customer promotion?data analytics\\nA subset of business intelligence functionality that encompasses a wide range of mathematical, statistical, and modeling techniques with the purpose of extracting knowledge from data.\\nexplanatory analytics\\nData analysis that provides ways to discover relationships, trends, and patterns among data.\\npredictive analytics\\nData analytics that use advanced statistical and modeling techniques to predict future business outcomes with great accuracy.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f94077f2-40a8-4033-bfee-5a742394d3a9', embedding=None, metadata={'page_label': '671', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    671\\nY ou can think of explanatory analytics as explaining the past and present, while  \\npredictive analytics forecasts the future. However, you need to understand that both  \\nsciences work together; predictive analytics uses explanatory analytics as a stepping \\nstone to create predictive models.\\nData analytics has evolved over the years from simple statistical analysis of business \\ndata to dimensional analysis with OLAP tools, and then from data mining that discovers \\ndata patterns, relationships, and trends to its current status of predictive analytics. The \\nnext sections illustrate the basic characteristics of data mining and predictive analytics.\\n14-4a  Data Mining\\nData mining  refers to analyzing massive amounts of data to uncover hidden trends, pat -\\nterns, and relationships; to form computer models to simulate and explain the findings; \\nand then to use such models to support business decision making. In other words, data \\nmining focuses on the discovery and explanation stages of knowledge acquisition.\\nTo put data mining in perspective, look at the pyramid in Figure 14.12, which rep -\\nresents how knowledge is extracted from data. Data  forms the pyramid base and rep -\\nresents what most organizations collect in their operational databases. The second level \\ncontains information  that represents the purified and processed data. Information forms \\nthe basis for decision making and business understanding. Knowledge  is found at the \\npyramid’s apex and represents highly distilled information that provides concise, action -\\nable business insight.\\ndata mining\\nA process that employs \\nautomated tools \\nto analyze data in a \\ndata warehouse and \\nother sources and to \\nproactively identify \\npossible relationships \\nand anomalies.FIGURE 14.12  EXTRACTING KNOWLEDGE FROM DATA\\nLowHighProcessing\\nCurrent-generation data-mining tools contain many design and application variations \\nto fit specific business requirements. Depending on the problem domain, data-mining \\ntools focus on market niches such as banking, insurance, marketing, retailing, finance, \\nand health care. Within a given niche, data-mining tools can use certain algorithms that \\nare implemented in different ways and applied over different data. Despite the lack of \\nprecise standards, data mining consists of four general phases:\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='321b4c1b-015b-44ff-84aa-d5ad265dff38', embedding=None, metadata={'page_label': '672', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='672   Part 4    Advanced Database Concepts\\n• Data preparation\\n• Data analysis and classification\\n• Knowledge acquisition\\n• Prognosis\\nIn the data preparation phase , the main data sets to be used by the data-mining oper -\\nation are identified and cleansed of any data impurities. Because the data in the data \\nwarehouse is already integrated and filtered, the data warehouse usually is the target set for data-mining operations.\\nThe data analysis and classification phase studies the data to identify common data \\ncharacteristics or patterns. During this phase, the data-mining tool applies specific algo-rithms to find:\\n•\\n Data groupings, classifications, clusters, or sequences\\n• Data dependencies, links, or relationships\\n• Data patterns, trends, and deviations\\nThe knowledge acquisition phase  uses the results of the data analysis and classifica-\\ntion phase. During the knowledge acquisition phase, the data-mining tool (with possible \\nintervention by the end user) selects the appropriate modeling or knowledge acquisi-tion algorithms. The most common algorithms used in data mining are based on neural networks, decision trees, rules induction, genetic algorithms, classification and regres-sion trees, memory-based reasoning, and nearest neighbor. A data-mining tool may use many of these algorithms in any combination to generate a computer model that reflects the behavior of the target data set.\\nAlthough many data-mining tools focus on the knowledge–discovery phase, others \\ncontinue to the prognosis phase . In that phase, the data-mining findings are used to pre-\\ndict future behavior and forecast business outcomes. Examples of data-mining findings can be:\\n•\\n Sixty-five percent of customers who did not use a particular credit card in the last  \\nsix months are 88 percent likely to cancel that account.\\n• Eighty-two percent of customers who bought a 42-inch or larger LCD TV are 90 per -\\ncent likely to buy an entertainment center within the next four weeks.\\n• If age < 30, income <= 25,000, credit rating < 3, and credit amount > 25,000, then the \\nminimum loan term is 10 years.\\nThe complete set of findings can be represented in a decision tree, a neural network, a \\nforecasting model, or a visual presentation interface that is used to project future events or results. For example, the prognosis phase might project the likely outcome of a new product rollout or a new marketing promotion. Figure 14.13 illustrates the different phases of the data-mining process.\\nBecause of the nature of the data-mining process, some findings might fall out-\\nside the boundaries of what business managers expect. For example, a data-mining tool might find a close relationship between a customer’s favorite brand of soda and the brand of tires on the customer’s car. Clearly, that relationship might not be held in high regard among sales managers. (In regression analysis, those relationships are commonly described by the label “idiot correlation. ”) Fortunately, data mining usu-ally yields more meaningful results. In fact, data mining has proven helpful in finding practical relationships among data that help define customer buying patterns, improve product development and acceptance, reduce health care fraud, analyze stock markets, and so on.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b383e539-dc3e-40e1-8bcb-17f7228b9c6c', embedding=None, metadata={'page_label': '673', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    673\\nData mining can be run in two modes:\\n• Guided . The end user guides the data-mining tool step by step to explore and explain \\nknown patterns or relationships. In this mode, the end user decides what techniques \\nto apply to the data.\\n• Automated . In this mode, the end user sets up the data-mining tool to run automat -\\nically and uncover hidden patterns, trends, and relationships. The data-mining tool \\napplies multiple techniques to find significant relationships.\\nAs you learned in this section, data-mining methodologies focus on discovering and \\nextracting information that describes and explains the data. For example, an explanatory \\nmodel could create a customer profile that describes a given customer group. However, \\ndata mining can also be used as the basis to create advanced predictive data models. For \\nexample, a predictive model could be used to predict future customer behavior, such as a \\ncustomer response to a target marketing campaign. The next section explains the use of \\npredictive analytics in more detail.\\n14-4b  Predictive Analytics\\nAlthough the term predictive analytics  is used by many BI vendors to indicate many \\ndifferent levels of functionality, the promise of predictive analytics is very attractive for \\nbusinesses looking for ways to improve their bottom line. Therefore, predictive analytics \\nis receiving a lot of marketing buzz; vendors and businesses are dedicating extensive \\nresources to this BI area. Predictive analytics refers to the use of advanced mathematical, \\nstatistical, and modeling tools to predict future business outcomes with high degrees of \\naccuracy.FIGURE 14.13  DATA-MINING PHASES\\nData preparation phase• Identify data set\\n• Clean data set\\n• Integrate data set\\nData analysis and\\nclassiﬁcation phase\\nKnowledge\\nacquisition phase\\nPrognosis phase• Classiﬁcation analysis\\n• Clustering and sequence analysis\\n• Link analysis\\n• Trend and deviation analysis\\n• Select and apply algorithms\\n• Neural networks\\n• Inductive logic\\n• Decision trees\\n• Clustering\\n• Regression tree\\n• Nearest neighbor\\n• Visualization, etc.\\n• Modeling\\n• Forecasting\\n• Prediction\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='07fe3d8e-3770-4644-960a-b7c4b3253d90', embedding=None, metadata={'page_label': '674', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='674   Part 4    Advanced Database Concepts\\nWhat is the difference between data mining and predictive analytics? As you learned \\nearlier, data mining also has predictive capabilities. In fact, data mining and predictive \\nanalytics use similar and overlapping sets of tools, but with a slightly different focus. Data mining focuses on answering the “how” and “what” of past  data, while predictive analyt-\\nics focuses on creating actionable models to predict future  behaviors and events. In some \\nways, you can think of predictive analytics as the next logical step after data mining; once you understand your data, you can use the data to predict future behaviors. In fact, most BI vendors are dropping the term data mining  and replacing it with the more alluring \\nterm predictive analytics .\\nThe origins of predictive analytics can be traced back to the banking and credit card \\nindustries. The need to profile customers and predict customer buying patterns in these industries was a critical driving force for the evolution of many modeling methodologies used in BI data analytics today. For example, based on your demographic information and purchasing history, a credit card company can use data-mining models to determine what credit limit to offer, what offers you are more likely to accept, and when to send those offers.\\nPredictive analytics received a big stimulus with the advent of social media. Compa-\\nnies turned to data mining and predictive analytics as a way to harvest the mountains of data stored on social media sites. Google was one of the first companies that offered tar-geted ads as a way to increase and personalize search experiences. Similar initiatives were used by all types of organizations to increase customer loyalty and drive up sales. Note the example of the airline and credit card industries and their frequent flyer and affinity card programs. Today, many organizations use predictive analytics to profile customers in an attempt to get and keep the right ones, which in turn will increase loyalty and sales.\\nPredictive analytics employs mathematical and statistical algorithms, neural networks, \\nartificial intelligence, and other advanced modeling tools to create actionable predictive models based on available data. The algorithms used to build the predictive model are specific to certain types of problems and work with certain types of data. Therefore, it is important that the end user, who typically is trained in statistics and understands busi-ness, applies the proper algorithms to the problem in hand. However, thanks to constant technology advances, modern BI tools automatically apply multiple algorithms to find the optimum model.\\nMost predictive analytics models are used in areas such as customer relationships, \\ncustomer service, customer retention, fraud detection, targeted marketing, and opti-mized pricing. Predictive analytics can add value to an organization in many different ways. For example, it can help optimize existing processes, identify hidden problems, and anticipate future problems or opportunities. However, predictive analytics is not the “secret sauce” to fix all business problems. Managers should carefully monitor and eval-uate the value of predictive analytics models to determine their return on investment.\\nIn Chapter 13, you learned about data warehouses and star schemas to model and \\nstore decision support data. In this chapter, you have added to that by exploring the vast stores of data that organizations are collecting in unstructured formats and the technologies that make that data available to users. Data analytics is used to extract knowledge from all of these sources of data—NoSQL databases, Hadoop data stores, and data warehouses—to provide decision support to all organizational users.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e1b3e029-50e9-4aff-98fe-42965c6fd83f', embedding=None, metadata={'page_label': '675', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    675\\nSummary\\n• Big Data is characterized by data of such volume, velocity, and/or variety that the rela-\\ntional model struggles to adapt to it. Volume refers to the quantity of data that must be stored. Velocity refers to both the speed at which data is entering storage as well as the speed with which it must be processed. Variety refers to the lack of uniformity in the structure of the data being stored. As a result of Big Data, organizations are having to employ a variety of data storage solutions that include technologies in addition to relational databases, a situation referred to as polyglot persistence.\\n•\\n Volume, velocity, and variety are collectively referred to as the 3 Vs of Big Data. How-ever, these are not the only characteristics of Big Data to which data administrators must be sensitive. Additional Vs that have been suggested by the data management industry include variability, veracity, value, and visualization. Variability is the varia-tion in the meaning of data that can occur over time. Veracity is the trustworthiness of the data. Value is concerned with whether or not the data is useful. Finally, visu-alization is the requirement that the data must be able to be presented in a manner that makes it comprehendible to decision makers. Most of these additional Vs are not unique to Big Data. They are also concerns for data in relational databases as well.\\n•\\n The Hadoop framework has quickly emerged as a standard for the physical storage of Big Data. The primary components of the framework include the Hadoop Dis-tributed File System (HDFS) and MapReduce. HDFS is a coordinated technology for reliably distributing data over a very large cluster of commodity servers. MapReduce is a complementary process for distributing data processing across distributed data. One of the key concepts for MapReduce is to move the computations to the data instead of moving the data to the computations. MapReduce works by combining the functions of map , which distributes subtasks to the cluster servers that hold data to \\nbe processed, and reduce , which combines the map results into a single result set. The \\nHadoop framework also supports an entire ecosystem of additional tools and technol-ogies, such as Hive, Pig, and Flume that work together to produce a complex system of Big Data processing.\\n•\\n NoSQL is a broad term to refer to any of several nonrelational database approaches to data management. Most NoSQL databases fall into one of four categories: key-value databases, document databases, column-oriented databases, or graph databases. Due to the wide variability of products under the NoSQL umbrella, these categories are not necessarily all-encompassing, and many products can fit into multiple categories.\\n•\\n Key-value databases store data in key-value pairs. In a key-value pair, the value of the key must be known to the DBMS, but the data in the value component can be of any type, and the DBMS makes no attempt to understand the meaning of the data in it. These types of databases are very fast when the data is completely independent, and the application programs can be relied on to understand the meaning of the data.\\n•\\n Document databases also store data in key-value pairs, but the data in the value com-ponent is an encoded document. The document must be encoded using tags, such as in XML or JSON. The DBMS is aware of the tags in the documents, which makes  \\nquerying on tags possible. Document databases expect documents to be self-contained  \\nand relatively independent of each other.\\n•\\n Column-oriented databases, also called column family databases, organize data into key-value pairs in which the value component is composed of a series of columns, which are themselves key-value pairs. Columns can be grouped into super columns, similar to a composite attribute in the relational model being composed of simple \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a518e1c1-789f-40fa-b21b-fbf2cb338fcd', embedding=None, metadata={'page_label': '676', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='676   Part 4    Advanced Database Concepts\\nattributes. All objects of a similar type are identified as rows, given a row key, and \\nplaced within a column family. Rows within a column family are not required to have the same structure, that is, they are not required to have the same columns.\\n•\\n Graph databases are based on graph theory and represent data through nodes, edges, and properties. A node is similar to an instance of an entity in the relational model. Edges are the relationships between nodes. Both nodes and edges can have properties, which are attributes that describe the corresponding node or edge. Graph databases excel at tracking data that is highly interrelated, such as social media data. Due to the many relationships among the nodes, it is difficult to distribute a graph database across a cluster in a highly-distributed manner.\\n•\\n NewSQL databases attempt to integrate features of both RDBMS (providing ACID-compliant transactions) and NoSQL databases (using a highly distributed infrastructure).\\n•\\n Data analytics is a subset of BI functionality that provides advanced data analysis tools to extract knowledge from business data. Data analytics can be divided into explanatory and predictive analytics. Explanatory analytics focuses on discovering and explaining data characteristics and relationships. Predictive analytics focuses on creating models to predict future outcomes or events based on the existing data.\\n•\\n Data mining automates the analysis of operational data to find previously unknown data characteristics, relationships, dependencies, and trends. The data-mining pro-cess has four phases: data preparation, data analysis and classification, knowledge acquisition, and prognosis.\\n•\\n Predictive analytics uses the information generated in the data-mining phase to create advanced predictive models with high degrees of accuracy.\\nKey Terms\\nalgorithm\\nbatch processingblock reportBSON (Binary JSON)bucketcolumn familycolumn family databasecolumn-centric storagedata analyticsdata miningdocument databaseedgeexplanatory analyticsfeedback loop processinggraph databaseHadoop Distributed File \\nSystem (HDFS)heartbeat\\njob trackerJSON (JavaScript Object \\nNotation)\\nkey-value (KV) databasemapMapReducemapperNewSQLnodeNoSQLpolyglot persistencepredictive analyticspropertiesreducereducerrow-centric storagescaling outscaling upsentiment analysisstream processingstructured datasuper columntask trackertraversalunstructured datavaluevariabilityvarietyvelocityveracityvisualizationvolume\\nFlashcards and crossword \\npuzzles for key term practice are available at  www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2315edb5-990a-449f-b9ac-263ccd467a56', embedding=None, metadata={'page_label': '677', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 14    Big Data Analytics and NoSQL    677\\nReview Questions\\n1. What is Big Data? Give a brief definition.\\n2. What are the traditional 3 Vs of Big Data? Briefly, define each.\\n3. Explain why companies like Google and Amazon were among the first to address \\nthe Big Data problem.\\n4. Explain the difference between scaling up  and scaling out .\\n5. What is stream processing, and why is it sometimes necessary?\\n6. How is stream processing different from feedback loop processing?\\n7. Explain why veracity, value, and visualization can also be said to apply to relational databases as well as Big Data.\\n8.\\n What is polyglot persistence, and why is it considered a new approach?\\n9. What are the key assumptions made by the Hadoop Distributed File System approach?\\n10.\\n What is the difference between a name node and a data node in HDFS?\\n11. Explain the basic steps in MapReduce processing.\\n12. Briefly explain how HDFS and MapReduce are complementary to each other.\\n13. What are the four basic categories of NoSQL databases?\\n14. How are the value components of a key-value database and a document database different?\\n15.\\n Briefly explain the difference between row-centric and column-centric data storage.\\n16. What is the difference between a column and a super column in a column family database?\\n17.\\n Explain why graph databases tend to struggle with scaling out.\\n18. What is data analytics? Briefly define explanatory and predictive analytics.\\n19. Describe and contrast the focus of data mining and predictive analytics. Give some examples.\\n20.\\n How does data mining work? Discuss the different phases in the data mining process.\\n21. Describe the characteristics of predictive analytics. What is the impact of Big Data in predictive analytics?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9a705fdd-5da7-4983-8739-480d908ca169', embedding=None, metadata={'page_label': '678', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Copyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e74aa663-8f3b-499d-834f-f92a34c273a7', embedding=None, metadata={'page_label': '679', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 5\\nDatabases and the Internet\\n15 Database Connectivity and Web Technologies\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b1b05668-430c-4371-9a08-c997cebe699b', embedding=None, metadata={'page_label': '680', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 15\\nDatabase Connectivity and Web Technologies\\nIn this chapter, you will learn:\\n• About database connectivity fundamentals\\n• About various database connectivity technologies: ODBC, OLE, ADO.NET, JDBC\\n• How web-to-database middleware is used to integrate databases with the Internet\\n• What services are provided by web application servers\\n• What Extensible Markup Language (XML) is and why it is important for web database development\\n• About cloud computing and how it enables the database-as-a-service model\\nPreviewDatabases are the central repository for critical data generated by business applications, \\nincluding newer channels such as the web and mobile devices. For businesses to remain competitive, such data must be readily available, anywhere and anytime, to all business users and in all types of formats: a desktop spreadsheet, a Visual Basic application, a web front end, and using newer technologies such as smartphones and tablets. In this chapter, you will learn about various architectures used to connect applications to databases.\\nThe Internet has changed how organizations of all types operate. Buying goods and \\nservices via the Internet has become commonplace. This chapter examines the funda-mentals of web database technologies used to open databases to the Internet. In today’s environment, interconnectivity occurs not only between an application and the database but between applications exchanging messages and data. Extensible Markup Language (XML) provides a standard way of exchanging unstructured and structured data between applications.\\nCompanies that want to integrate database and web technologies within their applica-\\ntions portfolio can now choose from a range of Internet-based services. Therefore, you will learn how organizations can benefit from cloud computing by leveraging the data-base-as-a-service model within their IT environments. These cloud-based services offer  \\na quick and cost-efficient way to provide new business services.\\nData Files Available on cengagebrain.comData Files and Available Formats\\nMS Access Oracle MS SQL My SQL\\nCH15_Orderdb  P\\t P\\t P\\t PMS Access Oracle MS SQL My SQL\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ef6da8e6-9b11-46ac-9ae1-2432b0017b4a', embedding=None, metadata={'page_label': '681', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    681\\n15-1  Database Connectivity\\nDatabase connectivity refers to the mechanisms through which application programs \\nconnect and communicate with data repositories. Databases store data in persistent stor -\\nage structures so it can be retrieved at a later time for processing. As you already learned, the database management system (DBMS) functions as an intermediary between the data (stored in the database) and the end-user’s applications. Before learning about the various data connectivity options, it is important to review some important fundamen-tals you have learned in this book:\\n•\\n DBMSs provide means to interact with the data in their databases. This could be in \\nthe form of administrative tools and data manipulation tools. DBMSs also provide a proprietary way for external application programs to connect to the database by the means of an application programing interface. See Chapter 1, Database Systems.\\n•\\n Modern DBMSs have the option to store data locally or distributed in multiple loca-tions. Locally stored data resides in the same processing host as the DBMS. A dis-tributed database stores data in multiple geographically distributed nodes with data management capability. See Chapter 12, Distributed Database Management Systems.\\n•\\n The database connectivity software we discuss in this chapter supports Structured Query Language (SQL) as the standard data manipulation language. However, depending on the type of database model, some database connectivity interfaces may support other proprietary data manipulation languages.\\n•\\n Database connectivity software works in a client/server architecture, by which pro-cessing tasks are split among multiple software layers. In this model, the multiple layers exchange control messages and data. See Chapter 12 and Appendix F, Client/Server Systems, for more information on this topic.\\nTo better understand database connectivity software, we use client/server concepts in \\nwhich an application is broken down in interconnected functional layers. In the case of database connectivity software, you could break down its basic functionality into three broad layers:\\n1.\\n A data layer where the data resides. Y ou could think of this layer as the actual data \\nrepository interface. This layer resides closest to the database itself and normally is provided by the DBMS vendor.\\n2.\\n A middle layer that manages multiple connectivity and data transformation issues. This layer is in charge of dealing with data logic issues, data transformations, ways to “talk” to the database below it, and so on. This would also include translating multiple data manipulation languages to the native language supported by the specific data repository.\\n3.\\n A top layer that interfaces with the actual external application. This mostly comes in the form of an application programming interface that publishes specific protocols for the external programs to interact with the data.\\nFrom the previous discussion, you can understand why the database connectivity \\nsoftware is also known as database middleware—because it provides an interface between the application program and the database or data repository. The data reposi-tory, also known as the data source , represents the data management application, such as \\nOracle, SQL Server, IBM DB2, or NoSQL that will be used to store the data generated by the application program. Ideally, a data source or data repository could be located any-where and hold any type of data. Furthermore, the same database connectivity middle-ware could support multiple data sources at the same time. For example, the data source could be a relational database, a NoSQL database, a spreadsheet, a MS Access database, \\ndatabase middleware\\nDatabase connectivity software through which application programs connect and communicate with data repositories.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='18a83303-8198-4c9d-8634-80d55a59bac8', embedding=None, metadata={'page_label': '682', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='682   Part 5     Databases and the Internet\\nor a text data file. This multi-data-source type capability is based on the support of \\nwell-established data access standards.\\nThe need for standard database connectivity interfaces cannot be overstated. Just as \\nSQL has become the de facto data manipulation language, a standard database connec -\\ntivity interface is necessary for enabling applications to connect to data repositories. \\nAlthough there are many ways to achieve database connectivity, this section covers only \\nthe following interfaces:\\n• Native SQL connectivity (vendor provided)\\n• Microsoft’s Open Database Connectivity (ODBC), Data Access Objects (DAO), and \\nRemote Data Objects (RDO)\\n• Microsoft’s Object Linking and Embedding for Database (OLE-DB)\\n• Microsoft’s ActiveX Data Objects (ADO.NET)\\n• Oracle’s Java Database Connectivity (JDBC)\\nThe data connectivity interfaces illustrated here are dominant players in the market, \\nand more importantly, they enjoy the support of most database vendors. In fact, ODBC, \\nOLE-DB, and ADO.NET form the backbone of Microsoft’s Universal Data Access \\n(UDA)  architecture, a collection of technologies used to access any type of data source \\nand manage the data through a common interface. As you will see, Microsoft’s database \\nconnectivity interfaces have evolved over time: each interface builds on top of the other, \\nthus providing enhanced functionality, features, flexibility, and support.\\n15-1a  Native SQL Connectivity\\nMost DBMS vendors provide their own methods for connecting to their databases. Native \\nSQL connectivity refers to the connection interface that is provided by the database ven -\\ndor and is unique to that vendor. The best example of this type of native interface is the \\nOracle RDBMS. To connect a client application to an Oracle database, you must install \\nand configure Oracle’s SQL*Net interface on the client computer. Figure 15.1 shows the \\nconfiguration of the Oracle SQL*Net interface on the client computer.\\nNative database connectivity interfaces are optimized for “their” DBMS, and those \\ninterfaces support access to most or all of the database features. However, maintaining \\nUniversal Data \\nAccess (UDA)\\nWithin the Microsoft \\napplication framework, \\na collection of \\ntechnologies used to \\naccess any type of data \\nsource and to manage \\nthe data through a \\ncommon interface.FIGURE 15.1  ORACLE NATIVE CONNECTIVITY  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='363d34ef-08f2-47af-b7fb-db2325ad6c7a', embedding=None, metadata={'page_label': '683', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    683\\nmultiple native interfaces for different databases can become a burden for the program-\\nmer. Therefore, the need for universal database connectivity arises. Usually, the native database connectivity interface provided by the vendor is not the only way to connect to a database; most current DBMS products support other database connectivity standards, the most common being ODBC.\\n15-1b  ODBC, DAO, and RDO\\nDeveloped in the early 1990s, Open Database Connectivity (ODBC) is Microsoft’s imple-mentation of a superset of the SQL Access Group Call Level Interface (CLI) standard for database access. ODBC is probably the most widely supported database connectivity inter -\\nface. ODBC allows any Windows application to access relational data sources, using SQL via a standard application programming interface (API). The Webopedia online dictionary (www.webopedia.com ) defines an API as “a set of routines, protocols, and tools for building \\nsoftware applications. ” A good API makes it easy to develop a program by providing all of the building blocks; the programmer puts the blocks together. Most operating environ-ments, such as Windows, provide an API so that programmers can write applications con-sistent with the operating environment. Although APIs are designed for programmers, they are ultimately good for users because they guarantee that all programs using a common API will have similar interfaces. That makes it easy for users to learn new programs.\\nODBC was the first widely adopted database middleware standard, and it enjoyed \\nrapid adoption in Windows applications. As programming languages evolved, ODBC did not provide significant functionality beyond the ability to execute SQL to manipu-late relational-style data. Therefore, programmers needed a better way to access data. To answer that need, Microsoft developed two other data access interfaces:\\n•\\n Data Access Objects (DAO) is an object-oriented API used to access desktop data-\\nbases, such as MS Access and FileMaker Pro. DAO provides an optimized interface that exposes programmers to the functionality of the Jet data engine, on which MS Access is based. The DAO interface can also be used to access other relational-style data sources.\\n•\\n Remote Data Objects (RDO) is a higher-level, object-oriented application interface used to access remote database servers. RDO uses the lower-level DAO and ODBC for direct access to databases. RDO is optimized to deal with server-based databases such as MS SQL Server, Oracle, and DB2.\\nFigure 15.2 illustrates how Windows applications can use ODBC, DAO, and RDO to \\naccess local and remote relational data sources.\\nThe DAO and RDO object interfaces provide more functionality than ODBC. DAO \\nand RDO make use of the underlying ODBC data services. ODBC, DAO, and RDO are implemented as shared code that is dynamically linked to the Windows operating environment through dynamic-link libraries (DLLs), which are stored as files with a .dll extension. Running as a DLL, the code speeds up load and run times.\\nThe basic ODBC architecture has three main components:\\n•\\n A high-level ODBC API  through which application programs access ODBC functionality\\n• A driver manager that is in charge of managing all database connections\\n• An ODBC driver  that communicates directly to the DBMS\\nDefining a data source is the first step in using ODBC. To define a data source, you must \\ncreate a data source name (DSN) for it. To create a DSN, you need to provide the following:\\n• An ODBC driver. Y ou must identify the driver to use to connect to the data source. \\nThe ODBC driver is normally provided by the database vendor, although Microsoft  provides several drivers that connect to most common databases. For example, if you Open Database Connectivity (ODBC)\\nMicrosoft database middleware that provides a database access API to Windows applications.\\nCall Level Interface (CLI)\\nA standard developed by the SQL Access Group for database access.\\napplication programming interface (API)\\nSoftware through which programmers interact with middleware. An API allows the use of generic SQL code, thereby allowing client processes to be database server-independent.\\nData Access Objects (DAO)\\nAn object-oriented application programming interface used to access MS Access, FileMaker Pro, and other Jet-based databases.\\nRemote Data Objects (RDO)\\nA higher-level, object-oriented application interface used to access remote database servers. RDO uses the lower-level DAO and ODBC for direct access to databases. \\ndynamic-link  library (DLL)\\nShared code module that is treated as part of the operating system or server process so it can be dynamically invoked at run time.\\ndata source name (DSN)\\nA name that identifies and defines an ODBC data source.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ad81ed03-fda9-4745-ad8c-ab0f530fddb6', embedding=None, metadata={'page_label': '684', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='684   Part 5     Databases and the Internet\\nare using an Oracle DBMS, you would select the Oracle ODBC driver provided by \\nOracle. Or, you could instead select the Microsoft-provided ODBC driver for Oracle.\\n• A name . This is a unique name by which the data source will be known to ODBC, and \\ntherefore to applications. ODBC offers two types of data sources: user and system. \\nUser data sources  are available only to the user. System data sources  are available to all \\nusers, including operating system services.\\n• ODBC driver parameters . Most ODBC drivers require specific parameters to establish \\na connection to the database. For example, if you are using an MS Access database, \\nyou must point to the location of the MS Access file and then provide a username and \\npassword if necessary. If you are using a DBMS server, you must provide the server \\nname, the database name, the username, and the password needed to connect to the \\ndatabase. Figure 15.3 shows the ODBC screens required to create a system ODBC \\ndata source for an Oracle DBMS. Note that some ODBC drivers use the native driver \\nprovided by the DBMS vendor.\\nOnce the ODBC data source is defined, application programmers can write to the \\nODBC API by issuing specific commands and providing the required parameters.  \\nThe ODBC Driver Manager will properly route the calls to the appropriate data source. FIGURE 15.2  USING ODBC, DAO, AND RDO TO ACCESS DATABASES  \\nMS Word MS Access MS Excel\\nRDO\\nDAO\\nJet Engine\\nODBC API\\nODBC Driver Manager\\nODBC Database Driver\\nOracle\\nDriverMS SQL\\nDriverODBC\\nDriver\\nOracle MS SQL AccessRemote Data Objects\\nData Access Objects\\nJet Engine supports MS\\nAccess databases and other\\nSQL-aware data sources.\\nDatabase vendors provide ODBC \\ndatabase drivers so Windows\\napplications can access their\\nrespective databases.Client Applications\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='88bd97d8-2723-47ba-809d-2e58aadb0758', embedding=None, metadata={'page_label': '685', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    685\\nThe ODBC API standard defines three levels of compliance: Core, Level-1, and Level-2, \\nwhich provide increasing levels of functionality. For example, Level-1 might provide sup -\\nport for most SQL DDL and DML statements, including subqueries and aggregate func -\\ntions, but not for procedural SQL or cursors. The database vendors can choose which \\nlevel to support. However, to interact with ODBC, the database vendor must implement \\nall of the features in the specified ODBC API support level.\\nFigure 15.4 shows how you could use MS Excel to retrieve data from an Oracle RDBMS \\nusing ODBC. Because much of the functionality provided by these interfaces is oriented \\ntoward accessing relational data sources, the use of the interfaces was limited with other \\ndata source types. With the advent of object-oriented programming languages, it has \\nbecome more important to provide access to other nonrelational data sources.\\n15-1c  OLE-DB\\nAlthough ODBC, DAO, and RDO are used, they do not provide support for nonrela -\\ntional data. To answer that need and to simplify data connectivity, Microsoft developed  \\nObject Linking and Embedding for Database (OLE-DB) . Based on Microsoft’s Com -\\nponent Object Model (COM), OLE-DB is database middleware that adds object-oriented  \\nfunctionality for access to relational and nonrelational data. OLE-DB was the first part \\nof Microsoft’s strategy to provide a unified object-oriented framework for the develop -\\nment of next-generation applications.\\nOLE-DB is composed of a series of COM objects that provide low-level database \\nconnectivity for applications. Because OLE-DB is based on COM, the objects contain \\ndata and methods, also known as the interface. The OLE-DB model is better understood \\nwhen you divide its functionality into two types of objects:\\n• Consumers  are objects (applications or processes) that request and use data. Consum -\\ners request data by invoking the methods exposed by the data provider objects (public \\ninterface) and passing the required parameters.FIGURE 15.3  CONFIGURING AN ORACLE ODBC DATA SOURCE  \\nDeﬁning an ODBC\\nsystem data source name (DSN )\\nto connect to an Oracle DBMS,\\nusing Oracle ODBC Driver\\nOracle ODBC Driver\\nuses the native Oracle\\nSQL connectivity.\\nIf no user ID is provided,\\nODBC will prompt for the\\nuser ID and password at\\nrun time.\\nObject Linking and \\nEmbedding for \\nDatabase (OLE-DB)\\nBased on Microsoft’s \\nComponent Object \\nModel (COM), OLE-DB \\nis database middleware \\nthat adds object-\\noriented functionality for \\naccessing relational and \\nnonrelational data. \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3b4dce8b-311d-4f4c-b1fe-b501d0d681cc', embedding=None, metadata={'page_label': '686', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='686   Part 5     Databases and the Internet\\n• Providers  are objects that manage the connection with a data source and provide data \\nto the consumers. Providers are divided into two categories: data providers and ser -\\nvice providers.\\n –Data providers  provide data to other processes. Database vendors create data pro -\\nvider objects that expose the functionality of the underlying data source (relational, \\nobject-oriented, text, and so on).\\n –Service providers  provide additional functionality to consumers. The service provider \\nis located between the data provider and the consumer. The service provider requests \\ndata from the data provider, transforms the data, and then provides the transformed \\ndata to the data consumer. In other words, the service provider acts like a data con -\\nsumer of the data provider and as a data provider for the data consumer (end-user \\napplication). For example, a service provider could offer cursor management services, \\ntransaction management services, query processing services, and indexing services.\\nAs a common practice, many vendors provide OLE-DB objects to augment their \\nODBC support, effectively creating a shared object layer on top of their existing database \\nconnectivity (ODBC or native) through which applications can interact. The OLE-DB \\nobjects expose functionality about the database; for example, there are objects that deal \\nwith relational data, hierarchical data, and flat-file text data. Additionally, the objects FIGURE 15.4  MS EXCEL USES ODBC TO CONNECT TO AN ORACLE DATABASE  \\n3\\n 41. From Excel, click the Data Tab, under Get External Data, select\\n    the From Other Sources and From Microsoft Query options to\\n    retrieve data from an Oracle RDBMS.\\n2. Select the Gradora ODBC data source.\\n3. Enter the authentication parameters. ODBC uses the connection\\n    parameters to connect to the data source. Click OK. The ﬁrst time,\\n    all tables to which the user has access are listed. \\n4. To limit to only tables owned by the user, click on Options and\\n    choose the user name from the Owner drop down list.\\n5. Select the table and columns to use in the query.\\n6. Select ﬁltering options to restrict the rows returned.\\n7. Select sorting options to order the rows.\\n8. Select Return Data to Microsoft Ofﬁce Excel. \\n9. Select how you want to view the data and where you want it\\n    placed in your Excel workbook.\\n10. Excel uses the ODBC API to pass the SQL request down to the\\n    database. Oracle executes the request and generates a result set.\\n    Excel issues calls to the ODBC API to retrieve the result set and\\n    populate the spreadsheet.DATABASEDATABASE\\nSERVER\\nCOMPUTERRDBMS SERVER ODBC API\\nODBC\\nDRIVER MGR\\nODBC DRIVERODBC InterfaceCLIENT APPLICATION\\n1\\n2\\n5\\n6\\n7\\n8\\n9\\n10\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b9759e18-fc5b-4d10-9d34-bd55babede13', embedding=None, metadata={'page_label': '687', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    687\\nimplement specific tasks, such as establishing a connection, executing a query, invoking \\na stored procedure, defining a transaction, or invoking an OLAP function. By using OLE-DB objects, the database vendor can choose what functionality to implement in a modular way, instead of being forced to include all of the functionality all of the time. Table 15.1 shows a sample of the object-oriented classes used by OLE-DB and some of the methods (interfaces) exposed by the objects.\\nOLE-DB provides additional capabilities for the applications accessing the data. However, \\nit does not provide support for scripting languages, especially the ones used for web develop-ment, such as Active Server Pages (ASP) and ActiveX. (A script is written in a programming language that is not compiled but is interpreted and executed at run time.) To provide that support, Microsoft developed a new object framework called ActiveX Data Objects (ADO), \\nwhich provides a high-level, application-oriented interface to interact with OLE-DB, DAO, and RDO. ADO provides a unified interface to access data from any programming language that uses the underlying OLE-DB objects. Figure 15.5 illustrates the ADO/OLE-DB architec-ture and how it interacts with ODBC and native connectivity options.\\nADO introduced a simpler object model that was composed of only a few interacting \\nobjects to provide the data manipulation services required by the applications. Sample objects in ADO are shown in Table 15.2.\\nAlthough the ADO model is a tremendous improvement over the OLE-DB model, \\nMicrosoft is actively encouraging programmers to use its newer data access framework, ADO.NET.\\n15-1d  ADO.NET\\nBased on ADO, ADO.NET is the data access component of Microsoft’s .NET applica-tion development framework. The Microsoft .NET framework is a component-based platform for developing distributed, heterogeneous, interoperable applications aimed at manipulating any type of data using any combination of network, operating system, and programming language. Comprehensive coverage of the .NET framework is beyond the scope of this book. Therefore, this section only introduces the basic data access compo-nent of the .NET architecture, ADO.NET.\\nIt is important to understand that the .NET framework extends and enhances the func -\\ntionality provided by the ADO/OLE-DB duo. ADO.NET introduced two new features that are critical for the development of distributed applications: DataSets and XML support.TABLE 15.1\\nSAMPLE OLE-DB CLASSES AND INTERFACES\\nOBJECT CLASS USAGE SAMPLE INTERFACES\\nSession Used to create an OLE-DB session between a data consumer application and a data providerIGetDataSource\\nCommand Used to process commands to manipulate \\na data provider’s data; generally, the command object will create RowSet objects to hold the data returned by a data providerICommandPrepare\\nRowSet Used to hold the result set returned by a \\nrelational-style database or a database that supports SQL; represents a collection of rows in a tabular formatIRowsetInfoIRowsetFindIRowsetScroll\\nscript\\nA programming language that is not compiled, but is interpreted and executed at run time.\\nActiveX Data Objects (ADO)\\nA Microsoft object framework that provides a high-level, application-oriented interface to OLE-DB, DAO, and RDO. ADO provides a unified interface to access data from any programming language that uses the underlying OLE-DB objects.\\nADO.NET\\nThe data access component of Microsoft’s .NET application development framework.\\nMicrosoft .NET framework\\nA component-based platform for the development of distributed, heterogeneous, interoperable applications aimed at manipulating any type of data over any network regardless of operating system and programming language.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b630479-1f8e-4ffc-9785-a7a3082a3d27', embedding=None, metadata={'page_label': '688', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='688   Part 5     Databases and the Internet\\nTo understand the importance of this new model, you should know that a DataSet  \\nis a disconnected, memory-resident representation of the database. That is, the DataSet \\ncontains tables, columns, rows, relationships, and constraints. Once the data is read from \\na data provider, it is placed in a memory-resident DataSet, which is then disconnected \\nfrom the data provider. The data consumer application interacts with the data in the \\nDataSet object to make inserts, updates, and deletes in the DataSet. Once the processing \\nis done, the DataSet data is synchronized with the data source and the changes are made \\npermanent.FIGURE 15.5  OLE-DB ARCHITECTURE  \\nOLE-DB Data Providers\\nOLE-DB Provider\\nfor SQL ServerOLE-DB Provider\\nfor ODBCOLE-DB Provider\\nfor ExchangeOLE-DB Provider\\nfor Oracl e\\nSQL ServerODBC SQL*NET\\nEMAILOLE-DB Service Providers\\nQuery\\nProcessingCursor\\nProcessingE-Mail\\nProcessingIndexing\\nProcessing\\nDATABASE DATABASEOLE-DB Consumers\\nActiveX Data Objects (ADO)Client Applications\\nAccess Excel Visual C++\\nDataSet\\nIn ADO.NET, a \\ndisconnected, memory-\\nresident representation \\nof the database. The \\nDataSet contains \\ntables, columns, rows, \\nrelationships, and \\nconstraints.TABLE 15.2\\nSAMPLE ADO OBJECTS\\nOBJECT CLASS USAGE\\nConnection Used to set up and establish a connection with a data source. ADO will connect to any OLE-DB \\ndata source. The data source can be of any type.\\nCommand Used to execute commands against a specific connection (data source)\\nRecordset Contains the data generated by the execution of a command. It will also contain any new data to \\nbe written to the data source. The Recordset can be disconnected from the data source.\\nFields Contains a collection of field descriptions for each column in the Recordset\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13540661-12dd-41a2-b76d-59570bb6d60d', embedding=None, metadata={'page_label': '689', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    689\\nThe DataSet is internally stored in XML format, and the data in the DataSet can be \\nmade persistent as XML documents. This is critical in today’s distributed environments. \\nY ou can think of the DataSet as an XML-based, in-memory database that represents the \\npersistent data stored in the data source. (Y ou will learn about XML later in this chapter.)\\nFigure 15.6 illustrates the main components of the ADO.NET object model.\\nThe ADO.NET framework consolidates all data access functionality under one integrated \\nobject model. In this object model, several objects interact with one another to perform  \\nspecific data manipulations. These objects can be grouped as data providers and consumers.\\nData provider objects are provided by the database vendors. However, ADO.NET \\ncomes with two standard data providers: one for OLE-DB data sources and one for SQL \\nServer. That way, ADO.NET can work with any previously supported database, includ -\\ning an ODBC database with an OLE-DB data provider. At the same time, ADO.NET \\nincludes a highly optimized data provider for SQL Server.\\nWhatever the data provider is, it must support a set of specific objects to manipulate \\nthe data in the data source. Some of those objects are shown in Figure 15.6. A brief \\ndescription of the objects follows. FIGURE 15.6  ADO.NET FRAMEWORK  \\nDataReaderDataAdapter\\nCommand\\nConnection\\nOLE-DB\\nDATABASEADO.NETClient Applications\\nDataRelationCollectionDataTableCollection\\nDataTable\\nDataColumnCollection\\nDataRowCollection\\nConstraintCollectionDataSet (XML)\\nData Providers\\nInternetData Consumers\\nAccess\\n Excel\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a710d05b-0476-4721-90f3-c5af19b5bab8', embedding=None, metadata={'page_label': '690', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='690   Part 5    Databases and the Internet\\n• Connection . The Connection object defines the data source used, the name of the \\nserver, the database, and so on. This object enables the client application to open and \\nclose a connection to a database.\\n• Command . The Command object represents a database command to be executed \\nwithin a specified database connection. This object contains the actual SQL code or a stored procedure call to be run by the database. When a SELECT statement is exe-cuted, the Command object returns a set of rows and columns.\\n•\\n DataReader. The DataReader object is a specialized object that creates a read-only  \\nsession with the database to retrieve data sequentially (forward only) and very quickly.\\n• DataAdapter . The DataAdapter object is in charge of managing a DataSet object, and \\nit is the most specialized object in the ADO.NET framework. The DataAdapter object contains the following objects that aid in managing the data in the DataSet: Select-Command, InsertCommand, UpdateCommand, and DeleteCommand. The Data-Adapter object uses these objects to populate and synchronize the data in the DataSet with the permanent data source data.\\n•\\n DataSet . The DataSet object is the in-memory representation of the data in the data-\\nbase. This object contains two main objects. The DataTableCollection object contains a collection of DataTable objects that make up the “in-memory” database, and the DataRelationCollection object contains a collection of objects that describe the data relationships and ways to associate one row in a table to the related row in another table.\\n•\\n DataTable . The DataTable object represents the data in tabular format. This object has \\none very important property: PrimaryKey, which allows the enforcement of entity integrity. In turn, the DataTable object is composed of three main objects:\\n –DataColumnCollection  contains one or more column descriptions. Each column \\ndescription has properties such as column name, data type, nulls allowed, maxi-mum value, and minimum value.\\n –DataRowCollection  contains zero rows, one row, or more than one row with data as \\ndescribed in the DataColumnCollection.\\n –ConstraintCollection  contains the definition of the constraints for the table. Two \\ntypes of constraints are supported: ForeignKeyConstraint and UniqueConstraint.\\nAs you can see, a DataSet is a simple database with tables, rows, and constraints. Even \\nmore importantly, the DataSet does not require a permanent connection to the data source. The DataAdapter uses the SelectCommand object to populate the DataSet from a data source. However, once the DataSet is populated, it is completely independent of the data source, which is why it is called disconnected.\\nAdditionally, DataTable objects in a DataSet can come from different data \\nsources. This means that you could have an EMPLOYEE table in an Oracle database and a SALES table in a SQL Server database. Y ou could then create a DataSet that relates both tables as though they were in the same database. In short, the DataSet object paves the way for truly heterogeneous, distributed database support within applications.\\nThe ADO.NET framework is optimized to work in disconnected environments. \\nIn a disconnected environment, applications exchange messages in request/reply format. The most common example of a disconnected system is the Internet. Mod-ern applications rely on the Internet as the network platform and on the web browser as the graphical user interface. In later sections, you will learn about how Internet databases work.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e5c6d21-610a-4331-bf79-b3c9b61c750f', embedding=None, metadata={'page_label': '691', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    691\\n15-1e  Java Database Connectivity (JDBC)\\nJava  is an object-oriented programming language developed by Sun Microsystems \\n(acquired by Oracle in 2010) that runs on top of web browser software. Java is one of the \\nmost-common programming languages for web development. Sun Microsystems cre -\\nated Java as a “write once, run anywhere” environment, which means that a programmer \\ncan write a Java application once and then run it in multiple environments without any \\nmodification. The cross-platform capabilities of Java are based on its portable architec -\\nture. Java code is normally stored in preprocessed “chunks” known as applets that run \\nin a virtual machine environment in the host operating system. This environment has \\nwell-defined boundaries, and all interactivity with the host operating system is closely \\nmonitored. Java run-time environments are available for most operating systems, from \\ncomputers to handheld mobile devices to TV set-top boxes. Another advantage of using \\nJava is its “on-demand” architecture. When a Java application loads, it can dynamically \\ndownload all its modules or required components via the Internet.\\nWhen Java applications need to access data outside the Java runtime environment, they \\nuse predefined application programming interfaces. Java Database Connectivity (JDBC)  \\nis an application programming interface that allows a Java program to interact with a wide \\nrange of data sources, including relational databases, tabular data sources, spreadsheets, \\nand text files. JDBC allows a Java program to establish a connection with a data source, \\nprepare and send the SQL code to the database server, and process the result set.\\nOne main advantage of JDBC is that it allows a company to leverage its existing invest -\\nment in technology and personnel training. JDBC allows programmers to use their SQL \\nskills to manipulate the data in the company’s databases. As a matter of fact, JDBC allows \\ndirect access to a database server or access via database middleware. Furthermore, JDBC \\nprovides a way to connect to databases through an ODBC driver. Figure 15.7 illustrates \\nthe basic JDBC architecture and the various database access styles.\\nJava\\nAn object-oriented \\nprogramming language \\ndeveloped by Sun \\nMicrosystems that \\nruns on top of the \\nweb browser software. \\nJava applications are \\ncompiled and stored on \\nthe web server. Java’s \\nmain advantage is its \\nability to let application \\ndevelopers create their \\napplications once and \\nthen run them in many \\nenvironments.\\nJava Database \\nConnectivity (JDBC)\\nAn application \\nprogramming interface \\nthat allows a Java \\nprogram to interact \\nwith a wide range of \\ndata sources, including \\nrelational databases, \\ntabular data sources, \\nspreadsheets, and text \\nfiles.FIGURE 15.7  JDBC ARCHITECTURE  \\nJava Client Application\\nJDBC API\\nJDBC Driver Manager\\nJava DB Driver Java DB DriverJDBC-ODBC\\nBridge Driver\\nODBCDatabase\\nMiddleware\\nDATABASE D ATABASE D ATABASE D ATABASE\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7cf7f46f-8b66-4f56-b2c8-420e4b82e112', embedding=None, metadata={'page_label': '692', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='692   Part 5    Databases and the Internet\\nAs you see in Figure 15.7, the database access architecture in JDBC is very similar to \\nthe ODBC/OLE/ADO.NET architecture. All database access middleware shares similar \\ncomponents and functionality. One advantage of JDBC over other middleware is that it requires no configuration on the client side. The JDBC driver is automatically downloaded and installed as part of the Java applet download. Because Java is a web-based technol -\\nogy, applications can connect to a database directly using a simple URL. Once the URL is invoked, the Java architecture comes into play, the necessary applets are downloaded to the client (including the JDBC database driver and all configuration information), and then the applets are executed securely in the client’s runtime environment. This framework is used successfully in many vertical database markets, in particular in the rapidly growing data analytics market, where open source players like Hadoop and MapReduce provide end-users with advanced application programming interfaces to high-performance data analytics functions using large-scale clusters of interconnected data stores.\\nEvery day, more and more companies are investing resources to develop and expand \\ntheir web presence and are finding ways to do more business on the Internet. Such busi-ness generates increasing amounts of data to be stored in databases. Java and the .NET framework are part of the trend toward increasing reliance on the Internet as a critical business resource. In fact, the Internet has become a major development platform for most businesses. In the next section, you will learn more about Internet databases and how they are used.\\n15-2  Database Internet Connectivity\\nMillions of people all over the world access the Internet and connect to databases via web browsers or data services. For example, they can use a smartphone app to get weather forecasts, stock prices, driving directions, concert tickets, or music downloads. Internet database connectivity opens the door to new, innovative services that do the following:\\n•\\n Permit rapid responses to competitive pressures by bringing new services and prod-\\nucts to market quickly.\\n• Increase customer satisfaction through the creation of innovative data services such as mapping data combined with GPS (Global Positioning System) information to pro-vide location-aware services. These applications present end users with information or services located near the users’ current location.\\n•\\n Allow anywhere, anytime data access using mobile smart devices via the Internet.\\n• Yield fast and effective information dissemination through universal access from across the street or across the globe.\\nGiven these advantages, many organizations rely on their IT departments to create \\nuniversal data access architectures based on Internet standards. Table 15.3 shows a sam-ple of Internet technology characteristics and the benefits they provide.\\nAs you will learn in the following sections, database application development— \\nparticularly the creation and management of user interfaces and database connectivity—is  \\nprofoundly affected by the web. However, having a web-based database interface does not negate the design and implementation issues that were addressed in the previous chapters. In the final analysis, whether you make a purchase by going online or by stand-ing in line, the system-level transaction details are essentially the same, and they require the same basic database structures and relationships. If any immediate lesson is to be learned, it is this: The effects of bad database design, implementation, and management are magnified in an environment in which transactions might be measured in hundreds of thousands per day rather than hundreds.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bedfbf5d-41a0-442f-b501-0fc8af64c028', embedding=None, metadata={'page_label': '693', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    693\\nThe simplicity of the web’s interface and its cross-platform functionality are at the core \\nof its success as a data access platform. In fact, the web has helped create a new infor -\\nmation dissemination standard. The following sections examine how web-to-database \\nmiddleware enables end users to interact with databases over the web.\\n15-2a  Web-to-Database Middleware: Server-Side Extensions\\nIn general, the web server is the main hub through which all Internet services are accessed. For example, when an end user uses a web browser to dynamically query a database, the client browser requests a webpage from the web server. When the web server receives the page request, it looks for the page on the hard disk; when it finds the page, the server sends it back to the client.\\nDynamic webpages are at the heart of current websites. In this database query sce-\\nnario, the web server generates the webpage contents before it sends the page to the client web browser. The only problem with the preceding query scenario is that the web server must include the database query result on the page before  it sends that page back to the \\nclient. Unfortunately, neither the web browser nor the web server knows how to connect to and read data from the database. Therefore, to support this type of request, the web server’s capability must be extended so it can understand and process database requests. This job is known as a server-side extension.\\nA server-side extension is a program that interacts directly with the web server to \\nhandle specific types of requests. In the preceding database query example, the server- side extension program retrieves the data from databases and passes the retrieved data  \\nto the web server, which in turn sends the data to the client’s browser for display. The server-side extension makes it possible to retrieve and present the query results, but more importantly, it provides its services to the web server in a way that is totally transpar -\\nent to the client browser. In short, the server-side extension adds significant functionality to the web server, and therefore to the Internet.TABLE 15.3\\nCHARACTERISTICS AND BENEFITS OF INTERNET TECHNOLOGIES\\nINTERNET CHARACTERISTIC BENEFIT\\nHardware and software independenceSavings in equipment and software acquisitionAbility to run on most existing equipmentPlatform independence and portabilityNo need for multiple platform development\\nCommon and simple user interfaceReduced training time and costReduced end-user support costNo need for multiple platform development\\nLocation independence Global access through Internet infrastructure and mobile smart devicesCreation of new location-aware servicesReduced requirements (and costs!) for dedicated connections\\nRapid development at manageable costsAvailability of multiple development toolsPlug-and-play development tools (open standards)More interactive developmentReduced development timesRelatively inexpensive toolsFree client access tools (web browsers)Low entry costs; frequent availability of free web serversReduced costs of maintaining private networksDistributed processing and scalability using multiple servers\\nClient/server systems are covered in detail in Appendix F, Client/Server Systems, at www.cengagebrain.com.Online \\nContent\\nserver-side \\nextension\\nA program that interacts directly with the server process to handle specific types of requests. Server-side extensions add significant functionality to web servers and intranets.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='684403e5-d175-4225-b1c6-398565f745c9', embedding=None, metadata={'page_label': '694', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='694   Part 5     Databases and the Internet\\nA database server-side extension program is also known as web-to-database \\nmiddleware . Figure 15.8 shows the interaction between the browser, the web server, \\nand the web-to-database middleware.\\nTrace the web-to-database middleware actions in Figure 15.8:\\n1. The client browser sends a page request to the web server.\\n2. The web server receives and passes the request to the web-to-database middleware \\nfor processing.\\n3. Generally, the requested page contains some type of scripting language to enable \\nthe database interaction. The web server passes the script to the web-to-database \\nmiddleware.\\n4. The web-to-database middleware reads, validates, and executes the script. In this case, \\nit connects to the database and passes the query using the database connectivity layer.web-to-database \\nmiddleware\\nA database server-side \\nextension that retrieves \\ndata from databases \\nand passes them to the \\nweb server, which in \\nturn sends the data to \\nthe client’s browser for \\ndisplay.FIGURE 15.8  WEB-TO-DATABASE MIDDLEWARE  \\nCLIENT\\nCOMPUTER\\nHTML\\nPAGE\\nThe result of the\\ndatabase query is\\ndisplayed in\\nHTML formatHTTP page\\nrequestWeb server\\nreceives\\nrequestWEB\\nSERVERWeb server determines the\\npage contains script language\\nand passes the script page to\\nthe web-to-database\\nmiddleware\\nWeb-to-database\\nmiddleware\\nconnects\\n to the database\\nand passes query\\nusing database\\nconnectivity layerSCRIPT\\nPAGESERVER\\nCOMPUTER\\nHTML\\nPAGE\\nDatabase server\\npasses the query\\nresults back to the\\nweb-to-database\\nmiddlewareRDBMS\\nComputerWeb server\\nsends the HTML\\nformatted page\\nto the client\\nWeb-to-database\\nmiddleware passes the\\nquery results in HTML\\nformat back to the\\nweb serverWEB-TO-DATABASE\\nMIDDLEWARE\\nJDBC\\nADO.NET\\nADO\\nOLE-DB\\nODBC\\n5\\nRDBMS\\nSERVER\\nDATABASETCP/IP\\nNETWORK\\n7643\\n2\\n1\\n8\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ea419fe-667c-4eb3-ba05-502115662cf4', embedding=None, metadata={'page_label': '695', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    695\\n5. The database server executes the query and passes the result back to the web-to-database \\nmiddleware.\\n6. The web-to-database middleware compiles the result set, dynamically generates an HTML-formatted page that includes the data retrieved from the database, and sends it to the web server.\\n7.\\n The web server returns the just-created HTML page, which now includes the query result, to the client browser.\\n8.\\n The client browser displays the page on the local computer.\\nThe interaction between the web server and the web-to-database middleware \\nis crucial to the development of a successful Internet database implementation. Therefore, the middleware must integrate closely via a well-defined web server interface.\\n15-2b  Web Server Interfaces\\nExtending web server functionality implies that the web server and the web-to-  \\ndatabase middleware will properly communicate with each other. (Database profession-als often use the word interoperate  to indicate that each party can respond to the com-\\nmunications of the other.) A web server interface defines a standard way to exchange messages with external programs. Currently, there are two well-defined web server interfaces:\\n•\\n Common Gateway Interface (CGI)\\n• Application programming interface (API)\\nThe Common Gateway Interface (CGI) uses script files that perform specific func-\\ntions based on the client’s parameters that are passed to the web server. The script file is a \\nsmall program containing commands written in a programming language—usually Perl, C#, or Visual Basic. The script file’s contents can be used to connect to the database and to retrieve data from it, using the parameters passed by the web server. Next, the script converts the retrieved data to HTML format and passes the data to the web server, which sends the HTML-formatted page to the client.\\nThe main disadvantage of using CGI scripts is that the script file is an external pro-\\ngram that executes separately for each user request and therefore causes a resource bot-tleneck. Performance also could be degraded by using an interpreted language or by writing the script inefficiently.\\nAn application programming interface (API) is a newer web server interface stan-\\ndard that is more efficient and faster than a CGI script. APIs are more efficient because they are implemented as shared code or as dynamic-link libraries (DLLs). That means the API is treated as part of the web server program that is dynamically invoked when needed.\\nAPIs are faster than CGI scripts because the code resides in memory, so there is \\nno need to run an external program for each request. Instead, the same API serves all requests. Another advantage is that an API can use a shared connection to the database instead of creating a new one every time, as is the case with CGI scripts.\\nAlthough APIs are more efficient in handling requests, they have some disadvantages. \\nBecause the APIs share the same memory space as the web server, an API error can bring down the web server. Another disadvantage is that APIs are specific to the web server and to the operating system.\\nThe web interface architecture is illustrated in Figure 15.9.\\nCommon Gateway Interface (CGI)\\nA web server interface standard that uses script files to perform specific functions based on a client’s parameters.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1f9d04ff-79e1-4487-ae31-607fcb1ed6c4', embedding=None, metadata={'page_label': '696', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='696   Part 5     Databases and the Internet\\nRegardless of the type of web server interface used, the web-to-database middle -\\nware program must be able to connect with the database. That connection can be \\naccomplished in one of two ways:\\n• Use the native SQL access middleware provided by the vendor. For example, you can \\nuse SQL*Net if you are using Oracle.\\n• Use the services of general database connectivity standards such as ODBC, OLE-DB, \\nADO, ADO.NET, or JDBC.\\n15-2c  The Web Browser\\nThe web browser is software such as Microsoft Internet Explorer, Google Chrome, Apple \\nSafari, or Mozilla Firefox that lets end users navigate the web from their client computer. \\nEach time the end user clicks a hyperlink, the browser generates an HTTP GET page \\nrequest that is sent to the designated web server using the TCP/IP Internet protocol.\\nThe web browser’s job is to interpret  the HTML code that it receives from the web server \\nand to present the various page components in a standard formatted way. Unfortunately, FIGURE 15.9  WEB SERVER CGI AND API INTERFACES  \\nCLIENT\\nCOMPUTER\\nWEB\\nSERVERCGISERVER\\nCOMPUTER\\nRDBMS\\nCOMPUTERAPI\\n(DLL call)TCP/IP\\nnetworkExternal\\nprogram\\nJDBC\\nADO.NET\\nADO\\nOLE-DB\\nODBC\\nRDBMS\\nSERVER\\nDATABASEDatabase Connectivity\\nMiddleware\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='da60fa2d-b3c2-48be-ac3f-f7b3a205cd5c', embedding=None, metadata={'page_label': '697', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    697\\nthe browser’s interpretation and presentation capabilities are not sufficient to develop  \\nweb-based applications. The web is a stateless system—at any given time, a web server \\ndoes not know the status of any of the clients communicating with it. That is, there is no open communication line between the server and each client accessing it, which of course is impractical in a worldwide  web! Instead, client and server computers interact in \\nvery short “conversations” that follow the request-reply model. For example, the browser is concerned only with the current page, so there is no way for the second page to know what was done in the first page. The only time the client and server computers communi-cate is when the client requests a page—when the user clicks a link—and the server sends the requested page to the client. Once the client receives the page and its components, the client/server communication is ended. Therefore, although you may be browsing a page and think  that the communication is open, you are actually just browsing the \\nHTML document stored in the local cache (temporary directory) of your browser. The server does not have any idea what the end user is doing with the document, what data is entered in a form, what option is selected, and so on. On the web, if you want to act on a client’s selection, you need to jump to a new page (go back to the web server), thus losing track of what was done before.\\nThe web browser, through its use of HTML, does not have computational abilities \\nbeyond formatting output text and accepting form field inputs. Even when the browser accepts form field data, there is no way to perform immediate data entry validation. Therefore, to perform such crucial processing in the client, the web defers to other web programming languages such as Java, JavaScript, and VBScript. The browser resembles a dumb terminal that displays only data and can perform only rudimentary processing such as accepting form data inputs. To improve the capabilities of the web browser, you must use plug-ins and other client-side extensions. On the server side, web application servers provide the necessary processing power.\\n15-2d  Client-Side Extensions\\nClient-side extensions add functionality to the web browser. Although client-side extensions are available in various forms, the most common are:\\n•\\n Plug-ins\\n• Java and JavaScript\\n• ActiveX and VBScript\\nA plug-in is an external application that is automatically invoked by the browser \\nwhen needed. The plug-in is associated with a data object—generally using the file exten-\\nsion—to allow the web server to properly handle data that is not originally supported. For example, if one of the page components is a PDF document, the web server will receive the data, recognize it as a Portable Document Format object, and launch Adobe Reader to present the document on the client computer.\\nJavaScript is a scripting language (one that enables the execution of a series of com-\\nmands or macros) that allows web authors to design interactive sites. JavaScript code is embedded in the webpage and executed after a specific event, such as a mouse click on an object or a page being loaded from the server into memory.\\nActiveX is Microsoft’s alternative to Java. ActiveX is a specification for writing pro-\\ngrams that run inside the Microsoft client browser, Internet Explorer. Because ActiveX is oriented toward Windows applications, it has low portability. ActiveX extends the web browser by adding controls to webpages, including drop-down lists, a slider, a calendar, and a calculator. Those controls are downloaded from the web server when needed so you can manipulate data inside the browser. ActiveX controls can be created in several stateless system\\nA system in which a web server does not know the status of the clients communicating with it. The web does not reserve memory to maintain an open communications state between the client and the server.\\nclient-side extension\\nExtension that adds functionality to a web browser. The most common extensions are plug-ins, Java, JavaScript, ActiveX, and VBScript.\\nplug-in\\nOn the web, a client-side, external application that is automatically invoked by the browser when needed to manage specific types of data.\\nJavaScript\\nA scripting language that allows web authors to design interactive websites. JavaScript code is embedded in webpages, and then downloaded with the page and activated when a specific event takes place, such as a mouse click on an object.\\nActiveX\\nMicrosoft’s alternative to Java. A specification for writing programs that will run inside the Microsoft client browser. Oriented mainly to Windows applications, it is not portable. It adds controls such as drop-down windows and calendars to webpages.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7666e199-c6d2-4e6d-b9e6-83fa96db0ca1', embedding=None, metadata={'page_label': '698', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='698   Part 5    Databases and the Internet\\nprogramming languages; C++ and Visual Basic are most commonly used. Microsoft’s \\n.NET framework allows for wider interoperability of ActiveX-based applications (such as ADO.NET) across multiple operating environments.\\nVBScript is another Microsoft product that is used to extend browser functionality. \\nVBScript is derived from Microsoft Visual Basic. Like JavaScript, VBScript code is embedded inside an HTML page and is activated by triggering events such as clicking a link.\\nFrom the developer’s point of view, using routines that permit data validation on the \\nclient side is an absolute necessity. For example, when data is entered in a web form and no data validation is done on the client side, the entire data set must be sent to the web server. That scenario requires the server to perform all data validation, thus wasting valuable CPU processing cycles. Therefore, client-side data input validation is one of the most basic requirements for web applications. Most of the data validation routines are done in Java, JavaScript, ActiveX, or VBScript.\\n15-2e  Web Application Servers\\nA web application server is a middleware application that expands the functionality \\nof web servers by linking them to a wide range of services, such as databases, directory systems, and search engines. The web application server also provides a consistent run-time environment for web applications. Web application servers can be used to perform the following:\\n•\\n Connect to and query a database from a webpage.\\n• Present database data in a webpage using various formats.\\n• Create dynamic web search pages.\\n• Create webpages to insert, update, and delete database data.\\n• Enforce referential integrity in the application program logic.\\n• Use simple and nested queries and programming logic to represent business rules.\\nWeb application servers provide features such as:•\\n An integrated development environment with session management and support for \\npersistent application variables\\n• Security and authentication of users through user IDs and passwords\\n• Computational languages to represent and store business logic in the application server\\n•\\n Automatic generation of HTML pages integrated with Java, JavaScript, VBScript, ASP , and so on\\n•\\n Performance and fault-tolerant features\\n• Database access with transaction management capabilities\\n• Access to multiple services, such as file transfers (FTP), database connectivity, email, and directory services\\nExamples of web application servers include ColdFusion/JRun by Adobe, WebSphere \\nApplication Server by IBM, WebLogic Server by Oracle, Fusion by NetObjects, Visual Studio .NET by Microsoft, and WebObjects by Apple. All web application servers offer the ability to connect web servers to multiple data sources and other services. They vary in their range of available features, robustness, scalability, compatibility with other web and database tools, and extent of the development environment.VBScript\\nA Microsoft client-side extension that extends a browser’s functionality; VBScript is derived from Visual Basic.\\nweb application server\\nA middleware application that expands the functionality of web servers by linking them to a wide range of services, such as databases, directory systems, and search engines.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='79a5d979-0825-4b02-883e-f99d26a9c053', embedding=None, metadata={'page_label': '699', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    699\\n15-2f  Web Database Development\\nWeb database development deals with the process of interfacing databases with \\nthe web browser—in short, how to create webpages that access data in a database. \\nAs you learned earlier in this chapter, multiple web environments can be used to \\ndevelop web database applications. This section presents two simple code exam -\\nples (ColdFusion and PHP). Because this is a database book, the examples focus \\nonly on the commands used to interface with the database rather than the specifics \\nof HTML code.\\nA Microsoft Access database named Ch15_Orderdb  is used to illustrate the \\nweb-to-database interface examples. The Ch15_Orderdb database, whose relational dia -\\ngram is shown in Figure 15.10, was designed to track the purchase orders placed by users \\nin a multidepartment company.\\nThe following examples explain how to use ColdFusion and PHP to create a simple \\nwebpage to list the VENDOR rows. The scripts used in these examples perform two basic \\ntasks:\\n1. Query the database using standard SQL to retrieve a data set that contains all records \\nin the VENDOR table. The examples will use an ODBC data source named Rob -\\nCor. The ODBC data source was defined using the operating system tools shown in \\nSection 15-1b.\\n2. Format the records generated in Step 1 in HTML so they are included in the webpage \\nthat is returned to the client browser.\\nFigure 15.11 shows the ColdFusion code to query the VENDOR table.To see and try a partic -\\nular web-to-database \\ninterface in action, con -\\nsult Appendix J, Web \\nDatabase Development \\nwith ColdFusion, at \\nwww.cengagebrain.com . \\nThis appendix steps you \\nthrough the process of \\ncreating and using a \\nsimple web-to-database \\ninterface, and provides \\nmore detailed informa -\\ntion on developing web \\ndatabases with Adobe \\nColdFusion middleware.Online \\nContent\\nFIGURE 15.10   THE ORDERDB RELATIONAL DIAGRAM FOR WEB \\nDATABASE DEVELOPMENT EXAMPLES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c5fb8ac-f829-42bd-970e-df98a730814b', embedding=None, metadata={'page_label': '700', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='700   Part 5     Databases and the Internet\\nIn the code in Figure 15.11, note that its ColdFusion tags are CFQUERY (to query \\na database) and CFOUTPUT (to display the data returned by the query). Take a closer \\nlook at these two CFML tags:\\n• <CFQUERY>tag (lines 4–6). This tag sets the stage for the database connection and the \\nexecution of the enclosed SQL statement. The CFQUERY tag uses the following parameters:\\n –NAME = “ queryname ” . This name uniquely identifies the record set returned by \\nthe database query.\\n –DATASOURCE = “ datasourcename ” . This parameter uses the previously defined \\nODBC data source name.\\n –The SQL statement (line 5) is the SQL code used to retrieve the data rows from the \\nVENDOR table.\\n• <CFOUTPUT>tag (lines 15–17 and 18–35). This tag is used to display the results \\nfrom a CFQUERY or to call other ColdFusion variables or functions. Its parameters \\nare as follows:\\n –QUERY = “ queryname ” . This is an optional parameter (see line 18). The tag works \\nlike a loop that is executed as many times as the number of rows in the named \\nquery set. Y ou can include any valid HTML tags or text within the opening and \\nclosing CFOUTPUT tags.\\n –ColdFusion uses pound signs (#) to reference query fields in the resulting query \\nset or to call other ColdFusion variables. For example, #venlist.RecordCount# (line \\n16) displays the number of rows returned by the “venlist” query result set.\\n –Lines 19−34 are repeated as a loop, one for each record returned in the named query.\\nFigure 15.12 shows the PHP code to query the VENDOR table.FIGURE 15.11  COLDFUSION CODE TO QUERY THE VENDOR TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='855242d2-e2b9-483a-8ca9-23c1fad5a0a9', embedding=None, metadata={'page_label': '701', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    701\\nIn the figure, note that PHP uses multiple tags to query and display the data returned \\nby the query. Take a closer look at the PHP functions:\\n• The odbc_connect  function (line 11) opens a connection to the ODBC data source.  \\nA handle to this database is set in the $dbc variable.\\n• The odbc_exec  function (line 13) executes the SQL query stored in the $sql variable \\nagainst the $dbc database connection. The query’s result set is stored in the $rs variable.\\n• The while  function (line 15) loops through the result set ($rs) and uses the ODBC_\\nFETCH_ROW function to get one row at a time from the result set. Notice that PHP \\nvariables start with the dollar sign ($).\\n• The odbc_result  function (lines 17−30) gets a column value from a row in the result \\nset and stores it in a variable. This function extracts the different values for each field \\nto be displayed and stores them in variables.\\n• The echo  function (lines 32−47) outputs text to the webpage using the variables \\ndefined in the previous lines. Y ou can also combine text (HTML code) and PHP vari -\\nables (lines 33–46) using the “. ” delimiter.\\n• The odbc_close  function closes the database connection.FIGURE 15.12  PHP CODE TO QUERY THE VENDOR TABLE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2811d95f-120b-4086-b9e1-cff913f5a0fc', embedding=None, metadata={'page_label': '702', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='702   Part 5    Databases and the Internet\\nThe previous examples are just two of the many ways you can interface webpages and \\ndatabases to web applications. These examples only scratch the surface of the multiple \\nfeatures that web application servers provide.\\nCurrent-generation systems involve more than just the development of web-enabled \\ndatabase applications. They also require applications that can communicate with each other and with other systems not based on the web. Clearly, systems must be able to exchange data in a standard-based format. That is the role of XML.\\n15-3  Extensible Markup Language (XML)\\nCompanies use the Internet to generate business transactions and integrate data to increase efficiency and reduce costs. These transactions are known as electronic com-merce (e-commerce); it enables all types of organizations to sell products and services to a global market. E-commerce transactions—the sale of products or services—can take place between businesses (business-to-business, or B2B) or between a business and a consumer (business-to-consumer, or B2C).\\nMost e-commerce transactions take place between businesses. Because B2B \\ne-commerce integrates business processes among companies, it requires the trans-fer of business information among different business entities. However, the way in which businesses represent, identify, and use data tends to differ substantially from company to company. As a simple example, some companies use the term product code , while others use item ID.\\nUntil recently, a purchase order traveling over the web was expected to be in the \\nform of an HTML document. The HTML webpage displayed on the web browser would include formatting as well as the order details. HTML tags describe how something looks  on the webpage, such as typefaces and heading styles, and they often come in pairs \\nto start and end formatting features. For example, the following tags in angle brackets would display FOR SALE in bold Arial font:\\n<strong><font face=Arial>FOR SALE</font><strong>\\nIf an application needs to get the order data from the webpage, there is no easy way to \\nextract details such as the order number, date, customer number, product code, quantity, \\nor price from an HTML document. The HTML document can only describe how to dis-play the order in a web browser; it does not permit the manipulation of the order’s data elements. To solve that problem, a new markup language known as Extensible Markup Language was developed.\\nExtensible Markup Language (XML) is a meta-language used to represent and \\nmanipulate data elements. XML is designed to facilitate the exchange of structured doc-uments, such as orders and invoices, over the Internet. The World Wide Web Consor -\\ntium (W3C) published the first XML 1.0 standard definition in 1998, setting the stage for giving XML the real-world appeal of being a true vendor-independent platform. It is not surprising that XML has rapidly become the data exchange standard for e-commerce applications.\\nThe XML meta-language allows the definition of new tags, such as <ProdPrice>, \\nto describe the data elements used in an XML document. This ability to extend the language explains the X  in XML; the language is said to be extensible. XML is derived \\nfrom the Standard Generalized Markup Language (SGML), an international stan-dard for the publication and distribution of highly complex technical documents. For example, documents used by the aviation industry and the military services are too complex and unwieldy for the web. Just like HTML, which was also derived from tag\\nIn markup languages such as HTML and XML, a command inserted in a document to specify how the document should be formatted. Tags are used in server-side markup languages and interpreted by a web browser for presenting data.\\nExtensible Markup Language (XML)\\nA meta-language used to represent and manipulate data elements. Unlike other markup languages, XML permits the manipulation of a document’s data elements. XML facilitates the exchange of structured documents such as orders and invoices over the Internet.Online \\nContent\\nTo learn more about \\ne-commerce, consult Appendix I, Databases in Electronic Commerce, at www.cengagebrain.com.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fe35cddc-7628-4586-874e-07b497a3b7f1', embedding=None, metadata={'page_label': '703', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    703\\nSGML, an XML document is a text file. However, it has a few important additional \\ncharacteristics:\\n• XML allows the definition of new tags to describe data elements.\\n• XML is case sensitive: <ProductID>is not the same as <Productid>.\\n• XML must be well formed; that is, tags must be properly formatted. Most openings \\nalso have a corresponding closing. For example, a product’s identification would \\nrequire the format <ProductId>2345-AA</ProductId>.\\n• XML must be properly nested. For example, properly nested XML might look like \\nthis: <Product><ProductId>2345-AA</ProductId></Product>.\\n• Y ou can use the <‐‐ and ‐‐> symbols to enter comments in the XML document.\\n• The XML  and xml prefixes are reserved for XML only.\\nXML is not a new version or replacement for HTML. XML is concerned with the \\ndescription and representation of the data, rather than the way the data is displayed. \\nXML provides the semantics that facilitate the sharing, exchange, and manipulation \\nof structured documents over organizational boundaries. XML and HTML perform \\ncomplementary functions rather than overlapping functions. Extensible Hypertext \\nMarkup Language (XHTML) is the next generation of HTML based on the XML \\nframework. The XHTML specification expands the HTML standard to include XML \\nfeatures. Although it is more powerful than HTML, XHTML requires strict adherence \\nto syntax requirements.\\nTo illustrate the use of XML for data exchange purposes, consider a B2B example in \\nwhich Company A uses XML to exchange product data with Company B over the Inter -\\nnet. Figure 15.13 shows the contents of the productlist.xml document.\\nFIGURE 15.13  CONTENTS OF THE PRODUCTLIST.XML DOCUMENT  \\nThe preceding example illustrates several important XML features:\\n• The first line represents the XML document declaration, and it is mandatory.\\n• Every XML document has a root element . In the example, the second line declares the \\nProductList root element.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4b95e1e6-5337-4ade-bc31-27fab287b12a', embedding=None, metadata={'page_label': '704', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='704   Part 5     Databases and the Internet\\n• The root element contains child elements  or subelements. In the example, line 3 \\ndeclares Product as a child element of ProductList.\\n• Each element can contain subelements . For example, each Product element is com -\\nposed of several child elements, represented by P_CODE, P_DESCRIPT, P_INDATE, \\nP_QOH, P_MIN, and P_PRICE.\\nOnce Company B receives productlist.xml, it can process the document, assuming \\nthat it understands the tags created by Company A. The meaning of the XML in Fig -\\nure 15.13 is fairly self-evident, but there is no easy way to validate the data or to check \\nwhether the data is complete. For example, you could encounter a P_INDATE value of \\n“25/14/2016, ” but is that value correct? What happens if Company B expects a Vendor \\nelement as well? How can companies share data descriptions about their business data \\nelements? The next section shows how document type definitions and XML schemas are \\nused to address such concerns.\\n15-3a  Document Type Definitions (DTD) and XML Schemas\\nCompanies that use B2B transactions must have a way to understand and validate each \\nother’s tags. One way to accomplish that task is through the use of document type defi -\\nnitions. A document type definition (DTD)  is a file with a .dtd extension that describes \\nXML elements—in effect, a DTD file provides the composition of the database’s logical \\nmodel and defines the syntax rules or valid elements for each type of XML document. \\n(The DTD component is similar to having a public data dictionary for business data.) \\nCompanies that intend to engage in e-commerce transactions must develop and share \\nDTDs. Figure 15.14 shows the productlist.dtd document for the productlist.xml docu -\\nment shown earlier in Figure 15.13.\\nFIGURE 15.14  CONTENTS OF THE PRODUCTLIST.DTD DOCUMENT  \\nIn Figure 15.14, the productlist.dtd file provides definitions of the elements in the \\nproductlist.xml document. In particular, note the following:\\n• The first line declares the ProductList root element.\\n• The ProductList root element has one child, the Product element. The second line \\ndescribes the Product element.\\n• The plus symbol (+) indicates that Product occurs one or more times within \\nProductList.\\n• An asterisk (*) would mean that the child element occurs zero or more times.\\n• The question mark (?) after P_INDATE and P_MIN indicates that they are optional \\nchild elements.\\n• The third through eighth lines show that the Product element has six child elements.\\n• The #PCDATA keyword represents the actual text data.document type \\ndefinition (DTD)\\nA file with a .dtd \\nextension that describes \\nXML elements; in effect, \\na DTD file describes a \\ndocument’s composition \\nand defines the syntax \\nrules or valid tags for \\neach type of XML \\ndocument.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='91cfa7c5-66c3-40da-be98-9c1bf244f828', embedding=None, metadata={'page_label': '705', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    705\\nTo be able to use a DTD file to define elements within an XML document, \\nthe DTD must be referenced within that XML document. Figure 15.15 shows the \\nproductlistv2.xml document that includes the reference to productlist.dtd in the \\nsecond line.\\nIn Figure 15.15, note that P_INDATE and P_MIN do not appear in all Product defini -\\ntions because they were declared to be optional elements. The DTD can be referenced by \\nmany XML documents of the same type. For example, if Company A routinely exchanges \\nproduct data with Company B, it will need to create the DTD only once. All subsequent \\nXML documents will refer to the DTD, and Company B will be able to verify the data \\nbeing received.\\nTo further demonstrate the use of XML and DTD for e-commerce data exchanges, \\nconsider the case of two companies exchanging order data. Figure 15.16 shows the DTD \\nand XML documents for that scenario.\\nAlthough the use of DTDs is a great improvement for data sharing over the web, \\na DTD only provides descriptive information for understanding how the elements—\\nroot, parent, child, mandatory, or optional—relate to one another. A DTD provides lim -\\nited additional semantic value, such as data type support or data validation rules. That \\ninformation is very important for database administrators who are in charge of large \\ne-commerce databases. To solve the DTD problem, the W3C published an XML schema \\nstandard that better describes XML data.\\nThe XML schema  is an advanced data definition language that is used to \\ndescribe the structure of XML data documents. This structure includes elements, \\ndata types, relationship types, ranges, and default values. One of the main advan -\\ntages of an XML schema is that it more closely maps to database terminology and \\nfeatures. For example, an XML schema can define common database types such as \\ndate, integer, or decimal; minimum and maximum values; a list of valid values; and \\nrequired elements. Using the XML schema, a company would be able to validate \\ndata for values that may be out of range, have incorrect dates, contain invalid val -\\nues, and so on. For example, a university application must be able to specify that \\na GPA value is between 0 and 4.0, and it must be able to detect an invalid birth \\ndate such as “14/13/2016. ” (There is no 14th month.) Many vendors are adopting \\nthis new standard and are supplying tools to translate DTD documents into XML \\nschema definition documents. It is widely expected that XML schemas will replace \\nDTD as the method to describe XML data.FIGURE 15.15  CONTENTS OF THE PRODUCTLISTV2.XML DOCUMENT  \\nXML schema\\nAn advanced data \\ndefinition language used \\nto describe the elements, \\ndata types, relationship \\ntypes, ranges, and \\ndefault values of XML \\ndata documents. One of \\nthe main advantages of \\nan XML schema is that \\nit more closely maps to \\ndatabase terminology \\nand features.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fcd1f26f-a59a-4889-bba8-8db2e52de52a', embedding=None, metadata={'page_label': '706', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='706   Part 5     Databases and the Internet\\nUnlike a DTD document, which uses a unique syntax, an XML schema definition \\n(XSD)  file uses a syntax that resembles an XML document. Figure 15.17 shows the XSD \\ndocument for the OrderData XML document.\\nThe code shown in Figure 15.17 is a simplified version of the XML schema document. \\nAs you can see, the XML schema syntax is similar to the XML document syntax. How -\\never, the XML schema introduces additional semantic information for the OrderData \\nXML document, such as string, date, and decimal data types; required elements; and \\nminimum and maximum cardinalities for the data elements.\\n15-3b  XML Presentation\\nOne of the main benefits of XML is that it separates data structure from its presentation \\nand processing. By separating the two, you can present the same data in different ways—\\nwhich is similar to having views in SQL. The Extensible Style Language (XSL) specifi -\\ncation provides the mechanism to display XML data. XSL is used to define the rules by \\nwhich XML data is formatted and displayed. The XSL specification is divided into two \\nparts: Extensible Style Language Transformations (XSLT) and XSL style sheets. \\n• Extensible Style Language Transformations (XSLT)  describes the general mechanism that \\nis used to extract and process data from one XML document and enable its transforma -\\ntion within another document. Using XSLT, you can extract data from an XML docu -\\nment and convert it into a text file, an HTML webpage, or a webpage that is formatted FIGURE 15.16  DTD AND XML DOCUMENTS FOR ORDER DATA  \\nOrderData.dtd\\nOrderData.xml“+” sign indicates\\none or more\\nORD_PRODS elements\\nTwo ORD_PRODS\\n elements in XML\\ndocument\\nXML schema \\ndefinition (XSD)\\nA file that contains the \\ndescription of an XML \\ndocument.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f26cad8-07d4-4b72-9d30-617c04159a3d', embedding=None, metadata={'page_label': '707', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    707\\nfor a mobile device. What the user sees in those cases is actually a view (or HTML rep -\\nresentation) of the XML data. XSLT can also be used to extract certain elements from an \\nXML document, such as product codes and product prices, to create a product catalog. \\nXSLT can even be used to transform one XML document into another.\\n• XSL style sheets  define the presentation rules applied to XML elements—somewhat \\nlike presentation templates. The XSL style sheet describes the formatting options to \\napply to XML elements when they are displayed on a browser, smartphone, tablet \\nscreen, and so on.\\nFigure 15.18 illustrates the framework used by the various components to translate \\nXML documents into viewable webpages, an XML document, or some other document.FIGURE 15.17  THE XML SCHEMA DOCUMENT FOR THE ORDER DATA  \\nFIGURE 15.18  FRAMEWORK FOR XML TRANSFORMATIONS  \\nHTML\\nXML\\ndocument\\nHTMLXSL\\ntransformationsXSL\\nstyle sheets\\n•Extract\\n•Convert\\nXSLT can be used to transform one XML\\ndocument into another XML document.Apply\\nformatting\\nrules to\\nXML\\nelements The process can render\\ndifferent webpages\\nfor different purposes,\\nsuch as one page for a\\nweb browser and\\nanother for a mobile device.New\\nXML\\ndocument\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0e4f2ce6-07df-4968-823e-916de2c069e3', embedding=None, metadata={'page_label': '708', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='708   Part 5     Databases and the Internet\\n15-3c  XML Applications\\nNow that you have some idea what XML is, how can you use it? What kinds of appli -\\ncations lend themselves particularly well to XML? This section lists some of the uses of \\nXML. Keep in mind that the future use of XML is limited only by the imagination and \\ncreativity of developers, designers, and programmers. \\n• B2B exchanges . XML enables the exchange of B2B data, providing the standard for all \\norganizations that need to exchange data with partners, competitors, the government, \\nor customers. In particular, XML is positioned to replace EDI as the standard for \\nautomation of the supply chain because it is less expensive and more flexible.\\n• Legacy systems integration . XML provides the “glue” to integrate legacy system data with \\nmodern e-commerce web systems. Web and XML technologies could be used to inject \\nsome new life into old but trusted legacy applications. Another example is the use of \\nXML to import transaction data from multiple databases to a data warehouse database.\\n• Webpage development . XML provides several features that make it a good fit for cer -\\ntain web development scenarios. For example, web portals with large amounts of per -\\nsonalized data can use XML to pull data from multiple external sources (such as news, \\nweather, and stock sites) and apply different presentation rules to format pages on \\ndesktop computers as well as mobile devices.\\n• Database support . A DBMS that supports XML exchanges can integrate with external \\nsystems such as the web, mobile data, and legacy systems, thus enabling the creation To display the XML document with Windows Internet Explorer (IE), enter the URL \\nof the XML document in the browser’s address bar. Figure 15.19 is based on the product -\\nlist.xml document created earlier. As you examine Figure 15.19, note that IE shows the \\nXML data in a color-coded, collapsible, tree-like structure. (Actually, this is the IE default \\nstyle sheet that is used to render XML documents.)\\nFIGURE 15.19  DISPLAYING XML DOCUMENTS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='92df1598-42eb-47a5-9379-0027a3a2a8a1', embedding=None, metadata={'page_label': '709', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    709\\nof new types of systems. These databases can import or export data in XML format \\nor generate XML documents from SQL queries while still storing the data using their native data model format. An example is the use of the FOR XML clause in the SQL SELECT statement in SQL Server. Alternatively, a DBMS can also support an XML data type to store XML data in its native format—enabling support to store tree-like hierarchical structures inside a relational structure.\\n•\\n Database metadictionaries . XML is also used to create metadictionaries, or vocabular -\\nies, for entire industries. Examples of metadictionaries include HR-XML for the human resources industry, the metadata encoding and transmission standard (METS) from the Library of Congress, the clinical accounting information (CLAIM) data exchange standard for patient data exchange in electronic medical record systems, and the extensible business reporting language (XBRL) standard for exchanging business and financial information.\\n•\\n XML databases.1 Most databases on the market support XML to manage data in some \\nshape or form. The approaches range from simple middleware XML software to object databases with XML interfaces to full XML database engines and servers. XML data-bases provide for the storage of data in complex relationships. For example, an XML database would be well suited to store the contents of a book. The book’s structure would dictate its database structure: a book typically consists of chapters, sections, paragraphs, figures, charts, footnotes, endnotes, and so on. Examples of databases with XML data type support are Oracle, IBM DB2, and MS SQL Server. Fully XML databases examples are Tamino from Software AG (www.softwareag.com) and the open source dbXML from http://sourceforge.net/projects/dbxml-core.\\n•\\n XML services. Many companies are already working to develop a new breed of services based on XML and web technologies. These services break down the interoperability barriers among systems and companies alike. XML provides the infrastructure that helps heterogeneous systems to work together across the desk, the street, and the world. Services would use XML and other Internet technologies to publish their interfaces. Other services that want to interact with existing ser -\\nvices would locate them and learn their vocabulary (service request and replies) to establish a “conversation. ”\\nOne area in which Internet, web, virtualization, and XML technologies work together \\nin innovative ways to leverage IT services is cloud computing.\\n15-4  Cloud Computing Services\\nY ou have almost certainly heard about the “cloud” from the thousands of publica-tions and TV ads that have used the term over the years, although it has represented different concepts. In the late 1980s, the term cloud  was used by telecommunication \\ncompanies to describe their data networks. In the late 1990s, during the peak of Internet growth, the term depicted the Internet itself. Then, in 2006, Google and Amazon began using the term cloud computing  to describe a new set of innovative \\nweb-based services. Google, Y ahoo, eBay, and Amazon were early adopters of this new computing paradigm.\\nBut what exactly is cloud computing? According to the National Institute of Standards \\nand Technology (NIST),\\n2 cloud computing is “a computing model for enabling ubiquitous, \\nconvenient, on-demand network access to a shared pool of configurable computer resources \\n1  For a comprehensive analysis of XML database products, see “XML Database Products” by Ronald Bourret \\nat www.rpbourret.com .\\n2  Recommendations of the National Institute of Standards and Technology, Peter Mell and Timothy Grance, Special Publication 800–145 (Draft), January 2011.cloud computing\\nA computing model that \\nprovides ubiquitous, on-demand access to a shared pool of configurable resources that can be rapidly provisioned.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b39f91b6-f25d-4d7a-856e-d24dd717b1ee', embedding=None, metadata={'page_label': '710', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='710   Part 5     Databases and the Internet\\n(e.g., networks, servers, storage, applications and services) that can be rapidly provisioned \\nand released with minimal management effort or service provider interaction. ” The term \\ncloud services  is used in this book to refer to the services provided by cloud computing. \\nCloud services allow any organization to quickly and economically add information tech -\\nnology services such as applications, storage, servers, processing power, databases, and infra -\\nstructure to its IT portfolio. Figure 15.20 shows a representation of cloud computing services \\non the Internet.\\nCloud computing allows IT-savvy organizations such as Amazon, Google, and Microsoft \\nto build high-performance, fault-tolerant, flexible, and scalable IT services. These services \\ninclude applications, storage, servers, processing power, databases, and email, which are deliv -\\nered via the Internet to individuals and organizations using a pay-as-you-go price model.\\nFor example, imagine that the chief technology officer of a nonprofit organization \\nwants to add email services to the IT portfolio. A few years ago, this proposition would \\nhave implied building the email system’s infrastructure from the ground up, includ -\\ning hardware, software, setup, configuration, operation, and maintenance. However, \\nin today’s cloud computing era, you can use Google Apps for Business or Microsoft  \\nExchange Online and get a scalable, flexible, and more reliable email solution for a frac -\\ntion of the cost. The best part is that you do not have to worry about the daily chores of \\nmanaging and maintaining the IT infrastructure, such as OS updates, patches, security, \\nfault tolerance, and recovery. What used to take months or years to implement can now \\nbe done in a matter of minutes. If you need more space, you just add another storage unit \\nto your storage cloud. If you need more processing power to handle last-minute orders \\nduring the busy holiday season, you simply add more processing units to your cloud \\nservers. Even more importantly, you can scale down as easily as you scaled up. Once \\nyour need for additional processing or storage subsides, you can go back to your previous FIGURE 15.20  CLOUD SERVICES  \\nCloud\\nService\\nProviders• Email\\n• Storage\\n• RDBMS\\nContent\\nDelivery\\nSimple\\nMessaging\\nSimple\\nQueuing\\nElastic\\nComputeNoSQL\\nDBRelational\\nDBSimple\\nStorage• Desktop\\n• Server\\n• NoSQL\\ncloud services\\nThe services provided \\nby cloud computing. \\nCloud services allow any \\norganization to quickly \\nand economically add \\ninformation technology \\nservices such as \\napplications, storage, \\nservers, processing \\npower, databases, and \\ninfrastructure.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5e927985-6b60-4931-a9f9-9347a1e6e128', embedding=None, metadata={'page_label': '711', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    711\\nlevels of usage and pay only for what you use. The beauty of cloud services is that you can \\nscale down automatically, without an administrator’s intervention.\\nCloud computing is important for database technologies because it has the potential \\nto become a “game changer. ” Cloud computing eliminates financial and technological \\nbarriers so organizations can leverage database technologies in their business processes \\nwith minimal effort and cost. In fact, cloud services have the potential to turn basic IT \\nservices into “commodity” services such as electricity, gas, and water, and to enable a \\nrevolution that could change not only the way that companies do business, but the IT \\nbusiness itself. As Nicholas Carr put it so vividly: “Cloud computing is for IT what the \\ninvention of the power grid was for electricity. ”3\\nThe technologies that make cloud computing work have been around for a few years \\nnow; these technologies include the web, messaging, virtualization, remote desktop proto -\\ncols, VPN, and XML. However, cloud computing itself is still in the early years and needs to \\nmature further before it can be widely adopted. Despite this, more and more organizations \\nare tapping into cloud services to secure advanced database services (relational or NoSQL) \\nfor their organizations. Currently, you can log in to Amazon Web Services (AWS) or  \\nMicrosoft Azure and have a relational database ready for use in a matter of minutes. Instead \\nof spending large amounts of cash buying hardware and software, organizations can employ \\na pay-per-use model for their IT services. Figure 15.21 depicts the cost of provisioning a \\nrelational database instance in Microsoft Azure and Amazon RDS services, respectively.\\n3 Nicholas Carr, The Big Switch: Rewiring the World, from Edison to Google . W .W . Norton & Co., 2009.FIGURE 15.21  PROVISIONING RDBMS IN THE CLOUD  \\nProvisioning a MySQL RDBMS\\ninstance in\\nAmazon Web Services (AWS)\\nProvisioning MS SQL Azure RDBMS\\ninstance in\\nMicrosoft Azure\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='36f04ed8-13ef-492b-87f9-345ca411837e', embedding=None, metadata={'page_label': '712', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='712   Part 5    Databases and the Internet\\nAlthough Figure 15.21 shows a cloud that requires some degree of customization on \\nthe customer’s part, other cloud computing services are more transparent to the user and \\nrequire less customization. For example, Dropbox is a simple cloud service that lets you synchronize your documents, photos, music, and other files transparently over the Inter -\\nnet across many devices. Apple provides a similar service, known as iCloud, to seam-lessly exchange data among all its mobile and nonmobile devices. Both services work transparently behind the scenes with minimal end-user intervention. As you can see, cloud computing implementations vary; the next section explains the basic types.\\n15-4a  Cloud Implementation Types\\nCloud computing has different types of implementations based on who the target cus-tomers are:\\n•\\n Public cloud. This type of cloud infrastructure is built by a third-party organiza-\\ntion to sell cloud services to the general public. The public cloud is the most com-mon type of cloud implementation; examples include Amazon Web Services (AWS), Google Application Engine, and Microsoft Azure. In this model, cloud consumers share resources with other consumers transparently. The public cloud infrastructure is managed exclusively by the third-party provider.\\n•\\n Private cloud. This type of internal cloud is built by an organization for the sole pur -\\npose of servicing its own needs. Private clouds are often used by large, geographically dispersed organizations to add agility and flexibility to internal IT services. The cloud infrastructure could be managed by internal IT staff or an external third party.\\n•\\n Community cloud. This type of cloud is built by and for a specific group of organi-zations that share a common trade, such as agencies of the federal government, the military, or higher education. The cloud infrastructure could be managed by internal IT staff or an external third party.\\nRegardless of the implementation an organization uses, most cloud services share a \\ncommon set of core characteristics. These characteristics are explored in the next section.\\n15-4b  Characteristics of Cloud Services\\nCloud computing services share a set of guiding principles. The characteristics listed in this section are shared by prominent public cloud providers such as Amazon, Google, Salesforce, SAP , and Microsoft. The prevalent characteristics are:\\n•\\n Ubiquitous access via Internet technologies . All cloud services use Internet and web \\ntechnologies to provision, deliver, and manage the services they provide. The basic \\nrequirement is that the device has access to the Internet.\\n• Shared infrastructure . The cloud service infrastructure is shared by multiple users. \\nSharing is made possible by web and virtualization technologies. Cloud services effectively provide an organization with a virtual IT infrastructure, which is locally managed by the consumer’s organization as if it were the only user of the infrastructure.\\n•\\n Lower costs and variable pricing. The initial costs of using cloud services tend to be sig-nificantly lower than building on-premise IT infrastructures. According to some stud -\\nies,\\n4 the savings could range from 35 percent to 55 percent depending on company \\n4  “The Compelling TCO Case for Cloud Computing in SMB and Mid-Market Enterprises: A 4-year total \\ncost of ownership (TCO) perspective comparing cloud and on-premise business application development, ” Sanjeev Aggarwal, Partner; Laurie McCabe, Partner: Hurwitz & Associates, 2009.public cloud\\nA form of computing \\nin which the cloud infrastructure is built by a third-party organization to sell cloud services to the general public.\\nprivate cloud\\nA form of cloud computing in which an internal cloud is built by an organization to serve its own needs.\\ncommunity cloud\\nA type of cloud built by and for a specific group of organizations that share a common trade, such as agencies of the federal government, the military, or higher education.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04e4a721-7de0-4ecd-97b3-427c5fac6049', embedding=None, metadata={'page_label': '713', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    713\\nsize, although more research is needed in this area. Because the web service’s usage is \\nmetered per volume and time utilization, consumers benefit from lower and flexible pricing options. These options range from pay-as-you-go to fixed pricing based on min -\\nimum levels of service.\\n•\\n Flexible and scalable services. The cloud services are built on an infrastructure that is highly scalable, fault tolerant, and very reliable. The services can scale up and down on demand according to resource demands.\\n•\\n Dynamic provisioning . The consumer can quickly provision any needed resources, \\nincluding servers, processing power, storage, and email, by accessing the web man-agement dashboard and then adding and removing services on demand. This process also could be automated via other services.\\n•\\n Service orientation . Cloud computing focuses on providing consumers with specific, \\nwell-defined services that use well-known interfaces. These interfaces hide the com-plexity from the end user, and can be delivered anytime and anywhere.\\n•\\n Managed operations. Cloud computing minimizes the need for extensive and expen-sive in-house IT staff. The system infrastructure is managed by the cloud provider. The consumer organization’s IT staff is free from routine management and maintenance tasks so they can focus on other tasks within the organization. Managed operations apply to organizations that use public clouds and that outsource cloud management to an external third party.\\nThe preceding list is not exhaustive, but it is a starting point to understand most \\ncloud computing offerings. Although most companies move to cloud services because of cost savings, some companies move to them because they are the best way to gain access to specific IT resources that would otherwise be unavailable. Not all cloud ser -\\nvices are the same; in fact, there are several different types, as explained in the next section.\\n15-4c  Types of Cloud Services\\nCloud services come in different shapes and forms; no single type of service works for all consumers. In fact, cloud services often follow an à la carte model; consumers can choose multiple service options according to their individual needs. These services can build on top of each other to provide sophisticated solutions. Based on the types of services pro-vided, cloud services can be classified by the following categories:\\n•\\n Software as a Service (SaaS). The cloud service provider offers turnkey applications that \\nrun in the cloud. Consumers can run the provider’s applications internally in their organi-zations via the web or any mobile device. The consumer can customize certain aspects of the application but cannot make changes to the application itself. The application is actu-ally shared among users from multiple organizations. Examples of SaaS include MS Office 365, Google Docs, Intuit’s TurboTax Online, and SCALA digital signage.\\n•\\n Platform as a Service (PaaS). The cloud service provider offers the capability to build and deploy consumer-created applications using the provider’s cloud infrastructure. In this scenario, the consumer can build, deploy, and manage applications using the provider’s cloud tools, languages, and interfaces. However, the consumer does not manage the underlying cloud infrastructure. Examples of PaaS include the Micro-soft Azure platform with .NET and the Java development environment, and Google Application Engine with Python or Java.\\n•\\n Infrastructure as a Service (IaaS). In this case, the cloud service provider offers con-sumers the ability to provision their own resources on demand; these resources include Software as a Service (SaaS)\\nA model in which the cloud service provider offers turnkey applications that run in the cloud.\\nPlatform as a Service (PaaS)\\nA model in which the cloud service provider can build and deploy consumer-created applications using the provider’s cloud infrastructure.\\nInfrastructure as a Service (IaaS)\\nA model in which the cloud service provider offers consumers the ability to provision their own resources on demand; these resources include storage, servers, databases, processing units, and even a complete virtualized desktop.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f46ca27b-d952-4221-9e1d-d05b4d2a8069', embedding=None, metadata={'page_label': '714', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='714   Part 5     Databases and the Internet\\nstorage, servers, databases, processing units, and even a complete virtualized desktop. \\nThe consumer then can add or remove the resources as needed. For example, a con -\\nsumer can use Amazon Web Services (AWS) and provision a server computer that runs \\nLinux and Apache Web server using 16 GB of RAM and 160 GB of storage.\\nFigure 15.22 illustrates a sample of the different types of cloud services; these services \\ncan be accessed from any computing device.\\nCloud computing services have evolved in their sophistication and flexibility. The \\nmerging of new technologies has enabled the creation of new options such as “desktop as \\na service, ” which effectively creates a virtual computer on the cloud that can be accessed \\nfrom any device over the Internet. For example, you can use a service such as Desktone \\n(http://www.vmwhorizonair.com/ ) and get a Windows desktop running over the web for \\nyour personal use in a matter of minutes. Moreover, you can access your virtual desktop \\nvia the web browser or using any Remote Desktop Protocol (RDP) application.\\n15-4d  Cloud Services: Advantages and Disadvantages\\nCloud computing has grown remarkably in the past few years. Companies of all sizes \\nare enjoying the advantages of cloud computing, but its widespread adoption is still lim -\\nited by several factors. Table 15.4 summarizes the main advantages and disadvantages of \\ncloud computing.FIGURE 15.22  TYPES OF CLOUD SERVICES  \\nInternetServers\\nLaptops\\nDesktopsTablets\\nSmartphones\\nSoftware as a Service\\n• MS Ofﬁce 365, MS Exchange Online\\n• Google Docs, Google Email\\n• Salesforce CRM Online\\n• SAP Business ByDesign\\nPlatform as a Service\\n• Amazon Web Services, Amazon Relational Data Service, Amazon Simple DB\\n• MS Azure Platform, MS SQL Service\\n• Google Application Engine\\nInfrastructure as a Service\\n• Amazon Web Services Elastic Computing Cloud 2 (EC2)\\n• Amazon Elastic MapReduce Service\\n• Amazon Simple Storage Service (S3)\\n• Amazon Elastic Load Balancing Service\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f68389bc-c24e-45a8-98ab-e8a1bf7a6d71', embedding=None, metadata={'page_label': '715', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    715\\nAs the table shows, the top-perceived benefit of cloud computing is the lower cost of \\nentry. At the same time, the chief concern of cloud computing is data security and pri-\\nvacy, particularly in companies that deal with sensitive data and are subject to high levels of regulation and compliance. This concern leads to the perception that cloud services are mainly implemented in small to medium-sized companies where the risk of service loss is minimal. In fact, some companies that are subject to strict data security regula-tions tend to favor private clouds rather than public ones.\\nOne of the biggest growth segments in cloud services is mobile computing. For \\nexample, Netflix, the video-on-demand trailblazer, moved significant parts of its IT infrastructure to AWS. Netflix decided to move to the cloud because of the challenges of building IT infrastructure fast enough to keep up with its relentless growth.TABLE 15.4\\nADVANTAGES AND DISADVANTAGES OF CLOUD COMPUTING\\nADVANTAGE DISADVANTAGE\\nLow initial cost of entry. Cloud computing has lower costs of entry when compared with the alternative of building in house.Issues of security, privacy, and compliance. Trusting sensitive company data to external entities is difficult for most data-cautious organizations.\\nScalability/elasticity. It is easy to add and remove resources on demand.Hidden costs of implementation and operation. It is hard to estimate bandwidth and data migration costs.\\nSupport for mobile computing. Cloud computing providers support multiple types of mobile computing devices.Data migration is a difficult and lengthy process. Migrating large amounts of data to and from the cloud infrastructure can be difficult and time-consuming.\\nUbiquitous access. Consumers can access the cloud resources from anywhere at any time, as long as they have Internet access.Complex licensing schemes. Organizations that implement cloud services are faced with complex licensing schemes and complicated service-level agreements.\\nHigh reliability and performance. Cloud providers build solid infrastructures that otherwise are difficult for the average organization to leverage.Loss of ownership and control. Companies that use cloud services are no longer in complete control of their data. What is the responsibility of the cloud provider if data are breached? Can the vendor use your data without your consent?\\nFast provisioning. Resources can be provisioned on demand in a matter of minutes with minimal effort.Organization culture. End users tend to be resistant to change. Do the savings justify being dependent on a single provider? Will the cloud provider be around in 10 years?\\nManaged infrastructure. Most cloud implementations are managed by dedicated internal or external staff. This allows the organization’s IT staff to focus on other areas.Difficult integration with internal IT system. Configuring the cloud services to integrate transparently with internal authentication and other internal services could be a daunting task.\\nCloud Reality Check: Is the Cloud Enterprise-Ready?\\nCloud service outages and security breach incidents are reported every year. Such inci-dents affect all types and sizes of organizations from data breaches in large universities to service interruptions in cloud infrastructure providers. Some are very public, such as the iCloud security breach that allowed hackers to steal thousands of private pictures from well-known celebrities. Other incidents could affect millions of people all over the world, such as recent interruptions in social media services (Instagram, Vines, and Twitter.) These incidents can cause service interruption, data loss, performance degradation, or cost mil-lions of dollars in lost business.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed5261b9-59d3-448d-add6-5c615dae6bae', embedding=None, metadata={'page_label': '716', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='716   Part 5    Databases and the Internet\\nRegardless of a company’s size, databases remain at the center of all system devel-\\nopment. Cloud computing brings a new dimension to data management that is within \\nreach of any type of organization.\\n15-4e  SQL Data Services\\nAs you have seen in this chapter, data access technologies have evolved from simple ODBC data retrieval to advanced remote data processing using ADO.NET and XML. At the same time, companies are looking for ways to better manage ever-growing amounts of data while controlling costs without sacrificing data management features. Cloud computing provides a relatively stable and reliable platform for developing and deploy-ing business services; cloud vendors have expanded their business to offer SQL data ser -\\nvices. SQL data services (SDS) refers to a cloud computing-based data management \\nservice that provides relational data storage, access, and management to companies of all sizes without the typically high costs of in-house hardware, software, infrastructure, and personnel. This type of service provides some unique benefits:\\n•\\n Hosted data management. SDS typically uses a cluster of database servers that provide \\na large subset of database functionality over the Internet to database administrators and users. Typically, features such as SQL queries, indexing, stored procedures, trig-gers, reporting, and analytical functions are available to end users. Other features such as data synchronization, data backup and restore, and data importing and exporting are available for administrative purposes.\\n•\\n Standard protocols . SDS uses standard data communication and relational data access \\nprotocols. Typically, these services encapsulate SQL networking protocols, such as SQL-Net for Oracle databases and Tabular Data Services (TDS) for Microsoft SQL Server databases, inside the TCP/IP networking protocol.\\n•\\n A common programming interface . SDS is transparent to application developers. \\nProgrammers continue to use familiar programming interfaces such as ADO.NET and Visual Studio .NET to manipulate the data. Programmers write embedded SQL code in their applications and connect to the database as if the data was stored locally instead of in a remote location on the Internet. One potential disadvantage, however, is that some specialized data types may not be supported by SDS.\\nSQL data services offer the following advantages when compared with in-house systems:\\n•\\n Highly reliable and scalable relational database for a fraction of the cost\\n• High level of failure tolerance because data is normally distributed and replicated among multiple servers\\n•\\n Dynamic and automatic load balancing\\n• Automated data backup and disaster recovery included with the service\\n• Dynamic creation and allocation of database processes and storage\\nCloud providers such as Amazon and Microsoft allow you to get your own database \\nserver running in a matter of minutes. Even better, you do not have to worry about backups, fault tolerance, scalability, and routine maintenance tasks. The use of SQL data services enables rapid application development for businesses with limited information technology resources, and allows them to rapidly deploy business solutions. A consumer of cloud services is free to use the database to create the best solution for the problem at hand. However, having access to relational database technology via a SQL data service is just the start—you still need to be knowledgeable in database design and SQL to develop high-quality applications.SQL data services (SDS)\\nData management services that provide relational data storage, access, and management over the Internet.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='88ad793a-4925-406a-b1dd-9822f19a29a2', embedding=None, metadata={'page_label': '717', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    717\\n• Database connectivity refers to the mechanisms through which application programs \\nconnect and communicate with data repositories. Database connectivity software is also known as database middleware .\\n•\\n Microsoft database connectivity interfaces are dominant players in the market and enjoy the support of most database vendors. ODBC, OLE-DB, and ADO.NET form the backbone of Microsoft’s Universal Data Access (UDA) architecture.\\n•\\n Native database connectivity refers to the connection interface that is provided by the database vendor and is unique to that vendor. ODBC is probably the most widely supported database connectivity interface. ODBC allows any Windows application to access relational data sources using standard SQL. Data Access Objects (DAO) is an older, object-oriented application interface. Remote Data Objects (RDO) is a higher-level, object-oriented application interface used to access remote database servers. RDO was optimized to deal with server-based databases such as MS SQL Server and Oracle.\\n•\\n Object Linking and Embedding for Database (OLE-DB) is database middleware developed with the goal of adding object-oriented functionality for access to rela-tional and nonrelational data. ActiveX Data Objects (ADO) provides a high-level, application-oriented interface to interact with OLE-DB, DAO, and RDO. Based on ADO, ADO.NET is the data access component of Microsoft’s .NET application devel-opment framework. Java Database Connectivity (JDBC) is the standard way to inter -\\nface Java applications with data sources.\\n•\\n Database access through the web is achieved through middleware. To improve the capabilities on the client side of the web browser, you must use plug-ins and other client-side extensions such as Java and JavaScript, or ActiveX and VBScript. On the server side, web application servers are middleware that expand the functionality of web servers by linking them to a wide range of services, such as databases, directory systems, and search engines.\\n•\\n Extensible Markup Language (XML) facilitates the exchange of B2B and other data over the Internet. XML provides the semantics that facilitate the exchange, sharing, and manipulation of structured documents across organizational boundaries. XML produces the description and the representation of data, thus setting the stage for data manipulation in ways that were not possible before. XML documents can be validated through the use of document type definition (DTD) documents and XML schema definition (XSD) documents.\\n•\\n Cloud computing is a computing model that provides ubiquitous, on-demand access to a shared pool of configurable resources that can be rapidly provisioned.\\n•\\n SQL data services (SDS) refers to a cloud computing-based data management ser -\\nvice that provides relational data storage, ubiquitous access, and local management to companies of all sizes. This service enables rapid application development for busi-nesses with limited information technology resources. SDS allows rapid deployment of business solutions using standard protocols and common programming interfaces.Summary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d878f54e-da99-4c63-b840-e5c5bdda416c', embedding=None, metadata={'page_label': '718', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='718   Part 5    Databases and the Internet\\nActiveX\\nActiveX Data Objects (ADO)ADO.NETapplication programming \\ninterface (API)\\nCall Level Interface (CLI)client-side extensioncloud computingcloud servicesCommon Gateway Interface \\n(CGI)\\ncommunity cloudData Access Objects (DAO)data source name (DSN)database middlewareDataSetdocument type definition \\n(DTD)dynamic-link library (DLL)Extensible Markup \\nLanguage (XML)\\nInfrastructure as a Service \\n(IaaS)\\nJavaJava Database Connectivity \\n(JDBC)\\nJavaScriptMicrosoft .NET frameworkObject Linking and \\nEmbedding for Database \\n(OLE-DB)\\nOpen Database \\nConnectivity (ODBC)\\nPlatform as a Service (PaaS)\\nplug-inprivate cloudpublic cloudRemote Data Objects (RDO)scriptserver-side extensionSoftware as a Service (SaaS)SQL data services (SDS)stateless systemtagsUniversal Data Access (UDA)VBScriptweb application serverweb-to-database \\nmiddleware\\nXML schemaXML schema definition \\n(XSD)\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term practice are available at www.cengagebrain.com.Online \\nContent\\n1. Give some examples of database connectivity options and what they are used for.\\n2. What are ODBC, DAO, and RDO? How are they related?\\n3. What is the difference between DAO and RDO?\\n4. What are the three basic components of the ODBC architecture?\\n5. What steps are required to create an ODBC data source name?\\n6. What is OLE-DB used for, and how does it differ from ODBC?\\n7. Explain the OLE-DB model based on its two types of objects.\\n8. How does ADO complement OLE-DB?\\n9. What is ADO.NET, and what two new features make it important for application \\ndevelopment?\\n10. What is a DataSet, and why is it considered to be disconnected?\\n11. What are web server interfaces used for? Give some examples.\\n12. Search the Internet for web application servers. Choose one and prepare a short presentation for your class.\\n13.\\n What does this statement mean: “The web is a stateless system. ” What implications does a stateless system have for database application developers?Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9f082f6-6fe8-4a38-8eec-fa6f8750dc38', embedding=None, metadata={'page_label': '719', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 15    Database Connectivity and Web Technologies    719\\n14. What is a web application server, and how does it work from a database  \\nperspective?\\n15. What are scripts, and what is their function? (Think in terms of database  \\napplication development.)\\n16. What is XML, and why is it important?\\n17. What are document type definition (DTD) documents, and what do they do?\\n18. What are XML schema definition (XSD) documents, and what do they do?\\n19. What is JDBC, and what is it used for?\\n20. What is cloud computing, and why is it a “game changer”?\\n21. Name and contrast the types of cloud computing implementation.\\n22. Name and describe the most prevalent characteristics of cloud computing services.\\n23. Using the Internet, search for providers of cloud services. Then, classify the types of \\nservices they provide (SaaS, PaaS, and IaaS).\\n24. Summarize the main advantages and disadvantages of cloud computing services.\\n25. Define SQL data services and list their advantages.The Ch02 databases used in the Problems for this chap -\\nter are available at www.  \\ncengagebrain.com.Online \\nContent\\nIn the following exercises, you will set up database connectivity using MS Excel.\\n1. Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, \\nand retrieve all of the AGENTs.\\n2. Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, and retrieve all of the CUSTOMERs.\\n3.\\n Use MS Excel to connect to the Ch02_InsureCo MS Access database using ODBC, and retrieve the customers whose AGENT_CODE is equal to 503.\\n4.\\n Create a System DSN ODBC connection called Ch02_SaleCo using the Administra-tive Tools section of the Windows Control Panel.\\n5.\\n Use MS Excel to list all of the invoice lines for Invoice 103 using the Ch02_SaleCo System DSN.\\n6.\\n Create a System DSN ODBC connection called Ch02_Tinycollege using the Admin-istrative Tools section of the Windows Control Panel.\\n7.\\n Use MS Excel to list all classes taught in room KLR200 using the Ch02_TinyCollege System DSN.\\nTo answer Problems 8−11, use Section 15-3a as your guide.\\n8.\\n Create a sample XML document and DTD for the exchange of customer data.\\n9. Create a sample XML document and DTD for the exchange of product and pricing data.\\n10.\\n Create a sample XML document and DTD for the exchange of order data.\\n11. Create a sample XML document and DTD for the exchange of student transcript data. Use your college transcript as a sample.Problems\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='50bb9432-96d8-4993-9356-4fdaacb4f9ca', embedding=None, metadata={'page_label': '720', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Copyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27ebe9a2-848f-4417-88e9-c17308ffb292', embedding=None, metadata={'page_label': '721', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PART 6\\nDatabase Administration\\n16 Database Administration and Security\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4160baf-9192-4d0c-80e7-8ddfd545ff99', embedding=None, metadata={'page_label': '722', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chapter 16\\nDatabase Administration and Security\\nIn this chapter, you will learn:\\n• That data is a valuable business asset requiring careful management\\n• How a database plays a critical role in an organization\\n• That the introduction of a DBMS has important technological, managerial, and cultural  \\nconsequences for an organization\\n• About the database administrator’s managerial and technical roles\\n• About data security, database security, and the information security framework\\n• About several database administration tools and strategies\\n• How cloud-based data services impact the DBA’s role\\n• How various technical tasks of database administration are performed with Oracle\\nPreviewThis chapter shows you the basis for a successful database administration strategy. Such a \\nstrategy requires that data be treated and managed as a valuable corporate asset.\\nIn this chapter, you will learn about important data management issues by looking at \\nthe managerial and technical roles of the database administrator (DBA). This chapter also explores database security issues, such as the confidentiality, integrity, and availability of data. In our information-based society, a key aspect of data management is ensuring that data is protected against intentional or unintentional access by unauthorized personnel. It is also essential to ensure that data is available as needed, even in the face of natural disas-ter or hardware failure, and to maintain the integrity of the data in the database.\\nThe chapter includes a discussion of database administration tools and the corpo-\\nrate-wide data architectural framework. Y ou will also learn how database administration management fits within classical organizational structures. Furthermore, you will learn about several considerations when evaluating cloud-based data services. Even though many new types of databases have emerged, recent studies\\n1 show that relational databases \\nstill dominate the market share of the enterprise. Therefore, with the preponderance of relational databases in the market, it is important that you learn about some basic data-base administration tasks in Oracle RDBMS. Similar tasks can be performed in all major databases, such as Microsoft SQL Server, IBM DB2, Oracle MySQL, and so on.\\n1 Emison, Joe Masters, “2014 State of Database Tech: Think Retro, ” InformationWeek.com , 3/10/2014.\\nBecause it is purely conceptual, this chapter does not reference any data filesNoteData Files Available on cengagebrain.com\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e313f395-4ab4-47c4-adf5-d538697b4e4b', embedding=None, metadata={'page_label': '723', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    723\\n16-1  Data as a Corporate Asset\\nIn Chapter 1, Database Systems, you learned that data is the raw material from which \\ninformation is produced. Therefore, in today’s information-driven environment, data is \\na valuable asset that requires careful management.\\nTo assess data’s monetary value, consider what is stored in a company database: data \\nabout customers, suppliers, inventory, operations, and so on. How many opportunities \\nare lost if the data is lost? What is the actual cost of data loss? For example, an accounting \\nfirm that lost its entire database would incur significant direct and indirect costs. The \\nfirm’s problems would be magnified if the data loss occurred during tax season. Data loss \\nputs any company in a difficult position. The company might be unable to handle daily \\noperations effectively, it might lose customers who require quick and efficient service, \\nand it might lose the opportunity to gain new customers.\\nData is a valuable resource  that can translate into information . If the information is \\naccurate and timely, it can enhance the company’s competitive position and generate \\nwealth. In effect, an organization is subject to a data-information-decision cycle ; that \\nis, the data user applies intelligence to data to produce information that is the basis of \\nknowledge used in decision making . This cycle is illustrated in Figure 16.1.\\nFIGURE 16.1  THE DATA-INFORMATION-DECISION-MAKING CYCLE  \\nDecision makingUser\\nInformationActions\\nDataKnowledgeused intriggers\\nwhich\\ngenerate\\nmorethat is\\nthe basis ofapplies\\nintelligence\\noverAnalysis\\nto produce\\nNote in Figure 16.1 that decisions made by high-level managers trigger actions within \\nthe organization’s lower levels. Such actions produce additional data to be used for mon -\\nitoring company performance. In turn, the additional data must be recycled within the \\ndata-information-decision framework. Thus, data forms the basis for decision making, \\nstrategic planning, control, and operations monitoring.\\nEfficient asset management is critical to the success of an organization. To manage \\ndata as a corporate asset, managers must understand the value of information. For some \\ncompanies, such as credit reporting agencies, their only product is information, and \\ntheir success is solely a function of information management.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='adac5814-f4ab-4b70-9f36-9121f7ec7f81', embedding=None, metadata={'page_label': '724', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='724   Part 6    Database Administration\\nMost organizations continually seek new ways to leverage their data resources to get \\ngreater returns. This leverage can take many forms, from data warehouses that support \\nimproved customer relationships to tighter integration with customers and suppliers in support of the electronic supply chain. As organizations become more dependent on information, that information’s accuracy becomes more critical. Dirty data, or data that suffers from inaccuracies and inconsistencies, becomes an even greater threat. Data can become dirty for many reasons:\\n•\\n Lack of enforcement of integrity constraints, such as not null, uniqueness, and refer -\\nential integrity\\n• Data-entry errors and typographical errors\\n• Use of synonyms and homonyms across systems\\n• Nonstandard use of abbreviations in character data\\n• Different decompositions of composite attributes into simple attributes across systems\\nSome causes of dirty data, such as improper implementation of constraints, can be \\naddressed within an individual database. However, addressing other causes is more com-\\nplicated. Some dirty data comes from the movement of data across systems, as in the creation of a data warehouse. Efforts to control dirty data are generally referred to as data quality initiatives.\\nData quality is a comprehensive approach to ensuring the accuracy, validity, and \\ntimeliness of data. This comprehensive approach is important because data quality involves more than just clening dirty data; it also focuses on preventing future inaccu-racies and building user confidence in the data. Large-scale data quality initiatives tend to be complex and expensive projects, so the alignment of these initiatives with business goals is a must, as is buy-in from top management. While data quality efforts vary greatly from one organization to another, most involve the following:\\n•\\n A data governance structure that is responsible for data quality\\n• Measurements of current data quality\\n• Definition of data quality standards in alignment with business goals\\n• Implementation of tools and processes to ensure future data quality\\nA number of tools can assist in data quality initiatives. In particular, data-profiling \\nand master data management software are available from many vendors. Data-profiling  \\nsoftware gathers statistics, analyzes existing data sources and metadata to determine data pat -\\nterns, and compares the patterns against standards that the organization has defined. This anal-\\nysis can help to assess the quality of existing data and identify sources of dirty data. Master data  \\nmanagement (MDM) software helps to prevent dirty data by coordinating common data across multiple systems. MDM software provides a “master” copy of entities, such as cus -\\ntomers, that appear in numerous systems throughout the organization.\\nWhile these technological approaches provide an important part of data quality, the \\noverall solution to high-quality data within an organization still relies heavily on data administration and management.\\n16-2   The Need for a Database and its  Role in an Organization\\nData is used by different people in different departments for various reasons. There-fore, data management must address the concept of shared data. Chapter 1 showed how dirty data\\nData that contain inaccuracies and/or inconsistencies.\\ndata quality\\nA comprehensive approach to ensuring the accuracy, validity, and timeliness of data.\\ndata profiling software\\nPrograms that analyze data and metadata to determine patterns that can help assess data quality.\\nmaster data management (MDM) software\\nSoftware the provides a “master copy” of entities such as customers, that appear in numerous systems throughout the organization. This software helps prevent dirty data by coordinating common data across multiple systems.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='096c2f47-4693-40e8-a43f-4f6d6078dd32', embedding=None, metadata={'page_label': '725', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    725\\nthe need for data sharing made the DBMS almost inevitable. Used properly, the DBMS  \\nfacilitates:\\n• Interpretation  and presentation  of data in useful formats by transforming raw data into \\ninformation\\n• Distribution  of data and information to the right people at the right time\\n• Data preservation  and monitoring  data usage for adequate periods of time\\n• Control  over data duplication and use, both internally and externally\\nRegardless of the organization, the database’s predominant role is to support mana -\\ngerial decision making at all levels in the organization while preserving data privacy and \\nsecurity.\\nAn organization’s managerial structure might be divided into three levels: top-level \\nmanagement makes strategic decisions, middle management makes tactical decisions, and operational management makes daily working decisions. Operational  decisions \\nare short term; for example, a manager might change the price of a product to clear it from inventory. Tactical  decisions involve a longer time frame and affect larger-scale \\noperations—for example, changing the price of a product in response to competitive pressures. Strategic  decisions affect the long-term well-being of the company or even \\nits survival—for example, changing the pricing strategy across product lines to capture market share.\\nThe DBMS must give each level of management a useful view of the data and support \\nthe required level of decision making. The following activities are typical of each man-agement level.\\nAt the top management level, the database must be able to:\\n•\\n Provide the information necessary for strategic decision making, strategic planning, policy formulation, and goals definition.\\n•\\n Provide access to external and internal data to identify growth opportunities and to chart the direction of such growth. (Direction refers to the nature of the operations: will a company become a service organization, a manufacturing organization, or some combination of the two?)\\n•\\n Provide a framework for defining and enforcing organizational policies that are trans-lated into business rules at lower levels in the organization.\\n•\\n Improve the likelihood of a positive return on investment by searching for new ways to reduce costs and boost productivity in the company.\\n•\\n Provide feedback to monitor whether the company is achieving its goals.\\nAt the middle management level, the database must be able to:\\n•  Deliver the data necessary for tactical decisions and planning.\\n• Monitor and control the allocation and use of company resources and evaluate the performance of various departments.\\n•\\n Provide a framework for enforcing and ensuring the security and privacy of the data in the database. Security means protecting the data against accidental or intentional use by unauthorized users. In the context of database administration, privacy is the \\nextent to which individuals and organizations have the right to determine the details of data usage (who, what, when, where, and how).\\nAt the operational management level, the database must be able to:\\n•\\n Represent and support company operations as closely as possible. The data model must be flexible enough to incorporate all current and future data.security\\nActivities and measures to ensure the confidentiality, integrity, and availability of an information system and its main asset, data.\\nprivacy\\nThe rights of individuals and organizations to determine access to data about themselves.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='207fc977-ed82-40d2-adca-1071209c35b8', embedding=None, metadata={'page_label': '726', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='726   Part 6    Database Administration\\n• Produce query results within specified performance levels. Keep in mind that the \\nperformance requirements increase for lower levels of management and operations. Thus, the database must support fast responses to a greater number of transactions at the operational management level.\\n•\\n Enhance the company’s short-term operations by providing timely information for customer support and for application development and computer operations.\\nA general objective for any database is to provide a seamless flow of information \\nthroughout the company.\\nThe company’s database is also known as the corporate or enterprise database. The \\nenterprise database might be defined as the company’s data representation that pro-vides support for all present and expected future operations. Most of today’s successful organizations depend on the enterprise database to provide support for all of their oper -\\nations—from design to implementation, from sales to services, and from daily decision making to strategic planning.\\n16-3   Introduction of a Database:  Special Considerations\\nHaving a computerized database management system does not guarantee that the data will be properly used to provide the best solutions required by managers. A DBMS is a tool for managing data; like any tool, it must be used effectively to pro-duce the desired results. In the hands of a carpenter, a hammer can help produce furniture, but in the hands of a child it might do damage. The solution to company problems is not the mere existence of a computer system or its database, but its  \\neffective management and use.\\nThe introduction of a DBMS represents a big change and challenge. Throughout the orga-\\nnization, the DBMS is likely to have a profound impact, which might be positive or negative depending on how it is administered. For example, one key consideration is to adapt the DBMS to the organization rather than forcing the organization to adapt to the DBMS. The main issue should be the organization’s needs rather than the DBMS’s technical capabilities. However, the introduction of a DBMS (internally hosted or outsourced to a cloud service) cannot be accom-plished without affecting the organization. The flood of new information has a profound effect on the way the organization functions and therefore on its corporate culture.\\nThe introduction of a DBMS has been described as a process that includes three \\nimportant aspects:\\n2\\n• Technological— DBMS software and hardware\\n• Managerial—Administrative functions\\n• Cultural— Corporate resistance to change\\nThe technological  aspect includes selecting, installing, configuring, and monitoring the \\nDBMS to make sure that it efficiently handles data storage, access, and security. The personnel in charge of installing the DBMS must have the technical skills to provide or secure adequate support for various users of the system: programmers, managers, and end users. Therefore, database administration staffing is a key technological consideration. The selected personnel must have the right mix of technical and managerial skills to provide a smooth transition to the new shared-data environment. In today’s IT world, the technological aspects would apply to both internally hosted DBMS as well as cloud-based data environments.\\n2 Murray, John P ., “The Managerial and Cultural Issues of a DBMS, ” 370/390 Database Management 1(8), \\nSeptember 1991, pp. 32–33.enterprise database\\nThe overall company data representation, which provides support for present and expected future needs.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='49485b7c-7e6b-4d5d-b44d-e261e6008dcd', embedding=None, metadata={'page_label': '727', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    727\\nThe managerial  aspect of the DBMS introduction should not be taken lightly. A \\nhigh-quality DBMS does not guarantee a high-quality information system, just as hav-\\ning the best race car does not guarantee winning a race. Such managerial aspects would also include the management of the services and the relationship with the cloud-based data services provider.\\nThe introduction of a DBMS requires careful planning to create an appropriate orga-\\nnizational structure and accommodate the personnel responsible for administering the system. This structure must also be subject to well-developed monitoring and controls. The administrative personnel must have excellent interpersonal and communications skills combined with broad organizational and business understanding. Top manage-ment must be committed to the new system and must define and support data adminis-tration functions, goals, and roles within the organization.\\nThe cultural  impact of the new database system must be assessed carefully. The DBMS \\nis likely to have an effect on people, functions, and interactions. For example, addi-tional personnel might be hired, new roles might be allocated to existing personnel, and employee performance might be evaluated using new standards.\\nA cultural impact is likely because the database approach creates a more controlled \\nand structured information flow. Department managers who are accustomed to han-dling their own data must surrender ownership and share their data with the rest of the company. Application programmers must learn and follow new design and development standards. Managers might perceive an information overload and require time to adjust to the new environment.\\nWhen the new database comes online, people might be reluctant to use its infor -\\nmation and might question its value or accuracy. Many might be disappointed that the information does not fit their preconceived notions and strongly held beliefs. Database administrators must be prepared to open their doors to end users, listen to their con-cerns, act on those concerns when possible, and explain the system’s uses and benefits.\\n16-4  The Evolution of Database Administration\\nData administration has its roots in the old, decentralized world of the file system. The cost of data and managerial duplication in these systems gave rise to centralized data administration known as the electronic data processing (EDP) or data processing (DP) department. The DP department’s task was to pool all computer resources to support all departments at the operational level . DP administrators were given the authority to \\nmanage all company file systems as well as resolve data and managerial conflicts created by the duplication and misuse of data.\\nThe advent of the DBMS and its shared view of data produced a new level of data \\nmanagement sophistication and led the DP department to evolve into an information systems (IS) department. The responsibilities of the IS department were broadened to include the following:\\n•\\n A service  function to provide end users with data management support\\n• A production  function to provide end users with solutions for their information needs \\nthrough integrated application or management information systems\\nThe function of the IS department was reflected in its internal structure; a typical \\nstructure is shown in Figure 16.2.\\nAs demand grew, the IS application development segment was subdivided by the type \\nof system it supported: accounting, inventory, marketing, and so on. However, this devel-\\nopment meant that database administration responsibilities were divided. The applica-tion development segment was in charge of gathering database requirements and logical information systems (IS) department\\nA department responsible for all information technology services and production functions in an organization.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a498b323-7931-449f-979f-40d647022d7a', embedding=None, metadata={'page_label': '728', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='728   Part 6     Database Administration\\nFIGURE 16.2  THE IS DEPARTMENT’S INTERNAL ORGANIZATION  \\ndatabase design, whereas the database operations segment took charge of implementing, \\nmonitoring, and controlling DBMS operations.\\nAs the number of database applications grew, data management became increas -\\ningly complex, thus leading to the development of database administration. The per -\\nson responsible for control of the centralized and shared database became known as \\nthe database administrator (DBA) .\\nThe size and role of the DBA function varies from company to company, as does its \\nplacement within the organizational structure. On the organizational chart, the DBA func -\\ntion might be defined as either a staff or line position. In a staff position, the DBA often \\ntakes on a consulting role; the DBA can devise the data administration strategy but does \\nnot have the authority to enforce it or resolve possible conflicts.3 In a line position, the \\nDBA has both the responsibility and authority to plan, define, implement, and enforce the \\npolicies, standards, and procedures used in data administration. The two possible DBA \\npositions are illustrated in Figure 16.3.\\nThere is no standard for how the DBA function fits in an organization’s structure, \\npartly because the function itself is probably the most dynamic of any in an organiza -\\ntion. In fact, the fast-paced changes in DBMS technology dictate changing organizational \\nstyles. For example:\\n• The development of distributed databases can force an organization to decentralize \\ndata administration further. The distributed database requires the system DBA to \\ndefine and delegate the responsibilities of each local DBA, thus imposing new and \\nmore complex coordinating  activities on the system DBA.\\n• The growing use of Internet-accessible data and the growing number of data \\nwarehousing applications are likely to expand the DBA ’s data-modeling and \\ndesign activities.\\n• The increasing sophistication and power of personal-computer-based DBMS \\npackages provide an easy platform for developing user-friendly, cost-effective, \\nand efficient solutions. However, such an environment also invites data dupli -\\ncation, not to mention the problems created by people who lack the technical \\nqualifications to produce good database designs. In short, the new computing \\nenvironment requires the DBA to develop a new set of technical and managerial \\nskills.\\n• The increasing use of cloud data services is pushing many database platforms \\nand infrastructures into the cloud. This can free the DBA from many lower-level \\n3 For a historical perspective on the development of the DBA function, refer to Jay-Louise Weldon’s classic \\nData Base Administration  (New Y ork, Plenum Press, 1981). Although you might think that the book’s publi -\\ncation date renders it obsolete, a surprising number of its topics are relevant to current databases.\\nInformation\\nsystems (IS)\\nApplication\\ndevelopmentDatabase\\noperations\\ndatabase \\nadministrator (DBA)\\nThe person responsible \\nfor planning, organizing, \\ncontrolling, and \\nmonitoring the \\ncentralized and shared \\ncorporate database. \\nThe DBA is the general \\nmanager of the \\ndatabase administration \\ndepartment.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76144641-c0c3-4bce-bdbc-e0862617ea35', embedding=None, metadata={'page_label': '729', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    729\\ntechnology-oriented tasks, allowing DBAs to focus on higher-value strategic issues. \\nIn such environments, the DBA becomes a data use service provider and advisor for \\nthe organization.\\n• Conversely, the growing use of Big Data in organizations can force the DBA to \\nbecome more technology-oriented. Ongoing efforts to integrate Hadoop storage \\nsystems with both NoSQL and relational databases require DBAs to be familiar with \\nthe lower-level storage and access issues that are still dominant in those emerging \\ndisciplines.\\nDBA operations are commonly defined and divided according to the phases of the \\nDatabase Life Cycle (DBLC). If that approach is used, the DBA function requires person -\\nnel to cover the following activities:\\n• Database planning, including the definition of standards, procedures, and enforcement\\n• Database requirements gathering and conceptual design\\n• Database logical and transaction design\\n• Database physical design and implementation\\n• Database testing and debugging\\n• Database operations and maintenance, including installation, conversion, and \\nmigration\\n• Database training and support\\n• Data quality monitoring and management\\nFigure 16.4 represents a DBA functional organization according to the preceding \\nmodel.FIGURE 16.3  THE PLACEMENT OF THE DBA FUNCTION  \\nInformation\\nsystems (IS)\\nApplication\\ndevelopmentDatabase\\noperationsDatabase\\nadministration\\nInformation\\nsystems (IS)\\nApplication\\ndevelopmentDatabase\\noperationsDatabase\\nadministrationLine Authority Position\\nStaff Consulting Position\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='155b167e-cc30-493b-916d-4b9cf04a202c', embedding=None, metadata={'page_label': '730', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='730   Part 6     Database Administration\\nKeep in mind that a company might have several incompatible DBMSs installed to \\nsupport different operations. For example, some corporations have a hierarchical DBMS \\nto support daily transactions at the operational level and a relational database to support \\nmiddle and top management’s ad hoc information needs. A variety of personal computer \\nDBMSs might be installed in different departments. In such an environment, the company \\nmight have one DBA assigned for each DBMS. The general coordinator of all DBAs is \\nsometimes known as the systems administrator ; that position is illustrated in Figure 16.5.\\nThere is a growing trend toward specialization in data management. For exam -\\nple, the organizational charts used by some larger corporations make a distinction \\nbetween a DBA and the data administrator (DA) . The DA, also known as the \\ninformation resource manager (IRM) , usually reports directly to top manage -\\nment and is given a higher degree of responsibility and authority than the DBA, \\nalthough the two roles can overlap.\\nThe DA is responsible for controlling the overall corporate data resources, both com -\\nputerized and manual. Thus, the DA ’s job covers more operations than the DBA ’s because \\nthe DA controls data outside the scope of the DBMS in addition to computerized data. \\nDepending on an organization’s structure, the DBA might report to the DA, the IRM, the \\nIS manager, or directly to the company’s CEO.FIGURE 16.4  A DBA FUNCTIONAL ORGANIZATION  \\nDBA\\nPlanning Design Implementation Operations Training\\nConceptual Logical Physical Testing\\nsystems \\nadministrator\\nThe person responsible \\nfor coordinating and \\nperforming day-to-day \\ndata-processing activities.\\ndata administrator \\n(DA)\\nThe person responsible \\nfor managing the entire \\ndata resource, whether it is \\ncomputerized or not. The \\nDA has broader authority \\nand responsibility than the \\ndatabase administrator \\n(DBA). Also known as \\nan information resource \\nmanager (IRM) .\\ninformation resource \\nmanager (IRM)\\nSee data administrator (DA) .FIGURE 16.5  MULTIPLE DATABASE ADMINISTRATORS IN AN ORGANIZATION  \\nSystems\\nadministrator\\nDBA DBA DBA DBAMicrocomputer\\nDBMS manager\\nDB2\\nrelationalOracle\\nrelationalMongoDB\\nNoSQLSQL Server\\nrelational\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ac26ab5d-507e-4701-bccf-fcff01b14b0a', embedding=None, metadata={'page_label': '731', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    731\\n16-5   The Database Environment’s Human \\nComponent\\nA substantial portion of this book is devoted to relational database design and imple-mentation, and to DBMS features and characteristics. Thus far, the book has focused on very important technical aspects of the database. However, even the most carefully crafted database system cannot operate without human assistance. In this section, you will explore how people perform the data administration activities that make a good database design useful.\\nEffective data administration requires both technical and managerial skills. For exam-\\nple, the DA ’s job typically has a strong managerial orientation with company-wide scope, along with a technical orientation that has a narrower, DBMS-specific scope. However, the DBA also must have considerable people skills. For example, both the DA and DBA direct and control personnel staffing and training within their respective departments.\\nTable 16.1 contrasts the general characteristics of both positions by summarizing \\ntypical DA and DBA activities. All of these activities are assigned to the DBA if the organization does not employ both a DA and a DBA.\\nNote that the DA provides a global and comprehensive administrative strategy for the \\norganization’s data. In other words, the DA ’s plans must consider the entire data spec-trum. Thus, the DA is responsible for the consolidation and consistency of both manual and computerized data.\\nThe DA must also set data administration goals. Those goals are defined by issues \\nsuch as:\\n•\\n Data “sharability” and time availability\\n• Data consistency and integrity\\n• Data security and privacy\\n• Data quality standards\\n• Extent and type of data use\\nNaturally, the list can be expanded to fit an organization’s specific data needs. Regard-\\nless of how data management is conducted—and despite the fact that great authority is \\ninvested in the DA or DBA to define and control the way company data is used—the DA and DBA do not own the data. Instead, their functions are defined to emphasize that data is a shared company asset.TABLE 16.1\\nCONTRASTING DA AND DBA ACTIVITIES AND CHARACTERISTICS\\nDATA ADMINISTRATOR (DA) DATABASE ADMINISTRATOR (DBA)\\nPerforms strategic planning Controls and supervises\\nSets long-term goals Executes plans to reach goals\\nSets policies and standards Enforces policies and proceduresEnforces programming standards\\nJob is broad in scope Job is narrow in scope\\nFocuses on the long term Focuses on the short term (daily operations)\\nHas a managerial orientation Has a technical orientation\\nIs DBMS-independent Is DBMS-specific\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0e18c8ce-ec73-4921-8493-ba4e40f50d33', embedding=None, metadata={'page_label': '732', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='732   Part 6     Database Administration\\nThe preceding discussion should not lead you to believe that there are universally \\naccepted DA and DBA administrative standards. The style, duties, organizational place -\\nment, and internal structure of both functions vary from company to company. For \\nexample, many companies distribute DA duties between the DBA and the manager of \\ninformation systems. For simplicity and to avoid confusion, the label DBA  is used here \\nas a general title that encompasses all appropriate data administration.\\nThe arbitration of interactions between the two most important assets of any organization, \\npeople and data, places the DBA in the dynamic environment portrayed in Figure 16.6.\\nAs you examine Figure 16.6, note that the DBA is the focal point for data and user \\ninteraction. The DBA defines and enforces the procedures and standards to be used by \\nprogrammers and end users during their work with the DBMS. The DBA also verifies \\nthat programmer and end-user access meets the required quality and security standards.\\nDatabase users might be classified by the following criteria:\\n• Type of decision-making support required (operational, tactical, or strategic)\\n• Degree of computer knowledge (novice, proficient, or expert)\\n• Frequency of access (casual, periodic, or frequent)\\nThese classifications are not exclusive and usually overlap. For example, an operational \\nuser can be an expert with casual database access, or a top-level manager might be a \\nstrategic novice user with periodic database access. On the other hand, a database appli -\\ncation programmer is an operational expert and frequent database user. Thus, each orga -\\nnization employs people whose levels of database expertise span an entire spectrum. The \\nDBA must be able to interact with all of them, understand their different needs, answer \\nquestions at all levels of expertise, and communicate effectively.\\nThe DBA activities portrayed in Figure 16.6 suggest the need for a diverse mix of \\nskills. In large companies, such skills are likely to be distributed among several DBAs. FIGURE 16.6  A SUMMARY OF DBA ACTIVITIES  \\nProcedures\\nand standardsdeﬁnes and enforces\\nused by\\nApplication\\nprogramsProgrammerveriﬁes\\nwrites\\nManagers\\nand clerksDBMS\\ninterfaceand/orDBMS\\nmanagesmanages and\\nmonitors\\nuse\\nEnd users\\nDataDBA\\nDBA\\ninterface\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38472944-688a-402a-bf89-6eb69082d614', embedding=None, metadata={'page_label': '733', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    733\\nIn small companies, the skills might be the domain of just one DBA. The skills can be \\ndivided into two categories—managerial and technical—as summarized in Table 16.2.\\nAs you examine Table 16.2, keep in mind that the DBA must perform two distinct \\nroles. The DBA ’s managerial role is focused on personnel management and on interac-tions with end users. The DBA ’s technical role involves the use of the DBMS—database design, development, and implementation—as well as the production, development, and use of application programs. Both roles are examined in greater detail in the following sections.\\n16-5a  The DBA’s Managerial Role\\nAs a manager, the DBA must concentrate on the control and planning of database administration. Therefore, the DBA is responsible for the following:\\n•\\n Coordinating, monitoring, and allocating database administration resources: people \\nand data\\n• Defining goals and formulating strategic plans for database administration\\nMore specifically, the DBA ’s responsibilities are shown in Table 16.3.TABLE 16.2\\nDESIRED DBA SKILLS\\nMANAGERIAL TECHNICAL\\nBroad business understanding Broad data-processing background and up-to-date \\nknowledge of database technologies\\nCoordination skills Understanding of Systems Development Life Cycle\\nAnalytical skills Structured methodologies \\n• Data flow diagrams\\n• Structure charts\\n• Programming languages\\nConflict resolution skills Knowledge of Database Life Cycle\\nCommunication skills  (oral and written)Database modeling and design skills \\n• Conceptual\\n• Logical\\n• Physical\\nNegotiation skills Operational skills: Database implementation, data dictionary management, security, and so on\\nExperience: 10 years in a large DP department\\nTABLE 16.3\\nDBA ACTIVITIES AND SERVICES\\nDBA ACTIVITY DBA SERVICE\\nPlanning End-user support\\nOrganizing Policies, procedures, and standards\\nTesting Data security, privacy, and integrity\\nMonitoring Data backup and recovery\\nDelivering Data distribution and use          of       \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='77ffa5f4-b183-4c74-b307-96701caf008c', embedding=None, metadata={'page_label': '734', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='734   Part 6    Database Administration\\nTable 16.3 illustrates that the DBA is generally responsible for planning, organizing, \\ntesting, monitoring, and delivering quite a few services. Those services might be per -\\nformed by the DBA, although they are more likely to be performed by the DBA ’s person-\\nnel. The following sections examine the services in greater detail.\\nEnd-User Support  The DBA interacts with end users by providing data and information \\nsupport to their departments. Because end users usually have dissimilar computer back-\\ngrounds, support services include the following:\\n• Gathering user requirements. The DBA must work with end users to help gather the \\ndata required to identify and describe their present and future information needs. The DBA ’s communication skills are important in working closely with people who have varying computer backgrounds and communication styles.\\n•\\n Building end-user confidence. Finding adequate solutions to end users’ problems increases their trust and confidence in the DBA. The DBA also should educate end users about the services provided and how they enhance data stewardship and data security.\\n•\\n Resolving conflicts and problems. Finding solutions to end users’ problems in one department might trigger conflicts with other departments. End users are typically concerned with their own data needs rather than those of others, and they might not consider how their data might affect other departments within the organization. When conflicts arise, the DBA must have the authority and responsibility to resolve them.\\n•\\n Finding solutions to information needs . The ability and authority to resolve data con-\\nflicts enables the DBA to develop solutions that will properly fit within the data man-agement framework and address end users’ information needs. Given the growing importance of the Internet, those solutions are likely to require the development and management of web servers to interface with the databases. In fact, the explosive growth of e-commerce requires the use of dynamic  interfaces to facilitate interactive \\nproduct queries and product sales.\\n•\\n Ensuring quality and integrity of data and applications. Once the right solution has been found, it must be properly implemented and used. The DBA must work with application programmers and end users to teach them the database standards and procedures required for data quality, access, and manipulation. The DBA must also make sure that the database transactions do not adversely affect data quality. Likewise, certifying the quality of application programs that access the database is a crucial DBA function. Special attention must be given to DBMS Internet interfaces because they are prone to security issues, particularly when using cloud data services.\\n•\\n Managing the training and support of DBMS users. One of the most time-consuming DBA activities is teaching end users how to use the database. The DBA must ensure that all users understand the basic functions of the DBMS software. The DBA coordi-nates and monitors all DBMS training activities.\\nPolicies, Procedures, and Standards\\n A successful data administration strategy requires \\nthe continuous enforcement of policies, procedures, and standards for correct data cre-ation, usage, and distribution within the database. The DBA must define, document, and communicate the following before they can be enforced:\\n•\\n Policies are general statements of direction or action that communicate and support \\nDBA goals.\\n• Standards describe the minimum requirements of a given DBA activity; they are more detailed and specific than policies. In effect, standards are rules that evaluate policy\\nGeneral statement of direction that is used to manage company operations through the communication and support of the organization’s objectives.\\nstandard\\nA detailed and specific set of instructions that describes the minimum requirements for a given activity. Standards are used to evaluate the quality of the output.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cb2ad162-8dc7-46e0-8bfb-1ea4dc27be30', embedding=None, metadata={'page_label': '735', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    735\\nthe quality of the activity. For example, standards define the structure of application \\nprograms and the naming conventions programmers must use.\\n• Procedures are written instructions that describe a series of steps to be fol-lowed during the performance of a given activity. Procedures must be developed within existing working conditions, and they must support and enhance the work environment.\\nTo illustrate the distinctions among policies, standards, and procedures, look at the \\nfollowing examples:\\nPolicies\\n•\\n All users must have passwords.\\n• Passwords must be changed every six months.\\nStandards  \\n• A password must have a minimum of 5 characters.\\n• A password must have a maximum of 12 characters.\\n• Social Security numbers, names, and birth dates cannot be used as passwords.\\nProcedures\\nTo create a password, (1) the end user sends the DBA a written request for the cre-\\nation of an account; (2) the DBA approves the request and forwards it to the computer \\noperator; (3) the computer operator creates the account, assigns a temporary password, and sends the account information to the end user; (4) a copy of the account information is sent to the DBA; and (5) the user changes the temporary password to a permanent one.\\nStandards and procedures defined by the DBA apply to all end users who want to \\nbenefit from the database. Standards and procedures must complement each other and must constitute an extension of data administration policies. Procedures must facilitate the work of end users and the DBA. The DBA must define, communicate, and enforce procedures that cover areas such as:\\n•\\n End-user database requirements gathering. What documentation is required? What \\nforms must be used?\\n• Database design and modeling . What database design methodology will be used (nor -\\nmalization or object-oriented)? What tools will be used (CASE tools, data dictionar -\\nies, UML or ER diagrams)?\\n• Documentation and naming conventions. What documentation must be used in the definition of all data elements, sets, and programs that access the database?\\n•\\n Design, coding, and testing of database application programs. The DBA must define the standards for application program coding, documentation, and testing. The DBA standards and procedures are given to the application programmers, and the DBA must enforce those standards.\\n•\\n Database software selection . The selected DBMS must properly interface with existing \\nsoftware, have the features needed by the organization, and provide a positive return on investment. In today’s Internet environment, the DBA must also work with web and network administrators to implement efficient and secure web and cloud data-base connectivity.\\n•\\n Database security and integrity. The DBA must define policies that govern security and integrity. Database security is especially crucial. Security standards must be procedure\\nSeries of steps to be followed during the performance of an activity or process.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ff75b2bb-b6b0-40bc-a07a-e1241390f30f', embedding=None, metadata={'page_label': '736', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='736   Part 6    Database Administration\\nclearly defined and strictly enforced. Security procedures must handle a multitude \\nof scenarios to ensure that problems are minimized. Although no system can ever be completely secure, procedures must meet critical standards. The growing use of Internet interfaces to databases opens the door to new security threats that are far more complex and difficult to manage than those in traditional interfaces—this is particularly important when working with cloud data services. Therefore, the DBA must work closely with Internet security specialists to ensure that the databases are properly protected from attacks.\\n•\\n Database backup and recovery. Database backup and recovery procedures must include information that guarantees proper execution and management of the backups. The DBA must work closely with any cloud-based data services provider to ensure the proper procedures are in place to manage data backups and restores and to ensure ownership and security of the data.\\n•\\n Database maintenance and operation. The DBMS’s daily operations must be clearly documented. Operators must keep job logs and must write operator instructions and notes. Such notes help pinpoint the causes and solutions of problems. Opera-tional procedures must also include precise instructions for backup and recovery procedures.\\n•\\n End-user training. A full-featured training program must be established within the organization, and training procedures must be clearly specified. Each end user must be aware of available training.\\nProcedures and standards must be revised at least annually to keep them up to date \\nand to ensure that the organization can adapt quickly to changes in the work environ-ment. Naturally, the introduction of new DBMS software, the discovery of security or integrity violations, company reorganizations, and similar changes require revision of procedures and standards.\\nData Security, Privacy, and Integrity\\n Data security, privacy, and integrity are of great \\nconcern to DBAs who manage DBMS installations. Technology has pointed the way to \\ngreater productivity through information management, and it has enabled the distri-bution of data across multiple sites, making it more difficult to maintain data control, security, and integrity. Thus, the DBA must use the security and integrity mechanisms provided by the DBMS to enforce the database administration policies defined in the previous section. In addition, DBAs must team up with Internet security experts to build security mechanisms that safeguard data from possible attacks or unauthorized access. Section 16-6 covers security issues in more detail.\\nData Backup and Recovery\\n When data is not readily available, companies face \\npotentially ruinous losses. Therefore, data backup and recovery procedures are crit-\\nical in all database installations. The DBA must also ensure that data can be fully recovered in case of data loss or loss of database integrity. These losses can be partial or total; therefore, backup and recovery procedures are the cheapest database insur -\\nance you can buy.\\nThe management of database security, integrity, backup, and recovery is so criti-\\ncal that many DBA departments have created a position called the database security  \\nofficer (DSO). The DSO’s sole job is to ensure database security and integrity. In large organizations, the DSO’s activities are often classified as disaster management.\\nDisaster management includes all of the DBA activities designed to secure data \\navailability following a physical disaster or a database integrity failure. Disaster man-agement includes all planning, organizing, and testing of database contingency plans database security officer (DSO)\\nThe person responsible for the security, integrity, backup, and recovery of the database.\\ndisaster management\\nThe set of DBA activities dedicated to securing data availability following a physical disaster or a database integrity failure.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c98836d-dc3f-479e-9f26-d7b529fd9df2', embedding=None, metadata={'page_label': '737', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    737\\nand recovery procedures. The backup and recovery measures must include at least the \\nfollowing:\\n• Periodic data and application backups . Some DBMSs include tools to ensure automatic \\nbackup and recovery of the database. Products such as IBM’s DB2 allow different types \\nof backups: full, incremental, and concurrent. A full backup, also known as a database dump, produces a complete copy of the entire database. An incremental backup pro -\\nduces a backup of all data since the last backup date. A concurrent backup takes place while the user is working on the database.\\n•\\n Proper backup identification . Backups must be clearly identified through detailed \\ndescriptions and date information, thus enabling the DBA to ensure that the correct backups are used to recover the database. The most common backup medium has traditionally been tape; computer operators must diligently store and label the tapes, and the DBA must keep track of the current tape’s location. However, organizations that are large enough to hire a DBA do not typically use tapes for enterprise backup. Other solutions include optical and disk-based backup devices. Such backup solu-tions include online storage based on network-attached storage (NAS), storage area networks (SAN), and cloud-based data storage. Enterprise backup solutions use a lay-ered approach in which the data is first backed up to fast disk media for intermediate storage and fast restoration. Later, the data is transferred to tape for archival storage.\\n•\\n Convenient and safe backup storage. Multiple backups of the same data are required, and each backup copy must be stored in a different location. The storage locations must include sites inside and outside the organization. (Keeping different backups in the same place defeats the purpose of having multiple backups.) The storage locations must be properly prepared, and they may include fire-safe and quakeproof vaults as well as humidity and temperature controls. The DBA must establish a policy to respond to two questions: (1) Where are the backups to be stored? (2) How long are backups to be stored?\\n•\\n Physical protection of both hardware and software. Protection might include the use of closed installations with restricted access, as well as preparation of the computer sites to provide air conditioning, backup power, and fire protection. Physical protection also includes a backup computer and DBMS to be used in case of emergency. For example, when Hurricane Sandy hit the east coast of North America in 2012, the U.S. Northeast suffered widespread destruction of its communications infrastructure. The storm served as a wake-up call for many organizations and educational institutions that did not have adequate disaster recovery plans for such an extreme level of service interruption.\\n•\\n Personal access control to the software of a database installation. Multilevel passwords and privileges as well as hardware and software challenge/response tokens can be used to identify authorized users of resources.\\n•\\n Insurance coverage for the data in the database. The DBA or security officer must buy an insurance policy to provide financial protection in the event of a database failure. The insurance might be expensive, but it is less expensive than the disaster created by massive data loss.\\nTwo additional points are worth making are:\\n•\\n Data recovery and contingency plans must be thoroughly tested and evaluated, and \\nthey must be practiced frequently. So-called fire drills should not be disparaged, and they require top-level management’s support and enforcement.\\n•\\n A backup and recovery program is not likely to cover all components of an informa-tion system. Therefore, it is appropriate to establish priorities for the nature and extent of data recovery.full backup (database dump)\\nA complete copy of an entire database saved and periodically updated in a separate memory location. A full backup ensures a full recovery of all data after a physical disaster or database integrity failure.\\nincremental backup\\nA process that only backs up data that has changed in the database since the last incremental or full backup.\\nconcurrent backup\\nA backup that takes place while one or more users are working on a database.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='975fb9e4-5018-4c25-acf8-a187ac34f384', embedding=None, metadata={'page_label': '738', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='738   Part 6    Database Administration\\nData Distribution and Use  Data is useful only when it reaches the right users in a timely \\nfashion. The DBA is responsible for ensuring that data is distributed to the right people, \\nat the right time, and in the right format. These tasks can become very time-consuming, especially when data delivery capacity is based on a typical applications programming environment, where users depend on programmers to deliver the programs that access the database. Although the Internet and its intranet and extranet extensions have opened databases to corporate users, they have also created a new set of challenges for the DBA.\\nCurrent data distribution philosophy makes it easy for authorized  end users to access \\nthe database. One way to accomplish this task is to facilitate the use of new, more sophis-ticated query tools and new web front ends. They enable the DBA to educate end users to produce required information without being dependent on applications program-mers. Naturally, the DBA must ensure that users adhere to appropriate standards and procedures.\\nThis data-sharing philosophy is common today, and it probably will become more \\ncommon as database technology marches on. Such an environment is more flexible for end users; by becoming more self-sufficient in the acquisition and use of data, they can make better decisions. Y et, this “data democracy” can also produce some trouble-some side effects. Letting end users micromanage their data subsets could inadvertently sever the connection between those users and data administrators. The DBA ’s job could become more complicated, and the efficiency of data administration could be com-promised. Data duplication might flourish again without checks at the organizational level to ensure the uniqueness of data elements. Thus, end users who do not completely understand the nature and sources of data might use the data elements improperly.\\n16-5b  The DBA’s Technical Role\\nThe DBA ’s technical role requires a broad understanding of DBMS functions, config-uration, programming languages, and data-modeling and design methodologies. For example, the DBA ’s technical activities include the selection, installation, operation, maintenance, and upgrading of the DBMS and utility software, as well as the design, development, implementation, and maintenance of application programs that interact with the database.\\nMany of the DBA ’s technical activities are a logical extension of the DBA ’s managerial \\nactivities. For example, the DBA deals with database security and integrity, backup and recovery, and training and support. The technical aspects of the DBA ’s job are rooted in the following areas of operation:\\n•\\n Evaluating, selecting, and installing the DBMS and related utilities\\n• Designing and implementing databases and applications\\n• Testing and evaluating databases and applications\\n• Operating the DBMS, utilities, and applications\\n• Training and supporting users\\n• Maintaining the DBMS, utilities, and applications\\nThe following sections explore the details of each area.\\nEvaluating, Selecting, and Installing the DBMS and Utilities  One of the DBA ’s first and \\nmost important technical responsibilities is selecting the database management system, \\nutility software, and supporting hardware to be used in the organization. The DBMS selection might also include the consideration of cloud-based data services. This task requires extensive planning, which must be based on the organization’s needs rather than \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c9124fec-3879-407d-8f00-422460d3c5df', embedding=None, metadata={'page_label': '739', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    739\\nspecific software and hardware features. The DBA must recognize that the objective is \\nsolving problems rather than buying a computer or DBMS software. Put simply, a DBMS is a management tool and not a technological toy.\\nThe first and most important step of the plan is to determine company needs. The \\nDBA must make sure that all end users, including top-level and midlevel managers, are involved in the process. Once the needs are identified, the objectives of data adminis-tration can be clearly established and the DBMS features and selection criteria can be defined.\\nTo match DBMS capability to the organization’s needs, the DBA would be wise to \\ndevelop a checklist of desired DBMS features that addresses at least the following issues:\\n•\\n DBMS model. Are the company’s needs better served by a relational, object-oriented, \\nobject/relational, or a NoSQL DBMS? If a data warehouse application is required, should a relational or multidimensional DBMS be used? Does the DBMS support star schemas? To determine which model is best, you need to identify the main goal of the application: is it high availability, high performance, transaction accuracy (ACID enforcement), or being able to manage a variety of types of data and complex relationships?\\n•\\n DBMS storage capacity. What maximum disk and database sizes are required? How many disk packages must be supported? What is the minimum number of indepen-dent disk spindles required for the “recommended” installation? What are other stor -\\nage needs? If using a cloud storage service, in addition to initial data size, special attention should be given to expected data growth rates because of contracted incre-mental data storage costs. Cloud storage introduces issues such as location, security, replication, redundancy, and data synchronization.\\n•\\n Application development support . Which programming languages are supported? \\nWhat application development tools are available? (Options include database schema design, a data dictionary, performance monitoring, and screen and menu painters.) Are end-user query tools provided? Does the DBMS provide web front-end access?\\n•\\n Security and integrity. Does the DBMS support referential and entity integrity rules, access rights, and so on? Does the DBMS support the use of audit trails to spot errors and security violations? Can the audit trail’s size be modified? If the data is stored in a public cloud, how secure is the data?\\n•\\n Backup and recovery . Does the DBMS provide automated backup and recovery tools? \\nDoes the DBMS support tape, optical disc, or network-based backups? Does the DBMS automatically back up the transaction logs?\\n•\\n Concurrency control . Does the DBMS support multiple users? What levels of isolation \\n(table, page, row) does the DBMS offer? How much manual coding is needed in the application programs?\\n•\\n Performance . How many transactions per second does the DBMS support? Are addi-\\ntional transaction processors needed? Is an in-memory database required to ensure top performance?\\n•\\n Database administration tools . Does the DBMS offer some type of DBA management \\ninterface? What type of information does the DBA interface provide? Does the DBMS provide alerts to the DBA when errors or security violations occur?\\n•\\n Interoperability and data distribution . Can the DBMS work with other DBMS types in \\nthe same environment? What coexistence or interoperability level is achieved? Does the DBMS support read and write operations to and from other DBMS packages? Does the DBMS support a client/server architecture? Would a cloud-based data ser -\\nvice be a better choice for the given system?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b47274a4-08a1-4b79-9e61-44637f6d015e', embedding=None, metadata={'page_label': '740', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='740   Part 6    Database Administration\\n• Portability and standards . Can the DBMS run on different operating systems and plat-\\nforms? Can the DBMS run on mainframes, midrange computers, and personal com-\\nputers? Can the DBMS applications run without modification on all platforms? What national and industry standards does the DBMS follow?\\n•\\n Hardware . What hardware does the DBMS require? Can the DBMS run in a virtual \\nmachine? Does the DBMS implementation require the use of hardware clusters or a distributed environment?\\n•\\n Data dictionary . Does the DBMS have an “accessible” data dictionary? Does the \\nDBMS interface with any data dictionary tool? Does the DBMS support any open management tools?\\n•\\n Vendor training and support . Does the vendor offer in-house training? What type and \\nlevel of support does the vendor provide? Is the DBMS documentation easy to read and helpful? What is the vendor’s upgrade policy?\\n•\\n Available third-party tools . What additional tools are offered by third-party vendors? \\nDo they include query tools, a data dictionary, access management and control, and storage allocation management tools?\\n•\\n Costs . What costs are involved in the acquisition of the software and hardware? How \\nmany additional personnel are required, and what level of expertise is required of them? What are the recurring costs? What is the expected payback period?\\nIf cloud data services are being considered, there are additional issues that need to be \\naddressed with any potential cloud provider. Recall that the use of cloud databases frees the client organization from costs of acquiring and implementing the infrastructure as well as daily costs of maintenance. However, these services come with a loss of control over the data and the infrastructure. Any potential cloud-based vendors need to be eval-uated based on several factors, including:\\n•\\n Downtime history . Historically, how often are the cloud provider’s services unavail-\\nable, and what provisions will they make to ensure that your data is always accessible?\\n• Security. How does the provider secure your data using firewalls, authentication, \\nsecurity audits, and encryption? Who at the cloud company will have access to your data files?\\n•\\n Support . What customer support options are available if the client has issues or con-\\ncerns with the data services provided?\\n• Data loss contingencies. The expectation is that the cloud provider will keep the data safe. However, what happens if they lose the client’s data? What type of compensation or insurance against data loss is provided? What types of redundancies and backups are used to ensure that data loss will not happen? Where are the backups and redun-dancies kept to ensure that a natural disaster in one geographic area cannot cause the loss of all copies of the data?\\nPros and cons of several alternative solutions must be evaluated during the selection \\nprocess. Available alternatives are often restricted because software must be compat-ible with the organization’s existing computer system. Remember that a DBMS is just part of a solution; it requires support from collateral hardware, application software, and utility programs. For example, the DBMS’s use is likely to be constrained by the available CPU(s), front-end processor(s), auxiliary storage devices, data communica-tion devices, the operating system, a transaction processor system, and so on. The costs associated with the hardware and software components must be included in the estimations.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6063516-8a87-4998-85a8-e68a30bdec8f', embedding=None, metadata={'page_label': '741', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    741\\nThe selection process must also consider the site’s preparation costs. For example, the \\nDBA must include both one-time and recurring expenditures for preparing and main-\\ntaining the computer room installations.\\nThe DBA must supervise the installation of all software and hardware that supports \\nthe data administration strategy, and must thoroughly understand the components being installed, including their installation, configuration, and startup procedures. The installation procedures include the location of backup and transaction log files, network configuration information, and physical storage details.\\nKeep in mind that installation and configuration details are DBMS-dependent. There-\\nfore, such details cannot be addressed in this book. Consult the installation and configu-ration sections of your system’s DBMS administration guide for details.\\nDesigning and Implementing Databases and Applications\\n The DBA also provides \\ndata-modeling and design services to end users. Such services are often coordinated \\nwith an application development group within the data-processing department. There-fore, one of the primary activities of a DBA is to determine and enforce standards and procedures to be used. Once a framework of appropriate standards and procedures are in place, the DBA must ensure that the database-modeling and design activities are per -\\nformed within the framework. The DBA then provides necessary assistance and support during the design of the database at the conceptual, logical, and physical levels. (Remem-ber that the conceptual design is both DBMS- and hardware-independent, the logical design is DBMS-dependent and hardware-independent, and the physical design is both DBMS- and hardware-dependent.)\\nThe DBA function usually requires that several people be dedicated to database model-\\ning and design activities. Those people might be grouped according to the organizational areas covered by the application. For example, database modeling and design personnel may be assigned to production systems, financial and managerial systems, or executive and decision support systems. The DBA schedules the design jobs to coordinate the data design and modeling activities. That coordination may require reassignment of available resources based on externally determined priorities.\\nThe DBA also works with application programmers to ensure the quality and integrity \\nof database design and transactions. Such support services include reviewing the data-base application design to ensure that transactions are:\\n•\\n Correct . The transactions mirror real-world events.\\n• Efficient. The transactions do not overload the DBMS.\\n• Compliant . Transactions comply with integrity rules and standards.\\nThese activities require personnel with broad database design and programming \\nskills.\\nThe implementation of the applications requires the implementation of the physical \\ndatabase. Therefore, the DBA must provide assistance and oversight during the physical \\ndesign, including determination and creation of storage space, data loading, conversion, and database migration services. The DBA ’s implementation tasks also include the gen-eration, compilation, and storage of the application’s access plan. An access plan is a \\nset of instructions generated when the application is compiled that predetermines how the application will access the database at run time. To be able to create and validate the access plan, the user must have the required rights to access the database (see Chapter 11, Database Performance Tuning and Query Optimization).\\nBefore an application comes online, the DBA must develop, test, and implement the \\noperational procedures required by the new system. Such procedures include training, security, and backup and recovery plans, as well as assigning responsibility for database access plan\\nA set of instructions generated at application compilation time that is created and managed by a DBMS. The access plan predetermines how an application’s query will access the database at run time.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b0ff7505-85b9-4476-b018-87bc9db5cb06', embedding=None, metadata={'page_label': '742', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='742   Part 6    Database Administration\\ncontrol and maintenance. Finally, the DBA must authorize application users to access the \\ndatabase from which the applications draw the required data.\\nThe addition of a new database might require fine-tuning or reconfiguring of the \\nDBMS. Remember that the DBMS assists all applications by managing the shared corpo-rate data repository. Therefore, when data structures are added or modified, the DBMS might require the assignment of additional resources to serve new and original users with equal efficiency (see Chapter 11).\\nTesting and Evaluating Databases and Applications\\n The DBA must also provide test-\\ning and evaluation services for all database and end-user applications. These services are \\nthe logical extension of the design, development, and implementation services described in the preceding section. Testing procedures and standards must already be in place before any application program can be approved for use in the company.\\nAlthough testing and evaluation services are closely related to database design and \\nimplementation services, they usually are maintained independently. The reason for the separation is that application programmers and designers are often too close to the prob-lem being studied to detect errors and omissions.\\nTesting usually starts with the loading of the “test bed” database, which contains test \\ndata for the applications. Its purpose is to check the data definition and integrity rules of the database and application programs.\\nThe testing and evaluation of a database application cover all aspects of the system, \\nfrom the simple collection and creation of data to its use and retirement. The evaluation process covers the following:\\n•\\n Technical aspects of both the applications and the database; backup and recov-\\nery, security and integrity, use of SQL, and application performance must be evaluated\\n•\\n Evaluation of the written documentation and procedures to ensure that they are accu-rate and easy to follow\\n•\\n Observance of standards for naming, documenting, and coding\\n• Checking for data duplication conflicts with existing data\\n• The enforcement of all data validation rules\\nFollowing the thorough testing of all applications, the database, and the procedures, \\nthe system is declared operational and can be made available to end users.\\nOperating the DBMS, Utilities, and Applications  DBMS operations can be divided into \\nfour main areas:\\n• System support\\n• Performance monitoring and tuning\\n• Backup and recovery\\n• Security auditing and monitoring\\nSystem support  activities cover all tasks directly related to the day-to-day operations \\nof the DBMS and its applications. These activities include filling out job logs, changing \\ntape, and verifying the status of computer hardware, disk packages, and emergency power sources. System-related activities include periodic tasks such as running spe-cial programs and resource configurations for new and upgraded versions of database applications.\\nPerformance monitoring and tuning  require much of the DBA ’s attention and time. \\nThese activities are designed to ensure that the DBMS, utilities, and applications \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ca15ab3-f45b-423c-a6ef-168df77d224a', embedding=None, metadata={'page_label': '743', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    743\\nmaintain satisfactory performance levels. To carry out performance monitoring and \\ntuning tasks, the DBA must:\\n• Establish DBMS performance goals.\\n• Monitor the DBMS to evaluate whether the performance objectives are being met.\\n• Isolate the problem and find solutions if performance objectives are not met.\\n• Implement the selected performance solutions.\\nDBMSs often include performance-monitoring tools that allow the DBA to query \\ndatabase usage information. Performance-monitoring tools are available from many \\ndifferent sources: DBMS utilities are provided by third-party vendors, or they might be included in operating system utilities or transaction processor facilities. Most of the performance-monitoring tools allow the DBA to focus on selected system bottlenecks. The most common bottlenecks in DBMS performance tuning are related to the use of indexes, query optimization algorithms, and management of storage resources.\\nBecause improper index selection can have a deleterious effect on system perfor -\\nmance, most DBMS installations adhere to a carefully defined index creation and usage plan. Such a plan is especially important in a relational database environment.\\nTo produce satisfactory performance, the DBA might train programmers and end \\nusers in the proper use of SQL statements. Typically, DBMS programming manuals and administration manuals contain useful performance guidelines and examples that demonstrate the proper use of SQL statements, both at the command line and within application programs. Because relational systems do not give the user an index choice within a query, the DBMS makes the index selection for the user. Therefore, the DBA should create indexes that can be used to improve system performance. (For examples of database performance tuning, see Chapter 11.)\\nQuery optimization routines are usually integrated into the DBMS package, allowing \\nfew tuning options. Query optimization routines are oriented toward improving concur -\\nrent access to the database. Several database packages let the DBA specify parameters for determining the desired level of concurrency. Concurrency is also affected by the types of locks used by the DBMS and requested by the applications. Because concurrency is important to the efficient operation of the system, the DBA must be familiar with the factors that influence concurrency. (See Chapter 10, Transaction Management and Con-currency Control, for more information.)\\nDuring DBMS performance tuning, the DBA must also consider available storage \\nresources in terms of both primary and secondary memory. The allocation of storage resources is determined when the DBMS is configured. Storage configuration parame-ters can be used to determine:\\n•\\n The number of databases that may be opened concurrently\\n• The number of application programs or users supported concurrently\\n• The amount of primary memory (buffer pool size) assigned to each database and each \\ndatabase process\\n• The size and location of the log file (remember that these files are used to recover the database; the log files can be located in a separate volume to reduce the disk’s head movement and to increase performance)\\nPerformance-monitoring issues are DBMS-specific. Therefore, the DBA must become \\nfamiliar with the DBMS manuals to learn the technical details involved in performance monitoring (see Chapter 11).\\nBecause data loss could be devastating to the organization, backup and recovery activ -\\nities are of primary concern during the DBMS operation. The DBA must establish a \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2eb01dbc-6129-4b07-8d1c-63361e728540', embedding=None, metadata={'page_label': '744', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='744   Part 6    Database Administration\\nschedule for backing up database and log files at appropriate intervals. Backup frequency \\nis dependent on the application type and on the relative importance of the data. All crit-ical system components—the database, the database applications, and the transaction logs—must be backed up periodically.\\nMost DBMS packages include utilities that schedule automated database backups, \\neither full or incremental. Although incremental backups are faster than full backups, an incremental backup requires the existence of a periodic full backup to be useful for recovery purposes.\\nDatabase recovery after a media or systems failure requires application of the transac-\\ntion log to the correct database copy. The DBA must plan, implement, test, and enforce a “bulletproof ” backup and recovery procedure.\\nSecurity auditing and monitoring  assumes the appropriate assignment of access rights \\nand the proper use of access privileges by programmers and end users. The technical aspects of security auditing and monitoring involve creating users, assigning access rights, and using SQL commands to grant and revoke access rights to users and database objects. The DBA also must periodically generate an audit trail report to find actual or attempted security violations. If any are found, the DBA must ascertain where the viola-tions occurred, and if possible, who committed them. For a comprehensive discussion of database security, see Section 16-6.\\nTraining and Supporting Users\\n Training people to use the DBMS and its tools is part of \\nthe DBA ’s technical activities. In addition, the DBA provides or secures technical train-\\ning for applications programmers in the use of the DBMS and its utilities. Applications programmer training covers the use of the DBMS tools as well as the procedures and standards required for database programming.\\nUnscheduled, on-demand technical support for end users and programmers is also \\npart of the DBA ’s activities. A technical troubleshooting procedure can be developed to facilitate such support. The procedure might include the development of a technical database to find solutions to common technical problems.\\nPart of the support is provided by interaction with DBMS vendors. Establishing \\ngood relationships with software suppliers is one way to ensure that the company has a good external support source. Vendors are the source for up-to-date information con-cerning new products and personnel retraining. Good vendor-company relations also are likely to give organizations an edge in determining the future direction of database development.\\nMaintaining the DBMS, Utilities, and Applications\\n The maintenance activities of the \\nDBA are an extension of the operational activities. Maintenance activities are dedicated \\nto the preservation of the DBMS environment.\\nPeriodic DBMS maintenance includes management of the physical or secondary stor -\\nage devices. One of the most common maintenance activities is reorganizing the physical location of data in the database. (This is usually done as part of the DBMS fine-tuning activities.) The reorganization of a database might be designed to allocate contiguous disk-page locations to the DBMS to increase performance. The reorganization process also might free the space allocated to deleted data, thus providing more disk space for new data.\\nMaintenance activities also include upgrading the DBMS and utility software. The \\nupgrade might require installing a new version of the DBMS software or an Internet front-end tool. Or, it might create an additional DBMS gateway to allow access to a host DBMS running on a different host computer. DBMS gateway services are very common in distributed DBMS applications running in a client/server environment. Also, new-generation databases include features such as spatial data support, data \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f14e1fc-b3af-426a-806a-27199848214c', embedding=None, metadata={'page_label': '745', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    745\\nwarehousing and star query support, and support for Java programming interfaces for \\nInternet access (see Chapter 15, Database Connectivity and Web Technologies).\\nQuite often companies are faced with the need to exchange data in dissimilar formats \\nor between databases. The maintenance efforts of the DBA include migration and con-version services for data in incompatible formats or for different DBMS software. Such conditions are common when the system is upgraded from one version to another or when the existing DBMS is replaced by an entirely new DBMS. Database conversion ser -\\nvices also include downloading data from the host DBMS (mainframe-based) to an end user’s personal computer to allow the user to perform a variety of activities—spreadsheet analysis, charting, statistical modeling, and so on. Migration and conversion services can be done at the logical level (DBMS-specific or software-specific) or at the physical level (storage media or operating system-specific). Current-generation DBMSs support XML as a standard format for data exchange among database systems and applications (see Chapter 15).\\n16-6  Security\\nInformation system security refers to activities and measures that ensure the confidenti-ality, integrity, and availability of an information system and its main asset, data.\\n4 Secur -\\ning data requires a comprehensive, company-wide approach. That is, you cannot secure data if you do not secure all the processes and systems around it, including hardware systems, software applications, the network and its devices, internal and external users, procedures, and the data itself. To understand the scope of data security, consider each of the three security goals in more detail:\\n•\\n Confidentiality deals with ensuring that data is protected against unauthorized \\naccess, and if the data is accessed by an authorized user, that it is used only for an authorized purpose. In other words, confidentiality entails safeguarding data against disclosure of any information that would violate the privacy rights of a person or organization. Data must be evaluated and classified according to the level of confi-dentiality: highly restricted (very few people have access), confidential (only certain groups have access), and unrestricted (can be accessed by all users). The data security officer spends a great amount of time ensuring that the organization is in compliance with desired levels of confidentiality. Compliance refers to activities that meet data privacy and security reporting guidelines. These guidelines are either part of internal procedures or are imposed by external regulatory agencies such as the federal govern-ment. Examples of U.S. legislation enacted to ensure data privacy and confidentiality include the Health Insurance Portability and Accountability Act (HIPAA), Gramm-Leach-Bliley Act (GLBA), and Sarbanes-Oxley Act (SOX).\\n•\\n Integrity, within the data security framework, is concerned with keeping data con-sistent and free of errors or anomalies. (See Chapter 1 to review the concepts of data inconsistencies and data anomalies.) The DBMS plays a pivotal role in ensuring the integrity of the data in the database. However, from the security point of view, the organizational processes, users, and usage patterns also must maintain integrity. For example, a work-at-home employee using the Internet to access product costing could be considered an acceptable use; however, security standards might require the employee to use a secure connection and follow strict procedures to manage the data at home, such as shredding printed reports and using encryption to copy data to the local hard drive. Maintaining data integrity is a process that starts with data collection \\n4 Krause, M. and Tipton, H., Handbook of Information Security Management, CRC Press LLC, 1999.confidentiality\\nIn the context of data security, ensuring that data is protected against unauthorized access, and if the data is accessed by an authorized user, that the data is used only for an authorized purpose.\\ncompliance\\nActivities that meet data privacy and security reporting guidelines or requirements.\\nintegrity\\nIn a data security framework, refers to keeping data consistent and free of errors or anomalies. See also data integrity.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4600043d-3978-426c-8f14-6221e36b0a52', embedding=None, metadata={'page_label': '746', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='746   Part 6    Database Administration\\nand continues with data storage, processing, usage, and archiving (see Chapter 13, \\nBusiness Intelligence and Data Warehouses). The rationale behind integrity is to treat data as the most-valuable asset in the organization and to ensure that rigorous data validation is carried out at all levels within the organization.\\n•\\n Availability refers to the accessibility of data whenever required by authorized users and for authorized purposes. To ensure data availability, the entire system must be protected from service degradation or interruption caused by any internal or external source. Service interruptions could be very costly for companies and users alike. Sys-tem availability is an important goal of security.\\n16-6a  Security Policies\\nNormally, the tasks of securing the system and its main asset, the data, are performed by the database security officer and the database administrator(s), who work together to establish a cohesive data security strategy. Such a strategy begins with defining a sound and comprehensive security policy. A security policy is a collection of standards, pol-\\nicies, and procedures created to guarantee the security of a system and ensure auditing and compliance. The security audit process starts by identifying security vulnerabilities in the organization’s information system infrastructure and identifying measures to pro-tect the system and data against those vulnerabilities.\\n16-6b  Security Vulnerabilities\\nA security vulnerability is a weakness in a system component that could be exploited \\nto allow unauthorized access or cause service disruptions. Such vulnerabilities could fall under one of the following categories:\\n•\\n Technical . An example would be a flaw in the operating system or web browser.\\n• Managerial . For example, an organization might not educate users about critical secu-\\nrity issues.\\n• Cultural . Users might hide passwords under their keyboards or forget to shred confi-\\ndential reports.\\n• Procedural . Company procedures might not require complex passwords or the check-\\ning of user IDs.\\nWhen a security vulnerability is left unchecked, it could become a security threat. A \\nsecurity threat is an imminent security violation.\\nA security breach occurs when a security threat is exploited to endanger the \\nintegrity, confidentiality, or availability of the system. Security breaches can lead to \\na database whose integrity is either preserved or corrupted:\\n• Preserved . In these cases, action is required to avoid the recurrence of similar security \\nproblems, but data recovery may not be necessary. As a matter of fact, most security \\nviolations are produced by unauthorized and unnoticed access for information pur -\\nposes, but such snooping does not disrupt the database.\\n• Corrupted . Action is required to avoid the recurrence of similar security problems, \\nand the database must be recovered to a consistent state. Corrupting security breaches include database access by computer viruses and by hackers who intend to destroy or alter data.\\nTable 16.4 illustrates some security vulnerabilities of system components and typical \\nprotective measures against them.availability\\n In the context of data security, it refers to the accessibility of data whenever required by authorized users and for authorized purposes.\\nsecurity policy\\nA collection of standards, policies, and procedures created to guarantee the security of a system and ensure auditing and compliance.\\nsecurity vulnerability\\nA weakness in a system component that could be exploited to allow unauthorized access or cause service disruptions.\\nsecurity threat\\nAn imminent security violation that could occur due to unchecked security vulnerabilities.\\nsecurity breach\\nAn event in which a security threat is exploited to endanger the integrity, confidentiality, or availability of the system.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61c90cf7-d681-41fc-a646-e47ed5a35409', embedding=None, metadata={'page_label': '747', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    747\\nTABLE 16.4\\nSAMPLE SECURITY VULNERABILITIES AND RELATED PROTECTIVE MEASURES\\nSYSTEM COMPONENT SECURITY VULNERABILITY SECURITY MEASURES\\nPeople • The user sets a blank password.\\n• The password is short or includes a \\nbirth date.\\n• The user leaves the office door open all the time.\\n• The user leaves payroll information on the screen for long periods of time.• Enforce complex password policies.\\n• Use multilevel authentication.\\n• Use security screens and screen savers.\\n• Educate users about sensitive data.\\n• Install security cameras.\\n• Use automatic door locks.\\nWorkstation and servers • The user copies data to a flash drive.\\n• The workstation is used by multiple users.\\n• A power failure crashes the computer.\\n• Unauthorized personnel can use the computer.\\n• Sensitive data is stored on a laptop computer.\\n• Data is lost due to a stolen hard disk or laptop.\\n• A natural disaster occurs.• Use group policies to restrict the use of flash drives.\\n• Assign user access rights to workstations.\\n• Install uninterrupted power supplies (UPSs).\\n• Add security locks to computers.\\n• Implement a kill switch for stolen laptops.\\n• Create and test data backup and recovery plans.\\n• Protect the system against natural disasters—use co-location strategies.\\nOperating system\\n• Buffer overflow attacks\\n• Virus attacks\\n• Root kits and worm attacks\\n• Denial-of-service attacks\\n• Trojan horses\\n• Spyware applications\\n• Password crackers• Apply OS security patches and updates.\\n• Apply application server patches.\\n• Install antivirus and antispyware software.\\n• Enforce audit trails on the computers.\\n• Perform periodic system backups.\\n• Install only authorized applications.\\n• Use group policies to prevent unauthorized installations.\\nApplications\\n• Application bugs—buffer overflow\\n• SQL injection, session hijacking, etc.\\n• Application vulnerabilities—cross-site scripting, nonvalidated inputs\\n• Email attacks—spamming, phishing, etc.\\n• Social engineering emails• Test application programs extensively.\\n• Build safeguards into code.\\n• Do extensive vulnerability testing in applications.\\n• Install spam filters and antivirus software for email systems.\\n• Use secure coding techniques (see www.owasp.org).\\n• Educate users about social engineering attacks.\\nNetwork\\n• IP spoofing\\n• Packet sniffers\\n• Hacker attacks\\n• Clear passwords on network• Install firewalls.\\n• Use virtual private networks (VPNs).\\n• Use intrusion detection systems (IDSs).\\n• Use network access control (NAC).\\n• Use network activity monitoring.\\nData • Data shares are open to all users.\\n• Data can be accessed remotely.\\n• Data can be deleted from a shared resource.• Implement file system security.\\n• Implement share access security.\\n• Use access permission.\\n• Encrypt data at the file system or database level.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13a90ece-080b-4f93-ae2d-271065ea4198', embedding=None, metadata={'page_label': '748', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='748   Part 6    Database Administration\\n16-6c  Database Security\\nDatabase security refers to DBMS features and other related measures that comply \\nwith the organization’s security requirements. From the DBA ’s point of view, security measures should be implemented to protect the DBMS against service degradation and to protect the database against loss, corruption, or mishandling. In short, the DBA should secure the DBMS from the point of installation through operation and maintenance.\\ndatabase security\\nThe use of DBMS features and other related measures to comply with the security requirements of an organization.\\nauthorization management\\nProcedures that protect and guarantee database security and integrity. Such procedures include user access management, view definition, DBMS access control, and DBMS usage monitoring.To protect the DBMS against service degradation, some security safeguards are rec-\\nommended. For example:\\n• Change default system passwords.\\n• Change default installation paths.\\n• Apply the latest patches.\\n• Secure installation folders with proper access rights.\\n• Make sure that only required services are running.\\n• Set up auditing logs.\\n• Set up session logging.\\n• Require session encryption.\\nFurthermore, the DBA should work closely with the network administrator to imple-\\nment network security that protects the DBMS and all services running on the network. \\nIn modern organizations, one of the most critical components in the information archi-tecture is the network.\\nProtecting the data in the database is a function of authorization management. \\nAuthorization management defines procedures to protect and guarantee database security and integrity. Those procedures include the following:\\n•\\n User access management . This function is designed to limit access to the database; it \\nlikely includes at least the following procedures:\\n –Define each user to the database. The DBA performs this function at the operat-\\ning system level and the DBMS level. At the operating system level, the DBA can request the creation of a unique user ID for each end user who logs on to the com-puter system. At the DBMS level, the DBA can either create a different user ID or employ the same one to authorize the end user to access the DBMS.\\n –Assign passwords to each user . The DBA also performs this function at both the \\noperating system and DBMS levels. The database passwords can be assigned with predetermined expiration dates, which enable the DBA to screen end users peri-odically and remind them to change their passwords, thus making unauthorized access less likely.\\nJames Martin’s excellent description of the desirable attributes of a database security strat -\\negy remains relevant today (Managing the Database Environment, Prentice-Hall, 1977). Martin’s security strategy is based on the seven essentials of database security, and may be summarized as one in which data is protected, reconstructable, auditable, and tamper -\\nproof, and users are identifiable, authorized, and monitored.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7ebb967c-11bf-48a5-9b6d-9ac0760c62f1', embedding=None, metadata={'page_label': '749', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    749\\n –Define user groups. Classifying users into groups according to common access \\nneeds can help the DBA control and manage the access privileges of individual users. Also, the DBA can use database roles and resource limits to minimize the impact of rogue users in the system. (See Section 16-10d for more information about these topics.)\\n –Assign access privileges . The DBA assigns access privileges to specific users to access \\ncertain databases. Access rights may be limited to read-only, or the authorized access might include read, write, and delete privileges. Access privileges in rela-tional databases are assigned through SQL GRANT and REVOKE commands.\\n –Control physical access . Physical security can prevent unauthorized users from \\ndirectly accessing the DBMS installation and facilities. Common physical security for large database installations includes secured entrances, password-protected workstations, electronic personnel badges, closed-circuit video, voice recognition, and biometric technology.\\n•\\n View definition . The DBA must define data views to protect and control the scope of \\nthe data that are accessible to an authorized user. The DBMS must provide tools that allow the definition of views composed of one or more tables, and must assign access rights to users. The SQL CREATE VIEW command is used in relational databases to define views. Oracle DBMS offers Virtual Private Database (VPD), which allows the DBA to create customized views of the data for different users. With this feature, the DBA could restrict regular users who query a payroll database to see only the nec-essary rows and columns, while department managers would see only the rows and columns pertinent to their departments.\\n•\\n DBMS access control . Database access can be controlled by placing limits on the use of \\nDBMS query and reporting tools. The DBA must make sure the tools are used prop-erly and only by authorized personnel.\\n•\\n DBMS usage monitoring. The DBA must also audit the use of data in the data-base. Several DBMS packages contain features that allow the creation of an audit log, which automatically records a brief description of database opera-tions performed by all users. Such audit trails enable the DBA to pinpoint access violations. The audit trails can be tailored to record all database accesses or just failed ones.\\nThe integrity of a database could be lost because of external factors beyond the DBA ’s \\ncontrol. For example, the database might be damaged or destroyed by an explosion, a fire, or an earthquake. Whatever the reason, the specter of database corruption or destruction makes backup and recovery procedures crucial to any DBA.\\n16-7  Database Administration Tools\\nThe extraordinary growth of data management activities within organizations created the need for better management standards, processes, and tools. Over the years, a new industry arose dedicated exclusively to data administration tools. These tools cover the entire spectrum of data administration tasks, from selection to inception, deployment, migration, and day-to-day operations. For example, you can find sophisticated data administration tools for:\\n•\\n Database monitoring\\n• Database load testing\\n• Database performance tuningaudit log\\nA security feature of a \\ndatabase management system that automatically records a brief description of the database operations performed by all users.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6b652a85-52c7-47ff-b90f-091cf449cc88', embedding=None, metadata={'page_label': '750', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='750   Part 6    Database Administration\\n• SQL code optimization\\n• Database bottleneck identification and remediation\\n• Database modeling and design\\n• Database data extraction, transformation, and loading\\nAll the above-mentioned tools have something in common. They all expand the data-\\nbase’s metadata or data dictionary. The importance of the data dictionary as a DBA tool \\ncannot be overstated. This section examines the data dictionary as a data administration tool, as well as the DBA ’s use of computer-aided systems engineering (CASE) tools to support database analysis and design.\\n16-7a  The Data Dictionary\\nIn Chapter 1, a data dictionary  was defined as “a DBMS component that stores the \\ndefinition of data characteristics and relationships. ” Y ou may recall that such “data about data” are called metadata . The DBMS data dictionary provides the DBMS with \\nits self-describing characteristic. In effect, the data dictionary resembles an x-ray of the company’s entire data set, and it is a crucial element in data administration.\\nTwo main types of data dictionaries exist: integrated  and standalone . An integrated \\ndata dictionary is included with the DBMS. For example, all relational DBMSs include a built-in data dictionary or system catalog that is frequently accessed and updated by the RDBMS. Other DBMSs, especially older types, do not have a built-in data dictionary; instead, the DBA may use third-party standalone  systems.\\nData dictionaries can also be classified as active  or passive . An active data dictionary  \\nis automatically updated by the DBMS with every database access to keep its access infor -\\nmation up to date. A passive data dictionary is not updated automatically and usually \\nrequires running a batch process. Data dictionary access information is normally used by the DBMS for query optimization.\\nThe data dictionary’s main function is to store the description of all objects that inter -\\nact with the database. Integrated data dictionaries tend to limit their metadata to the data managed by the DBMS. Standalone data dictionary systems are usually more flexible and allow the DBA to describe and manage all of the organization’s data, whether they are computerized or not. Whatever the data dictionary’s format, it provides database design-ers and end users with a much-improved ability to communicate. In addition, the data dictionary is the tool that helps the DBA resolve data conflicts.\\nAlthough there is no standard format for the information stored in the data dictio-\\nnary, several features are common. For example, the data dictionary typically stores descriptions of the following:\\n•\\n Data elements that are defined in all tables of all databases. Specifically, the data dic-\\ntionary stores element names, data types, display format, internal storage format, and validation rules. The data dictionary explains where an element is used, who used it, and so on.\\n•\\n Tables defined in all databases. For example, the data dictionary is likely to store the name of the table creator, the date of creation, access authorizations, and the number of columns.\\n•\\n Indexes defined for each database table. For each index, the DBMS stores at least the index name, the attributes used, the location, specific index characteristics, and the creation date.\\n•\\n Defined databases. This information includes who created each database, when the database was created, where the database is located, the DBA ’s name, and so on.active data dictionary\\nA data dictionary that is automatically updated by the database management system every time the database is accessed, thereby keeping its information current.\\npassive data dictionary\\nA DBMS data dictionary that requires a command initiated by an end user to update its data access statistics.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a0eb2b44-308f-4314-86a2-bf2538f89300', embedding=None, metadata={'page_label': '751', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    751\\n• End users and administrators of the database. This information defines the users of the \\ndatabase.\\n• Programs that access the database. This information includes screen formats, report formats, application programs, and SQL queries.\\n•\\n Access authorizations for all users of all databases. This information defines who can manipulate which objects and what types of operations can be performed.\\n•\\n Relationships among data elements. This information includes which elements are involved, whether the relationships are mandatory or optional, and connectivity and cardinality requirements.\\nIf the data dictionary can be organized to include data external to the DBMS itself, \\nit becomes an especially flexible tool for more general corporate resource management. Such an extensive data dictionary thus makes it possible to manage the use and alloca-tion of all of the organization’s information, regardless of whether it has its roots in the database data. For this reason, some managers consider the data dictionary to be a key element of information resource management, which is why the data dictionary can be described as the information resource dictionary.\\nThe metadata stored in the data dictionary is often the basis for monitoring data-\\nbase use and for assigning access rights to database users. The information stored in the data dictionary is usually based on a relational table format, thus enabling the DBA to query the database with SQL commands. For example, SQL commands can be used to extract information about the users of a specific table or the access rights of a particular user. In the following section, the IBM DB2 system catalog tables are the basis for several examples of how a data dictionary is used to derive information:\\n•\\n SYSTABLES stores one row for each table or view.\\n• SYSCOLUMNS stores one row for each column of each table or view.\\n• SYSTABAUTH stores one row for each authorization given to a user for a table or \\nview in a database.\\nExamples of Data Dictionary Usage  \\nExample 1\\nList the names and creation dates of all tables created by the user JONESVI in the current \\ndatabase.\\nSELECT NAME, CTIME\\nFROM SYSTABLESWHERE CREATOR = ‘JONESVI’;\\nExample 2\\nList the names of the columns for all tables created by JONESVI in the current \\ndatabase.\\nSELECT NAME\\nFROM SYSCOLUMNSWHERE TBCREATOR = ‘JONESVI’;\\nExample 3\\nList the names of all tables for which the user JONESVI has DELETE authorization.information resource \\ndictionary\\nAnother name for data dictionary.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5e5098d5-fc99-4d1a-81ba-efd92839e2aa', embedding=None, metadata={'page_label': '752', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='752   Part 6    Database Administration\\nSELECT TTNAME\\nFROM SYSTABAUTHWHERE GRANTEE = ‘JONESVI’ AND DELETEAUTH = ‘Y’;\\nExample 4List the names of all users who have some type of authority over the INVENTORY table.SELECT DISTINCT GRANTEE\\nFROM SYSTABAUTHWHERE TTNAME = ‘INVENTORY’;\\nExample 5List the user and table names for all users who can alter the database structure for any \\ntable in the database.\\nSELECT GRANTEE, TTNAME\\nFROM SYSTABAUTHWHERE ALTERAUTH = ‘Y’ORDER BY GRANTEE, TTNAME;\\nAs you can see in the preceding examples, the data dictionary can be a tool for \\nmonitoring database security by checking the assignment of data access privileges. Although the preceding examples targeted database tables and users, information about the application programs that access the database can also be drawn from the data dictionary.\\nThe DBA can use the data dictionary to support data analysis and design. For exam-\\nple, the DBA can create a report that lists all data elements to be used in a particular application; a list of all users who access a particular program; a report that checks for data redundancies, duplications, and the use of homonyms and synonyms; and a number of other reports that describe data users, data access, and data structure. The data dictionary can also be used to ensure that application programmers have met the naming standards for data elements in the database, and that the data validation rules are correct. Thus, the data dictionary can be used to support a wide range of data administration activities and facilitate the design and implementation of information systems. Integrated data dictionaries are also essential to the use of computer-aided systems engineering tools.\\n16-7b  Case Tools\\nCASE is the acronym for computer-aided systems engineering. A CASE tool provides an automated framework for the Systems Development Life Cycle (SDLC). CASE uses structured methodologies and powerful graphical interfaces. Because they automate many tedious system design and implementation activities, CASE tools play an increas-ingly important role in information systems development.\\nCASE tools are usually classified according to the extent of support they pro-\\nvide for the SDLC. For example, front-end CASE tools provide support for the planning, analysis, and design phases; back-end CASE tools provide support for the coding and implementation phases. The benefits associated with CASE tools include:\\n•\\n A reduction in development time and costs\\n• Automation of the SDLCcomputer-aided \\nsystems engineering (CASE)\\nTools used to automate part or all of the Systems Development Life Cycle.\\nfront-end CASE tool\\nA computer-aided software tool that provides support for the planning, analysis, and design phases of the SDLC.\\nback-end CASE tool\\nA computer-aided software tool that provides support for the coding and implementation phases of the SDLC.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2e72c09a-43f6-4ede-aa23-59ce27b0abf2', embedding=None, metadata={'page_label': '753', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    753\\n• Standardization of systems development methodologies\\n• Easier maintenance of application systems developed with CASE tools\\nOne of the CASE tools’ most important components is an extensive data dictio-\\nnary, which keeps track of all objects created by the systems designer. For example, \\nthe CASE data dictionary stores data flow diagrams, structure charts, descriptions of all external and internal entities, data stores, data items, report formats, and screen formats. A CASE data dictionary also describes the relationships among system components.\\nSeveral CASE tools provide interfaces that work with the DBMS and allow the \\nCASE tool to store its data dictionary information using the DBMS. Such inter -\\naction demonstrates the interdependence that exists between systems develop-ment and database development, and it helps create a fully integrated development environment.\\nIn a CASE development environment, database and application designers use the \\nCASE tool to store the description of the database schema, data elements, application processes, screens, reports, and other data relevant to development. The CASE tool inte-grates all systems development information in a common repository, which the DBA can check for consistency and accuracy.\\nAs an additional benefit, a CASE environment tends to improve the extent and quality \\nof communication among the DBA, application designers, and end users. The DBA can use the CASE tool to check the definition of the application’s data schema, the obser -\\nvance of naming conventions, the duplication of data elements, validation rules for the data elements, and a host of other developmental and managerial variables. When the CASE tool finds conflicts, rules violations, and inconsistencies, it facilitates making cor -\\nrections. Better yet, the CASE tool can make a correction and then cascade its effects throughout the applications environment, which greatly simplifies the job of the DBA and the application designer.\\nA typical CASE tool provides five components:\\n•\\n Graphics designed to produce structured diagrams such as data flow diagrams, ER diagrams, class diagrams, and object diagrams\\n•\\n Screen painters and report generators to produce the information system’s input and output formats (for example, the end-user interface)\\n•\\n An integrated repository for storing and cross-referencing the system design data; this repository includes a comprehensive data dictionary\\n•\\n An analysis segment to provide a fully automated check on system consistency, syn-tax, and completeness\\n•\\n A program documentation generator\\nFigure 16.7 illustrates how Microsoft Visio Professional can be used to produce an ER \\ndiagram.\\nMost CASE tools, produce fully documented ER diagrams that can be displayed \\nat different abstraction levels. For example, ERwin Data Modeler by Computer Asso-ciates can produce detailed relational designs. The user specifies the attributes and primary keys for each entity and describes the relations. Current generation data modeling tools assign foreign keys based on the specified relationships among the entities. Changes in primary keys are always updated automatically throughout the system. Table 16.5 shows a short list of the many available CASE Data Modeling tool vendors.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8721488e-8ad0-41b7-b8d6-e7ab5e7cafbf', embedding=None, metadata={'page_label': '754', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='754   Part 6     Database Administration\\nMajor relational DBMS vendors, such as Oracle, now provide fully integrated CASE tools \\nfor their own DBMS software as well as for RDBMSs supplied by other vendors. For example, \\nOracle’s CASE tools can be used with IBM’s DB2, and Microsoft’s SQL Server to produce fully \\ndocumented database designs. Some vendors even take nonrelational DBMSs, develop their \\nschemas, and produce the equivalent relational designs automatically.FIGURE 16.7  AN EXAMPLE OF A CASE TOOL: MICROSOFT VISIO PROFESSIONAL  \\nMain menu\\nModeling options\\nCompleted ERD\\nTABLE 16.5\\nCASE DATA MODELING TOOLS\\nCOMPANY PRODUCT WEBSITE\\nCasewise Corporate Modeler Suite www.casewise.com\\nComputer Associates ERwin www.erwin.com\\nEmbarcadero Technologies ER/Studio www.embarcadero.com/products/er-studio-data-architect\\nMicrosoft Visio office.microsoft.com/en-us/visio\\nOracle SQL Developer Data \\nModelerwww.oracle.com/technetwork/developer-tools/datamodeler/\\noverview/index.html\\nIBM Rational Software \\nArchitectwww-01.ibm.com/software/rational/products/swarchitect/\\nSAP Power Designer http://www.sap.com/pc/tech/database/software/model-\\ndriven-architecture/index.html\\nVisible Visible Analyst www.visible.com/Products/Analyst\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a2b77334-bca5-4cd7-9523-edf6238239dc', embedding=None, metadata={'page_label': '755', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    755\\nThere is no doubt that CASE tools have enhanced the efficiency of database designers \\nand application programmers. However, no matter how sophisticated the CASE tool, its \\nusers must be well versed in conceptual design. In the hands of database novices, CASE \\ntools produce impressive-looking but bad designs.\\n16-8  Developing a Data Administration Strategy\\nFor a company to succeed, its activities must be committed to its main objectives or mis -\\nsion. Therefore, regardless of its size, a critical step for any organization is to ensure that \\nits information system supports its strategic plans for each business area.\\nThe database administration strategy must not conflict with the information systems \\nplans. After all, these plans are derived from a detailed analysis of the company’s goals, \\nits condition or situation, and its business needs. Several methodologies are available to \\nensure the compatibility of data administration and information systems plans and to \\nguide strategic plan development. The most commonly used methodology is known as \\ninformation engineering.\\nInformation engineering (IE)  allows for translation of the company’s strategic goals \\ninto the data and applications that will help the company achieve those goals. IE focuses \\non the description of corporate data instead of the processes. The IE rationale is simple: \\nbusiness data types tend to remain fairly stable, but processes change often and thus \\nrequire frequent modification of existing systems. By placing the emphasis on data, IE \\nhelps decrease the impact on systems when processes change.\\nThe output of the IE process is an information systems architecture (ISA)  that \\nserves as the basis for planning, development, and control of future information systems. \\nFigure 16.8 shows the forces that affect ISA development.\\nImplementing IE in an organization is a costly process that involves planning, a com -\\nmitment of resources, management liability, well-defined objectives, identification of \\ncritical factors, and control. An ISA provides a framework that includes computerized, \\nautomated, and integrated tools such as a DBMS and CASE tools.\\nThe success of the overall information systems strategy and data administration strategy \\ndepends on several critical success factors that the DBA needs to understand. Critical suc -\\ncess factors include the following managerial, technological, and corporate culture issues:\\n• Management commitment . The commitment of top-level management is necessary to \\nenforce the use of standards, procedures, planning, and controls. The example must \\nbe set at the top.\\n• Thorough analysis of the company situation . The current state of the corporate data \\nadministration must be analyzed to understand the company’s position and to have information \\nengineering (IE)\\nA methodology that \\ntranslates a company’s \\nstrategic goals into \\nhelpful data and \\napplications. IE focuses \\non the description of \\ncorporate data instead of \\nthe processes.\\ninformation systems \\narchitecture (ISA)\\nThe output of the \\ninformation engineering \\n(IE) process that \\nserves as the basis for \\nplanning, developing, \\nand controlling future \\ninformation systems.FIGURE 16.8  FORCES AFFECTING THE DEVELOPMENT OF THE ISA  \\nCompany\\nmissionInformation\\nengineeringCompany managers\\n(provide Goals and\\nCritical Success Factors)\\nInformation\\nsystems\\narchitectureStrategic\\nplan\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4c908a4a-5bfb-4db8-9d5c-a97cfb46834a', embedding=None, metadata={'page_label': '756', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='756   Part 6    Database Administration\\na clear vision of what must be done. For example, how are database analysis, design, \\ndocumentation, implementation, standards, codification, and other issues handled? Needs and problems should be identified first and then prioritized.\\n•\\n End-user involvement. What degree of organizational change is involved? Successful change requires that people be able to adapt to it. Users should have an open com-munication channel to upper management to ensure success of the implementation. Good communication is key to the overall process.\\n•\\n Defined standards . Analysts and programmers must be familiar with appropriate \\nmethodologies, procedures, and standards. If not, they might need training.\\n• Training . The vendor must train DBA personnel in the use of the DBMS and other \\ntools. End users must be trained to use the tools, standards, and procedures. Key per -\\nsonnel should be trained first so they can train others.\\n• A small pilot project . A small project is recommended to ensure that the DBMS will \\nwork in the company, that it produces expected output, and that the personnel have been trained properly.\\nThis list of factors is not comprehensive, but it does provide the framework for devel-\\noping a successful strategy. Remember that no matter how comprehensive you make the list, it must be based on developing and implementing a data administration strategy that is tightly integrated with the organization’s overall information systems planning.\\nDeveloping a comprehensive data administration strategy within an organization is a \\nlarge undertaking encompassing technical, operational, and managerial roles. Enterprises today also have the option of moving entire computing functions (such as servers, storage, backup, and even the database) outside the walls of the enterprise and into the cloud.\\n16-9  The DBA’s Role in the Cloud\\nThe use of cloud-based data services does not signal the end of DBAs, but it does have a significant impact on their role. As discussed in previous chapters, services such as Microsoft Azure and Amazon Web Services (AWS) allow outsourcing database tech-nology as a highly scalable, capability-on-demand service. In this new world, some of the tasks that once resided in a single “in-house” DBA function are now split between the internal DBA and the cloud service provider. As a result, the use of cloud-based data services alters and expands the typical DBA ’s role in both technical and manage-rial dimensions. In general, the cloud services partner company provides:\\n•\\n DBMS installation and updates. The DBMS is installed on a virtual server by the ser -\\nvice provider. As the DBMS vendor releases required updates and security fixes to the \\nDBMS software, the service provider manages the application of the updates within a specified maintenance window. The DBA ’s role now has to carefully coordinate such updates with the external cloud-based data service provider.\\n•\\n Server/network management. The service provider configures and manages the server where the DBMS resides, including scaling the database across multiple servers as needed. If the database is distributed across multiple servers, the service provider can supply load balancing to ensure a high level of performance. However, the DBA must work with his or her /her company’s network department to ensure that the network is properly configured for security, performance, availability and management.\\n•\\n Backup and recovery operations. The service provider performs regular backups and stores backups in secure facilities. The DBA must ensure that internal data privacy and retention policies are enforced and maintained.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3b642731-ac1e-4dac-97f0-6b9d4245e11b', embedding=None, metadata={'page_label': '757', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    757\\nAlthough these services are valuable and free the DBA from these tasks, the primary \\nbenefit of cloud-based data services is their ability to provide and manage computing \\nhardware and software configuration at a low cost. The preceding tasks are only a small part of the DBA ’s responsibilities; the DBA ’s managerial role is largely unchanged and sometimes is even augmented with the new cloud data services dimension. User require-ments must still be gathered; data solutions must still be designed; end users need train-ing; and policies, standards, and procedures must be developed and enforced.\\nEven the technical role of the DBA still exists with the use of cloud data services. \\nThere are many cloud data service providers, and some offer a variety of DBMS products, including proprietary systems. Only some versions of these DBMSs are available, includ-ing multiple versions of the same DBMS. For example, a given service provider may sup-port both MySQL 5.1 and MySQL 5.5. In this environment, the DBA evaluates different DBMSs to determine which software product to use, and evaluates from which provider to purchase the DBMS. In addition, the DBA must work with the cloud data services provider to reconcile the required database technical features with the ones supported by the cloud data service provider and ensure data availability, security, and integrity within the expanded boundaries of the company network.\\nA variety of pricing schemes are offered by cloud data service providers. Pricing is \\ntypically based on factors such as storage space, computing resources (CPU cycles and memory), and data transfer sizes. Service users are billed monthly for the amount of resources used. Service providers have a vested interest in their clients’ databases being as large as possible; it is also in their interest for database designs to be inefficient in processing queries because clients will have to buy more memory and CPU capacity. Service providers benefit if your database is filled with poorly designed tables that con-tain lots of unnecessarily redundant data, with every attribute in every table indexed, and queries that take a long time to run or return thousands of rows of data that must be transferred to a front-end application for additional processing. Therefore, the DBA can save the organization significant time and money by ensuring that databases are properly designed with minimal redundancy and that database coding is efficient. Clearly, the DBA ’s technical role is still critical to organizations that use cloud-based data services. The DBA ’s efforts in efficient and effective database design, coding, monitoring database performance, and database tuning still affect the organization’s ability to use data and information as a resource, and they have an immediate visible impact on the monthly data service bill.\\nRegardless of whether the database is stored in the enterprise’s server or in the cloud, \\nthe DBA must ensure the data’s availability, security, and integrity.\\n16-10   The DBA at Work: Using Oracle for  Database Administration\\nThus far, you have learned about the DBA ’s work environment and responsibilities in general terms. This section provides a more detailed look at how a DBA might handle the following technical tasks in a specific DBMS:\\n•\\n Creating and expanding database storage structures\\n• Managing the end-user database environment, including the type and extent of data-\\nbase access\\n• Customizing database initialization parameters\\nMany of these tasks require the DBA to use software tools and utilities that are \\ncommonly provided by the database vendor. In fact, all DBMS vendors provide a set \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f1e8f9b7-2aba-4a4e-8732-016ac2660f82', embedding=None, metadata={'page_label': '758', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='758   Part 6    Database Administration\\nof programs to interface with the database and to perform a wide range of database \\nadministrative tasks.\\nOracle 12c for Windows is used to illustrate selected DBA tasks in this section because \\nOracle is typically used in organizations that are large and complex enough to employ a DBA. Also, Oracle has good market presence and is often used in small colleges and universities.\\nMost of the tasks described in this section are not particular to any DBMS or operat-\\ning system. However, the execution of those tasks tends to be specific to the DBMS and operating system. Therefore, if you use IBM DB2 Universal Database or Microsoft SQL Server, you must adapt the procedures shown here to your DBMS. Also, these examples run under the Windows operating system, so you must adapt the procedures shown in this section if you use a different OS.\\nThis section is not a database administration manual; it offers a brief introduction to \\nperforming typical DBA tasks in Oracle. Before learning these tasks, you should become familiar with Oracle’s database administration tools and its procedures for logging on. These tools and procedures are discussed in the next two sections.\\n16-10a  Oracle Database Administration Tools\\nAll database vendors supply a set of database administration tools. In Oracle, you per -\\nform most DBA tasks via the Oracle Enterprise Manager interface. (See Figure 16.9.)\\nNote that the interface shows the status of the current database. (This section uses the \\nBASEORA database.) In the following sections, you examine the tasks most commonly encountered by a DBA.\\n16-10b  Ensuring that the RDBMS Starts Automatically\\nOne of a DBA ’s basic tasks is to ensure that database access starts automatically when you turn on the computer. Startup procedures are different for each operating system. Oracle is used for this section’s examples; if you use a different system, you need to identify the required services to ensure automatic database startup. A service  is the Windows name \\nAlthough Microsoft Access is a superb DBMS, it is typically used in smaller organizations or in organizations and departments with relatively simple data environments. Access has a superior database prototyping environment, and its easy-to-use GUI tools enable rapid front-end application development. Also, Access is a component in the MS Office suite, which makes applications integration relatively simple and seamless for end users. Finally, while Access does provide some important database administration tools, an Access-based database environment does not typically require a DBA, so MS Access is not a good fit for this section.Note\\nAlthough the format of creating a database tends to be generic, its execution tends to be DBMS-specific. For a step-by-step procedure of creating a database using the Oracle Data -\\nbase Configuration Assistant, see Appendix N, Creating a New Database Using Oracle 12c.Note\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7c711d83-b4b9-4114-979f-2896bce681d6', embedding=None, metadata={'page_label': '759', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    759\\nfor a special program that runs automatically as part of the operating system. This pro -\\ngram ensures the availability of required services to the system and to end users on the \\nlocal computer or the network. Figure 16.10 shows the required Oracle services that are \\nstarted automatically when Windows starts.\\nAs you examine Figure 16.10, note the following Oracle services:\\n• OracleOraDB12Home1TNSListener  is the process that “listens to” and processes end-\\nuser connection requests over the network. For example, when a SQL connection \\nrequest such as “connect userid/password@BASEORA ” is sent over the network, the \\nlistener service will validate the request and establish the connection.FIGURE 16.9  THE ORACLE ENTERPRISE MANAGER EXPRESS INTERFACE  \\nFIGURE 16.10  ORACLE RDBMS SERVICES  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a35007c4-9e7e-4aff-ad7e-4584627bd6a8', embedding=None, metadata={'page_label': '760', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='760   Part 6     Database Administration\\n• OracleServiceBASEORA  refers to the Oracle processes running in memory that \\nare associated with the BASEORA database instance. Y ou can think of a database  \\ninstance  as a separate location in memory that is reserved to run your database. \\nBecause you can have several databases (and therefore several instances) running in \\nmemory at the same time, you need to identify each database instance uniquely, using \\na different suffix for each one.\\n16-10c  Creating Tablespaces and Datafiles\\nEach DBMS manages data storage differently. In this example, the Oracle RDBMS is used \\nto illustrate how the database manages data storage at the logical and physical levels. In \\nOracle, \\n• A database is logically  composed of one or more tablespaces. A tablespace  is a logical \\nstorage space. Tablespaces are used primarily to group related data logically.\\n• The tablespace data is physically  stored in one or more datafiles. A datafile  physically \\nstores the database’s data. Each datafile is associated with only one tablespace, but each \\ndatafile can reside in a different directory on the physical storage devices. For example, \\nin Figure 16.11, the USERS tablespace data is physically stored in the datafile users01.dbf .\\ndatabase instance\\nIn an Oracle DBMS, the \\ncollection of processes \\nand data structures used \\nto manage a specific \\ndatabase.\\ntablespace\\nIn a DBMS, a logical \\nstorage space used to \\ngroup related data. Also \\nknown as a file group .\\ndatafile\\nA file on the hard drive \\nor storage system where \\nthe data in a tablespace \\nis physically stored.FIGURE 16.11  ORACLE STORAGE MANAGEMENT  \\nGiven the preceding descriptions, you can conclude that a database has a one-to-\\nmany relationship with tablespaces and that a tablespace has a one-to-many relationship \\nwith datafiles. This set of 1:M hierarchical relationships isolates the end user from any \\nphysical details of data storage. However, the DBA must be aware of these details to prop -\\nerly manage the database .\\nTo manage database storage, such as creating and managing tablespaces and datafiles, \\nthe DBA uses the Enterprise Manager → Server → Tablespaces option.\\nWhen the DBA creates a database, Oracle automatically creates the tablespaces and \\ndatafiles shown in Figure 16.11. A few of them are described as follows:\\n• The SYSTEM  tablespace is used to store the data dictionary data.\\n• The USERS  tablespace stores the table data created by the end users.\\n• The TEMP  tablespace stores the temporary tables and indexes created during \\nthe execution of SQL statements. For example, temporary tables are created \\nwhen your SQL statement contains an ORDER BY , GROUP BY , or HAVING \\nclause.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04ba58f3-8564-4ba2-8062-dd710e98eaa2', embedding=None, metadata={'page_label': '761', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    761\\n• The UNDOTBS1  tablespace stores database transaction recovery information. \\nIf a transaction must be rolled back (usually to preserve database integrity), the \\nUNDOTBS1 tablespace stores the undo information.\\nUsing the Enterprise Manager, the DBA can:\\n• Create additional tablespaces to organize the data in the database. Therefore, if you \\nhave a database with several hundred users, you can create several user tablespaces \\nto segment data storage for different types of users. For example, you might create a \\nteacher tablespace and a student tablespace.\\n• Create additional tablespaces to organize the various subsystems within the database. \\nFor example, you might create different tablespaces for human resources data, payroll \\ndata, accounting data, and manufacturing data. Figure 16.12 shows the wizard used \\nto create a tablespace called CORMOR that holds the tables used in this book. This \\ntablespace is stored in the datafile named CORMOR01.DBF, and its initial size is 100 \\nmegabytes. Note that the tablespace is available to users for data storage purposes. \\nAlso, you can click the Show SQL button at the top of the page to see the SQL code \\ngenerated by Oracle to create the tablespace. (All DBA tasks can be accomplished \\nthrough the direct use of SQL commands. In fact, some die-hard DBAs prefer writing \\ntheir own SQL code rather than using the GUI.)\\n• Expand the tablespace storage capacity by creating additional datafiles. Remember \\nthat the datafiles can be stored in the same directory or on different disks to increase \\naccess performance. For example, you could increase storage and access performance \\nto the USERS tablespace by creating a new datafile on a different drive.\\nFIGURE 16.12  CREATING A NEW ORACLE TABLESPACE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2403dc46-6201-4ec6-bdd7-10b02ff06b40', embedding=None, metadata={'page_label': '762', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='762   Part 6     Database Administration\\n16-10d  Managing Users and Establishing Security\\nOne of the most common database administration activities is creating and managing \\ndatabase users. The creation of user IDs is the first component of any well-planned data -\\nbase security function.\\nThe Security section of the Oracle Enterprise Manager enables the DBA to create \\nusers, roles, and profiles. \\n• A user  is a uniquely identifiable object that allows a given person to log on to the \\ndatabase. The DBA assigns privileges for accessing the objects in the database. Within \\nthe privilege assignment, the DBA may specify a set of limits that define how many \\ndatabase resources the user can use.\\n• A role is a named collection of database access privileges that authorize a user to \\nconnect to the database and use its system resources. Examples of roles are as follows:\\n –CONNECT  allows a user to connect to the database and then create and modify \\ntables, views, and other data-related objects.\\n –RESOURCE  allows a user to create triggers, procedures, and other data manage -\\nment objects.\\n –DBA  gives the user database administration privileges.\\n• A profile  is a named collection of settings that control how much of the database resource \\na given user can access. For example, a runaway query could cause the database to lock up \\nor stop responding to the user’s commands, so it is important to limit access to the data -\\nbase resource. By specifying profiles, the DBA can limit how much storage space a user \\ncan have, how long a user can be connected, how much idle time may be used before the \\nuser is disconnected, and so on. In an ideal world, all users would have unlimited access \\nto all resources at all times, but realistically, such access is neither possible nor desirable.\\nFigure 16.13 shows the Oracle Enterprise Manager Users page. From here, the DBA \\ncan manage the database and create security objects such as users, roles, and profiles.user\\nIn a system, a uniquely \\nidentifiable object that \\nallows a given person or \\nprocess to log on to the \\ndatabase.\\nrole\\nIn Oracle, a named \\ncollection of database \\naccess privileges that \\nauthorize a user to \\nconnect to a database \\nand use its system \\nresources.\\nprofile\\nIn Oracle, a named \\ncollection of settings \\nthat controls how much \\nof the database resource \\na given user can use.\\nFIGURE 16.13  THE ORACLE ENTERPRISE MANAGER USERS PAGE  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='35636906-5d5e-411b-94c0-d1e09477e6bc', embedding=None, metadata={'page_label': '763', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    763\\nTo create a new user, the DBA clicks the Create User button to start the wizard shown \\nin Figure 16.14.\\nThe User page buttons and menu items support many actions. For example, from this \\npage the DBA can:\\n• Drop the user from the database.\\n• Alter the user’s default and temporary tablespaces.\\n• Alter the privileges and roles assigned to the user.\\n• View the user details to adjust object privileges and quotas. Quotas allow the DBA to \\nspecify the maximum amount of storage that the user can have in each tablespace. For \\nexample, Figure 16.15 shows a user being assigned a maximum storage allocation of \\n20 megabytes on the CORMOR tablespace.\\n16-10e   Customizing the Database Initialization  \\nParameters\\nFine-tuning a database is another important DBA task that usually requires the mod -\\nification of database configuration parameters, some of which can be changed in real \\ntime using SQL commands. Changes to other parameters require the database to be shut \\ndown and restarted. Also, some parameters may affect only the database instance, while \\nothers affect the entire RDBMS and all instances that are running. So, it is very important FIGURE 16.14  THE CREATE USER WIZARD  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='74cbe343-98a6-4d25-8cdd-fcd23bed9c06', embedding=None, metadata={'page_label': '764', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='764   Part 6     Database Administration\\nthat the DBA become familiar with database configuration parameters, especially those \\nthat affect performance.\\nEach database has an associated initialization file that stores its run-time configu -\\nration parameters. The initialization file is read at instance startup and is used to set \\nthe working environment for the database. Oracle’s Enterprise Manager allows the DBA \\nto start, shut down, view, and edit the database configuration parameters of a database \\ninstance; these parameters are stored in the initialization file. The Oracle Enterprise \\nManager provides a GUI to modify the file, as shown in Figure 16.16.FIGURE 16.15  ASSIGNING A USER QUOTA  \\nFIGURE 16.16  ORACLE ENTERPRISE MANAGER INITIALIZATION PARAMETERS  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bfd2bd03-9303-4dd1-b04f-40f1d6bf39b8', embedding=None, metadata={'page_label': '765', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    765\\nOne of the important functions of the initialization parameters is to reserve the \\nresources that the database uses at run time. One of those resources is the primary mem-\\nory reserved for database caching. Such caching is used to fine-tune database perfor -\\nmance. For example, the “db_cache_size” parameter sets the amount of memory reserved for database caching. This parameter should be set to a value that is large enough to support all concurrent transactions. Once you modify the initialization parameters, you may be required to restart the database.\\nAs you have seen in this brief section, the DBA is responsible for a wide range of tasks. \\nThe quality and completeness of administration tools go a long way toward making the DBA ’s job easier. Even so, the DBA must become familiar with the tools and technical details of the RDBMS to perform tasks properly and efficiently.\\n•\\n Data management is a critical activity for any organization, so data must be treated as \\na corporate asset. The value of a data set is measured by the utility of the information derived from it. Good data management is likely to produce good information, which is the basis for better decision making.\\n•\\n Data quality is a comprehensive approach to ensure the accuracy, validity, and timeli-ness of data. Data quality focuses on correcting dirty data, preventing future inaccu-racies in the data, and building user confidence in the data.\\n•\\n The DBMS is the most commonly used tool for corporate data management. The DBMS supports strategic, tactical, and operational decision making at all levels of the organization. The introduction of a DBMS into an organization is a delicate job; the impact of the DBMS on the organization’s managerial and cultural framework must be carefully examined.\\n•\\n The database administrator (DBA) is responsible for managing the corporate data-base. The internal organization of database administration varies from company to company. Although no standard exists, it is common practice to divide DBA opera-tions according to phases of the Database Life Cycle. Some companies have created a position with a broader mandate to manage computerized data and other data; this activity is handled by the data administrator (DA).\\n•\\n The DA and DBA functions tend to overlap. Generally speaking, the DA has more managerial tasks than the more technically oriented DBA. Compared to the DBA function, the DA function is DBMS-independent, with a broader and longer-term focus. However, when the organization does not include a DA position, the DBA exe-cutes all of the DA ’s functions. In this combined role, the DBA must have a diverse mix of technical and managerial skills.\\n•\\n A DBA ’s managerial services include supporting end users; defining and enforcing policies, procedures, and standards for the database; ensuring data security, privacy, and integrity; providing data backup and recovery services; and monitoring distribu-tion and use of the data in the database.\\n•\\n The DBA ’s technical role requires involvement in at least the following activities: evaluating, selecting, and installing the DBMS; designing and implementing data-bases and applications; testing and evaluating databases and applications; operating and maintaining the DBMS, utilities, and applications; and training and supporting users.Summary\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6cbce1fd-5ba4-499b-bdfe-519641a18003', embedding=None, metadata={'page_label': '766', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='766   Part 6    Database Administration\\n• Security refers to activities and measures that ensure the confidentiality, integrity, and \\navailability of an information system and its main asset, data. A security policy is a collection of standards, policies, and practices that guarantee the security of a system and ensure auditing and compliance.\\n•\\n A security vulnerability is a weakness in a system component that could be exploited to allow unauthorized access or service disruption. A security threat is an imminent security violation caused by an unchecked vulnerability. Security vulnerabilities exist in all components of an information system: people, hardware, software, net-work, procedures, and data. Therefore, it is critical to have robust database security. Database security refers to DBMS features and related measures that comply with the organization’s security requirements.\\n•\\n The development of a data administration strategy is closely related to the company’s mission and objectives. Therefore, the strategic plan requires a detailed analysis of company goals, its situation, and its business needs. To guide the development of this data administration plan, an integrating methodology is required. The most com-monly used integrating methodology is known as information engineering (IE).\\n•\\n To help translate strategic plans into operational plans, the DBA has access to an arse-nal of database administration tools, including a data dictionary and computer-aided systems engineering (CASE) tools.\\n•\\n With the introduction of reliable cloud-based data services, the role of the DBA has expanded beyond corporate walls.\\naccess plan\\nactive data dictionaryaudit logauthorization managementavailabilityback-end CASE toolcomputer-aided systems \\nengineering (CASE)\\ncomplianceconcurrent backupconfidentialitydata administrator (DA)data qualitydatabase administrator (DBA)database dumpdatabase instance (Oracle)database securitydatabase security officer \\n(DSO)datafile (Oracle)data-profiling softwaredirty datadisaster managemententerprise databasefront-end CASE toolfull backupincremental backupinformation engineering (IE)information resource \\ndictionary\\ninformation resource \\nmanager (IRM)\\ninformation systems (IS) \\ndepartment\\ninformation systems \\narchitecture (ISA)\\nintegritymaster data management \\n(MDM) softwarepassive data dictionarypoliciesprivacyproceduresprofile (Oracle)role (Oracle)securitysecurity breachsecurity policysecurity threatsecurity vulnerabilitystandardssystems administratortablespace (Oracle)user (Oracle)\\nKey Terms\\nFlashcards and crossword \\npuzzles for key term  practice are available at  www.cengagebrain.com.Online \\nContent\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a39efa8e-5321-435f-ac72-b3b45cfb2d48', embedding=None, metadata={'page_label': '767', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' Chapter 16    Database Administration and Security    767\\n1. Explain the difference between data and information. Give some examples of raw \\ndata and information.\\n2. Define dirty data, and identify some of its sources.\\n3. What is data quality, and why is it important?\\n4. Explain the interactions among end users, data, information, and decision making. Draw a diagram and explain the interactions.\\n5.\\n Suppose that you are a DBA. What data dimensions would you describe to top-level managers to obtain their support for data administration?\\n6.\\n How and why did database management systems become the data management standard in organizations? Discuss some advantages of the database approach over the file-system approach.\\n7.\\n Using a single sentence, explain the role of databases in organizations. Then explain your answer in more detail.\\n8.\\n Define security and privacy . How are the two concepts related?\\n9. Describe and contrast information needs at the strategic, tactical, and operational levels of an organization. Use examples to explain your answer.\\n10.\\n What special considerations must you take into account when introducing a DBMS into an organization?\\n11.\\n Describe the DBA ’s responsibilities.\\n12. How can the DBA function be placed within the organization chart? What effects will that placement have on the DBA function?\\n13.\\n Why and how are new technological advances in computers and databases changing the DBA ’s role?\\n14.\\n Explain the DBA department’s internal organization based on the DBLC approach.\\n15. Explain and contrast differences and similarities between the DBA and DA.\\n16. Explain how the DBA plays an arbitration role between an organization’s two main assets. Draw a diagram to illustrate your explanation.\\n17.\\n Describe and characterize the skills desired for a DBA.\\n18. What are the DBA ’s managerial roles? Describe the managerial activities and ser -\\nvices provided by the DBA.\\n19. What DBA activities support end users?\\n20. Explain the DBA ’s managerial role in the definition and enforcement of policies, procedures, and standards.\\n21.\\n Protecting data security, privacy, and integrity are important database functions. What activities are required in the DBA ’s managerial role of enforcing those functions?\\n22.\\n Discuss the importance and characteristics of database backup and recovery proce-dures. Then describe the actions that must be detailed in backup and recovery plans.\\n23.\\n Assume that your company has assigned you the responsibility of selecting the cor -\\nporate DBMS. Develop a checklist of the technical issues and other aspects involved in the selection process.Review Questions\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b07bbc1-8400-407e-b474-6a6b6c6c19f7', embedding=None, metadata={'page_label': '768', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='768   Part 6    Database Administration\\n24. Describe the activities that are typically associated with the design and implementation \\nservices of the DBA ’s technical function. What technical skills are desirable in a DBA?\\n25. Why are testing and evaluation of the database and applications not done by the same people who are responsible for design and implementation? What minimum standards must be met during testing and evaluation?\\n26.\\n Identify some bottlenecks in DBMS performance, and then propose some solutions used in DBMS performance tuning.\\n27.\\n What are typical activities in the maintenance of the DBMS and its utilities and applications? Would you consider application performance tuning to be part of the maintenance activities? Explain your answer.\\n28.\\n How do you normally define security? How is your definition similar to or different from the definition of database security in this chapter?\\n29.\\n What are the levels of data confidentiality?\\n30. What are security vulnerabilities? What is a security threat? Give some examples of security vulnerabilities in different IS components.\\n31.\\n Define the concept of a data dictionary, and discuss the different types of data dictio-naries. If you managed an organization’s entire data set, what characteristics would you want for the data dictionary?\\n32.\\n Using SQL statements, give some examples of how you would use the data dictio-nary to monitor database security.\\n33.\\n What characteristics do a CASE tool and a DBMS have in common? How can those characteristics be used to enhance data administration?\\n34.\\n Briefly explain the concepts of information engineering (IE) and information systems architecture (ISA). How do those concepts affect the data administra-tion strategy?\\n35.\\n Identify and explain some critical success factors in the development and implemen-tation of a good data administration strategy.\\n36.\\n How have cloud-based data services affected the DBA ’s role?\\n37. What tool is used in Oracle to create users?\\n38. In Oracle, what is a tablespace?\\n39. In Oracle, what is a database role?\\n40. In Oracle, what is a datafile? How does it differ from a file systems file?\\n41. In Oracle, what is a database profile?\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2e057c63-dc16-4585-80dd-566c551fa695', embedding=None, metadata={'page_label': '769', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    769\\nGLOSSARY\\nA\\nabstract data type (ADT)\\nData type that describes a set of similar objects with shared and encapsulated data representation and methods. An abstract data type is generally used to describe complex objects. See also \\nclass .\\naccess planA set of instructions generated at application compilation time that is created and managed by a DBMS. The access plan predetermines how an application’s query will access the database at run time.\\naccess point\\nIn the case of wireless networks, this allows you to connect wireless devices to a wired or wireless network.\\nactive data dictionary\\nA data dictionary that is automatically updated by the database management system every time the database is accessed, thereby keeping its information current.\\nActiveX\\nMicrosoft’s alternative to Java. A specification for writing programs that will run inside the Microsoft client browser. Oriented mainly to Windows applica-tions, it is not portable. It adds controls such as drop-down windows and calendars to webpages.\\nActiveX Data Objects (ADO)\\nA Microsoft object framework that provides a high-level, application-oriented interface to OLE-DB, DAO, and RDO. ADO provides a unified interface to access data from any programming language that uses the underlying OLE-DB objects.\\nad hoc query\\nA “spur-of-the-moment”  question.\\nADO.NET\\nThe data access component of Microsoft’s .NET application development framework.\\nalgorithms\\nA process or set of operations in a calculation.\\nalias\\nAn alternative name for a column or table in a SQL statement.\\nALTER TABLE\\nThe SQL command used to make changes to table structure. When the command is followed by a keyword (ADD or MODIFY), it adds a column or changes column characteristics.\\nAmerican National Standards \\nInstitute (ANSI)The group that accepted the DBTG recommenda-tions and augmented database standards in 1975 through its SPARC committee.\\nanalytical database\\nA database focused primarily on storing historical data and business metrics used for tactical or strategic decision making.\\nAND\\nThe SQL logical operator used to link multiple conditional expressions in a WHERE or HAVING clause. It requires that all conditional expressions evaluate to true.\\nanonymous PL/SQL block\\nA PL/SQL block that has not been given a specific name.\\napplication processor (AP)\\nSee \\ntransaction processor (TP) .\\nApplication Program-to-Program Communications (APPC)A communications protocol used in IBM mainframe systems network architecture (SNA). Allows for communications between personal computers and IBM mainframe applications.\\napplication programming  \\ninterface (API)Software through which programmers interact with middleware. An API allows the use of generic SQL code, thereby allowing client processes to be database server-independent.\\nAREA\\nIn DB2, a named section of permanent storage space that is reserved to store the database.\\nassociative entity\\nSee \\ncomposite entity .\\nassociative objectIn Object-oriented modeling, an object used to rep-resent a relationship between two or more objects.\\nasymmetric encryption\\nA form of encryption that uses two numeric keys—the public key and the private key. Both keys are able to encrypt and decrypt each other’s messages. See also \\npublic-key encryption .\\natomic attributeAn attribute that cannot be further subdivided to produce meaningful components. For example, a person’s last name attribute cannot be meaningfully subdivided.\\natomic transaction property\\nA property that requires all parts of a transaction to be treated as a single, logical unit of work in which all operations must be completed (committed) to produce a consistent database.\\natomicity\\nThe transaction property that requires all parts of a transaction to be treated as a single, indivisible, logical unit of work. All parts of a transaction must be completed or the entire transaction is aborted.\\nattribute\\nA characteristic of an entity or object. An attribute has a name and a data type.\\nattribute hierarchy\\nA top-down data organization that is used for two main purposes: aggregation and drill-down/roll-up data analysis.\\naudit log\\nA security feature of a database management system that automatically records a brief description of the database operations performed by all users.authenticationThe process through which a DBMS verifies that only registered users can access the database.\\nauthorization management\\nProcedures that protect and guarantee database security and integrity. Such procedures include user access management, view definition, DBMS access control, and DBMS usage monitoring.\\nautomatic query optimization\\nA method by which a DBMS finds the most efficient access path for the execution of a query.\\navailability\\nIn the context of data security, it refers to the ac-cessibility of data whenever required by authorized users and for authorized purposes.\\nAVG\\nA SQL aggregate function that outputs the mean average for a specified column or expression.\\nB\\nB-tree indexAn ordered data structure organized as an upside-down tree.\\nback-end application\\nThe process that provides service to clients.\\nback-end CASE tool\\nA computer-aided software tool that provides support for the coding and implementation phases of the SDLC. In comparison, front-end CASE tools provide support for the planning, analysis, and design phases.\\nbalancing\\nEnsuring that the processing load is distributed evenly among multiple servers.\\nbase data types\\nA term used to describe the data types frequently used in traditional programming languages. Base data types include \\nreal, integer , and  string.\\nbase tablesThe table on which a view is based.\\nbasically available, soft state, \\neventually consistent (BASE)A data consistency model in which data changes are not immediate but propagate slowly through the system until all replicas are eventually consistent.\\nbatch processing\\nA data processing method that runs data processing tasks from beginning to end without any user interaction.\\nbatch update routine\\nA routine that pools transactions into a single group to update a master table in a single operation.\\nBETWEEN\\nIn SQL, a special comparison operator used to check whether a value is within a range of specified values.\\nbidirectional physically paired \\nlogical relationshipsIn the hierarchical model, a relationship that links a logical child with its logical parent in two directions.bidirectional virtually paired logical relationshipsIn the hierarchical model, a relationship created when a logical child segment is linked to its logical parent in two directions. The virtually paired relationship is different from the phys-ically paired relationship in that no duplicates are created.\\nBig Data\\nA movement to find new and better ways to manage large amounts of web-generated data and derive business insight from it, while simultaneous-ly providing high performance and scalability at a reasonable cost.\\nbinary lock\\nA lock that has only two states: \\nlocked  (1) and un-\\nlocked  (0). If a data item is locked by a transaction, \\nno other transaction can use that data item.\\nbinary relationship\\nAn ER term for an association (relationship) between two entities. For example, PROFESSOR teaches CLASS.\\nbitmap index\\nAn index that uses a bit array (0s and 1s) to repre-sent the existence of a value or condition.\\nblock report\\nIn the Hadoop Distributed File System (HDFS), a report sent every 6 hours by the data node to the name node informing the name node which blocks are on that data node.\\nBoolean algebra\\nA branch of mathematics that uses the logical operators OR, AND, and NOT.\\nbottom-up design\\nA design philosophy that begins by identifying individual design components and then aggregates them into larger units. In database design, the process begins by defining attributes and then groups them into entities.\\nboundaries\\nThe external limits to which any proposed system is subjected. These limits include budgets, personnel, and existing hardware and software.\\nBoyce-Codd normal form (BCNF)\\nA special type of third normal form (3NF) in which every determinant is a candidate key. A table in BCNF must be in 3NF . See also \\ndeterminant .\\nbridgeA device that connects similar networks. Allows computers in one network to communicate with computers in another network.\\nbridge entity\\nSee \\ncomposite entity .\\nBSON (Binary JSON)A computer-readable format for data interchange that expands the JSON format to include additional data types including binary objects.\\nbucket\\nIn a key-value database, a logical collection of related key-value pairs.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fdba9825-b073-478b-bd06-38701d14bfaa', embedding=None, metadata={'page_label': '770', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='770   Glossary\\nbuffer cache\\nSee data cache .\\nbuffersTemporary storage area in primary memory used to speed up disk operations.\\nbus topology\\nNetwork topology requiring that all computers be connected to a main network cable.  It bears the disadvantage that a single lost computer can result in network segment breakdown.\\nBusiness intelligence (BI)\\nA comprehensive, cohesive, and integrated set of tools and processes used to capture, collect, integrate, store, and analyze data with the purpose of generating and presenting information to support business decision making.\\nbusiness rule\\nA description of a policy, procedure, or principle within an organization. For example, a pilot cannot be on duty for more than 10 hours during a 24-hour period, or a pro\\n fessor may teach up to four classes \\nduring a semester.\\nBusiness to business (B2B)\\nElectronic commerce between businesses.\\nBusiness to consumer (B2C)\\nElectronic commerce between a business and consumers.\\nC\\nCall Level Interface (CLI)A standard developed by the SQL Access Group for database access.\\ncampuswide network (CWN)\\nA typical college or university network in which buildings containing LANs are connected through a network backbone.\\ncandidate key\\nA minimal superkey; that is, a key that does not contain a subset of attributes that is itself a superkey. See \\nkey.\\ncardinalityA property that assigns a specific value to connec-tivity and expresses the range of allowed entity occurrences associated with a single occurrence of the related entity.\\ncascading order sequence\\nA nested ordering sequence for a set of rows, such as a list in which all last names are alphabetically ordered and, within the last names, all first names are ordered.\\nCASE\\nSee \\nComputer-aided software engineering.\\ncentralized data allocationA data allocation strategy in which the entire database is stored at one site. Also known as a \\ncentralized database .\\ncentralized databaseA database located at a single site.\\ncentralized design\\nA process by which all database design decisions are carried out centrally by a small group of people. Suitable in a top-down design approach when the problem domain is relatively small, as in a single unit or department in an organization.certification authority (CA)In the context of Internet security, a private entity or company that certifies the user or vendor is who (s)he claims to be.\\ncheckpoints\\nIn transaction management, an operation in which the database management system writes all of its updated buffers to disk.\\nChen notation\\nSee \\nentity relationship (ER) model .\\nclassA collection of similar objects with shared structure (attributes) and behavior (methods). A class encapsulates an object’s data representation and a method’s implementation. Classes are organized in a class hierarchy.\\nclass diagram notation\\nThe set of symbols used in the creation of class diagrams in UML object modeling.\\nclass diagrams\\nA diagram used to represent data and their relation-ships in UML object notation.\\nclass hierarchy\\nThe organization of classes in a hierarchical tree in which each parent class is a \\nsuperclass  and each \\nchild class is a subclass . See also inheritance .\\nclass instanceEach individual object stored in a class. Each class instance must share the same structure and respond to the same messages if they are located in the same class. Also known as \\nobject \\ninstance .\\nclass latticeThe class hierarchy is known as a class lattice if its classes can have multiple parent classes.\\nclient\\nAny process that requests specific services from server processes in a client/server environment.\\nclient node\\nOne of three types of nodes used in the Hadoop Distributed File System (HDFS). The client node acts as the interface between the user application and the HDFS. See also \\nname node  and data node .\\nclient-side extensionsExtension that adds functionality to a web browser. The most common extensions are plug-ins, Java, JavaScript, ActiveX, and VBScript.\\nclient/server architecture\\nA hardware and software system composed of clients, servers, and middleware. Features a user of resources (client) and a provider of resources (server).\\nclosure\\nA property of relational operators that permits the use of relational algebra operators on existing tables (relations) to produce new relations.\\ncloud computing\\nA computing model that provides ubiquitous, on-demand access to a shared pool of configurable resources that can be rapidly provisioned.\\ncloud database\\nA database that is created and maintained using cloud services, such as Microsoft Azure or Amazon AWS.cloud servicesThe services provided by cloud computing. Cloud services allow any organization to quickly and economically add information technology services such as applications, storage, servers, processing power, databases, and infrastructure.\\ncluster tables\\nA data storage structure that physically stores \\n related rows from different tables together to improve the speed at which related data can be accessed.\\nclustered index table\\nSee \\nindex organized table .\\ncoaxial cableCopper cables enclosed in two layers of insulation or shielding. Often referred to as “coax. ”  Very similar to cable used for home cable TV .\\ncohesivity\\nThe strength of the relationships between a module’s components. Module cohesivity must be high.\\nColdFusion Markup Language \\n(CFML)A server-side markup language (HTML extensions or tags) that is used to create ColdFusion application pages known as \\nscripts .\\ncollection objectAn object that contains one or more objects.\\ncolumn family\\nIn a column family database, a collection of columns or super columns related to a collection of rows.\\ncolumn family database\\nA NoSQL database model that organizes data into key-value pairs, in which the value component is composed of a set of columns that vary by row.\\ncolumn-centric storage\\nA physical data storage technique in which data is stored in blocks, which hold data from a single column across many rows.\\nCOMMIT\\nThe SQL command that permanently writes data changes to a database.\\nCommon Gateway Interface (CGI)\\nA web server interface standard that uses script files to perform specific functions based on a client’s parameters.\\ncommunity cloud\\nA type of cloud built by and for a specific group of organizations that share a common trade, such as agencies of the federal government, the military, or higher education.\\ncompleteness constraint\\nA constraint that specifies whether each entity supertype occurrence must also be a member of at least one subtype. The completeness constraint can be partial or total.\\ncomplex object\\nAn object formed by several different objects in complex relationships. See also \\nabstract data types .\\ncomplianceIn the context of data security, activities that meet data privacy and security reporting guidelines or requirements.composite attributeAn attribute that can be further subdivided to yield additional attributes. For example, a phone number such as 615-898-2368 may be divided into an area code (615), an exchange number (898), and a four-digit code (2368). Compare to \\nsimple attribute .\\ncomposite entityAn entity designed to transform an M:N relation-ship into two 1:M relationships. The composite entity’s primary key comprises at least the primary keys of the entities that it connects. Also known as a \\nbridge entity or associative entity . See also \\nlinking table .\\ncomposite identifierIn ER modeling, a key composed of more than one attribute.\\ncomposite key\\nA multiple-attribute key.\\ncomposite object\\nAn object that contains at least one multivalued attribute and has no attributes that refer to another object.\\ncompound object\\nAn object that contains at least one attribute that references another object.\\ncomputer-aided software  \\nengineering (CASE)Tools used to automate part or all of the Systems Development Life Cycle. Also known as \\n computer-aided systems engineering.\\ncomputer-aided systems engi-\\nneeringSee \\ncomputer-aided software engineering.\\nconcentratorA device that takes multiple wires and combines them into a single method of transfer to allow multiple users to access the line simultaneously. It resembles a network wiring closet.\\nconceptual design\\nA process that uses data-modeling techniques to create a model of a database structure that represents real-world objects as realistically as possible. The The design is both software- and hardware-independent.\\nconceptual model\\nThe output of the conceptual design process. The conceptual model provides a global view of an entire database and describes the main data objects, avoiding details.\\nconceptual schema\\nA representation of the conceptual model, usually expressed graphically. See also \\nconceptual model .\\nconcurrency controlA DBMS feature that coordinates the simultaneous execution of transactions in a multiprocessing database system while preserving data integrity.\\nconcurrent backup\\nA backup that takes place while one or more users are working on a database.\\nconfidentiality\\nIn the context of data security, ensuring that data is protected against unauthorized access, and if the data is accessed by an authorized user, that the data is used only for an authorized purpose.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='937cb6eb-9218-44e9-801e-8da167c3d6a6', embedding=None, metadata={'page_label': '771', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    771\\nconnectivity\\nThe type of relationship between entities. Classifica-tions include 1:1, 1:M, and M:N.\\nconsistency\\nA database condition in which all data integrity constraints are satisfied. To ensure consistency of a database, every transaction must begin with the database in a known consistent state. If not, the transaction will yield an inconsistent database that violates its integrity and business rules.\\nconsistent database state\\nA database state in which all data integrity constraints are satisfied.\\nconstraint\\nA restriction placed on data, usually expressed in the form of rules. For example, “ A student’s GPA must be between 0.00 and 4.00. ”  Constraints are important because they help to ensure data integrity.\\ncontent management\\nAutomation of the creation and management of a Web site’s contents.\\nconventional data types\\nSee \\nbase data types .\\ncoordinatorThe transaction processor (TP) node that coordinates the execution of a two-phase COMMIT in a DDBMS.\\ncorrelated subquery\\nA subquery that executes once for each row in the outer query.\\ncost-based optimizer\\nA query optimization mode that uses an algorithm based on statistics about the objects being accessed, including number of rows, indexes available, index sparsity, and so on.\\nCOUNT\\nA SQL aggregate function that outputs the number of rows containing not null values for a given col-umn or expression, sometimes used in conjunction with the DISTINCT clause.\\nCREATE INDEX\\nA SQL command that creates indexes on the basis of a selected attribute or attributes.\\nCREATE TABLE\\nA SQL command that creates a table’s structures using the characteristics and attributes given.\\nCREATE VIEW\\nA SQL command that creates a logical, “virtual”  table. The view can be treated as a real table.\\ncross join\\nA join that performs a relational product (or Cartesian product) of two tables.\\nCrow’s Foot notation\\nA representation of the entity relationship diagram that uses a three-pronged symbol to represent the “many”  sides of the relationship.\\ncube cache\\nIn multidimensional OLAP , the shared, reserved memory area where data cubes are held. Using the cube cache assists in speeding up data access.\\ncurrency\\nIn the Network Data Model, this term indicates the position of the record pointer within the database and \\nrefers to the most recently accessed record .cursorA special construct used in procedural SQL to hold the data rows returned by a SQL query. A cursor may be considered a reserved area of memory in which query output is stored, like an array holding columns and rows. Cursors are held in a reserved memory area in the DBMS server, not in the client computer.\\nD\\ndashboardsIn business intelligence, a web-based system that presents key business performance indicators or information in a single, integrated view with clear and concise graphics.\\ndata\\nRaw facts, or facts that have not yet been processed to reveal their meaning to the end user.\\nData Access Objects (DAO)\\nAn object-oriented application programming interface used to access MS Access, FileMaker Pro, and other Jet-based databases.\\ndata administrator (DA)\\nThe person responsible for managing the entire data resource, whether it is computerized or not. The DA has broader authority and responsibility than the database administrator (DBA). Also known as an \\ninformation resource manager (IRM) .\\ndata allocationIn a distributed DBMS, the process of deciding where to locate data fragments.\\ndata analytics\\nA subset of business intelligence functionality that encompasses a wide range of mathematical, statis-tical, and modeling techniques with the purpose of extracting knowledge from data.\\ndata anomaly\\nA data abnormality in which inconsistent changes have been made to a database. For example, an employee moves, but the address change is not corrected in all files in the database.\\ndata cache\\nA shared, reserved memory area that stores the most recently accessed data blocks in RAM. Also called \\nbuffer cache .\\ndata cubeThe multidimensional data structure used to store and manipulate data in a multidimensional DBMS. The location of each data value in the data cube is based on its x-, y-, and z-axes. Data cubes are static, meaning they must be created before they are used, so they cannot be created by an ad hoc query.\\ndata definition language (DDL)\\nThe language that allows a database administrator to define the database structure, schema, and subschema.\\ndata dependence\\nA data condition in which data representation and manipulation are dependent on the physical data storage characteristics.\\ndata dictionary\\nA DBMS component that stores metadata—data about data. Thus, the data dictionary contains the data definition as well as their characteristics and relationships. A data dictionary may also include data that are external to the DBMS. Also known as an \\ninformation resource dictionary . See also active data dictionary, metadata , and passive data \\ndictionary .\\nData Encryption Standard (DES)The most widely used standard for private-key encryption. DES is used by the U.S. government.\\ndata files\\nA named physical storage space that stores a database’s data. It can reside in a different directory on a hard disk or on one or more hard disks. All data in a database is stored in data files. A typical enterprise database is normally composed of several data files. A data file can contain rows from one or more tables.\\ndata fragmentation\\nA characteristic of a DDBMS that allows a single object to be broken into two or more segments or fragments. The object might be a user’s database, a system database, or a table. Each fragment can be stored at any site on a computer network.\\ndata inconsistency\\nA condition in which different versions of the same data yield different (inconsistent) results.\\ndata independence\\nA condition in which data access is unaffected by changes in the physical data storage characteristics.\\ndata integrity\\nIn a relational database, a condition in which the data in the database complies with all entity and referential integrity constraints.\\ndata management\\nA process that focuses on data collection, storage, and retrieval. Common data management functions include addition, deletion, modification, and listing.\\ndata manager (DM)\\nSee \\ndata processor (DP) .\\ndata manipulation languageThe set of commands that allows an end user to manipulate the data in the database, such as SELECT, INSERT, UPDATE, DELETE, COMMIT, and ROLLBACK.\\ndata mart\\nA small, single-subject data warehouse subset that provides decision support to a small group of people.\\ndata mining\\nA process that employs automated tools to analyze data in a data warehouse and other sources and to pro -\\nactively identify possible relationships and anomalies.\\ndata model\\nA representation, usually graphic, of a complex “real-world”  data structure. Data models are used in the database design phase of the Database Life Cycle.\\ndata modeling\\nThe process of creating a specific data model for a determined problem domain.\\ndata node\\nOne of three types of nodes used in the Hadoop Distributed File System (HDFS). The data node  stores fixed-size data blocks (that could be replicated to other data nodes). See also \\nclient node  \\nand name node .\\ndata processing (DP) specialistThe person responsible for developing and manag-ing a computerized file processing system.data processor (DP)The resident software component that stores and re -\\ntrieves data through a DDBMS. The DP is responsible for managing the local data in the computer and coordinating access to that data. Also known as \\ndata \\nmanager (DM) .\\ndata qualityA comprehensive approach to ensuring the accura-cy, validity, and timeliness of data.\\ndata redundancy\\nExists when the same data is stored unnecessarily at different places.\\ndata replication\\nThe storage of duplicated database fragments at mul-tiple sites on a DDBMS. Duplication of the fragments is transparent to the end user. Data replication provides fault tolerance and performance enhancements.\\ndata source name (DSN)\\nWith ODBC, a name that identifies and defines an ODBC data source.\\ndata sparsity\\nA column distribution of values or the number of different values a column can have.\\ndata visualization\\nAbstracting data to provide information in a visual format that enhances the user’s ability to effectively comprehend the meaning of the data.\\ndata warehouse\\nAn integrated, subject-oriented, time-variant, \\n nonvolatile collection of data in a specialized \\n database that stores historical and aggregated data in a format that provides support for decision making.\\ndata-profiling software\\nPrograms that analyze data and metadata to deter-mine patterns that can help assess data quality.\\ndatabase\\nA shared, integrated computer structure that houses a collection of related data. A database contains two types of data: end-user data (raw facts) and metadata.\\ndatabase administrator (DBA)\\nThe person responsible for planning, organizing, controlling, and monitoring the centralized and shared corporate database. The DBA is the general manager of the database administration department.\\nDatabase Administrator Control \\nSystem (DBACS)In the network model, the database definition pro -\\ncessor that reads the database definition and validates the schema (The DBACS works like a compiler.).\\ndatabase description (DBD) \\nstatementIn the hierarchical model, the series of commands that define the hierarchical tree structure and how the segments are stored in the database.\\ndatabase design\\nThe process that yields the description of the database structure and determines the database components. The second phase of the Database Life Cycle.\\ndatabase development\\nThe process of database design and implemen-tation.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='47a1d7b8-878f-4b7f-9360-095300fb96f2', embedding=None, metadata={'page_label': '772', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='772   Glossary\\ndatabase dump\\nA complete copy of an entire database saved and periodically updated in a separate memory location. A full backup ensures a full recovery of all data after a physical disaster or database integrity failure.\\ndatabase fragment\\nA subset of a distributed database. Although the fragments may be stored at different sites within a computer network, the set of all fragments is treated as a single database. See also \\nhorizontal \\nfragmentation  and vertical fragmentation .\\ndatabase instanceIn an Oracle DBMS, the collection of processes and data structures used to manage a specific database.\\ndatabase integration\\nIn the context of e-commerce databases, a business enabling service where a company’s database is used in their Web page development.\\nDatabase Life Cycle (DBLC)\\nA cycle that traces the history of a database within an information system. The cycle is divided into six phases: initial study, design, implementation and loading, testing and evaluation, operation and maintenance, and evolution.\\ndatabase management system \\n(DBMS)The collection of programs that manages the database structure and controls access to the data stored in the database.\\ndatabase middleware\\nDatabase connectivity software through which application programs connect and communicate with data repositories.\\ndatabase performance tuning\\nA set of activities and procedures designed to reduce the response time of a database system—that is, to ensure that an end-user query is processed by the DBMS in the minimum amount of time.\\ndatabase recovery\\nThe process of restoring a database to a previous consistent state.\\ndatabase request\\nThe equivalent of a single SQL statement in an application program or a transaction.\\ndatabase role\\nA set of database privileges that could be assigned as a unit to a user or group.\\ndatabase security\\nThe use of DBMS features and other related measures to comply with the security requirements of an organization.\\ndatabase security officer (DSO)\\nThe person responsible for the security, integrity, backup, and recovery of the database.\\ndatabase statistics\\nIn query optimization, measurements about database objects, such as the number of rows in a table, number of disk blocks used, maximum and average row length, number of columns in each row, and number of distinct values in each column. Such statistics provide a snapshot of database characteristics.database systemAn organization of components that defines and regulates the collection, storage, management, and use of data in a database environment.\\ndatabase translator\\nA middleware component that translates generic SQL calls into specific database server syntax to create database server independence.\\ndatabase-level lock\\nA type of lock that restricts database access to the owner of the lock and allows only one user at a time to access the database. This lock works for batch processes but is unsuitable for online multiuser DBMSs.\\ndatafile\\nA file on the hard drive or storage system where the data in a tablespace is physically stored.\\nDataSet\\nIn ADO.NET, a disconnected, memory-resident representation of the database. The DataSet contains tables, columns, rows, relationships, and constraints.\\nDBGEN\\nIn the hierarchical model, the component that generates the physical database with all its necessary structures.\\nDBMS performance tuning\\nActivities to ensure that clients’  requests are addressed as quickly as possible while making optimum use of existing resources.\\ndeadlock\\nA condition in which two or more transactions wait indefinitely for the other to release the lock on a previously locked data item. Also called \\ndeadly \\nembrace .\\ndeadly embraceSee \\ndeadlock .\\ndecentralized designA process in which conceptual design models subsets of an organization’s database requirements, which are then aggregated into a complete design. Such modular designs are typical of complex systems with a relatively large number of objects and procedures.\\ndecision support system (DSS)\\nAn arrangement of computerized tools used to as-sist managerial decision making within a business.\\ndeferred update\\nIn transaction management, a condition in which transaction operations do not immediately update a physical database. Also called \\ndeferred write \\ntechnique .\\ndeferred-write techniqueSee \\ndeferred update .\\nDELETEA SQL command that allows data rows to be deleted from a table.\\ndenial-of-service\\nOne of the most common hacker activities. This attack overloads Web servers and routers with mil-lions of requests for service, rendering the services unavailable to legitimate users.\\ndenormalization\\nA process by which a table is changed from a higher-level normal form to a lower-level normal form, usually to increase processing speed. Denor-malization potentially yields data anomalies.\\ndependency diagram\\nA representation of all data dependencies (primary key, partial, or transitive) within a table.\\ndependent\\nAn attribute whose value is determined by another attribute.\\nderived attribute\\nAn attribute that does not physically exist within  the entity and is derived via an algorithm.  For example, the Age attribute might be  derived by subtracting the birth date from the current date.\\ndescription of operations\\nA document that provides a precise, detailed, up-to-date, and thoroughly reviewed description of the activities that define an organization’s operating environment.\\ndesign trap\\nA problem that occurs when a relationship is improperly or incompletely identified and therefore is represented in a way that is not consistent with the real world. The most common design trap is known as a \\nfan trap .\\ndesktop databaseA single-user database that runs on a personal computer.\\ndeterminant\\nAny attribute in a specific row whose value directly determines other values in that row. See also \\nBoyce-\\nCodd normal form (BCNF) .\\ndeterminationThe role of a key. In the context of a database table, the statement “ A determines B”  indicates that knowing the value of attribute A means that the value of attribute B can be looked up.\\nDIFFERENCE\\nIn relational algebra, an operator used to yield all rows from one table that are not found in another union-compatible table.\\ndifferential backup\\nA level of database backup in which only the last modifications to the database are copied.\\ndigital cash\\nIn an e-commerce environment, the digital equivalent of hard currency (coins or bills of a given denomination).\\ndigital certificate\\nA unique identifier given to an entity. The certificate holder may be an end user, a Web site, a computer, a Web page, or even a program. Digital certificates are used in combination with encryption to provide security and authentication.\\ndigital signature\\nAn encrypted attachment added to an electronic message to verify the sender’s identity.\\ndimension tables\\nIn a data warehouse, tables used to search, filter, or classify facts within a star schema.\\ndimensions\\nIn a star schema design, qualifying characteristics that provide additional perspectives to a given fact.dirty dataData that contain inaccuracies and/or inconsis-tencies.\\ndirty read\\nIn transaction management, when a transaction reads data that is not yet committed.\\ndisaster management\\nThe set of DBA activities dedicated to securing data availability following a physical disaster or a database integrity failure.\\ndiscipline-specific databases\\nA database that contains data focused on specific subject areas.\\ndisjoint subtypes\\nIn a specialization hierarchy, a unique and nonover-lapping subtype entity set.\\ndiskpage\\nIn permanent storage, the equivalent of a disk block, which can be described as a directly addressable section of a disk. A diskpage has a fixed size, such as 4K, 8K, or 16K.\\nDISTINCT\\nA SQL clause that produces only a list of values that are different from one another.\\ndistributed data catalog (DDC)\\nA data dictionary that contains the description (fragment names and locations) of a distributed database.\\ndistributed data dictionary (DDD)\\nSee \\ndistributed data catalog .\\ndistributed databaseA logically related database that is stored in two or more physically independent sites.\\ndistributed database  \\nmanagement system (DDBMS)A DBMS that supports a database distributed across several different sites; a DDBMS governs the storage and processing of logically related data over interconnected computer systems in which both data and processing functions are distributed among several sites.\\ndistributed global schema\\nThe database schema description of a distributed database as seen by the database administrator.\\ndistributed processing\\nSharing the logical processing of a database over two or more sites connected by a network.\\ndistributed request\\nA database request that allows a single SQL statement to access data in several remote data processors (DPs) in a distributed database.\\ndistributed transaction\\nA database transaction that accesses data in several remote data processors (DPs) in a distributed database.\\ndistribution transparency\\nA DDBMS feature that allows a distributed database to look like a single logical database to an end user.\\nDIVIDE\\nIn relational algebra, an operator that answers queries about one set of data being associated with all values of data in another set of data.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='898b1e42-1ebf-46d2-98f1-45e37c238f92', embedding=None, metadata={'page_label': '773', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    773\\nDO-UNDO-REDO protocol\\nA protocol used by a data processor (DP) to roll back or roll forward transactions with the help of a system’s transaction log entries.\\ndocument databases\\nA NoSQL database model that stores data in key-value pairs in which the value component is composed of a tag-encoded document.\\ndocument type definition (DTD)\\nA file with a .dtd extension that describes XML el-ements; in effect, a DTD file describes a document’s composition and defines the syntax rules or valid tags for each type of XML document.\\ndomain\\nIn data modeling, the construct used to organize and describe an attribute’s set of possible values.\\ndrill down\\nTo decompose data into more atomic compo-nents—that is, data at lower levels of aggregation. This approach is used primarily in a decision support system to focus on specific geographic areas, business types, and so on.\\nDROP INDEX\\nA SQL command used to delete database objects such as tables, views, indexes, and users.\\nDROP TABLE\\nA SQL command used to delete database objects such as tables, views, indexes, and users.\\ndurability\\nThe transaction property that ensures that once transaction changes are done and committed, they cannot be undone or lost, even in the event of a system failure.\\ndynamic query optimization\\nThe process of determining the SQL access strategy at run time, using the most up-to-date information about the database.\\ndynamic SQL\\nAn environment in which the SQL statement is not known in advance, but instead is generated at run time. In a dynamic SQL environment, a program can generate the SQL statements that are required to respond to ad hoc queries.\\ndynamic statistical generation \\nmodeIn a DBMS, the capability to automatically evaluate and update the database access statistics after each data access operation.\\ndynamic webpage\\nPage with contents that change over time and can-not be anticipated; for example, an online ordering system. The content of dynamic Web pages is not predetermined, but is generated at run-time.\\ndynamic-link libraries (DLLs)\\nShared code module that is treated as part of the operating system or server process so it can be dynamically invoked at run time.\\nE\\nearly bindingA property by which the data type of an object’s attribute must be known at definition time, bonding the data type to the object’s attribute. Characteristic of an object oriented data model. See also \\nlate binding .edgeIn a graph database, the representation of a relationship between nodes.\\nEER diagram (EERD)\\nThe entity relationship diagram resulting from the application of extended entity relationship concepts that provide additional semantic content in the ER model.\\nelectronic commerce  \\n(e-commerce)The use of electronic computer-based technology to bring products, services, or ideas to market and to support or enhance business operations.\\nelectronic data interchange (EDI)\\nA communications protocol that enabled companies to exchange business documents over private phone networks.\\nelectronic mail (email)\\nThe graphics and text messages sent to other, specific computer end users connected to the same network. Widely used for its low cost and ability to instantly send and receive information to one or more people. Also called e-mail.\\nelectronic wallet \\nSoftware that securely stores digital cash to facilitate online transactions.\\nembedded SQL\\nSQL statements contained within application programming languages such as COBOL, C++, ASP , Java, and ColdFusion.\\nencapsulation\\nA feature by which the object can hide the internal data representation and method’s implementation from external objects. Characteristic of an object oriented data model.\\nencryption\\nA process of inputting data in “plain text”  to yield an output “encoded”  version of the data, making the data unintelligible to unauthorized users.\\nencryption key\\nUsed by encryption algorithms to encode data. The encryption key is a very large number used to encrypt and decrypt data.\\nenterprise database\\nThe overall company data representation, which provides support for present and expected future needs.\\nentity\\nA person, place, thing, concept, or event for which data can be stored. See also \\nattribute .\\nentity clusterA “virtual”  entity type used to represent multiple entities and relationships in the ERD. An entity cluster is formed by combining multiple interrelat-ed entities into a single abstract entity object. An entity cluster is considered “virtual”  or “abstract”  because it is not actually an entity in the final ERD.\\nentity instance\\nA row in a relational table. Also known as \\nentity \\noccurrence .\\nentity integrityThe property of a relational table that guarantees each entity has a unique value in a primary key and that the key has no null values.entity occurrenceA row in a relational table. Also known as \\nentity \\ninstance.\\nentity relationship (ER) modelA data model that describes relationships (1:1, 1:M, and M:N) among entities at the conceptual level with the help of ER diagrams. The model was developed by Peter Chen.\\nentity relationship diagram (ERD)\\nA diagram that depicts an entity relationship model’s entities, attributes, and relations.\\nentity set\\nA collection of like entities.\\nentity subtypes\\nIn a generalization/specialization hierarchy, a subset of an entity supertype. The entity supertype con-tains the common characteristics and the subtypes contain the unique characteristics of each entity.\\nentity supertype\\nIn a generalization/specialization hierarchy, a generic entity type that contains the common characteristics of entity subtypes.\\nequijoin\\nA join operator that links tables based on an equality condition that compares specified columns of the tables.\\nERM\\nA data model that describes relationships (1:1, 1:M, and M:N) among entities at the conceptual level with the help of ER diagrams. The model was developed by Peter Chen.\\nEthernet\\nThe dominant LAN standard used to interconnect computer systems. Ethernet is based on a bus or star topology that can use coaxial, twisted-pair, or fiber-optic cabling.\\neventual consistency\\nA model for database consistency in which updates to the database will propagate through the system so that all data copies will be consistent eventually.\\nexclusive lock\\nAn exclusive lock is issued when a transaction requests permission to update a data item and no locks are held on that data item by any other transaction. An exclusive lock does not allow other transactions to access the database.\\nexistence-dependent\\nA property of an entity whose existence depends on one or more other entities. In such an environment, the existence-independent table must be created and loaded first because the existence-dependent key cannot reference a table that does not yet exist.\\nexistence-independent\\nA property of an entity that can exist apart from one or more related entities. Such a table must be created first when referencing an existencedepen-dent table.\\nEXISTS\\nIn SQL, a comparison operator that checks whether a subquery returns any rows.\\nexplanatory analytics\\nData analysis that provides ways to discover relationships, trends, and patterns among data.explicit cursorIn procedural SQL, a cursor created to hold the output of a SQL statement that may return two or more rows, but could return zero or only one row.\\nextended entity relationship \\nmodel (EERM)Sometimes referred to as the enhanced entity relationship model; the result of adding more semantic constructs, such as entity supertypes, entity subtypes, and entity clustering, to the original entity relationship (ER) model.\\nextended relational data model\\nA model that includes the object-oriented model’s best features in an inherently simpler relational database structural environment. See \\nextended \\nentity relationship model (EERM) .\\nextensibleCapable of being extended by adding new data types and the operations to be performed on them.\\nExtensible Markup Language \\n(XML)A meta-language used to represent and manipulate data elements. Unlike other markup languages, XML permits the manipulation of a document’s data elements. XML facilitates the exchange of structured documents such as orders and invoices over the Internet.\\nextents\\nIn a DBMS environment, refers to the ability of data files to expand in size automatically using predefined increments.\\nexternal model\\nThe application programmer’s view of the data environment. Given its business focus, an external model works with a data subset of the global database schema.\\nexternal schema\\nThe specific representation of an external view; the end user’s view of the data environment.\\nextraction, transformation, and \\nloading (ETL)In a data warehousing environment, the integrated processes of getting data from original sources into the data warehouse. ETL includes retrieving data from original data sources (extraction), manipulating the data into an appropriate form (transformation), and storing the data in the data warehouse (loading).\\nF\\nfact tableIn a data warehouse, the star schema table that contains facts linked and classified through their com-mon dimensions. A fact table is in a one-to-many relationship with each associated dimension table.\\nfacts\\nIn a data warehouse, the measurements (values) that measure a specific business aspect or activity. For example, sales figures are numeric measure-ments that represent product or service sales.  Facts commonly used in business data analysis include units, costs, prices, and revenues.\\nfailure transparency\\nA feature that allows continuous operation of a DDBMS, even if a network node fails.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ba936ac-4eb3-4a0b-a2c8-d2745d52410f', embedding=None, metadata={'page_label': '774', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='774   Glossary\\nfan trap\\nA design trap that occurs when one entity is in two 1:M relationships with other entities, thus producing an association among the other entities that is not expressed in the model.\\nfat client\\nA client that carries a relatively larger proportion of the processing load than compared to the server. Fat clients are always paired with thin servers.\\nfat server\\nA server that carries a relatively larger proportion of the processing load than compared to the client. Fat servers are always paired with thin clients.\\nfeedback loop processing\\nAnalyzing stored data to produce actionable results.\\nfiber-optic cable\\nData transmission medium for computer networks. It used light pulses to transmit the data from node to node and allows for the highest speed of information transfer available.\\nfield\\nAn alphabetic or numeric character or group of characters that defines a characteristic of a person, place, or thing. For example, a person’s Social Security number, address, phone number, and bank balance all constitute fields.\\nfield-level lock\\nA lock that allows concurrent transactions to access the same row as long as they require the use of different fields (attributes) within that row. This type of lock yields the most flexible multiuser data access but requires a high level of computer overhead.\\nfile\\nA named collection of related records.\\nfile group\\nSee \\ntable space .\\nFile Transfer Protocol (FTP)Used to provide file transfer capabilities among computers on the Internet/intranet using a public or known name for classifying and grouping the messages.\\nfirewall\\nUsed to protect a network from unauthorized access from the outside world (public Internet). Specifically, a firewall is a hardware and/or software component that is used to limit and control Internet traffic going into a company’s network infrastruc-ture and data that are allowed to be moved outside a company’s network.\\nfirst normal form (1NF)\\nThe first stage in the normalization process. It describes a relation depicted in tabular format, with no repeating groups and a primary key identified. All nonkey attributes in the relation are dependent on the primary key.\\nflags\\nSpecial codes implemented by designers to trigger a required response, alert end users to specified conditions, or encode values. Flags may be used to prevent nulls by bringing attention to the absence of a value in a table.\\nforeign key (FK)\\nAn attribute or attributes in one table whose values must match the primary key in another table or whose values must be null. See \\nkey.fourth normal form (4NF)A table is in 4NF if it is in 3NF and contains no mul-tiple independent sets of multivalued dependencies.\\nfragmentation transparency\\nA DDBMS feature that allows a system to treat a distributed database as a single database even though it is divided into two or more fragments.\\nframe\\nCreate in the data-link layer to add control to the information by specifying the network and physical media being used. The information is added at the beginning (header) and at the end (trailer) of a network packet to enclose (frame) the packet data.\\nFROM\\nA SQL clause that specifies the table or tables from which data is to be retrieved.\\nfront-end application\\nAny process that the end user interacts with to request services from a server process.\\nfront-end CASE tool\\nA computer-aided software tool that provides support for the planning, analysis, and design phases of the SDLC.\\nfull backup\\nA complete copy of an entire database saved and periodically updated in a separate memory location. A full backup ensures a full recovery of all data after a physical disaster or database integrity failure.\\nfull functional dependence\\nA condition in which an attribute is functionally dependent on a composite key but not on any subset of the key.\\nfully heterogeneous DDBMS\\nA system that integrates different types of database management systems (hierarchical, network, and relational) over a network. It supports different database management systems that may even support different data models running under different computer systems. See also \\nheterogeneous \\nDDBMS  and homogeneous DDBMS .\\nfully replicated databaseIn a DDBMS, the distributed database that stores multiple copies of each database fragment at multiple sites.\\nfunction-based index\\nA type of index based on a specific SQL function or expression.\\nfunctional dependence\\nWithin a relation R, an attribute B is functionally dependent on an attribute A if and only if a given value of attribute A determines exactly one value of attribute B. The relationship “B is dependent on A”  is equivalent to “ A determines B, ”  and is written as A B.\\nG\\ngatewayA type of middleware software that is used to trans-late client requests into the appropriate protocols needed to access specific services.\\ngateway server firewall\\nA type of firewall that operates at the application level.\\ngeneral-purpose databases\\nA database that contains a wide variety of data used in multiple disciplines.generalizationIn a specialization hierarchy, the grouping of common attributes into a supertype entity.\\nGet Hold (GH)\\nIn an IMS hierarchical DBMS, this statement is used to hold a segment for delete or replace operations. There are three different Get Hold statements: Get Hold Next (GHN), Get Hold Next within Parent (GHNP), and Get Hold Unique (GHU).\\nGet Next (GN)\\nIn hierarchical databases, a statement to retrieve sequential segments.\\nGet Next Within Parent (GNP)\\nIn hierarchical databases, a statement to return all segments within the current parent.\\nGet Unique (GU)\\nIn an IMS hierarchical DBMS, a statement that is used to retrieve a database segment into the application program input area or record area.\\ngovernance\\nIn business intelligence, the methods for controlling and monitoring business health and promoting consistent decision making.\\ngovernment to business (G2B)\\nSpecial case of the Business to Business and Business to Commerce e-commerce styles. See also \\ngovernment to consumer (G2C) .\\ngovernment to consumer (G2C)Special case of the Business to Business and Business to Commerce e-commerce styles. See also \\ngovernment to business (G2B) .\\ngranularityThe level of detail represented by the values stored in a table’s row. Data stored at its lowest level of granularity is said to be \\natomic data .\\ngraph databaseA NoSQL database model based on graph theory that stores data on relationship-rich data as a collection of nodes and edges.\\nGROUP BY\\nA SQL clause used to create frequency distributions when combined with any of the aggregate functions in a SELECT statement.\\nH\\nhackerA person who maliciously and illegally accesses a Web site with the intention of stealing data, chang-ing Web pages, or impairing Web site operations.\\nHadoop\\nA Java based, open source, high speed, fault-tolerant distributed storage and computational framework. Hadoop uses low-cost hardware to create clusters of thousands of computer nodes to store and process data.\\nHadoop Distributed File System \\n(HDFS)A highly distributed, fault-tolerant file storage system designed to manage large amounts of data at high speeds.\\nhardware independence\\nA condition in which a model does not depend on the hardware used in the model’s implementation. Therefore, changes in the hardware will have no effect on the database design at the conceptual level.hash indexAn index based on an ordered list of hash values.\\nHAVING\\nA clause applied to the output of a GROUP BY operation to restrict selected rows.\\nheartbeat\\nIn the Hadoop Distributed File System (HDFS), a signal sent every 3 seconds from the data node to the name node to notify the name node that the data node is still available.\\nheterogeneity transparency\\nA feature that allows a system to integrate several centralized DBMSs into one logical DDBMS.\\nheterogeneous DDBMSs\\nA system that integrates different types of centralized database management systems over a network.\\nhierarchical model\\nAn early database model whose basic concepts and characteristics formed the basis for subsequent database development. This model is based on an upside-down tree structure in which each record is called a segment. The top record is the root segment. Each segment has a 1:M relationship to the segment directly below it.\\nhomogeneous DDBMSs\\nA system that integrates only one type of centralized database management system over a network.\\nhomonyms\\nThe use of the same name to label different attributes. Homonyms generally should be avoided. Some relational software automatically checks for homonyms and either alerts the user to their existence or automatically makes the appropriate adjustments. See also \\nsynonym .\\nhorizontal fragmentationThe distributed database design process that breaks a table into subsets of unique rows.\\nhost language\\nAny language that contains embedded SQL statements.\\nhub\\nA warehouse of data packets housed in a central location on a local area network. It contains multiple ports that copy the data in the data packets to make it accessible to selected or all segments of the network.\\nhybrid object\\nThe type of object classification that contains and represents a repeating group of attributes. One or more of the attributes reference another object that usually summarizes the contents of the hybrid object.\\nhyperlink\\nLink between Web pages in hypertext or other electronic document types.\\nHypertext Markup Language \\n(HTML)Standard document-formatting language for Web pages.\\nHypertext Transfer Protocol (HTTP)\\nStandard protocol used by Web browser and Web server to communicate.\\nI\\nI/O acceleratorsA device used to improve throughput for input/output operations.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d705ac1c-7575-45ce-bbaf-16611c031ece', embedding=None, metadata={'page_label': '775', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    775\\nidentifiers\\nOne or more attributes that uniquely identify each entity instance.\\nimaging server\\nA process that runs on a computer and provides image management services to client computers.\\nimmediate update\\nSee \\nwrite-through technique .\\nimplicit cursorA cursor that is automatically created in procedural SQL when the SQL statement returns only one row.\\nIN\\nIn SQL, a comparison operator used to check whether a value is among a list of specified values.\\nin-memory database\\nA database optimized to store large portions (if not all) of the database in primary (RAM) storage rather than secondary (disk) storage.\\ninconsistent retrievals\\nA concurrency control problem that arises when a transaction-calculating summary (aggregate) functions over a set of data while other transac-tions are updating the data, yielding erroneous results.\\nincremental backup\\nA process that only backs up data that has changed in the database since the last incremental or full backup.\\nindex\\nAn ordered array of index key values and row ID values (pointers). Indexes are generally used to speed up and facilitate data retrieval. Also known as an \\nindex key .\\nindex keySee \\nindex .\\nindex selectivityA measure of how likely an index is to be used in query processing.\\nindex-organized table\\nIn a DBMS, a type of table storage organization that stores end-user data and index data in consecutive locations in permanent storage. Also known as \\ncluster-indexed table .\\ninformationThe result of processing raw data to reveal its meaning. Information consists of transformed data and facilitates decision making.\\nInformation Engineering (IE)\\nA methodology that translates a company’s strategic goals into helpful data and applications.  IE focuses on the description of corporate data instead of the processes.\\ninformation resource dictionary\\nAnother name for \\ndata dictionary .\\ninformation resource manager (IRM)See \\ndata administrator (DA) .\\ninformation systemA system that provides for data collection, storage, and retrieval; facilitates the transformation of data into information; and manages both data and information. An information system is composed of hardware, the DBMS and other software, database(s), people, and procedures.information systems (IS)  departmentA department responsible for all information technology services and production functions in an organization.\\ninformation systems  \\narchitecture (ISA)The output of the information engineering (IE) process that serves as the basis for planning, devel-oping, and controlling future information systems.\\nInfrastructure as a Service (IaaS)\\nA model in which the cloud service provider offers consumers the ability to provision their own resources on demand; these resources include storage, servers, databases, processing units, and even a complete virtualized desktop.\\ninheritance\\nIn the object-oriented data model, the ability of an object to inherit the data structure and methods of the classes above it in the class hierarchy. See also \\nclass hierarchy .\\ninner joinA join operation in which only rows that meet a given criterion are selected. The join criterion can be an equality condition (natural join or equijoin) or an inequality condition (theta join). The inner join is the most commonly used type of join. Contrast with \\nouter join .\\ninner queryA query that is embedded or nested inside another query. Also known as a \\nnested query  or \\na subquery .\\ninput/output (I/O) requestA low-level data access operation that reads or writes data to and from computer devices.\\nInsert (ISRT)\\nIn hierarchical databases, a statement used to add a segment to the database.\\nINSERT\\nA SQL command that allows the insertion of one or more data rows into a table.\\ninstance variables\\nIn the object-oriented model, another term for an attribute. See \\nattribute .\\nInstitute of Electrical and  Electronics Engineers (IEEE)An organization that develops standards to provide uniformity among the technical details that define network topology and data transmission across shared media for networks.\\nIntegrity\\nIn a data security framework, refers to keeping data consistent and free of errors or anomalies. See also \\ndata integrity .\\nintelligent terminalsA device that provides enhanced I/O functions to a mainframe system such as a PC connected to a mainframe computer.\\nInteractive Database Processor (IDP)\\nIn an IDS/II network DBMS, a processor that allows users to manipulate databases. The IDP front end is intended for users who have some programming knowledge and is not well-suited for most end users.internal modelIn database modeling, a level of data abstraction that adapts the conceptual model to a specific DBMS model for implementation. The internal model is the representation of a database as “seen”  by the DBMS. In other words, the internal model requires a designer to match the conceptual model’s characteristics and constraints to those of the selected implementation model.\\ninternal schema\\nA representation of an internal model using the data-base constructs supported by the chosen database.\\nInternational Organization for \\nStandardization (ISO)An organization formed to develop standards for diverse network systems.\\nInternet\\nA global network of computers connected together through a standard network protocol known as Transmission Control Protocol/Internet Protocol (TCP/IP). You can think of the Internet as the “high-way”  on which the data travel. The terms \\nInternet  \\nand World Wide Web  are often used interchange-\\nably, but they are not synonyms.\\nInternetwork Packet Exchange/\\nSequenced Packet Exchange  (IPX/SPX)A data communications protocol that determines how messages between computers are sent interpreted and processed.\\ninterobject relationship\\nAn attribute-class relationship created when an object’s attribute references another object of the same or a different class.\\ninterprocess communication (IPC)\\nA capability supported by various operating systems to allow two processes to communicate with each other so that applications can share data without interfering with each other.\\ninterrogate\\nTo ask for the interrogated object’s instance variable value or values. An object may send messages to interrogate another object’s state.\\nINTERSECT\\nIn relational algebra, an operator used to yield only the rows that are common to two union-compatible tables.\\nintrabusiness\\nA style of e-commerce that involves interactions internal to a company.\\nintranets\\nCompany-owned and -operated computer net-works that are restricted to the company’s internal use. Such systems can only be accessed by the computers inside the company’s computer network. The purpose of such a system is to enhance company operations through improved data access management and communication.\\nIS NULL\\nIn SQL, a comparison operator used to check whether an attribute has a value.\\nislands of information\\nIn the old file system environment, pools of inde-pendent, often duplicated, and inconsistent data created and managed by different departments.isolationA database transaction property in which a data item used by one transaction is not available to other transactions until the first one ends.\\niterative process\\nA process based on repetition of steps and procedures.\\nJ\\nJavaAn object-oriented programming language developed by Sun Microsystems that runs on top of the web browser software. Java applications are compiled and stored on the web server. Java’s main advantage is its ability to let application developers create their applications once and then run them in many environments.\\nJava Database Connectivity \\n(JDBC)An application programming interface that allows a Java program to interact with a wide range of data sources, including relational databases, tabular data sources, spreadsheets, and text files.\\nJavaScript\\nA scripting language that allows web authors to design interactive websites. JavaScript code is embedded in webpages, and then downloaded with the page and activated when a specific event takes place, such as a mouse click on an object.\\njob tracker\\nA central control program used to accept, distribute, monitor, and report on MapReduce processing jobs in a Hadoop environment.\\nJOIN\\nIn relational algebra, a type of operator used to yield rows from two tables based on criteria. There are many types of joins, such as natural join, theta join, equijoin, and outer join.\\njoin columns\\nColumns that are used in the criteria of join opera-tions. The join columns generally share similar values (have a compatible domain).\\nJSON (JavaScript Object Nota-\\ntion)A human-readable text format for data interchange that defines attributes and values in a document.\\nK\\nkeyOne or more attributes that determine other attributes. See also \\nsuperkey, candidate key, primary \\nkey (PK), secondary key , and foreign key .\\nkey attributeThe attributes that form a primary key. See also \\nprime attribute .\\nkey performance indicators (KPIs)In business intelligence, quantifiable numeric or scale-based measurements that assess a company’s effectiveness or success in reaching strategic and operational goals. Examples of KPIs are product turnovers, sales by promotion, sales by employee, and earnings per share.\\nkey-value (KV) databases\\nA NoSQL database model that stores data as a collection of key-value pairs in which the value component is unintelligible to the DBMS.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8d18df0f-38db-413b-bb4a-270484033479', embedding=None, metadata={'page_label': '776', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='776   Glossary\\nkey-value\\nA data model based on a structure composed of two data elements: a key and a value, in which every key has a corresponding value or set of values. The keyvalue data model is also called the associative or attribute-value data model.\\nknowledge\\nThe body of information and facts about a specific subject. Knowledge implies familiarity, awareness, and understanding of information as it applies to an environment. A key characteristic is that new knowledge can be derived from old knowledge.\\nL\\nlate bindingA characteristic in which the data type of an attri-bute is not known until execution time or run-time.\\nleft outer join\\nIn a pair of tables to be joined, a join that yields all the rows in the left table, including those that have no matching values in the other table. For example, a left outer join of CUSTOMER with AGENT will yield all of the CUSTOMER rows, including the ones that do not have a matching AGENT row. See also \\nouter \\njoin and right outer join .\\nLIKEIn SQL, a comparison operator used to check wheth-er an attribute’s text value matches a specified string pattern.\\nlinking table\\nIn the relational model, a table that implements an M:M relationship. See also \\ncomposite entity .\\nload testingServices to ensure that an application will support the load imposed by having thousands of users access it.\\nlocal area network\\nA network of computers that spans a small area, such as a single building.\\nlocal mapping transparency\\nA property of a DDBMS in which database access requires the user to know both the name and location of the fragments.\\nLOCATION MODE clause\\nIn an IDS/II network DBMS, this clause determines where a record will be (physically) stored in the database and how the record will be retrieved.\\nlocation transparency\\nA property of a DDBMS in which database access requires the user to know only the name of the database fragments. (Fragment locations need not be known.)\\nlock\\nA device that guarantees unique use of a data item in a particular transaction operation. A transaction requires a lock prior to data access; the lock is re -\\nleased after the operation’s execution to enable other transactions to lock the data item for their own use.\\nlock granularity\\nThe level of lock use. Locking can take place at the following levels: database, table, page, row, and field (attribute).\\nlock manager\\nA DBMS component that is responsible for assigning and releasing locks.logical data formatThe way a person views data within the context of a problem domain.\\nlogical design\\nA stage in the design phase that matches the con-ceptual design to the requirements of the selected DBMS and is therefore software dependent. Logical design is used to translate the conceptual design into the internal model for a selected database management system, such as DB2, SQL Server, Oracle, IMS, Informix, Access, or Ingress.\\nlogical independence\\nA condition in which the internal model can be changed without affecting the conceptual model. (The internal model is hardware independent because it is unaffected by the computer on which the software is installed. Therefore, a change in storage devices or operating systems will not affect the internal model.)\\nlost update\\nA concurrency control problem in which a data update is lost during the concurrent execution of transactions.\\nM\\nmandatory participationA relationship in which one entity occurrence must have a corresponding occurrence in another entity. For example, an EMPLOYEE works in a DIVISION. (A person cannot be an employee without being assigned to a company’s division.)\\nmanual query optimization\\nAn operation mode that requires the end user or programmer to define the access path for the execution of a query.\\nmanual statistical  \\ngeneration modeA mode of generating statistical data access information for query optimization. In this mode, the DBA must periodically run a routine to generate the data access statistics—for example, running the RUNSTAT command in an IBM DB2 database.\\nmany-to-many (M:N or *..*) \\nrelationshipAssociation among two or more entities in which one occurrence of an entity is associated with many occurrences of a related entity and one occurrence of the related entity is associated with many occurrences of the first entity.\\nmap\\nThe function in a MapReduce job that sorts and filters data into a set of key-value pairs as a subtask within a larger job.\\nmapper\\nA program that performs a map function.\\nMapReduce\\nAn open-source application programming interface (API) that provides fast data analytics services; one of the main Big Data technologies that allows organizations to process massive data stores.\\nmaster data management (MDM)\\nIn business intelligence, a collection of concepts, techniques, and processes for the proper identifica-tion, definition, and management of data elements within an organization.master data management (MDM) softwareSoftware the provides a “master copy”  of entities such as customers, that appear in numerous systems throughout the organization. This software helps prevent dirty data by coordinating common data across multiple systems.\\nmaterialized view\\nA dynamic table that not only contains the SQL query command to generate rows but stores the actual rows. The materialized view is created the first time the query is run and the summary rows are stored in the table. The materialized view rows are automatical-ly updated when the base tables are updated.\\nMAX\\nA SQL aggregate function that yields the maximum attribute value in a given column.\\nmessage\\nIn the OO data model, the name of a method sent to an object in order to perform an action. A message triggers the object’s behavior. See \\nmethod .\\nmessagingA service to ensure the proper routing and delivery of application-oriented data among multiple services.\\nmetadata\\nData about data; that is, data about data character-istics and relationships. See also \\ndata dictionary .\\nmethodIn the object-oriented data model, a named set of instructions to perform an action. Methods represent real-world actions, and are invoked through messages.\\nmetrics\\nIn a data warehouse, numeric facts that measure a business characteristic of interest to the end user.\\nmetropolitan area network (MAN)\\nNetwork type used to connect computers across a city or metropolitan area.\\nMicrosoft .NET framework\\nA component-based platform for the development of distributed, heterogeneous, interoperable applications aimed at manipulating any type of data over any network regardless of operating system and programming language.\\nmiddleware\\nThe computer software that allows clients and servers to communicate within the client/server architecture. It is used to insulate client processes from the network protocols and the details of the server process protocols.\\nMIN\\nA SQL aggregate function that yields the minimum attribute value in a given column.\\nminimal data rule\\nDefined as “ All that is needed is there, and all that is there is needed. ”  In other words, all data elements required by database transactions must be defined in the model, and all data elements defined in the model must be used by at least one database transaction.\\nmixed fragmentation\\nA combination of horizontal and vertical strategies for data fragmentation, in which a table may be divided into several rows and each row has a subset of the attributes (columns).module(1) A design segment that can be implemented as an autonomous unit, and is sometimes linked to produce a system. (2) An information system component that handles a specific function, such as inventory, orders, or payroll.\\nmodule coupling\\nThe extent to which modules are independent of one another.\\nmonotonicity\\nA quality that ensures that time stamp values always increase. (The time stamping approach to scheduling concurrent transactions assigns a global, unique time stamp to each transaction. The time stamp value produces an explicit order in which transactions are submitted to the DBMS.)\\nmultidimensional database  \\nmanagement systems (MDBMSs)A database management system that uses propri-etary techniques to store data in matrixlike arrays of \\nn dimensions known as cubes.\\nmultidimensional online  analytical processing (MOLAP)An extension of online analytical processing to multidimensional database management systems.\\nmultiple access unit (MAU)\\nA wiring concentrator through which a token ring’s computers are connected physically.\\nmultiple inheritance\\nExists when a class can have more than one immediate (parent) superclass above it in an object-oriented database environment.\\nmultiple-site processing,  \\nmultiple-site data (MPMD)A scenario describing a fully distributed database management system with support for multiple data processors and transaction processors at multiple sites.\\nmultiple-site processing,  \\nsingle-site data (MPSD)A scenario in which multiple processes run on different computers sharing a single data repository.\\nmultitenant database\\nA database environment in which a container database can hold other databases.\\nmultiuser database\\nA database that supports multiple concurrent users.\\nmultivalued attributes\\nAn attribute that can have many values for a single entity occurrence. For example, an EMP_ DEGREE attribute might store the string “BBA, MBA, PHD”  to indicate three different degrees held.\\nmutual consistency rule\\nA data replication rule that requires all copies of data fragments to be identical.\\nmutual exclusive rule\\nA condition in which only one transaction at a time can own an exclusive lock on the same object.\\nN\\nname nodeOne of three types of nodes used in the Hadoop Distributed File System (HDFS). The name node stores all the metadata about the file system. See also \\nclient node  and data node .\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4eaf6af-a473-4f6f-8cc3-4677f8a65007', embedding=None, metadata={'page_label': '777', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    777\\nnatural identifier\\nA generally accepted identifier for real-world objects. As its name implies, a natural key is familiar to end users and forms part of their day-to-day business vocabulary.\\nnatural join\\nA relational operation that yields a new table composed of only the rows with common values in their common attribute(s).\\nnatural key\\nSee \\nnatural identifier.\\nnested queryIn SQL, a query that is embedded in another query. See \\nsubquery .\\nnetwork backboneThe main network cabling system for one or more local area networks.\\nNetwork Basic Input/Output \\nSystem (NetBIOS)A network protocol originally developed by IBM and SYTEK Corporation in 1984.\\nNetwork interface cards (NICs)\\nElectronic circuit board that allows computers to communicate within a network.\\nnetwork latency\\nThe delay imposed by the amount of time required for a data packet to make a round trip from point A to point B.\\nnetwork model\\nAn early data model that represented data  as a collection of record types in 1:M  relationships.\\nnetwork operating system (NOS)\\nA computer operating system oriented toward providing server side services to clients (such as file and printer sharing and security \\n management).\\nnetwork partitioning\\n The delay that occurs when nodes become suddenly unavailable due to a network failure. In distributed databases, the system must account for the possibility of this condition.\\nnetwork protocol\\nA set of rules (at the physical level) that determines how messages between computers are sent, processed, and interpreted.\\nnetwork segment\\nA single section of cable that connects several computers.\\nnetwork translator\\nA middleware component that manages the network communications protocols.\\nnews and discussion group \\nservicesSpecialized services that allow the creation of “virtual communities”  in which users exchange messages regarding specific topics.\\nNewSQL\\nA database model that attempts to provide ACID-compliant transactions across a highly distributed infrastructure.\\nnode\\nIn a graph database, the representation of a single entity instance.non-identifying relationshipA relationship in which the primary key of the relat-ed entity does not contain a primary key component of the parent entity.\\nnonkey attribute\\nSee \\nnonprime attribute .\\nnonoverlapping subtypesSee \\ndisjoint subtype .\\nnonprime attributeAn attribute that is not part of a key.\\nnonrepeatable read\\nIn transaction management, when a transaction reads a given row at time t1, then reads the same row at time t2, yielding different results because the original row may have been updated or deleted.\\nnonserialized items\\nItems for which the attributes describe a generalized view of the that kind of item, without identifying each individual instance of the item.\\nnormalization\\nA process that assigns attributes to entities so that data redundancies are reduced or eliminated.\\nNoSQL\\nA new generation of database management sys-tems that is not based on the traditional relational database model.\\nNOT\\nA SQL logical operator that negates a given predicate.\\nnull\\nThe absence of an attribute value. Note that a null is not a blank.\\nO\\nobjectAn abstract representation of a real world entity that has a unique identity, embedded properties, and the ability to interact with other objects and itself.\\nobject ID (OID)\\nIn an object-oriented database environment, a system-generated object identifier that is independent of the object state and any physical address in memory.\\nobject instance\\nEach particular object belonging to a class.\\nObject Linking and Embedding \\nfor Database (OLE-DB)Based on Microsoft’s Component Object Model (COM), OLE-DB is database middleware that adds object-oriented functionality for accessing relational and nonrelational data.\\nobject orientation\\nA set of modeling and development principles focused on an autonomous entity with embedded intelligence to interact with other objects and itself.\\nobject query language (OQL)\\nThe database query language used by an object oriented database management system.\\nobject schema\\nSee Object space.\\nobject space\\nThe equivalent of the database schema, as seen by the designer in an object oriented database.object stateThe set of values that the object’s attributes have at a given time.\\nobject table\\nThe equivalent of a relational table composed of many rows, where each row is an object of the same type. Each row object has a unique system generated object ID (OID) or object identifier.\\nobject-oriented data model (OODM)\\nA data model whose basic modeling structure is an object.\\nobject-oriented database  \\nmanagement system (OODBMS)Data management software used to manage data in an object-oriented database model.\\nobject-oriented programming \\n(OOP)An alternative to conventional programming meth-ods based on object oriented concepts. It reduces programming time and lines of code, and increases programmers’  productivity.\\nobject-oriented programming \\nlanguages (OOPLs)A programming language based on object oriented concepts.\\nobject/relational database  \\nmanagement system (O/R DBMS)A DBMS based on the extended relational model (ERDM). The ERDM, championed by many relational database researchers, constitutes the relational model’s response to the OODM. This model includes many of the object-oriented model’s best features within an inherently simpler relational database structure.\\none-to-many (1:M or 1..*)  \\nrelationshipAssociations among two or more entities that are used by data models. In a 1:M relationship, one entity instance is associated with many instances of the related entity.\\none-to-one (1:1 or 1..1)  \\nrelationshipAssociations among two or more entities that are used by data models. In a 1:1 relationship, one entity instance is associated with only one instance of the related entity.\\nonline analytical processing \\n(OLAP)Decision support system (DSS) tools that use multidimensional data analysis techniques. OLAP creates an advanced data analysis environment that supports decision making, business modeling, and operations research.\\nonline transaction processing \\n(OLTP) databaseSee \\noperational database .\\nOpen Database Connectivity (ODBC)Microsoft database middleware that provides a database access API to Windows applications.\\nOpen Systems Interconnection \\n(OSI)A seven-layer reference model developed by the International Organization for Standardization (ISO) to help standardize diverse network systems.operational databaseA database designed primarily to support a company’s day-to-day operations. Also known as a \\ntransactional database , OLTP database , or \\nproduction database .\\noptimistic approachIn transaction management, a concurrency control technique based on the assumption that most database operations do not conflict.\\noptimizer hints\\nSpecial instructions for the query optimizer that are embedded inside the SQL command text.\\noptional attribute\\nIn ER modeling, an attribute that does not require a value; therefore, it can be left empty.\\noptional participation\\nIn ER modeling, a condition in which one entity occurrence does not require a corresponding entity occurrence in a particular relationship.\\nOR\\nThe SQL logical operator used to link multiple condition-al expressions in a WHERE or HAVING clause. It requires only one of the conditional expressions to be true.\\nORDER BY\\nA SQL clause that is useful for ordering the output of a SELECT query (for example, in ascending or descending order).\\nouter join\\nA relational algebra join operation that produces a table in which all unmatched pairs are retained; unmatched values in the related table are left null. Contrast with \\ninner join . See also left outer join  and \\nright outer join .\\noverlapping subtypesIn a specialization hierarchy, a condition in which each entity instance (row) of the supertype can appear in more than one subtype.\\nP\\npacket filter firewallA type of firewall that works at the TCP/IP packet level.\\npage\\nIn permanent storage, the equivalent of a disk block, which can be described as a directly addressable section of a disk. A diskpage has a fixed size, such as 4K, 8K, or 16K.\\npage-level lock\\nIn this type of lock, the database management system locks an entire diskpage, or section of a disk. A diskpage can contain data for one or more rows and from one or more tables.\\npartial completeness\\nIn a generalization/specialization hierarchy, a condition in which some supertype occurrences might not be members of any subtype.\\npartial dependency\\nA condition in which an attribute is dependent on only a portion (subset) of the primary key.\\npartially replicated database\\nA distributed database in which copies of only some database fragments are stored at multiple sites.\\nparticipants\\nAn ER term for entities that participate in a relation-ship. For example, in the relationship “PROFESSOR \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68d06592-3012-49ab-b647-f0e5578a35d9', embedding=None, metadata={'page_label': '778', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='778   Glossary\\nteaches CLASS, ”  the teaches  relationship is based on \\nthe participants PROFESSOR and CLASS.\\npartition key\\nIn partitioned databases, one or more attributes in a table that determine the fragment in which a row will be stored.\\npartitioned data allocation\\nA data allocation strategy of dividing a database into two or more fragments that are stored at two or more sites.\\npartitioning\\nThe process of splitting a table into subsets of rows or columns.\\npassive data dictionary\\nA DBMS data dictionary that requires a command initiated by an end user to update its data access statistics.\\nperformance transparency\\nA DDBMS feature that allows a system to perform as though it were a centralized DBMS.\\nperformance tuning\\nActivities that make a database perform more efficiently in terms of storage and access speed.\\nperiodicity\\nInformation about the time span of data stored in a table, usually expressed as current year only, previous years, or all years.\\npersistent stored module (PSM)\\nA block of code with standard SQL statements and procedural extensions that is stored and executed at the DBMS server.\\npersonalization\\nIn an e-commerce environment, customization of a Web page for individual users.\\npessimistic locking\\nThe use of locks based on the assumption that conflict between transactions is likely.\\nphantom read\\nIn transaction management, when a transaction executes a query at time t1, then runs the same query at time t2, yielding additional rows that satisfy the query.\\nphysical data format\\nThe way a computer “sees”  (stores) data.\\nphysical design\\nA stage of database design that maps the data storage and access characteristics of a database. Because these characteristics are a function of the types of devices supported by the hardware, the data access methods supported by the system phys-ical design are both hardware- and software-de-pendent. See also \\nphysical model .\\nphysical independenceA condition in which the physical model can be changed without affecting the internal model.\\nphysical model\\nA model in which physical characteristics such as location, path, and format are described for the data. The physical model is both hardware- and software dependent. See also \\nphysical design .\\nPlatform as a Service (PaaS)A model in which the cloud service provider can build and deploy consumer-created applications using the provider’s cloud infrastructure.plug-inOn the web, a client-side, external application that is automatically invoked by the browser when needed to manage specific types of data.\\npluggable database\\nIn a multitenant database environment, a database that can be contained within a container database.\\npolicies\\nGeneral statement of direction that is used to manage company operations through the communi-cation and support of the organization’s objectives.\\npolyglot persistence\\nThe coexistence of a variety of data storage and data management technologies within an organization’s infrastructure.\\npolymorphism\\nAn object oriented data model characteristic by which different objects can respond to the same message in different ways.\\nportals\\nIn terms of business intelligence, a unified, single point of entry for information distribution.\\npredicate logic\\nUsed extensively in mathematics to provide a framework in which an assertion (statement of fact) can be verified as either true or false.\\npredictive analytics\\nData analytics that use advanced statistical and modeling techniques to predict future business outcomes with great accuracy.\\nPretty Good Privacy (PGP)\\nAn example of public-key encryption by Pretty Good Privacy Inc. PGP is a fairly popular and inexpensive method for encrypting e-mail messages on the Internet.\\nprimary key (PK)\\nIn the relational model, an identifier composed of one or more attributes that uniquely identifies a row. Also, a candidate key selected as a unique entity identifier. See also \\nkey.\\nprime attributeA key attribute; that is, an attribute that is part of a key or is the whole key. See also \\nkey attributes .\\nprivacyThe rights of individuals and organizations to determine access to data about themselves.\\nprivate cloud\\nA form of cloud computing in which an internal cloud is built by an organization to serve its own needs.\\nprivate key\\nA key that is known only to the owner of the key.\\nprivate-key encryption\\nEncryption that uses a single numeric key to encode and decode data. Both sender and receiver must know the encryption key. See also \\nsymmetric \\nencryption .\\nProcedural Language SQL  (PL/SQL)An Oracle-specific programming language based on SQL with procedural extensions designed to run inside the Oracle database.\\nprocedure cache\\nSee \\nSQL cache .proceduresSeries of steps to be followed during the perfor-mance of an activity or process.\\nprocessing option (PROCOPT)\\nA type of access granted to a program.\\nPRODUCT\\nIn relational algebra, an operator used to yield all possible pairs of rows from two tables. Also known as the Cartesian product.\\nproduction database\\nSee \\noperational database .\\nprofileIn Oracle, a named collection of settings that controls how much of the database resource a given user can use.\\nprogram communication  \\nblock (PCB)In a hierarchical database, after the physical database has been defined through the DBD, a way through which application programs are given a subset of the physical database.\\nprogram specification block (PSB)\\nIn a hierarchical database, this represents a logical view of a selected portion of the database and also defines the database(s), segments, and types of op-erations that can be performed by the application. Using PSBs yields better data security as well as improved program efficiency by allowing access to only the portion of the database that is required to perform a given function.\\nPROJECT\\nIn relational algebra, an operator used to select a subset of columns.\\nproperties\\nIn a graph database, the attributes or characteristics of a node or edge that are of interest to the users.\\nprotocol\\nA specific set of rules to accomplish a specific function. In the object oriented data model, protocol refers to a collection of messages to which an object responds.\\nproxy server firewall\\nA firewall that operates as an intermediary between client computers inside a private network and the Internet.\\npublic cloud\\nA form of computing in which the cloud infrastruc-ture is built by a third-party organization to sell cloud services to the general public.\\npublic key\\nA key that is available to anyone wanting to communicate securely with the key’s owner.\\npublic-key encryption\\nA form of encryption that uses two numeric keys—the public key and the private key. Both keys are able to encrypt and decrypt each other’s messages. See also \\nasymmetric encryption .\\nQ\\nqueryA question or task asked by an end user of a database in the form of SQL code. A specific request for data manipulation issued by the end user or the application to the DBMS.query languageA nonprocedural language that is used by a DBMS to manipulate its data. An example of a query language is SQL.\\nquery optimizer\\nA DBMS process that analyzes SQL queries and finds the most efficient way to access the data. The query optimizer generates the access or execution plan for the query.\\nquery processing bottleneck\\nIn query optimization, a delay introduced in the processing of an I/O operation that causes the overall system to slow down.\\nquery result set\\nThe collection of data rows returned by a query.\\nR\\nRAIDAn acronym for Redundant Array of Independent Disks. RAID systems use multiple disks to create virtual disks (storage volumes) from several individual disks. RAID systems provide performance improve -\\nment, fault tolerance, and a balance between the two.\\nread committed\\nAn ANSI SQL transaction isolation level that allows transactions to read only committed data. This is the default mode of operations for most databases.\\nread uncommitted\\nAn ANSI SQL transaction isolation level that allows transactions to read uncommitted data from other transactions, and which allows nonrepeatable reads and phantom reads. The least restrictive level defined by ANSI SQL.\\nrecord\\nA collection of related (logically connected) fields.\\nrecord at a time\\nThis term indicates that the database commands affect a single record at a time.\\nRECORD NAME clause\\nIn the IDS/II network DBMS, this clause initiates the record’s definition by assigning it a unique name. An IDS/II network database must contain at least one record type.\\nrecursive query\\nA nested query that joins a table to itself.\\nrecursive relationship\\nA relationship found within a single entity type. For example, an EMPLOYEE is married to an EMPLOYEE or a PART is a component of another PART.\\nreduce\\nThe function in a MapReduce job that collects and summarizes the results of map functions to produce a single result.\\nreducer\\nA program that performs a reduce function.\\nredundant transaction logs\\nMultiple copies of the transaction log kept by database management systems to ensure that the physical failure of a disk will not impair the DBMS’s ability to recover data.\\nreferential integrity\\nA condition by which a dependent table’s foreign key must have either a null entry or a matching entry in the related table.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1a81f156-3a90-47cc-9b40-96cb751e864d', embedding=None, metadata={'page_label': '779', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    779\\nreferential object sharing\\nWhen an object instance is referenced by other objects. That is, two or more different objects point to the same object instance, a change in the referenced object instance values is automatically reflected in all other referring objects.\\nregular entity\\nSee \\nstrong entity .\\nrelationA logical construct perceived to be a two dimen-sional structure composed of intersecting rows (entities) and columns (attributes) that represents an entity set in the relational model.\\nrelational algebra\\nA set of mathematical principles that form the basis for manipulating relational table contents; the eight main functions are SELECT, PROJECT, JOIN, INTERSECT, UNION, DIFFERENCE, PRODUCT, and DIVIDE.\\nrelational database management \\nsystem (RDBMS)A collection of programs that manages a relational database. The RDBMS software translates a user’s logical requests (queries) into commands that physically locate and retrieve the requested data.\\nrelational diagram\\nA graphical representation of a relational database’s entities, the attributes within those entities, and the relationships among the entities.\\nrelational model\\nDeveloped by E. F . Codd of IBM in 1970, the relational model is based on mathematical set theory and represents data as independent relations. Each relation (table) is conceptually represented as a two dimen-sional structure of intersecting rows and columns. The relations are related to each other through the sharing of common entity characteristics (values in columns).\\nrelational online analytical  \\nprocessing (ROLAP)Analytical processing functions that use relational databases and familiar relational query tools to store and analyze multidimensional data.\\nrelational schema\\nThe organization of a relational database as described by the database administrator.\\nrelationship\\nAn association between entities.\\nrelationship degree\\nThe number of entities or participants associated with a relationship. A relationship degree can be unary, binary, ternary, or higher.\\nrelvar\\nShort for relation variable, a variable that holds a relation. A relvar is a container (variable) for holding relation data, not the relation itself.\\nRemote Data Objects (RDO)\\nA higher-level, object-oriented application interface used to access remote database servers. RDO uses the lower-level DAO and ODBC for direct access to databases.\\nremote request\\nA DDBMS feature that allows a single SQL statement to access data in a single remote DP .remote transactionA DDBMS feature that allows a transaction (formed by several requests) to access data in a single remote DP .\\nrepeatable read\\nAn ANSI SQL transaction isolation level that uses shared locks to ensure that other transactions do not update a row after the original query updates it. However, phantom reads are allowed.\\nrepeater\\nA device used in Ethernet networks to add network segments to the network and to extend its signal reach.\\nrepeating group\\nIn a relation, a characteristic describing a group of multiple entries of the same type for a single key attribute occurrence. For example, a car can have multiple colors for its top, interior, bottom, trim, and so on.\\nreplica transparency\\nThe DDBMS’s ability to hide the existence of multiple copies of data from the user.\\nreplicated data allocation\\nA data allocation strategy in which copies of one or more database fragments are stored at several sites.\\nreplication\\nThe process of creating and managing duplicate versions of a database. Replication is used to place copies in different locations and to improve access time and fault tolerance.\\nrequired attribute\\nIn ER modeling, an attribute that must have a value. In other words, it cannot be left empty.\\nreserved words\\nWords used by a system that cannot be used for any other purpose. For example, in Oracle SQL, the word INITIAL cannot be used to name tables or columns.\\nresource security\\nThe protection of the resource(s) from external and internal threats. Specifically, resource security means protecting the resource from viruses, unauthorized access by hackers, or denial of service attacks.\\nRESTRICT\\nSee \\nSELECT .\\nright outer joinIn a pair of tables to be joined, a join that yields all of the rows in the right table, including the ones with no matching values in the other table. For example, a right outer join of CUSTOMER with AGENT will yield all of the AGENT rows, including the ones that do not have a matching CUSTOMER row. See also \\nleft outer join  and outer join .\\nring topologyNetwork topology in which computers are connect-ed to one another via a cabling setup that, as the name implies, resembles a ring; it is more flexible than a bus topology, because addition or loss of a computer does not have a negative impact on other network activities.\\nrole\\nIn Oracle, a named collection of database access privileges that authorize a user to connect to a database and use its system resources.roll up(1) To aggregate data into summarized components, that is, higher levels of aggregation. (2) In SQL, an OLAP extension used with the GROUP BY clause to aggregate data by different dimensions. Rolling up the data is the exact opposite of drilling down the data.\\nROLLBACK\\nA SQL command that restores the database table contents to the condition that existed after the last COMMIT statement.\\nrouter\\n(1) An intelligent device used to connect dissimilar networks. (2) Hardware/software equipment that connects multiple and diverse networks.\\nrow-centric storage\\nA physical data storage technique in which data is stored in blocks, which hold data from all columns of a given set of rows.\\nrow-level lock\\nA less restrictive database lock in which the DBMS allows concurrent transactions to access different rows of the same table, even when the rows are on the same page.\\nrow-level trigger\\nA trigger that is executed once for each row affected by the triggering SQL statement. A row-level trigger requires the use of the FOR EACH ROW keywords in the trigger declaration.\\nrule-based optimizer\\nA query optimization mode based on the rule-based query optimization algorithm.\\nrule-based query optimization \\nalgorithmA query optimization technique that uses preset rules and points to determine the best approach to executing a query.\\nrules of precedence\\nBasic algebraic rules that specify the order in which operations are performed. For example, operations within parentheses are executed first, so in the equation 2 + (3 × 5), the multiplication portion is calculated first, making the correct answer 17.\\nS\\nscaling outA method for dealing with data growth that involves distributing data storage structures across a cluster of commodity servers.\\nscaling up\\nA method for dealing with data growth that involves migrating the same structure to more powerful systems.\\nscheduler\\nThe DBMS component that establishes the order in which concurrent transaction operations are executed. The scheduler \\ninterleaves  the execution of \\ndatabase operations in a specific sequence to ensure \\nserializability .\\nschemaA logical grouping of database objects, such as tables, indexes, views, and queries, that are related to each other. Usually, a schema belongs to a single user or application.scopeThe part of a system that defines the extent of the design, according to operational require -\\nments.\\nscript\\nA programming language that is not compiled, but is interpreted and executed at run time.\\nsearch services\\nA business enabling web service that allows Web sites to perform searches on their contents.\\nsecond normal form (2NF)\\nThe second stage in the normalization process, in which a relation is in 1NF and there are no partial dependencies (dependencies in only part of the primary key).\\nsecondary key\\nA key used strictly for data retrieval purposes. For example, customers are not likely to know their customer number (primary key), but the combination of last name, first name, middle initial, and telephone number will probably match the appropriate table row. See also\\n key.\\nSecure Electronic Transaction (SET)Initiative to provide a standard for secure credit card transactions over the Internet.\\nSecure Hypertext Transfer  \\nProtocol (S-HTTP)\\nProtocol used to securely transfer Web docu-ments over the Internet. S-HTTP supports use of private and public keys for authentication and encryption. S-HTTP has not been widely used, because it only supports encrypted HTTP data and does not support other Internet protocols as does SSL.\\nSecure Sockets Layer (SSL)\\nA protocol used to implement secure communica-tion channels between client and server computers on the Internet.\\nsecurity\\nActivities and measures to ensure the confidenti-ality, integrity, and availability of an information system and its main asset, data.\\nsecurity breach\\nAn event in which a security threat is exploited to endanger the integrity, confidentiality, or availability of the system.\\nsecurity policy\\nA collection of standards, policies, and procedures created to guarantee the security of a system and ensure auditing and compliance.\\nsecurity threat\\nAn imminent security violation that could occur due to unchecked security vulnerabilities.\\nsecurity vulnerability\\nA weakness in a system component that could be exploited to allow unauthorized access or cause service disruptions.\\nsegment (SEGM)\\nIn the hierarchical data model, the equivalent of a file system’s record type.\\nSELECT\\n(1) A SQL command that yields the values of all rows or a subset of rows in a table. The SELECT statement is used to retrieve data from tables.  \\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='37fca699-73ce-43f4-aa97-5214b5d1a01f', embedding=None, metadata={'page_label': '780', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='780   Glossary\\n(2) In relational algebra, an operator to select a \\nsubset of rows. Also known as RESTRICT .\\nsemantic data modelThe first of a series of data models that more closely represented the real world, modeling both data and their relationships in a single structure known as an object. The SDM, published in 1981, was developed by M. Hammer and D. McLeod.\\nsemistructured data\\nData that has already been processed to some extent.\\nSENSEG (SENsitive SEGment)\\nIn the IMS hierarchical database, this keyword de-clares the segments that will be available, starting with the root segment.\\nsentiment analysis\\nA method of text analysis that attempts to deter-mine if a statement conveys a positive, negative, or neutral attitude.\\nsequence\\n(1) A nested ordering sequence for a set of rows, such as a list in which all last names are alphabet-ically ordered and, within the last names, all first names are ordered. (2) An object for generating unique sequential values for a sequence field.\\nsequence field\\nAn attribute that contains values that are unique and sequential (ascending or descending). Some DBMS allows the explicit definition of sequence or autonumber attributes that are generally used to uniquely identify each row.\\nserializability\\nA property in which the selected order of concurrent transaction operations creates the same final database state that would have been produced if the transactions had been executed in a serial fashion.\\nserializable\\nAn ANSI SQL transaction isolation level that does not allow dirty reads, nonrepeatable reads, or phantom reads; the most restrictive level defined by the ANSI SQL standard.\\nserializable schedule\\nIn transaction management, a schedule of operations in which the interleaved execution of the transactions yields the same result as if they were executed in serial order.\\nserialized items\\nItems for which each instance of the item must be tracked as an individually identifiable item.\\nserver\\nAny process that provides requested services to clients. See \\nclient/server architecture .\\nserver-side extensionA program that interacts directly with the server process to handle specific types of requests. Serv-er-side extensions add significant functionality to web servers and intranets.\\nset theory\\nA part of mathematical science that deals with sets, or groups of things, and is used as the basis for data manipulation in the relational model.\\nset-oriented\\nDealing with or related to sets, or groups of things. In the relational model, SQL operators are set-oriented because they operate over entire sets of rows and columns at once.\\nshared lock\\nA lock that is issued when a transaction requests permission to read data from a database and no exclusive locks are held on the data by another transaction. A shared lock allows other read-only transactions to access the database.\\nsimple attribute\\nAn attribute that cannot be subdivided into mean-ingful components. Compare to \\ncomposite attribute .\\nsimple objectAn object that contains only single-valued attributes and has no attributes that refer to another object.\\nsingle inheritance\\nIn the object oriented data model, the property of an object that allows it to have only one parent superclass from which it inherits its data structure and methods. See also \\ninheritance, multiple \\ninheritance .\\nsingle-site processing,  single-site data (SPSD)A scenario in which all processing is done on a single host computer and all data is stored on the host computer’s local disk.\\nsingle-user database\\nA database that supports only one user at a time.\\nsingle-valued attribute\\nAn attribute that can have only one value.\\nsite monitoring and data analysis\\nIn an e-commerce environment, services to ensure that a Web site performs at an optimal level.\\nslice and dice\\nThe ability to focus on slices of a data cube (drill down or roll up) to perform a more detailed analysis.\\nsneakernet\\nOne of the original ways to share data. When users needed to share data, they would simply copy the data to a disk and walk to the coworker’s office, disk in hand.\\nsnowflake schema\\nA type of star schema in which dimension tables can have their own dimension tables. The snowflake schema is usually the result of normalizing dimension tables.\\nsocial media\\nWeb and mobile technologies that enable “any-where, anytime, always on”  human interactions.\\nSoftware as a Service (SaaS)\\nA model in which the cloud service provider offers turnkey applications that run in the cloud.\\nsoftware independence\\nA property of any model or application that does not depend on the software used to implement it.\\nsparse data\\nA case in which the number of table attributes is very large but the number of actual data instances is low.\\nsparsity\\nIn multidimensional data analysis, a measurement of the data density held in the data cube.\\nspecialization\\nIn a specialization hierarchy, the grouping of unique attributes into a subtype entity.specialization hierarchyA hierarchy based on the top-down process of iden-tifying lower-level, more specific entity subtypes from a higher-level entity supertype. Specialization is based on grouping unique characteristics and relationships of the subtypes.\\nSQL cache\\nA shared, reserved memory area that stores the most recently executed SQL statements or PL/SQL procedures, including triggers and functions. Also called \\nprocedure cache .\\nSQL data services (SDS)Data management services that provide relational data storage, access, and management over the Internet.\\nSQL performance tuning\\nActivities to help generate a SQL query that returns the correct answer in the least amount of time, using the minimum amount of resources at the server end.\\nstandards\\nA detailed and specific set of instructions that describes the minimum requirements for a given activity. Standards are used to evaluate the quality of the output.\\nstar schema\\nA data modeling technique used to map multidi-mensional decision support data into a relational database. The star schema represents data using a central table known as a fact table in a 1:M relation-ship with one or more dimension tables.\\nstar topology\\nNetwork topology with all computers connected to one another in a star configuration through a central computer or network hub. Like a ring topology, allows for computers to be added to or released from the network without having an impact on other computers.\\nstate inspection firewall\\nA type of firewall that compares parts of incoming packets and related outgoing packets.\\nstateless system\\nA system in which a web server does not know the status of the clients communicating with it. The web does not reserve memory to maintain an open communications state between the client and the server.\\nstatement-level trigger\\nA SQL trigger that is assumed if the FOR EACH ROW keywords are omitted. This type of trigger is  executed once, before or after the triggering statement completes, and is the default case.\\nstatic query optimization\\nA query optimization mode in which the access path to a database is predetermined at compilation time.\\nstatic SQL\\nA style of embedded SQL in which the SQL statements do not change while the application is running.\\nstatic webpage\\nWeb page used to display information that does not change much over time or is not time-critical.\\nstatistically based query optimi-\\nzation algorithmA query optimization technique that uses statistical information about a database. The DBMS then uses these statistics to determine the best access strategy.stored functionA named group of procedural and SQL statements that returns a value, as indicated by a RETURN statement in its program code.\\nstored procedure\\n(1) A named collection of procedural and SQL statements. (2) Business logic stored on a server in the form of SQL code or another DBMS-specific procedural language.\\nstream processing\\nThe processing of data inputs in order to make decisions about which data to keep and which data to discard before storage.\\nstrong (identifying) relationship\\nA relationship that occurs when two entities are existencedependent; from a database design perspective, this relationship exists whenever the primary key of the related entity contains the primary key of the parent entity.\\nstrong entity\\nAn entity that is existence-independent, that is, it can exist apart from all of its related entities. Also called a \\nregular entity .\\nstructural dependenceA data characteristic in which a change in the database schema affects data access, thus requiring changes in all access programs.\\nstructural independence\\nA data characteristic in which changes in the database schema do not affect data access.\\nstructured data\\nData that has been formatted to facilitate storage, use, and information generation.\\nStructured Query Language  \\n(SQL)A powerful and flexible relational database language composed of commands that enable users to create database and table structures, perform various types of data manipulation and data administration, and query the database to extract useful information.\\nsubclasses\\nSee \\nclass hierarchy .\\nsubordinatesIn a DDBMS, a data processor (DP) node that participates in a distributed transaction using the two-phase COMMIT protocol.\\nsubquery\\nA query that is embedded (or nested) inside another query. Also known as a \\nnested query  or an \\ninner query .\\nsubschemaThe portion of the database that interacts with application programs.\\nsubtype discriminator\\nThe attribute in the supertype entity that determines to which entity subtype each supertype occurrence is related.\\nSUM\\nA SQL aggregate function that yields the sum of all values for a given column or expression.\\nsuper column\\nIn a column family database, a column that  is composed of a group of other related  columns.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd31555d-2626-4296-962f-4f5f9faa54e0', embedding=None, metadata={'page_label': '781', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Glossary    781\\nsuperclass\\nIn a class hierarchy, the superclass is the more general classification from which the subclasses inherit data structures and behaviors.\\nsuperkey\\nAn attribute or attributes that uniquely identify each entity in a table. See \\nkey.\\nsurrogate keyA system-assigned primary key, generally numeric and autoincremented.\\nswitch\\nAn intelligent device that connects computers. Unlike a hub, a switch allows multiple simultaneous transmissions between two ports (computers). Therefore, switches have greater throughput and speed than regular hubs.\\nsymmetric encryption\\nEncryption that uses a single numeric key to encode and decode data. Both sender and receiver must know the encryption key. See also \\nprivate-key \\nencryption .\\nsynonymThe use of different names to identify the same object, such as an entity, an attribute, or a relation-ship; synonyms should generally be avoided. See also \\nhomonym .\\nsystem catalogA detailed system data dictionary that describes all objects in a database.\\nsystems administrator\\nThe person responsible for coordinating and performing day-to-day data-processing activities.\\nsystems analysis\\nThe process that establishes the need for an information system and its extent.\\nsystems development\\nThe process of creating an information system.\\nSystems Development Life Cycle \\n(SDLC)The cycle that traces the history of an information system. The SDLC provides the big picture within which database design and application development can be mapped out and evaluated.\\nSystems Network Architecture \\n(SNA)A network environment used by IBM mainframe computers\\nT\\ntableA logical construct perceived to be a two dimen-sional structure composed of intersecting rows (entities) and columns (attributes) that represents an entity set in the relational model.\\ntable space\\nIn a DBMS, a logical storage space used to group related data. Also known as a \\nfile group .\\ntable-level lockA locking scheme that allows only one transaction at a time to access a table. A table-level lock locks an entire table, preventing access to any row by transaction T2 while transaction T1 is using the table.tablespaceIn a DBMS, a logical storage space used to group related data. Also known as a \\nfile group .\\ntagsIn markup languages such as HTML and XML, a command inserted in a document to specify how the document should be formatted. Tags are used in server-side markup languages and interpreted by a web browser for presenting data.\\ntask trackers\\nA program in the MapReduce framework responsi-ble to running map and reduce tasks on a node.\\nternary relationship\\nAn ER term used to describe an association (relationship) between three entities. For example, a DOCTOR prescribes a DRUG for a PATIENT.\\ntheta join\\nA join operator that links tables using an inequality comparison operator (<, >, <=, >=) in the join condition.\\nthin client\\nA client that carries a relatively smaller proportion of the processing load than compared to the server, thin clients are always paired with fat servers.\\nthin server\\nA server that carries a lesser processing load than the client processes, thin servers are always paired with fat clients.\\nthird normal form (3NF)\\nA table is in 3NF when it is in 2NF and no nonkey attri\\n  bute is functionally dependent on another \\nnonkey attribute; that is, it cannot include transitive dependencies.\\nthree-tier client/server system\\nA system design where the client’s requests are handled by intermediate servers, which coordinate the execution of the client requests with subordinate servers. See also \\nclient/server .\\n3 VsThree basic characteristics of Big Data databases: volume, velocity, and variety.\\ntime stamping\\nIn transaction management, a technique used in scheduling concurrent transactions that assigns a global unique time stamp to each transaction.\\ntime-variant data\\nData whose values are a function of time. For example, timevariant data can be seen at work when a company’s history of all administrative appointments is tracked.\\ntoken\\nIn a ring topology network, the marker that passes from computer to computer, similar to a baton in a relay race. Only the computer with the token can transmit at a given time.\\ntoken ring networks\\nNetworks that use a ring topology and token passing access control.\\ntop-down design\\nA design philosophy that begins by defining the main structures of a system and then moves to define the smaller units within those structures. In database design, this process first identifies entities and then defines the attributes within the entities.total completenessIn a generalization/specialization hierarchy, a condition in which every supertype occurrence must be a member of at least one subtype.\\ntransaction\\nA sequence of database requests that accesses the database. A transaction is a logical unit of work; that is, it must be \\nentirely  completed or aborted—no \\nintermediate ending states are accepted. All transactions must have the properties of atomicity, consistency, isolation, and durability.\\ntransaction log\\nA feature used by the DBMS to keep track of all transaction operations that update the database. The information stored in this log is used by the DBMS for recovery purposes.\\ntransaction log backup\\nA backup of only the transaction log operations that are not reflected in a previous backup copy of the database.\\ntransaction manager (TM)\\nSee \\ntransaction processor (TP) .\\ntransaction processingIn electronic-commerce, this is the series of actions, changes, and/or functions among thousands of connected customers.\\ntransaction processor (TP)\\nIn a DDBMS, the software component on each computer that requests data. The TP is responsible for the execution and coordination of all database requests issued by a local application that accesses data on any DP . Also called \\ntransaction manager \\n(TM)  or application processor (AP) .\\ntransaction transparencyA DDBMS property that ensures database transactions will maintain the distributed database’s integrity and consistency, and that a transaction will be completed only when all database sites involved complete their part of the transaction.\\ntransactional database\\nSee \\noperational database .\\ntransitive dependencyA condition in which an attribute is dependent on another attribute that is not part of the primary key.\\nTransmission Control Protocol/\\nInternet Protocol (TCP/IP)The official communications protocol of the Internet, a worldwide network of heterogeneous computer systems.\\ntransparent\\nIndicating that the user is unaware of the system’s operations.\\nTransport Layer Security (TLS) \\nAn updated version of Secure Sockets Layer (SSL) that supports more secure encrypted communica-tion between a client and server on the Internet.\\ntraversal\\nA query in a graph database.\\ntrigger\\nA procedural SQL code that is automatically invoked by the relational database management system when a data manipulation event occurs.\\ntuple\\nIn the relational model, a table row.twisted pair cableNetwork cable formed by pairs of wires that are twisted inside a protective insulating cover; choice cabling for most network installations because it is easy to install and carries a low price tag. It resembles typical telephone cable.\\ntwo-phase commit protocol (2PC)\\nIn a DDBMS, an algorithm used to ensure atomicity of transactions and database consistency as well as integrity in distributed transactions.\\ntwo-phase locking (2PL)\\nA set of rules that governs how transactions acquire and relinquish locks. Two-phase locking guarantees serializability, but it does not prevent deadlocks. The two-phase locking protocol is divided into two phases: (1) A \\ngrowing phase  \\noccurs when the transaction acquires the locks it needs without unlocking any \\nexisting  data locks. \\nOnce all locks have been acquired, the transaction is in its \\nlocked  point. (2) A shrinking phase  occurs \\nwhen the transaction releases all locks and cannot obtain a new lock.\\ntwo-tier client/server system\\nA system within which a client requests services directly from the server. See also \\nclient/server .\\nU\\nunary relationshipAn ER term used to describe an association \\nwithin  an entity. For example, an EMPLOYEE might \\nmanage another EMPLOYEE.\\nuncommitted data\\nA concurrency control problem in which a trans-action accesses uncommitted data from another transaction.\\nunidirectional logical  \\nrelationshipsIn a hierarchical database, relationships that are established by linking a logical child with a logical parent in a one-way arrangement.\\nUnified Modeling Language \\n(UML)A language based on object-oriented concepts that provides tools such as diagrams and symbols to graphically model a system.\\nUniform Resource Locator (URL) \\nor web addressIdentifier for a resource on the Internet. Also called Web address.\\nUNION\\nIn relational algebra, an operator used to merge (append) two tables into a new table, dropping the duplicate rows. The tables must be \\nunion-com-\\npatible .\\nunion-compatibleTwo or more tables that have the same number of columns and the corresponding columns have compatible domains.\\nunique fragment\\nIn a DDBMS, a condition in which each row is unique, regardless of which fragment it is located in.\\nunique index\\nAn index in which the index key can have only one associated pointer value (row).\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='da88688f-deb8-49f8-bf6c-f6987b595fe6', embedding=None, metadata={'page_label': '782', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='782   Glossary\\nuniqueness\\nIn concurrency control, a property of time  stamping that ensures no equal time stamp values can exist.\\nUniversal Data Access (UDA)\\nWithin the Microsoft application framework, a collection of technologies used to access any type of data source and to manage the data through a common interface.\\nunreplicated database\\nA distributed database in which each database fragment is stored at a single site.\\nunstructured data\\nData that exists in its original, raw state; that is, in the format in which it was collected.\\nupdatable view\\nA view that can update attributes in base tables that are used in the view.\\nUPDATE\\nA SQL command that allows attribute values to be changed in one or more rows of a table.\\nusability testing\\nTesting performed to evaluate the degree to which a user interface is considered friendly and easy to use.\\nuser\\nIn a system, a uniquely identifiable object that allows a given person or process to log on to the database.\\nUWA\\nIn the Network Database Model, a specific area of memory that contains several fields used to access and inform regarding the status of the database. The UWA also contains space for each record type defined in the subschema.\\nV\\nvalueThe degree to which data can be analyzed to provide meaningful insights.\\nvalue chain\\nAll activities required to design, plan, manufacture, market, sell, and support a product or service.\\nvariability\\nThe characteristic of Big Data for the same data values to vary in meaning over time.\\nvariety\\nA characteristic of Big Data that describes the variations in the structure of data to be stored.\\nVBScript\\nA Microsoft client-side extension that extends a browser’s functionality; VBScript is derived from Visual Basic.velocityA characteristic of Big Data that describes the speed at which data enters the system and must be processed.\\nveracity\\nThe trustworthiness of a set of data.\\nverification\\nThe process of refining a conceptual data model into a detailed design that is capable of supporting all required database transactions, and input and output requirements.\\nversioning\\nA property of an OODBMS that allows the database to keep track of the different transformations performed on an object.\\nvertical fragmentation\\nIn distributed database design, the process that breaks a table into a subset of columns from the original table. Fragments must share a common primary key.\\nvery large databases (VLDBs)\\nDatabase that contains huge amounts of data—gigabyte, terabyte, and petabyte ranges are not unusual.\\nview\\nA virtual table based on a SELECT query that is saved as an object in the database.\\nvirtualization\\nA technique that creates logical representations of computing resources that are independent of the underlying physical computing resources.\\nvirus\\nA malicious program that affects the normal operation of a computer system.\\nvisualization\\nThe ability to graphically present data in such a way as to make it understandable to users.\\nvolume\\nA characteristic of Big Data that describes the quantity of data to be stored.\\nW\\nwait/dieA concurrency control scheme in which an older transaction must wait for the younger transaction to complete and release the locks before requesting the locks itself. Otherwise, the newer transaction dies and is rescheduled.\\nweak entity\\nAn entity that displays existence dependence and inherits the primary key of its parent entity.  For example, a DEPENDENT requires the existence of an EMPLOYEE.weak relationshipA relationship in which the primary key of the relat-ed entity does not contain a primary key component of the parent entity.\\nweb application server\\nA middleware application that expands the functionality of web servers by linking them to a wide range of services, such as databases, directory systems, and search engines.\\nweb browser\\nThe end-user application used to navigate the Internet; runs on a client computer and requests services from a Web server.\\nweb caching\\nPerformance-enhancing technique in which a temporary storage area is created to provide Web pages at an optimal speed.\\nweb development\\nThe process of adding “business logic”  to Web pages, thereby making them business-enabled.\\nweb server\\nA specialized application whose only function is to “listen”  for client requests, process them, and send the requested Web resource back to the client browser.\\nweb-to-database middleware\\nA database server-side extension that retrieves data from databases and passes them to the web server, which in turn sends the data to the client’s browser for display.\\nwebpage\\nA text document on the World Wide Web containing text and special commands written in Hypertext Markup Language.\\nwebsite\\nRefers to the Web server and the collection of Web pages stored on the local hard disk of the server computer.\\nWHERE\\nA SQL clause that adds conditional restrictions to a SELECT statement that limit the rows returned by the query.\\nwide area network (WAN)\\nNetwork type used to connect computer users across distant geographical areas; generally makes use of telephone or specialized communications companies.\\nwildcard character\\nA symbol that can be used as a general substitute for: (1) all columns in a table (*) when used in an attribute list of a SELECT statement or, (2) zero or more charac-ters in a SQL LIKE clause condition ( % and _ ).\\nwireless adapter\\nIn the case of wireless networks, this adapter, sometimes called a wireless NIC, allows a computer to communicate using a wireless network.wireless device supportServices that facilitate data integration with mobile communication devices, such as smart phones; allow users to conduct business, make hotel reservations, purchase groceries, and pay bills from virtually anywhere.\\nwireless LANs (WLANs)\\nLocal area networks that are connected by wireless technology rather than wires.\\nworkgroup database\\nA multiuser database that usually supports fewer than 50 users or is used for a specific department in an organization.\\nWorld Wide Web  \\n(WWW or the web)\\nWorldwide network collection of specially format-ted and interconnected documents known as Web pages. Also called the Web.\\nwound/wait\\nA concurrency control scheme in which an older transaction can request the lock, preempt the younger transaction, and reschedule it. Otherwise, the newer transaction waits until the older transaction finishes.\\nwrite-ahead protocol\\nA protocol that ensures transaction logs are written to permanent storage before any database data is actually updated.\\nwrite-ahead-log protocol\\nIn concurrency control, a process that ensures transaction logs are written to permanent  storage before any database data is actually updated. Also called a write-ahead protocol.\\nwrite-through technique\\nIn concurrency control, a process that ensures a database is immediately updated by operations during the transaction’s execution, even before the transaction reaches its commit point. Also called \\nimmediate update .\\nX\\nXML databaseA database system that stores and manages semistructured XML data.\\nXML schema\\nAn advanced data definition language used to de-scribe the elements, data types, relationship types, ranges, and default values of XML data documents. One of the main advantages of an XML schema is that it more closely maps to database terminology and features.\\nXML schema definition (XSD)\\nA file that contains the description of an XML document.\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3fba1734-70e9-481a-a062-ff82c1686676', embedding=None, metadata={'page_label': '783', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Index    783\\nINDEX\\nNote\\nPage numbers in boldface indicate \\nkey terms.\\nSymbols\\nasterisk (*), 704\\ncolon (:), 410, 412comma (,), 257dash (-), 401dollar sign ($), 701forward slash (/), 390Greek letter pi (π), 84Greek letter sigma (σ), 83Infinity symbol (∞), 44parentheses (), 257percent sign (%), 280plus symbol (+), 704question mark (?), 704semicolon (;), 391, 394underscore (_), 280\\nNumbers\\n1:1 relationship. See one-to-one \\n(1:1) relationship\\n1:M relationship. See one-to-many \\n(1:M) relationship\\n1NF. See first normal form\\n2NF. See second normal form\\n2PC. See two-phase commit \\nprotocol\\n2PL. See two-phase locking\\n3NF. See third normal form\\n3 Vs. See volume, velocity, and \\nvariety\\n4NF. See fourth normal form\\n5NF. See fifth normal form\\nA\\nABS function, 366access plan, 524, 542, 741access rights, 454ACID properties, 582active data dictionary, 750ActiveX, 697\\nActiveX Data Objects (ADO), 687adaptive maintenance, 445ADDDATE function, 365ADD_MONTHS function, 364ad hoc query, 7ADO. See ActiveX Data Objects\\nADO.NET, 687, 687–690\\nAGENT file, 16, 20–21aggregate functions, 292–297Agile Software Development, 441algorithm, 653\\nalias\\ndefinition, 275\\njoining tables with, 303\\nALL multirow operator, 353–355ALTER TABLE command, 247, \\n283, 283–284\\nAmazon AWS, 8American National Standards \\nInstitute (ANSI) Standards, 59, 248, 488, 504–505analytical database, 9AND logical operator, 277,  \\n277–278\\nanonymous PL/SQL block, 390ANY multirow operator, 353–355AP. See application processor\\nAPI. See application programming \\ninterface\\napplication code, 525application interface, 559application processor (AP), 560application programming interface \\n(API), 683, 695\\narithmetic operators, 276–277ASSIGNMENT table, 212, 216associative entities, 98, 138–140atomic attribute, 216atomicity, 216, 487\\natomic transaction property, 506AT&T, 4attribute(s)\\natomic, 216\\ncomposite, 120–121cursor, 408definition, 38\\nderived, 123–124description, 118–119discriminator, 175domains, 119identifiers, 119–120key, 77, 202\\nlist subqueries, 356–358multivalued, 121–123nonkey, 202\\nnonprime, 202\\noptional, 119\\nprime, 202\\nrequired, 119\\nsimple, 121\\nsingle-valued, 121\\naudit log, 749audit trails, 454authentication, 251\\nauthorization management, 748automated data mining, 673automatic query optimization, 520availability, 581, 746AVG function, 296, 296–297\\nB\\nback-end CASE tools, 752backup\\nconcurrent, 737\\ndifferential, 455\\nfull, 455,  737\\nincremental, 737\\ntransaction log, 455\\nBASE. See basically available, soft \\nstate, eventually consistent\\nbase tables, 377basically available, soft state, \\neventually consistent (BASE), 582\\nbatch processing, 660batch update routine, 379BCNF. See Boyce-Codd normal form\\nBETWEEN special operator, 279, \\n279–280\\nBI. See business intelligence\\nBig Data\\nbusiness intelligence, 601characteristics, 649–650current view of, 650databases, 29data models and, 50–53definition, 51\\nNoSQL in, 53original view of, 649polyglot persistence, 655sentiment analysis, 654value, 654\\nvariability, 654\\nvariety, 649,  653–654\\nvelocity, 649,  652–653\\nvisualization, 654\\nvolume, 649,  651–652\\nbinary JavaScript Object Notation \\n(BSON), 664\\nbinary lock, 498, 498–499binary relationship, 134, 134–135\\nbitmap index, 527block report, 657Boolean algebra, 278bottom-up design, 473, 473–474boundaries, 450\\nBoyce-Codd normal form (BCNF)\\ncharacteristics, 207conversion to, 221–224definition, 221\\nbridge entity, 98BSON. See binary JavaScript Object \\nNotation\\nB-tree index, 527bucket, 663\\nbuffer cache, 519buffers, 506\\nbusiness intelligence (BI)\\narchitecture, 592–597benefits, 598components, 593definition, 9, 590\\nevolution, 598–601framework, 591–592reporting styles, 597solving problems and adding \\nvalues, 591\\ntechnology trends, 601–602tools, 594\\nbusiness rule\\ndefinition, 39\\ndiscovering, 39–40examples of, 39naming conventions, 41translating into data model, \\n40–41\\nC\\ncall level interface (CLI), 683candidate key, 78cardinality, 125, 125–126cascading order sequence, 291CASE. See computer-aided software \\nengineering\\nCAST function, 369, 370CEIL function, 366CEILING function, 366centralized data allocation, 580centralized databases, 8centralized design, 474, 474–476central processing unit (CPU)\\nconditional expression, 533performance, 517query processing, 525\\nCGI. See Common Gateway \\nInterface\\ncharacter data types, 254CHAR data type, 392CHECK command, 247checkpoints, 507\\nChen notation\\ndefinition, 46\\nderived attributes, 123description, 118–119multivalued attributes, 121–122weak entities, 129–130\\nclass\\ndefinition, 48\\ndiagram, 49\\ndiagram notation, 46hierarchy, 48\\nCLI. See call level interface\\nclient node, 53, 657client-side extensions\\ncommon forms of, 697–698definition, 697\\nCLOSE command, 407closure, 83\\ncloud computing\\ndata architect, 29in database administrators, \\n756–757\\ndefinition, 709\\ndescription, 709–712implementation types, 712SQL data services, 716\\ncloud databases, 8, 30cloud services\\nadvantages/disadvantages of, \\n714–716\\ndefinition, 710\\ntypes of, 713–714\\nclustered index table, 538clustered table, 472Codd, E. F., 74, 104–105cohesivity, 466\\ncohorts, 572\\ncolumn(s)\\nadding, 284–285alias, 274–275computed, 274–275data characteristics, 284data types, 284dropping, 285\\ncolumn-centric storage, 665column family, 667\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c7404ccc-da3f-4e85-b849-d9b75be95d3c', embedding=None, metadata={'page_label': '784', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='784   Index\\ncolumn family database, 666\\ncolumn-oriented databases, \\n665–667\\n“commandments,” for distributed \\ndatabases, 583\\ncommands (listed by name)\\nALTER TABLE command, 247, \\n283,  283–284\\nCHECK command, 247CLOSE command, 407COMMIT command, 248, 266CREATE INDEX command, 247CREATE SCHEMA \\nAUTHORIZATION command, 247, 251–252\\nCREATE TABLE AS command, \\n247\\nCREATE TABLE command, \\n247, 255\\nCREATE VIEW command,  \\n247, 378\\nDEFAULT command, 247DELETE command, 248, 269DROP INDEX command, 247, \\n264\\nDROP SEQUENCE command, \\n387\\nDROP TABLE command, 247, \\n290\\nDROP VIEW command, 247FETCH command, 407FOREIGN KEY command, 247INSERT command, 248, 264,  \\n270–271\\nNOT NULL command, 247OPEN command, 407PRIMARY KEY command, 247ROLLBACK command, 248, 269SELECT command, 248, 266UNIQUE command, 247UPDATE command, 248, 268\\nCOMMIT command, 248, 266, 488Common Gateway Interface (CGI), \\n695\\ncommunications media, 560community cloud, 712comparison operators\\non character attributes, 273–274on dates, 274symbols, 273\\ncompleteness constraint, 175, \\n175–176\\ncompliance, 745\\ncomposite attributes, 120, 121composite entity, 98, 138–140composite identifiers, 119–120, 120composite key, 77composite primary keys, 178–180computer-aided software \\nengineering (CASE), 445, 752, \\n752–755\\ncomputerized file systems, 15–17computer workstations, 560conceptual design\\ndata analysis and requirements, \\n459–461\\ndata model verification, 464–467definition, 457description, 457–458distributed database design, 467entity relationship modeling and \\nnormalization, 461–464\\nsteps, 458\\nconceptual model\\nadvantages, 61–62definition, 61\\nconceptual schema, 61concurrency control\\nin DDBMS, 559definition, 490\\ndistributed, 571inconsistent retrievals, 492,  \\n492–493\\nlost update, 490,  490–491\\noptimistic approach, 503,  \\n503–504\\nscheduler, 493–495, 494time stamping, 502,  502–503\\nuncommitted data, 491,   \\n491–492\\nconcurrent backup, 737conditional criteria, 533–534conditional expression, 533–534confidentiality, 745\\nconnectivity, 46, 125, 125–126\\nconsistency, 487, 581\\nconsistency, availability, partition \\ntolerance (CAP) theorem, 581–582\\nconsistent database state, 484constraints\\ncompleteness, 175,  175–176\\ndefinition, 38\\ndisjoint, 174–175integrity, 470–471overlapping, 174–175SQL, 259–262\\nconversion functions, 368–370CONVERT function, 362, 370coordinator, 572\\ncorporate database, 726corrective maintenance, 445correlated subquery, 358,  \\n358–361\\ncost-based optimizer, 528–529COUNT function, 293, 293–295CPU. See central processing unit\\nCREATE SCHEMA \\nAUTHORIZATION command, 247, 251–252\\nCREATE TABLE AS command, 247CREATE TABLE command, 247, \\n255\\ndefinition, 247, 255MySQL, 257Oracle, 258–259\\nCREATE VIEW command, 247, \\n378\\ncross join, 342Crow’s Foot notation\\nassociative entity, 139cardinalities, 125definition, 46\\nderived attributes, 123mandatory participation, 131multivalued attributes, 121–122strong relationship, 128symbols, 132weak entities, 129–130weak relationship, 127\\ncube cache, 628cursor\\nattributes, 408commands, 407definition, 407\\nexplicit, 407\\nimplicit, 407\\nPL/SQL processing with, 407–409\\nD\\nDA. See data administrator\\nDAO. See data access objects\\ndashboards, 594\\ndata\\nanalysis, need for, 590cache, 519,  536\\nas corporate asset, 723–724cube, 628\\ndatabase system component, 24definition, 4, 15\\ndependence, 19\\nderived, 231dirty, 724\\ndistribution, 574encryption, 454file, 518,  760\\ngrouping, 297–300inconsistency, 7\\nindependence, 19\\nversus  information, 4–6\\nintegrity, 20\\nlogical view of, 73–76management, 6\\nmetadata, 6modeling, 36\\nnode, 52\\nnodes, 657preaggregated, 231quality, 8, 724\\nredundant, 231sparse, 55\\nsparsity, 527\\nstructured, 653\\nuncommitted, 491,  491–492\\nunstructured, 653\\nvisualization, 596,  596–597\\ndata abstraction\\nANSI Standards, 59conceptual model, 61,  61–62\\ndescription of, 57, 59external model, 60,  60–61\\ninternal model, 62,  62–63\\nlevels, 63physical model, 63\\ndata access objects (DAO), 683, \\n683–685\\nDataAdapter object, 690data administrator (DA)\\nversus  database administrators, \\n731–732\\ndefinition, 730\\ndata allocation\\nalgorithms, 581centralized, 580definition, 580\\npartitioned, 580\\nreplicated, 580\\ndata analytics\\ndata mining, 671,  671–673\\ndefinition, 670\\nexplanatory analytics, 670,  \\n670–671\\npredictive analytics, 670,  \\n673–674\\ndata anomaly\\ndefinition, 21\\ndeletion, 21insertion, 21update, 21\\ndatabase(s)\\nadministrator, 29analyst, 29architect, 29Big Data, 29consultant, 29corporate, 726\\ndefinition, 6\\ndescription, 2designer, 23, 29developer, 29development, 441\\ndump, 455,  737\\nenterprise, 726\\nversus  file systems, 22\\nfine-tuning, 454–455fragment, 467,  557\\nin-memory, 30instance, 760\\nintroduction to, 6–11middleware, 681\\nneed for, 724–726performance tuning, 516,  \\n516–517\\npervasive nature of, 3professional careers, preparing \\nfor, 28–30\\nrequest, 484\\nreasons for using, 3–4recovery, 505\\nrole, 472\\nrole in organization,  \\n724–726\\nsecurity officer, 29sources of failure, 456spreadsheets and, comparison \\nof, 27\\ntypes of, 8–11XML, 709\\ndatabase administration\\nevolution of, 727–730human component, 731–745Oracle for, 757–765strategy, developing, 755–756tools, 749–755\\ndatabase administrators (DBAs), 23, \\n518–519\\nactivities of, 732CASE tools, 752–755in cloud computing,  \\n756–757\\nversus  data administrators, \\n731–732\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98bfd7dc-43ed-4629-a02b-d3453bb9585e', embedding=None, metadata={'page_label': '785', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Index    785\\ndata backup and recovery, \\n736–737\\nin Database Life Cycle, 729\\ndata dictionary, 750–752data distribution and use, 738data security, privacy, and \\nintegrity, 736\\nDBMS technology, 728–729, \\n738–745\\ndefinition, 728\\nend-user support, 734functional organization, 730managerial role of, 733–738policies, procedures, and \\nstandards, 734–736\\ntechnical role of, 738–745training and supporting users, \\n744\\ndatabase connectivity. See also \\nInternet; network\\nbroad layers, 681definition, 681fundamentals of, 681interfaces, 682–692native, 682–683\\ndatabase design\\nbottom-up design, 473,  473–474\\ncentralized design, 474,  \\n 474–476\\nconflicting goals, 147–152decentralized design, 474,  \\n474–476\\ndefinition, 11\\ndistributed, 467importance of, 11–14improvements in normalization, \\n215–219\\npoor and good design, 12–13strategies, 473–474top-down design, 473,  473–474\\ndatabase design cases\\nfan trap, 186,  186–187\\nimplementing 1:1 relationships, \\n182–183\\nredundant relationships, \\n187–188\\ntime-variant data, 183,  183–186\\ndatabase design challenges\\ndesign standards, 148information requirements, \\n149–150\\nprocessing speed, 148–149\\ndatabase-level lock, 497Database Life Cycle (DBLC)\\nanalysis, 446–447definition, 445\\nimplementation and loading, \\n451–454\\ninitial study, 445–450maintenance and evolution, 457objectives, 449operational phase, 456–457problems and constraints, \\n447–449\\nprocedures, 450–451scope and boundaries, 449,  \\n449–450, 450\\ntesting and evaluation, 454–456database management system \\n(DBMS)\\naccess languages and application \\nprogramming interfaces, 27\\nadvantages of, 6–8architecture, 518–520backup and recovery \\nmanagement, 27\\ncommunication interfaces, 27cultural impact of, 727database security, 749definition, 6\\ndictionary management, 24–25end user and database \\ninteraction, 7\\nfunctions of, 24–27integrity management, 27management levels, 725–726managerial aspect of, 727multiuser access control, 26–27performance tuning, 517,  517–\\n518, 536–538\\nrole of, 6–8security management, 26software selection, 467storage management, 25technological aspect of, 726transformation and \\npresentation, 26\\ndatabase security\\nin DBMS, 749definition, 748\\nuser access management, \\n748–749\\nview definition, 749\\ndatabase security officer (DSO), 736database statistics\\ndefinition, 521\\ndescription, 521–522measurements, 521\\ndatabase systems\\ncomponents, 22–24definition, 22\\ndescription of, 21–22environment, 22–24management of, 28\\ndatabase table(s)\\njoining, 300–304linking table, 99\\ndata definition language (DDL), \\n42, 247\\ndata dictionary\\nactive, 750\\nin database administrators, \\n750–752\\ndefinition, 25, 91\\npassive, 750\\nsample, 92system analog, 91–93\\ndata fragmentation\\ndefinition, 575\\nhorizontal fragmentation, 575,  \\n576\\nmixed fragmentation, 575,  \\n577–578\\nstrategies, 575–578vertical fragmentation, 575,  \\n576–577data manager (DM), 560data manipulation language (DML), \\n42, 247\\ndata mart, 610data mining\\ndata analysis and classification \\nphase, 672–673\\ndata preparation phase, 672–673definition, 671\\nknowledge acquisition phase, \\n672–673\\nmodes of, 673prognosis phase, 672–673\\ndata model(s)\\nadvantages and disadvantages, \\n58\\nbasic building blocks, 37–38Big Data, 50–53definition, 36\\nentity relationship model, 45–48evolution of, 41–57hierarchical model, 41implementation-ready, 36importance of, 37key-value, 54\\nnetwork model, 41,  41–42\\nNoSQL, 53–56object-oriented model, 48–49object/relational database \\nmanagement system, 49–50\\nrelational model, 43,  43–45\\nterminology comparison, 59\\ndata-modeling checklist, 232–233data processing (DP) specialist\\nin computerized file system, \\n15–17\\ndefinition, 15\\ndata processor (DP), 560data-profiling software, 724DataReader object, 690data redundancy\\ndefinition, 20\\nrevisited, 101–103\\ndata replication, 574\\ndefinition, 578\\ninfluencing factors, 580mutual consistency rule, 578push and pull replication, \\n578–579\\nscenarios, 580\\nDataSets, 688, 690\\ndata source name (DSN), 683DataTable object, 690data types\\ncharacter, 254columns, 284date, 254numeric, 254SQL, 252–255\\ndata warehouse\\ncomponents, 607–608data mart, 610definition, 9, 607\\nintegrated, 607–609nonvolatile, 608–609versus  operational database data, \\n609\\nsubject-oriented, 608–609time-variant, 608–609twelve rules, 610–611\\ndate\\ncomparison operators, 274data types, 254in Microsoft Access, 362–363in MySQL, 365in Oracle, 363–364\\nDATEADD function, 363DATE_ADD function, 365Date, C. J., 583DATE data type, 392DATEDIFF function, 363Date_format function, 365DATE function, 362DAY function, 362, 365DBA. See database administrator\\nDBLC. See Database Life Cycle\\nDBMS. See database management \\nsystem\\nDDBMSs. See distributed database \\nmanagement systems\\nDDC. See distributed data catalog\\nDDD. See distributed data \\ndictionary\\nDDL. See data definition language\\ndeadlock\\navoidance, 502definition, 500\\ndescription, 500–501detection, 502prevention, 502\\ndeadly embrace, 501decentralized design, 474, 474–476decision support data\\ndatabase schema, 605–606database size, 607data extraction and filtering, 607operational data versus,   \\n602–605\\ndecision support system (DSS), 598DECODE function, 370DEFAULT command, 247deferred update method, 508deferred-write technique, 507DELETE command, 248, 269deletion anomalies, 21denormalization\\ndefinition, 202\\ndescription, 229–232examples, 231\\ndependency diagram\\ndefinition, 210\\nfirst normal form, 210–211\\ndependent attribute, 76derived attributes\\nadvantages and disadvantages, \\n124\\ndefinition, 123\\ndepiction, 124\\nderived data, 231description of operations, 460design trap, 186desktop databases, 8determinant, 76, 213\\ndetermination, 76\\nDIFFERENCE operator, 85, 85–86differential backup, 455\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f7db7d29-7b12-4684-b70a-ce16348e5eb8', embedding=None, metadata={'page_label': '786', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='786   Index\\ndimensional tables, normalizing, \\n618–619\\ndirty data, 724\\ndirty read, 504disaster management, 736discipline-specific databases, 9discriminator attributes, 175disjoint subtypes, 174, 174–175diskblock, 497diskless workstations, 454diskpage, 497\\nDISTINCT clause, 292distributed concurrency control, \\n571\\ndistributed data access, 555distributed database design\\ndata allocation, 580–581data fragmentation, 575–578data replication, 578–580\\ndistributed database management \\nsystems (DDBMSs)\\nadvantages and disadvantages, \\n556–557\\ncentralized database \\nmanagement, 554, 556\\ncharacteristics, 559–560“commandments,” 583components, 560–561database requirements, 555data levels and process \\ndistribution, 561–564\\ndefinition, 554\\ndistributed database, 556,  \\n556–558\\ndistributed processing, 556,  \\n556–558\\nevolution of, 554–556factors, 555fully heterogeneous, 563heterogeneous, 563\\nhomogeneous, 563\\ntransparency features, 564–575\\ndistributed databases, 8distributed data catalog (DDC), 567distributed data dictionary (DDD), \\n567\\ndistributed global schema, 567distributed request, 570, 570–571distributed transaction, 569, \\n569–570\\ndistribution transparency\\ndefinition, 564\\nfeatures, 565–567levels of, 565\\nDIVIDE operator, 90, 90–91DKNF. See domain-key normal \\nform\\nDLLs. See dynamic-link libraries\\nDM. See data manager\\nDML. See data manipulation \\nlanguage\\ndocument databases, 664, 664–665document type definition (DTD), \\n704, 704–706\\ndomain-key normal form (DKNF), \\n207\\ndomains, 119DO-UNDO-REDO protocol, 572DP. See data processor\\ndrill down, 602DROP INDEX command, 247, 264DROP SEQUENCE command, 387DROP TABLE command, 247, 290DROP VIEW command, 247DSN. See data source name\\nDSO. See database security officer\\nDSS. See decision support system\\nDTD. See document type definition\\ndurability, 487\\ndynamic-link libraries (DLLs), 683dynamic query optimization, 520dynamic SQL, 414dynamic statistical generation \\nmode, 521\\nE\\necho function, 701edge, 668\\nEERD. See extended entity \\nrelationship diagram\\nEERM. See extended entity \\nrelationship model\\nembedded SQL, 410–414end users\\nin database administrator, 734description, 24external model, 60online analytical processing, 623SQL-based relational database \\napplication, 45\\nenhanced entity relationship \\nmodel. See extended entity \\nrelationship model (EERM)\\nenterprise databases, 8, 726\\nentity\\nassociative, 98, 138–140\\nbridge, 98\\nclustering, 176,  176–177\\ncomposite, 98, 138–140\\ndefinition, 37\\ndescription, 118existence-dependent, 126\\nexistence-independent, 126\\ninstance, 46, 118\\nintegrity, 78, 177–181\\noccurrence, 46, 118\\nregular, 126\\nset, 46\\nstrong, 126\\nsubtypes, 170–171, 171supertypes, 170–171, 171weak, 129–131\\nentity relationship diagrams (ERDs)\\ndescription, 46\\niterative process, 140–147overview of, 118\\nentity relationship model (ERM)\\nassociative entities, 138–140attributes, 118–124cardinality, 125–126components, 46conceptual design, 461–464connectivity, 125–126definition, 46entities, 118existence dependence, 126notations, 46–48recursive relationship, 136–138relationship, 124–125relationship degree, 134–136relationship participation, \\n131–134\\nrelationship strength, 126–129weak entities, 129–131\\nequijoin, 89\\nERDs. See entity relationship \\ndiagrams\\nERM. See entity relationship model\\nETL. See extraction, transformation, \\nand loading\\neventual consistency, 55EXCEPT operator, 375–376exclusive lock, 499, 499–500existence-dependent entity, 126existence-independent entity, 126EXISTS special operator, 279, 283explanatory analytics, 670,  \\n670–671\\nextended entity relationship \\ndiagram (EERD), 170\\nextended entity relationship model \\n(EERM)\\ncompleteness constraint, 175,  \\n175–176\\ndefinition, 170\\ndisjoint subtypes, 174,  174–175\\nentity subtypes, 170–171, 171entity supertypes, 170–171, 171generalization, 176\\ninheritance, 172,  172–173\\nnonoverlapping subtypes, 174overlapping subtypes, 174,  \\n174–175\\nspecialization, 176\\nspecialization hierarchy, 171,  \\n171–172\\nsubtype discriminator, 174\\nextended relational data model \\n(ERDM), 49–50\\nExtensible Markup Language \\n(XML)\\napplications, 708–709characteristics, 703data models, 50definition, 10, 702\\ndocument type definition, 704,  \\n704–706\\nfeatures, 703–704presentation, 706–708schema, 705\\nExtensible Style Language \\nTransformations (XSLT), 706–707\\nextensions\\nclient-side, 697,  697–698\\nserver-side, 693\\nextents, 519\\nexternal model\\nadvantages, 61definition, 60\\nentity relationships, 60–61\\nexternal schema, 60extraction, transformation, and \\nloading (ETL), 593, 609F\\nFacebook, 10fact tables\\naggregation levels, 619denormalizing, 619–620multiple, 619–620periodicity, 621\\nfailure transparency, 565, 573–575fan trap, 186, 186–187feedback loop processing, 653FETCH command, 407field, 15field-level lock, 498fifth normal form (5NF), 207file\\nbasic terminology, 15definition, 15group, 519\\nfile systems\\ncomputerized, 15–17versus  databases, 22\\ndata processing, evolution of, \\n14–17\\nmanual, 14modern end-user productivity \\ntools and, 17–18\\nproblems with, 18–19simple, 17\\nfirst normal form (1NF)\\ncharacteristics, 207conversion to, 208–211definition, 211\\ndependencies, 209–210dependency diagram, 210–211primary key, 208–209repeating groups, 208\\nflags, 81\\nFLOOR function, 366Flume, Hadoop ecosystem, 661foreign key(s)\\n1:1 relationships, 183creating links through, 301definition, 79\\ndesignations, adding, 289\\nFOREIGN KEY command, 247fourth normal form (4NF)\\ncharacteristics, 207definition, 226\\ndescription, 224–226\\nfragmentation transparency\\ndatabase supports, 566definition, 565\\nFROM clause\\nconditional restrictions, 271–276definition, 267\\nFROM subqueries, 355–356front-end CASE tools, 752full backup, 455, 737\\nfull functional dependence, 77fully heterogeneous distributed \\ndatabase management systems, 563\\nfully replicated database, 580function(s)\\naggregate, 292–297conversion, 368–370date, 361–365numeric, 366\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a823cf34-4ecd-427b-bbc0-9900046f094a', embedding=None, metadata={'page_label': '787', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Index    787\\nSQL, 292–297, 361–370\\nstring, 366–368time, 361–365\\nfunctional dependence, 76,  \\n207–208\\nfunction-based index, 532functions (listed by name)\\nABS function, 366ADDDATE function, 365ADD_MONTHS function, 364AVG function, 296,  296–297\\nCAST function, 369, 370CEIL function, 366CEILING function, 366CONVERT function, 362, 370COUNT function, 293,  293–295\\nDATEADD function, 363DATE_ADD function, 365DATEDIFF function, 363Date_format function, 365DATE function, 362DAY function, 362, 365DECODE function, 370echo function, 701FLOOR function, 366LAST_DAY function, 364, 365LENGTH function, 368MAX function, 295,  295–296\\nMIN function, 295,  295–296\\nMONTH function, 362, 365odbc_close function, 701odbc_connect function, 701odbc_exec function, 701odbc_result function, 701ROUND function, 366SUBSTRING function, 368SUM function, 296SWITCH function, 370SYSDATE function, 364TO_CHAR function, 363, 369TO_DATE function, 364TO_NUMBER function, 370while function, 701YEAR function, 362, 365\\nG\\ngeneralization, 176\\ngeneral-purpose databases, 9Google, 4, 10governance, 595\\ngranularity, 216, 216–217\\nlock, 496,  496–498\\ngraph database\\ncomponents of, 668definition, 668\\nedge, 668\\nnode, 668\\nproperties, 668\\nrepresentation, 669traversal, 668\\nGROUP BY clause, 248, 297, \\n297–300\\nguided data mining, 673\\nH\\nHadoop\\ndata ingestion applications, 661definition, 52direct query applications, 661–662ecosystem, 660–662MapReduce, 658,  658–660\\nHadoop Distributed File System \\n(HDFS), 52, 655, 655–657\\nhardware\\ndatabase system component, 22independence, 62\\nperformance, 517query processing, 525in SDLC, 443\\nhash index, 527HAVING clause, 299, 299–300\\nconditional expression, 533\\nHAVING subqueries, 353HBase, column-oriented NoSQL \\ndatabase, 661\\nHDFS. See Hadoop Distributed File \\nSystem\\nheartbeat, 657\\nheterogeneity transparency, 565heterogeneous distributed database \\nmanagement systems, 563\\nhierarchical model, 41higher-order relationship, 135Hive, data warehousing system, 660homogeneous distributed database \\nmanagement systems, 563\\nhomonyms, 91\\nhorizontal fragmentation, 575, 576host language, 410\\nI\\nIaaS. See Infrastructure as a  \\nService\\nidentifiers\\ncomposite, 119–120definition, 119\\nnatural, 178\\nrelational schema, 119\\nidentifying relationship, 128IE. See information engineering\\nImpala, SQL-on-Hadoop \\napplication, 662\\ninconsistent retrievals, 492, 492–493incremental backup, 737index(es)\\nbitmap, 527\\nB-tree, 527\\nCREATE INDEX command, \\n263,  263–264\\ndefinition, 103\\nfunction-based, 532\\nhash, 527\\nquery optimization and, \\n526–528\\nrelational database, 103–104selectivity, 531–532, 532SQL, 263–264table space, 537unique, 104\\nindex-organized table (IOT), 538information\\nversus  data, 4–6\\ndefinition, 4\\nislands of, 20\\ninformation age, 5information engineering (IE), 755information resource dictionary, \\n751\\ninformation resource manager \\n(IRM), 730\\ninformation system (IS)\\ndefinition of, 440department, 727\\nperformance of, 440–441\\ninformation systems architecture \\n(ISA), 755\\nInfrastructure as a Service (IaaS), \\n713–714\\ninheritance, 48, 172, 172–173\\ninline subquery, 356in-memory databases, 30, 536Inmon, Bill, 610inner join, 89, 341\\ninner query, 270input/output (I/O) accelerators, 536input/output (I/O) request, 519INSERT command, 248, 264, \\n270–271\\ninsertion anomalies, 21IN special operator, 279, 282IN subqueries, 352–353integrated data warehouse, 607–609integrity\\ndata, 736entity, 78, 177–181\\nreferential, 79\\nrules, 80–81in security, 745–746\\ninternal model\\ndefinition, 62\\ndescription, 62–63\\ninternal schema, 62Internet database connectivity\\nbenefits, 693characteristics, 693client-side extensions, 697,  \\n697–698\\ndescription, 692web application server, 698web browser, 696–697web database development, \\n699–702\\nweb server interfaces, 695–696web-to-database middleware, \\n693–695, 694\\nINTERSECT operator, 85,  \\n373–375\\nIOT. See index-organized table\\nIRM. See information resource \\nmanager\\nIS. See information system\\nISA. See information systems \\narchitecture\\nIS NULL special operator, 279, 280isolation, 487\\nJ\\nJava, 691\\nJava Database Connectivity (JDBC)\\narchitecture, 691–692definition, 691\\nJavaScript, 697\\nJavaScript Object Notation (JSON), \\n664JDBC. See Java Database \\nConnectivity\\njob tracker, 659join(s)\\ncolumns, 87\\ncross, 342\\nequijoin, 89\\ninner, 89, 341\\nleft outer, 89natural, 87, 343,  343–344\\noperators, 341–349outer, 89, 341,  347–349\\nright outer, 89theta, 89\\nJOIN ON clause, 345–346JOIN operator, 87, 87–90JOIN USING clause, 344–345JSON. See JavaScript Object \\nNotation\\nK\\nKelley, Chuck, 610key(s). See also foreign keys; \\nprimary keys\\nattribute, 77\\ncandidate, 78\\ncomposite, 77\\ndefinition, 76\\ndependencies, 76–77foreign, 79\\nnatural, 178\\nprimary, 76\\nrelational database, 77–80secondary, 79\\nsuper, 77\\nsurrogate, 180–181, 181types of, 77–80\\nkey performance indicators (KPIs), \\n595\\nkey-value (KV) databases, 663, \\n663–664\\nkey-value data model, 54knowledge\\ncharacteristics, 5in data mining, 671explanation, 5\\nKPIs. See key performance \\nindicators\\nL\\nlanguage, host, 410LAST_DAY function, 364, 365left outer join, 89LENGTH function, 368LIKE special operator, 279,  \\n280–282\\nLinkedIn, 10linking table, 99listener, 519listing\\nordering, 290–292unique values, 292\\nlocal mapping transparency\\ndatabase supports, 567definition, 565\\nlocation transparency\\ndatabase supports, 566–567definition, 565\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='314cf4d5-96ef-45c8-90f8-ce293d8018e4', embedding=None, metadata={'page_label': '788', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='788   Index\\nlock(s)\\nbinary, 498,  498–499\\ndatabase-level, 496\\ndeadlock, 500\\ndefinition, 495\\nexclusive, 499,  499–500\\nfield-level, 498\\ngranularity, 496,  496–498\\nmanager, 495,  520\\npage-level, 497\\npessimistic, 495\\nrow-level, 498\\nshared, 499\\ntable-level, 496\\ntwo-phase locking, 500,  500–501\\ntypes of, 498–500\\nlogical data format, 19\\nlogical design, 62\\ndefinition, 468\\nmapping conceptual model to, \\n468–470\\nsteps, 468against user requirements, 471using integrity constraints, \\n470–471\\nusing normalization, 470\\nlogical independence, 63logical operators, 277–279logic, predicate, 73logs, transaction, 489, 489–490lost update, 490, 490–491\\nM\\nmandatory participation, 131, \\n131–134\\nmanual file systems, 14manual query optimization, 520manual statistical generation mode, \\n521\\nmany-to-many (M:N) relationship, \\n38, 97–100\\nmap function, 658mapper, 658\\nMapReduce, 53\\nbatch processing, 660conceptual illustration, 658definition of, 658general process, 659implementation of, 659simplification applications, \\n660–661\\nmaster data management (MDM), \\n595, 724\\nmaterialized view, 633, 633–636MAX function, 295, 295–296MDBMSs. See multidimensional \\ndatabase management systems\\nMDM. See master data \\nmanagement\\nmetadata, 6\\nMicrosoft Access\\nCOMMIT command, 266COUNT function, 294–295CREATE VIEW command, 378database creation, 251date functions, 362–363query by example, 271–272relational model, 74ROLLBACK command, 269sequences, 382–387time functions, 362–363\\nMicrosoft Azure, 8Microsoft Excel, 17Microsoft .NET framework, 687Microsoft SQL Server\\ndate functions, 362–363persistent stored module, 388query optimization, 545sequences, 382–387time functions, 362–363trigger, 394\\nmiddleware, web-to-database, \\n693–695\\nMIN function, 295, 295–296minimal data rule, 458mixed fragmentation, 575, 577–578M:N relationship. See many-to-\\nmany (M:N) relationship\\nmobile wireless revolution, 555model, 36\\nmodule\\ncoupling, 466\\ndefinition, 464\\nmonotonicity, 502\\nMONTH function, 362, 365MPMD. See multiple-site \\nprocessing, multiple-site data\\nMPSD. See multiple-site processing, \\nsingle-site data\\nmultidimensional database \\nmanagement systems (MDBMSs), 628\\nmultidimensional online analytical \\nprocessing (MOLAP)\\ndefinition, 628\\nrelational OLAP versus,  628–629\\nmultiple-site processing, multiple-\\nsite data (MPMD), 563, 563–564\\nmultiple-site processing, single-site \\ndata (MPSD), 562, 562–563\\nmultiuser databases, 8multivalued attributes\\nin an entity, 121components, 123definition, 121\\nimplementing, 122\\nmutual consistency rule, 578mutual exclusive rule, 499MySQL\\nCOMMIT command, 266CREATE TABLE command, 257date functions, 365DEFAULT/CHECK constraints, \\n261\\nDELETE command, 270query optimization, 545time functions, 365Twitter and, 10UPDATE command, 270\\nN\\nname node, 52, 657naming conventions, 41, 216, 233National Institute of Standards and \\nTechnology (NIST), 709native database connectivity, \\n682–683\\nnatural identifier, 178natural join, 87, 343, 343–344\\nnatural keys, 178nested query, 270network(s)\\ncomponents, 560latency, 574\\npartitioning, 574\\nperformance, 517query processing, 525\\nnetwork model, 41, 41–42NewSQL databases, 669, 669–670NIST. See National Institute of \\nStandards and Technology\\nnode\\navailability, 574client, 657data, 657definition, 668\\nin HDFS, 656–657name, 657\\nnon-identifying relationship, 127nonkey attribute, 202nonoverlapping subtypes, 174nonprime attribute, 202nonrepeatable read, 504nonvolatile data warehouse, \\n608–609\\nnormalization\\nconceptual design, 461–464database design, 215–219, \\n226–229\\ndata-modeling checklist, \\n232–233\\ndefinition, 202\\nfunctional dependencies, \\n207–208\\nhigher-level normal forms, \\n220–226\\nlogical design, 470need for, 202–206normal forms, 202process of, 206–215surrogate keys, 219–220\\nNoSQL. See Not only SQL\\nNOT logical operator, 278,  \\n278–279\\nNOT NULL command, 247Not only SQL (NoSQL)\\nin Big Data, 53column-oriented databases, \\n665–667\\ndata models in, 53–56definition, 662description, 11\\ndocument databases, 664,  \\n664–665\\ngraph database, 668,  668–669\\nkey-value databases, 663,  \\n663–664\\nNewSQL databases, 669,  \\n669–670\\nnull values\\nconditional expression, 533definition, 78\\nNUMBER data type, 392numeric data types, 254numeric functions, 366\\nO\\nObject Linking and Embedding for \\nDatabase (OLE-DB)\\narchitecture, 688classes and interfaces, 687consumers, 685data providers, 686definition, 685\\nservice providers, 686\\nobject-oriented database \\nmanagement system (OODBMS), 48\\nobject-oriented data model \\n(OODM), 48–49\\nobject/relational database \\nmanagement system (O/R DBMS), 50\\nODBC. See Open Database \\nConnectivity\\nodbc_close function, 701odbc_connect function, 701odbc_exec function, 701odbc_result function, 701OLE-DB. See Object Linking and \\nEmbedding for Database\\none-to-many (1:M) relationship, \\n38, 93–95\\none-to-one (1:1) relationship\\ndefinition, 38\\nERM components, 146foreign key in, 183implementing, 182–183recursive relationship, 136, 151relational database, 95–97specialization hierarchy, 172\\nonline analytical processing (OLAP)\\nadvanced database support, 623architecture, 623–626characteristics, 621CUBE extension, 631–632definition, 9, 621\\nend-user interfaces, 623materialized view, 633,   \\n633–636\\nmultidimensional, 628,  628–629\\nmultidimensional data analysis \\ntechniques, 621–623\\nrelational, 626,  626–627\\nrelational versus  \\nmultidimensional, 628–629\\nROLLUP extension, 630–631SQL extensions, 629–636\\nonline transaction processing \\n(OLTP) database, 9\\nOODBMS. See object-oriented \\ndatabase management system\\nOODM. See object-oriented data \\nmodel\\nOPEN command, 407Open Database Connectivity \\n(ODBC)\\nto access database, 684configuring Oracle data source, \\n685\\ndefinition, 683\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3074335c-a5e4-42b7-9f56-03282d7831f4', embedding=None, metadata={'page_label': '789', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Index    789\\noperand, 533\\noperational cost, 443operational data\\ndata warehouse data versus,  609\\ndecision support data versus,  \\n602–605\\noperational database, 9operator(s)\\narithmetic, 276–277comparison, 273–274logical, 277–279special, 279–283\\noptimistic method, concurrency \\ncontrol, 503, 503–504\\noptimizer\\ncost-based, 528–529\\ndatabase statistics, 529–530in DBMS, 520, 536hints, 530,  530–531\\nobjective, 529rule-based, 528\\noptional attributes, 119optional participation, 131Oracle\\nCREATE TABLE command, \\n258–259\\ndatabase administration tools, \\n757–765\\ndate functions, 363–364ODBC data source, 685query optimization, 544sequences, 382–387time functions, 363–364trigger, 394\\nO/R DBMS. See object/relational \\ndatabase management system\\nORDER BY clause, 248, 290, \\n290–292\\norganizational rigidity, 556OR logical operator, 277outer join, 89, 341, 347–349\\noverlapping subtypes, 174,  \\n174–175\\nP\\nPaaS. See Platform as a Service\\npage. See diskpage\\npage-level lock, 497partial completeness, 175partial dependency, 208partially replicated database, 580participants, 124\\nparticipation\\nmandatory, 131\\noptional, 131\\nrelationship, 131–134\\npartitioned data allocation, 580partitioning, 620\\npartition tolerance, 581passive data dictionary, 750passwords, 454people, database system component, \\n23–24\\nperfective maintenance, 445performance\\ndegradation, 556system, guidelines, 517transparency, 565,  573–575performance tuning\\ndatabase, 516,  516–517\\nDBMS, 517, 517–518, 536–538\\ndefinition, 25\\nSQL, 517, 517–518, 531–534\\nperiodicity, 621\\npersistent stored module (PSM), \\n388\\npessimistic locking, 495phantom read, 504physical data format, 19physical design\\ndata storage organization, 472definition, 471\\nintegrity and security measures, \\n472–473\\nperformance measurements, 473stages, 471\\nphysical independence, 63physical model, 63Pig, high-level scripting language, \\n661\\nPKs. See primary keys\\nPlatform as a Service (PaaS), 713plug-in, 697\\npolicy\\nin DBAs, 734security, 746\\nportals, 594\\npreaggregated data, 231predicate logic, 73predictive analytics, 670, 673–674PRIMARY KEY command, 247primary keys (PKs). See also \\nidentifiers; keys\\ncharacteristics, 179composite, 178–180data granularity, 216–217definition, 76\\ndesignations, adding, 289entity integrity, 177–178first normal form, 208–209guidelines, 178natural keys and, 178surrogate, 180–181, 181\\nprime attribute, 202privacy, 725\\nprivate cloud, 712Procedural Language SQL (PL/\\nSQL)\\ndata types, 392definition, 388\\ndescription of, 387–391processing with cursors, \\n407–409\\nstored functions, 409stored procedure, 401,  401–406\\ntriggers, 392–401, 393\\nprocedure\\ncache, 519\\ndata administration strategy, 735database system component, 24\\nproduction database, 9profile, 762\\nPROJECT operator, 83, 83–84PROJECT table, 212PSM. See persistent stored module\\npublic cloud, 712pull replication, 579push replication, 578\\nQ\\nquery\\nad hoc, 7definition, 7\\nformulation, 534–535inner, 270\\nlanguage, 27\\nnested, 270\\noptimizer, 523\\nrecursive, 303\\nresult set, 7subquery, 270\\nquery optimization\\nalgorithms, 520automatic, 520\\nin DDBMS, 559dynamic, 520\\nexamples, 538–545indexes and, 526–528manual, 520\\noperation modes, 520principles, 520static, 520\\ntechniques, 520–521\\nquery processing\\nbottleneck, 525,  525–526\\nDBMS process, 522I/O operations, 524SQL execution phase, 524SQL fetching phase, 525SQL parsing phase, 523–524\\nR\\nRAD. See Rapid Application \\nDevelopment\\nRAID. See redundant array of \\nindependent disks\\nRAM. See random access memory\\nrandom access memory (RAM)\\nperformance, 517query processing, 525\\nrapid ad hoc data access, 555Rapid Application Development \\n(RAD), 441\\nRDBMS. See relational database \\nmanagement system\\nRDO. See remote data objects\\nRead Committed isolation level, 504Read Uncommitted isolation level, \\n504\\nrecord, 15recursive joins, 303–304recursive query, 303recursive relationship, 136–138reduce function, 658reducer, 658\\nredundant array of independent \\ndisks (RAID), 537\\nredundant data, 231redundant transaction logs, 506referential constraint actions, \\n261–262\\nreferential integrity, 79regular entity, 126relation, 43relational algebra\\ndefinition, 82\\nformal definitions, 82operators, 83–91terminology, 82\\nrelational database\\nCodd rules, 104–105data redundancy revisited, \\n101–103\\nindexes, 103–104many-to-many (M:N) \\nrelationship, 97–100\\none-to-many (1:M) relationship, \\n93–95\\none-to-one (1:1) relationship, \\n95–97\\nrelational database management \\nsystem (RDBMS)\\ndefinition, 43\\nmultidimensional data schema \\nsupport, 626\\nSQL usage, 44\\nrelational diagram, 44, 483relational model\\ncharacteristics, 74definition, 43\\ndescription of, 43–44, 73–76end-user perspectives, 45Microsoft Access in, 74relational diagram, 44–45\\nrelational online analytical \\nprocessing (ROLAP)\\ndata access language, 626–627definition, 626\\nmultidimensional data schema \\nsupport, 626\\nmultidimensional OLAP versus,  \\n628–629\\nquery performance optimized \\nfor, 626–627\\nvery large databases, 627\\nrelational schema, 119relational set operators\\nDIFFERENCE operator, 85,  \\n85–86\\nDIVIDE operator, 90,  90–91\\nEXCEPT operator, 375–376INTERSECT operator, 85,  \\n373–375\\nJOIN operator, 87,  87–90\\nPROJECT operator, 83,  83–84\\nRESTRICT operator, 83SELECT operator, 83syntax alternatives, 377UNION operator, 84,  84–85, \\n371–373\\nUNION ALL operator, 373\\nrelational view, 379relationship(s)\\nbinary, 134,  134–135\\ndatabase design case, 187–188definition, 38\\ndegree, 134–136higher-order, 135identifying, 128\\nnon-identifying, 127\\nparticipants, 124\\nparticipation, 131–134\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5ca9df06-ed24-48a0-8b8c-6d8fe758aa7e', embedding=None, metadata={'page_label': '790', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='790   Index\\nrecursive, 136–138\\nstrength, 126–129strong, 128\\nternary, 134,  134–135\\nunary, 134,  134–135\\nweak, 127\\nreliability, 556relvar, 82\\nremote data objects (RDO), 683, \\n683–685\\nremote request, 568remote transaction, 568, 568–569Repeatable Read isolation level, 504repeating group, 208replicated data allocation, 580replication, 620\\nreplica transparency, 574required attributes, 119reserved words, 258RESTRICT operator, 83right outer join, 89roles, 762\\nROLLBACK command, 488, \\n507–508\\nrollback segment table space, 537roll up, 602ROUND function, 366row-centric storage, 665row-level lock, 498rule-based optimizer, 528rule-based query optimization \\nalgorithm, 521\\nrules of precedence, 277\\nS\\nSaaS. See Software as a Service\\nscalability, 556scaling out, 651scaling up, 651scheduler, 493–495, 494, 520schema\\nconceptual, 61\\ndefinition, 42, 251\\nexternal, 60\\ninternal, 62\\nXML, 705\\nscope, 449\\nscript, 687\\nSDLC. See Systems Development \\nLife Cycle\\nsecondary key, 79second normal form (2NF)\\ncharacteristics, 207conversion to, 211–213definition, 212\\ndependent attributes, 212eliminate partial dependencies, \\n211\\nsecurity\\nbreach, 746\\ndatabase, 748,  748–749\\ndefinition, 725\\ngoals, 745–746passwords, 454physical, 454policy, 746\\nthreat, 746\\nvulnerability, 746,  747segment, 41\\nSELECT command\\ndefinition, 248, 266GROUP BY clause, 248, 297,  \\n297–300\\nHAVING clause, 299,   \\n299–300\\njoining database table(s), \\n300–304\\nSELECT operator, 83SELECT queries, 271–283semantic data model, 48semistructured data, 10sequences, 382, 382–387\\nserializability, 487\\nserializable isolation level, 505serializable schedule, 494server-side extension, 693set-oriented commands, 371set theory, 73shards, 669shared lock, 499simple attributes, 121simple file systems, 17single-site processing, single-site \\ndata (SPSD), 561, 561–562\\nsingle-user databases, 8single-valued attributes, 121snowflake schema, 618social media, 10software\\ndatabase system component, \\n22–23\\ndata-profiling, 724\\nindependence, 62\\nMDM, 724\\nperformance, 517in SDLC, 443types of, 22–23\\nSoftware as a Service (SaaS), 713sort cache, 536SPARC. See Standards Planning \\nand Requirements Committee\\nsparse data, 55sparsity, 628\\nspecialization, 176\\nspecialization hierarchy, 171, \\n171–172\\nspecial operators, 279–283spreadsheets, databases and, \\ncomparison of, 27\\nSprint, 4SPSD. See single-site processing, \\nsingle-site data\\nSQL. See Structured Query \\nLanguage\\nSQLCODE variable, 412SQL data services, 716SQLSTATE variable, 412Sqoop, Hadoop ecosystem, 661standards, 734–735\\nStandards Planning and \\nRequirements Committee (SPARC), 59\\nstar schema\\nattribute hierarchy, 614,  614–616\\nattributes, 612–614definition, 610dimensions, 611\\nfacts, 611\\nperformance-improving \\ntechniques, 617–621\\nrepresentation, 616–617\\nstateless system, 697static query optimization, 520static SQL, 414statistically based query \\noptimization algorithm, 520, 520–521\\nstored functions, 409stored procedure, 401, 401–406stream processing, 652string functions, 366–368strong entity, 126strong relationship, 128structural dependence, 19structural independence, 19structured data, 9, 653\\nStructured Query Language (SQL)\\ncache, 519,  536\\nconstraints, 259–262database model, 249–251data definition commands, 247, \\n249–264\\ndata manipulation commands, \\n248, 264–271\\ndata types, 252–255definition, 27\\ndynamic, 414\\nembedded, 410–414functions, 292–297, 361–370indexes, 263–264introduction to, 247–249join operators, 341–349performance tuning, 517,  517–\\n518, 531–534\\nrelational set operators, 371–377schema, 251–252static, 414\\ntable structures, 255–259transaction management, \\n488–489\\nsubject-oriented data warehouse, \\n608–609\\nsubordinates, 572\\nsubqueries\\nFROM, 355–356IN, 352–353ALL multirow operator, 353–355ANY multirow operator, \\n353–355\\nattribute list, 356–358characteristics, 350correlated, 358,  358–361\\ndefinition, 270\\nexamples, 350HAVING, 353inline, 356overview of, 349–351WHERE, 351–352\\nsubschema, 42\\nSUBSTRING function, 368subtype discriminator, 174SUM function, 296super column, 667superkey, 77surrogate keys, 180–181, 181, \\n219–220\\nSWITCH function, 370synonym, 93\\nsyntax alternatives, 377SYSDATE function, 364system administrators, 23system analog\\ndata dictionary and, 91–93definition, 91\\nsystem analysts, 24system cost, 443system performance, guidelines,  \\n517\\nsystem programmers, 24systems administrator, 730systems analysis, 440systems development, 440Systems Development Life Cycle \\n(SDLC)\\nanalysis, 443–444definition, 442\\ndetailed systems design, 444implementation, 444–445maintenance, 445planning, 442–443\\nsystem table space, 537\\nT\\ntable(s)\\nbase, 377\\nclustered, 472\\ncopying parts of, 287–289CREATE TABLE command, 255creating structures, 255–259definition, 43, 73\\ndeleting from database, 290partitioning, 620\\nreplicating, 620\\nSQL, 255–259\\ntable-level lock, 497table row(s)\\nadding, 264–266deleting, 269–270inserting, 270–271listing, 266–268null attributes, 265optional attributes, 265selecting, 271–276updating, 268–269\\ntable space\\ndefinition, 519,  760\\nindex, 537rollback segment, 537system, 537temporary, 537user data, 537\\ntags, 702\\ntask tracker, 659temporary table space, 537ternary relationship, 134, 134–135theta join, 89third normal form (3NF)\\ncharacteristics, 207conversion to, 213–215definition, 214\\ndependent attributes, 213–214transitive dependencies, 213\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd58c9fe-d528-474e-8117-b13cf4e51d21', embedding=None, metadata={'page_label': '791', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Index    791\\ntime\\nMicrosoft Access, 362–363\\nMySQL, 365Oracle, 363–364\\ntime stamping, 502, 502–503time-variant data, 183, 183–186time-variant data warehouse, \\n608–609\\nTM. See transaction manager\\nTO_CHAR function, 363, 369TO_DATE function, 364TO_NUMBER function, 370top-down design, 473, 473–474total completeness, 175\\nTP. See transaction processor\\ntransaction(s)\\natomic transaction property,  \\n506\\ndefinition, 484\\nevaluating results, 484–487isolation, 504–505management, 559properties, 487–488relational diagram, 483SQL, 488–489understanding, 484\\ntransactional database, 9transaction logs\\nbackup, 455\\ndefinition, 489\\ndescription, 489–490redundant, 506\\ntransaction manager (TM), 560transaction processor (TP), 560transaction recovery management\\nbuffers, 506\\ncheckpoints, 507\\ndeferred update method, 508deferred-write technique, 507log characteristics, 508–509redundant transaction logs, 506ROLLBACK command \\noperation, 507–508\\nwrite-ahead-log protocol, 506write-through technique, 507\\ntransaction transparencydefinition, 565\\ndistributed concurrency control, \\n571\\ndistributed request, 570,  570–571\\ndistributed transaction, 569,  \\n569–570\\nremote request, 568remote transaction, 568,  \\n568–569\\ntwo-phase commit protocol, \\n571,  571–573\\ntransitive dependency, 208transparency\\ndistribution, 564\\nfailure, 565\\nfragmentation, 565\\nheterogeneity, 565\\nlocal mapping, 565location, 565\\nperformance, 565\\ntransaction, 565\\ntraversal, 668\\ntrigger(s)\\naction, conditional DML \\npredicates, 401\\ndefinition, 393\\nin PL/SQL, 392–401row-level, 394\\nstatement-level, 394\\ntuple, 43\\nTwitter, 10two-phase commit protocol (2PC), \\n571, 571–573\\ntwo-phase locking (2PL), 500, \\n500–501\\n%TYPE data type, 392\\nU\\nUDA. See Universal Data Access\\nUML. See Unified Modeling \\nLanguage\\nunary relationship, 134, 134–135\\nuncommitted data, 491, 491–492Unified Modeling Language (UML), \\n48, 118, 441\\nUNION operator, 84, 84–85, 371–373UNION ALL operator, 373union-compatible operator, 84, 371\\nUNIQUE command, 247unique fragment, 566unique index, 104uniqueness, 502\\nUniversal Data Access (UDA), 682unreplicated database, 580unstructured data, 9, 653\\nupdate anomalies, 21UPDATE command, 248, 268user(s). See also end users\\ndata table space, 537in DBMS, 520definition, 762\\nV\\nvalue, 654\\nVARCHAR2 data type, 392variability, 654\\nvariety, 649, 653–654\\nVBScript, 698\\nvelocity, 649, 652–653\\nvertical fragmentation, 575, \\n576–577\\nvery large databases (VLDBs), 29\\ndecision support databases,  \\n607\\ndefinition, 607\\nrelational online analytical \\nprocessing, 627\\nviability, 654view\\ndefinition, 377\\nrelational, 379updatable, 379–382, 380\\nvirtualization, 451\\nvirtual tables\\noverview of, 377–382updatable views, 379–382\\nvisualization, 654\\nVLDBs. See very large  \\ndatabases\\nVLDBs (very Large Databases), 29volume, 649, 651–652\\nvolume, velocity, and variety, 51W\\nW3C. See World Wide Web \\nConsortium\\nwait/die scheme, 502–503, 503weak entities, 129–131weak relationship, 127web application server, 698web browser, 696–697web database development, \\n699–702\\nweb server interfaces, 695–696web-to-database middleware\\ndefinition, 694\\ninteraction components, \\n694–695\\nserver-side extension, 693\\nWHERE clause\\nconditional expression, 533conditional restrictions,  \\n271–276\\ndefinition, 271\\nwhile function, 701wildcard character, 266,  \\n266–267\\nworkgroup databases, 8workstations, diskless, 454World Wide Web Consortium \\n(W3C), 702\\nwound/wait scheme, 502–503,  \\n503\\nwrite-ahead-log protocol, 506write-ahead protocol, 572write-through technique, 507\\nX\\nXML. See Extensible Markup \\nLanguage\\nXML schema definition (XSD),  \\n706\\nXSD. See XML schema  \\ndefinition\\nXSLT. See Extensible Style \\nLanguage Transformations\\nY\\nYEAR function, 362, 365\\nCopyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e44355e6-b190-436c-9de2-d01a10a0710c', embedding=None, metadata={'page_label': '792', 'file_name': 'Database System - Design, Implementation and Management (12th edition).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Database System - Design, Implementation and Management (12th edition).pdf', 'file_type': 'application/pdf', 'file_size': 58386181, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Copyright 2017 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). \\nEditorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8314d44b-c671-4335-9339-80845f8bd768', embedding=None, metadata={'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\info.txt', 'file_name': 'info.txt', 'file_type': 'text/plain', 'file_size': 57, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='hugging face token\\r\\n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', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='872dbdd6-4c39-4628-8aa7-bbd9e1056294', embedding=None, metadata={'page_label': 'Cover', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Visualization \\nAnalysis & Design\\nTamara MunznerA K Peters Visualization Series\\nIllustrations by  Eamonn MaguireVisualization/Human–Computer Interaction/Computer Graphics “A must read for researchers, sophisticated \\npractitioners, and graduate students.”\\n—Jim Foley, College of Computing, Georgia Institute of Technology \\nAuthor of Computer Graphics: Principles and Practice\\n“Munzner’s new book is thorough and beautiful. It \\nbelongs on the shelf of anyone touched and enriched by visualization.”\\n—Chris Johnson, Scientific Computing and Imaging Institute, \\nUniversity of Utah\\n“This is the visualization textbook I have long awaited. \\nIt emphasizes abstraction, design principles, and the importance of evaluation  and interactivity.”\\n—Jim Hollan,  Department of Cognitive Science,  \\nUniversity of California, San Diego\\n“Munzner is one of the world’s very top researchers in information visualization, and this meticulously crafted volume is probably the most thoughtful and deep synthesis the field has yet seen.”\\n—Michael McGuffin, Department of Software and IT Engineering, \\nÉcole de Technologie Supérieure“Munzner elegantly synthesizes an astounding amount of \\ncutting-edge work on visualization into a clear, engaging, and comprehensive textbook that will prove indispensable to students, designers, and researchers.”\\n—Steven Franconeri, Department of Psychology,  \\nNorthwestern University\\n“Munzner shares her deep insights in visualization with us \\nin this excellent textbook, equally useful for students and experts in the field.”\\n—Jarke van Wijk, Department of Mathematics and Computer Science, \\nEindhoven University of Technology\\n“The book shapes the field of visualization in an \\nunprecedented way.”\\n—Wolfgang Aigner,  Institute for Creative Media Technologies,  \\nSt. Pölten University of Applied Sciences\\n“This book provides the most comprehensive coverage of \\nthe fundamentals of visualization design that I have found. It is a much-needed and long-awaited resource for both teachers and practitioners of visualization.”\\n—Kwan-Liu Ma, Department of Computer Science,  \\nUniversity of California, Davis\\nThis book’s unified approach encompasses information visualization techniques for abstract data, scientific visualization techniques for spatial data, and visual analytics techniques for interweaving data transformation and analysis with interactive visual exploration. Suitable for both beginners and more experienced designers, the book does not assume any experience with programming, mathematics, human–computer interaction, or graphic design.\\nK14708WITH VITALSOURCE®\\nEBOOKAN A K PETERS BOOK\\n• Access online or download to your smartphone, tablet \\nor PC/Mac\\n• Search the full text of this and other titles you own\\n• Make and share notes and highlights\\n• Copy and paste text and figures for use in your own \\ndocuments\\n• Customize your view by changing font size and layout', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29efee01-ffb4-445a-8d3a-7ede85a28ba7', embedding=None, metadata={'page_label': 'i', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Visualization \\nAnalysis & Design', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='944cc672-18ca-47f0-b0e7-1e74aa78c2c8', embedding=None, metadata={'page_label': 'ii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A K PETERS VISUALIZATION SERIES\\nSeries Editor: Tamara Munzner\\nVisualization Analysis and Design\\nTamara Munzner\\n2014', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5137a536-0eed-4d25-999a-859d1751f688', embedding=None, metadata={'page_label': 'iii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Visualization \\nAnalysis & Design\\nTamara Munzner\\nDepartment of Computer Science\\nUniversity of British Columbia\\nIllustrations by Eamonn Maguire\\nBoca Raton  London  New York\\nCRC Press is an imprint of the\\nTaylor & Francis Group, an informa  business\\nAN A K PETERS BOOK', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cbbb8836-ed63-4f75-ac0b-977e84a3920e', embedding=None, metadata={'page_label': 'iv', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Cover art: Genesis 6-3-00 , by Aribert Munzner. Casein on paperboard, 26” × 20”, 2000. http://www.aribertmunzner.com\\nFor reuse of the diagram figures released under the CC-BY-4.0 license, written permission from the publishers is not required.\\nCRC Press\\nTaylor & Francis Group6000 Broken Sound Parkway NW, Suite 300Boca Raton, FL 33487-2742\\n© 2015 by Taylor & Francis Group, LLC\\nCRC Press is an imprint of Taylor & Francis Group, an Informa business\\nNo claim to original U.S. Government works\\nVersion Date: 20140909\\nInternational Standard Book Number-13: 978-1-4665-0893-4 (eBook - PDF)This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but \\nthe author and publisher cannot assume responsibility for the validity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may rectify in any future reprint.\\nExcept as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or utilized in any form by any electronic, mechanical, \\nor other means, now known or hereafter invented, including photocopying, microfilming, and recording, or in any information storage or retrieval system, without written permission from the publishers.\\nFor permission to photocopy or use material electronically from this work, please access www.copyright.com (http://www.copyright.com/) or contact the Copyright \\nClearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.\\nTrademark Notice:  Product or corporate names may be trademarks or registered trademarks, and are used only for identification and explanation without intent to \\ninfringe.\\nVisit the Taylor & Francis Web site at\\nhttp://www.taylorandfrancis.com\\nand the CRC Press Web site at\\nhttp://www.crcpress.com', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9d9d529-0abe-443a-837b-10020da41ef1', embedding=None, metadata={'page_label': 'v', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ii\\nii\\ni\\nii\\niContents\\nPreface xv\\nWhy a New Book? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv\\nExisting Books . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvi\\nAudience . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii\\nWho’s Who . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xviii\\nStructure: What’s in This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xviii\\nWhat’s Not in This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xx\\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xx\\n1 What’s Vis, and Why Do It? 1\\n1.1 The Big Picture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2 Why Have a Human in the Loop? . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.3 Why Have a Computer in the Loop? . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.4 Why Use an External Representation? . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.5 Why Depend on Vision? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.6 Why Show the Data in Detail? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.7 Why Use Interactivity? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.8 Why Is the Vis Idiom Design Space Huge? . . . . . . . . . . . . . . . . . . . . . 10\\n1.9 Why Focus on Tasks? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.10 Why Focus on Effectiveness? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.11 Why Are Most Designs Ineffective? . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n1.12 Why Is Validation Difﬁcult? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n1.13 Why Are There Resource Limitations? . . . . . . . . . . . . . . . . . . . . . . . . 14\\n1.14 Why Analyze? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n1.15 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2 What: Data Abstraction 20\\n2.1 The Big Picture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n2.2 Why Do Data Semantics and Types Matter? . . . . . . . . . . . . . . . . . . . . 21\\n2.3 Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n2.4 Dataset Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n2.4.1 Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n2.4.2 Networks and Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n2.4.2.1 Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nv', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4d9d5c4d-9e75-4ac4-a132-669ef43368a2', embedding=None, metadata={'page_label': 'vi', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='vi Contents\\n2.4.3 Fields ...................................... 2 7\\n2.4.3.1 Spatial Fields ............................ 2 8\\n2.4.3.2 Grid Types ............................. 2 9\\n2.4.4 Geometry .................................... 2 9\\n2.4.5 Other Combinations .............................. 3 0\\n2.4.6 Dataset Availability .............................. 3 1\\n2.5 Attribute Types ..................................... 3 1\\n2.5.1 Categorical ................................... 3 2\\n2.5.2 Ordered: Ordinal and Quantitative . . ................... 3 2\\n2.5.2.1 Sequential versus Diverging ................... 3 3\\n2.5.2.2 Cyclic ................................ 3 3\\n2.5.3 Hierarchical Attributes ............................ 3 3\\n2.6 Semantics ........................................ 3 4\\n2.6.1 Key versus Value Semantics ......................... 3 4\\n2.6.1.1 Flat Tables ............................. 3 4\\n2.6.1.2 Multidimensional Tables ..................... 3 6\\n2.6.1.3 Fields ................................ 3 7\\n2.6.1.4 Scalar Fields ............................ 3 7\\n2.6.1.5 Vector Fields ............................ 3 7\\n2.6.1.6 Tensor Fields ............................ 3 8\\n2.6.1.7 Field Semantics . . . ....................... 3 8\\n2.6.2 Temporal Semantics .............................. 3 8\\n2.6.2.1 Time-Varying Data . . ....................... 3 9\\n2.7 Further Reading .................................... 4 0\\n3 Why: T ask Abstraction 42\\n3.1 The Big Picture ..................................... 4 3\\n3.2 Why Analyze Tasks Abstractly? ........................... 4 3\\n3.3 Who: Designer or User ................................ 4 4\\n3.4 Actions .......................................... 4 5\\n3.4.1 Analyze ..................................... 4 5\\n3.4.1.1 Discover ............................... 4 7\\n3.4.1.2 Present ............................... 4 7\\n3.4.1.3 Enjoy ................................ 4 8\\n3.4.2 Produce ..................................... 4 9\\n3.4.2.1 Annotate .............................. 4 9\\n3.4.2.2 Record ................................ 4 9\\n3.4.2.3 Derive ................................ 5 0\\n3.4.3 Search ...................................... 5 3\\n3.4.3.1 Lookup ............................... 5 3\\n3.4.3.2 Locate ................................ 5 3\\n3.4.3.3 Browse ................................ 5 3\\n3.4.3.4 Explore ............................... 5 4', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1dd14009-d60b-4b89-83c5-94e4ba98dbbc', embedding=None, metadata={'page_label': 'vii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents vii\\n3.4.4 Query ...................................... 5 4\\n3.4.4.1 Identify ............................... 5 4\\n3.4.4.2 Compare ............................... 5 5\\n3.4.4.3 Summarize ............................. 5 5\\n3.5 Targets .......................................... 5 5\\n3.6 How: A Preview ..................................... 5 7\\n3.7 Analyzing and Deriving: Examples .......................... 5 9\\n3.7.1 Comparing Two Idioms ............................ 5 9\\n3.7.2 Deriving One Attribute ............................ 6 0\\n3.7.3 Deriving Many New Attributes . ....................... 6 2\\n3.8 Further Reading .................................... 6 4\\n4 Analysis: Four Levels for Validation 66\\n4.1 The Big Picture ..................................... 6 7\\n4.2 Why Validate? ...................................... 6 7\\n4.3 Four Levels of Design ................................. 6 7\\n4.3.1 Domain Situation ............................... 6 9\\n4.3.2 Task and Data Abstraction .......................... 7 0\\n4.3.3 Visual Encoding and Interaction Idiom ................... 7 1\\n4.3.4 Algorithm .................................... 7 2\\n4.4 Angles of Attack .................................... 7 3\\n4.5 Threats to Validity ................................... 7 4\\n4.6 Validation Approaches ................................. 7 5\\n4.6.1 Domain Validation ............................... 7 7\\n4.6.2 Abstraction Validation ............................ 7 8\\n4.6.3 Idiom Validation ................................ 7 8\\n4.6.4 Algorithm Validation .............................. 8 0\\n4.6.5 Mismatches ................................... 8 1\\n4.7 Validation Examples .................................. 8 1\\n4.7.1 Genealogical Graphs ............................. 8 1\\n4.7.2 MatrixExplorer ................................. 8 3\\n4.7.3 Flow Maps ................................... 8 5\\n4.7.4 LiveRAC ..................................... 8 7\\n4.7.5 LinLog ...................................... 8 9\\n4.7.6 Sizing the Horizon ............................... 9 0\\n4.8 Further Reading .................................... 9 1\\n5 Marks and Channels 94\\n5.1 The Big Picture ..................................... 9 5\\n5.2 Why Marks and Channels? .............................. 9 5\\n5.3 Deﬁning Marks and Channels ............................ 9 5\\n5.3.1 Channel Types ................................. 9 9\\n5.3.2 Mark Types ................................... 9 9', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='90d2c48c-f24c-4e83-895b-b070f0513ac2', embedding=None, metadata={'page_label': 'viii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='viii Contents\\n5.4 Using Marks and Channels .............................. 9 9\\n5.4.1 Expressiveness and Effectiveness . . . ................... 1 0 0\\n5.4.2 Channel Rankings ............................... 1 0 1\\n5.5 Channel Effectiveness ................................. 1 0 3\\n5.5.1 Accuracy .................................... 1 0 3\\n5.5.2 Discriminability ................................ 1 0 6\\n5.5.3 Separability ................................... 1 0 6\\n5.5.4 Popout ...................................... 1 0 9\\n5.5.5 Grouping .................................... 1 1 1\\n5.6 Relative versus Absolute Judgements . ....................... 1 1 2\\n5.7 Further Reading .................................... 1 1 4\\n6 Rules of Thumb 116\\n6.1 The Big Picture ..................................... 1 1 7\\n6.2 Why and When to Follow Rules of Thumb? ..................... 1 1 7\\n6.3 No Unjustiﬁed 3D ................................... 1 1 7\\n6.3.1 The Power of the Plane ............................ 1 1 8\\n6.3.2 The Disparity of Depth ............................ 1 1 8\\n6.3.3 Occlusion Hides Information ......................... 1 2 0\\n6.3.4 Perspective Distortion Dangers ....................... 1 2 1\\n6.3.5 Other Depth Cues ............................... 1 2 3\\n6.3.6 Tilted Text Isn’t Legibile ............................ 1 2 4\\n6.3.7 Beneﬁts of 3D: Shape Perception ...................... 1 2 4\\n6.3.8 Justiﬁcation and Alternatives ........................ 1 2 5\\nExample: Cluster–Calendar Time-Series Vis ............... 1 2 5\\nExample: Layer-Oriented Time-Series Vis ................. 1 2 8\\n6.3.9 Empirical Evidence .............................. 1 2 9\\n6.4 No Unjustiﬁed 2D ................................... 1 3 1\\n6.5 Eyes Beat Memory ................................... 1 3 1\\n6.5.1 Memory and Attention ............................ 1 3 2\\n6.5.2 Animation versus Side-by-Side Views . ................... 1 3 2\\n6.5.3 Change Blindness ............................... 1 3 3\\n6.6 Resolution over Immersion .............................. 1 3 4\\n6.7 Overview First, Zoom and Filter, Details on Demand ............... 1 3 5\\n6.8 Responsiveness Is Required ............................. 1 3 7\\n6.8.1 Visual Feedback ................................ 1 3 8\\n6.8.2 Latency and Interaction Design ....................... 1 3 8\\n6.8.3 Interactivity Costs ............................... 1 4 0\\n6.9 Get It Right in Black and White ........................... 1 4 0\\n6.10 Function First, Form Next .............................. 1 4 0\\n6.11 Further Reading .................................... 1 4 1', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1aeee5b8-ac4a-4ec1-b8a3-490cfe546de8', embedding=None, metadata={'page_label': 'ix', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents ix\\n7 Arrange T ables 144\\n7.1 The Big Picture ..................................... 1 4 5\\n7.2 Why Arrange? ...................................... 1 4 5\\n7.3 Arrange by Keys and Values ............................. 1 4 5\\n7.4 Express: Quantitative Values ............................. 1 4 6\\nExample: Scatterplots ............................ 1 4 6\\n7.5 Separate, Order, and Align: Categorical Regions .................. 1 4 9\\n7.5.1 List Alignment: One Key ........................... 1 4 9\\nExample: Bar Charts ............................. 1 5 0\\nExample: Stacked Bar Charts ........................ 1 5 1\\nExample: Streamgraphs ........................... 1 5 3\\nExample: Dot and Line Charts ....................... 1 5 5\\n7.5.2 Matrix Alignment: Two Keys . . . ...................... 1 5 7\\nExample: Cluster Heatmaps ......................... 1 5 8\\nExample: Scatterplot Matrix ......................... 1 6 0\\n7.5.3 Volumetric Grid: Three Keys . . . ...................... 1 6 1\\n7.5.4 Recursive Subdivision: Multiple Keys .................... 1 6 1\\n7.6 Spatial Axis Orientation ................................ 1 6 2\\n7.6.1 Rectilinear Layouts .............................. 1 6 2\\n7.6.2 Parallel Layouts ................................ 1 6 2\\nExample: Parallel Coordinates ........................ 1 6 2\\n7.6.3 Radial Layouts ................................. 1 6 6\\nExample: Radial Bar Charts ......................... 1 6 7\\nExample: Pie Charts ............................. 1 6 8\\n7.7 Spatial Layout Density ................................ 1 7 1\\n7.7.1 Dense ...................................... 1 7 2\\nExample: Dense Software Overviews .................... 1 7 2\\n7.7.2 Space-Filling .................................. 1 7 4\\n7.8 Further Reading .................................... 1 7 5\\n8 Arrange Spatial Data 178\\n8.1 The Big Picture ..................................... 1 7 9\\n8.2 Why Use Given? .................................... 1 7 9\\n8.3 Geometry ........................................ 1 8 0\\n8.3.1 Geographic Data ................................ 1 8 0\\nExample: Choropleth Maps ......................... 1 8 1\\n8.3.2 Other Derived Geometry ........................... 1 8 2\\n8.4 Scalar Fields: One Value ............................... 1 8 2\\n8.4.1 Isocontours ................................... 1 8 3\\nExample: Topographic Terrain Maps .................... 1 8 3\\nExample: Flexible Isosurfaces ........................ 1 8 5\\n8.4.2 Direct Volume Rendering ........................... 1 8 6\\nExample: Multidimensional Transfer Functions ............. 1 8 7', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a491b441-b702-486b-ab3a-6bcc008e9198', embedding=None, metadata={'page_label': 'x', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='x Contents\\n8.5 Vector Fields: Multiple Values ............................ 1 8 9\\n8.5.1 Flow Glyphs .................................. 1 9 1\\n8.5.2 Geometric Flow ................................ 1 9 1\\nExample: Similarity-Clustered Streamlines ................ 1 9 2\\n8.5.3 Texture Flow .................................. 1 9 3\\n8.5.4 Feature Flow .................................. 1 9 3\\n8.6 Tensor Fields: Many Values .............................. 1 9 4\\nExample: Ellipsoid Tensor Glyphs ..................... 1 9 4\\n8.7 Further Reading .................................... 1 9 7\\n9 Arrange Networks and T rees 200\\n9.1 The Big Picture ..................................... 2 0 1\\n9.2 Connection: Link Marks ................................ 2 0 1\\nExample: Force-Directed Placement .................... 2 0 4\\nExample: sfdp ................................. 2 0 7\\n9.3 Matrix Views ...................................... 2 0 8\\nExample: Adjacency Matrix View ...................... 2 0 8\\n9.4 Costs and Beneﬁts: Connection versus Matrix ................... 2 0 9\\n9.5 Containment: Hierarchy Marks ........................... 2 1 3\\nExample: Treemaps .............................. 2 1 3\\nExample: GrouseFlocks ........................... 2 1 5\\n9.6 Further Reading .................................... 2 1 6\\n10 Map Color and Other Channels 218\\n10.1 The Big Picture ..................................... 2 1 9\\n10.2 Color Theory ...................................... 2 1 9\\n10.2.1 Color Vision .................................. 2 1 9\\n10.2.2 Color Spaces .................................. 2 2 0\\n10.2.3 Luminance, Saturation, and Hue . . . ................... 2 2 3\\n10.2.4 Transparency .................................. 2 2 5\\n10.3 Colormaps ........................................ 2 2 5\\n10.3.1 Categorical Colormaps ............................ 2 2 6\\n10.3.2 Ordered Colormaps .............................. 2 2 9\\n10.3.3 Bivariate Colormaps .............................. 2 3 4\\n10.3.4 Colorblind-Safe Colormap Design ...................... 2 3 5\\n10.4 Other Channels ..................................... 2 3 6\\n10.4.1 Size Channels ................................. 2 3 6\\n10.4.2 Angle Channel ................................. 2 3 7\\n10.4.3 Curvature Channel .............................. 2 3 8\\n10.4.4 Shape Channel ................................. 2 3 8\\n10.4.5 Motion Channels ................................ 2 3 8\\n10.4.6 Texture and Stippling ............................. 2 3 9\\n10.5 Further Reading .................................... 2 4 0', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='01a933e0-6f47-4275-ae55-2ecd0108802b', embedding=None, metadata={'page_label': 'xi', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents xi\\n11 Manipulate View 242\\n11.1 The Big Picture ..................................... 2 4 3\\n11.2 Why Change? ...................................... 2 4 4\\n11.3 Change View over Time ................................ 2 4 4\\nExample: LineUp ............................... 2 4 6\\nExample: Animated Transitions ....................... 2 4 8\\n11.4 Select Elements ..................................... 2 4 9\\n11.4.1 Selection Design Choices ........................... 2 5 0\\n11.4.2 Highlighting .................................. 2 5 1\\nExample: Context-Preserving Visual Links ................ 2 5 3\\n11.4.3 Selection Outcomes .............................. 2 5 4\\n11.5 Navigate: Changing Viewpoint ............................ 2 5 4\\n11.5.1 Geometric Zooming .............................. 2 5 5\\n11.5.2 Semantic Zooming ............................... 2 5 5\\n11.5.3 Constrained Navigation ............................ 2 5 6\\n11.6 Navigate: Reducing Attributes ............................ 2 5 8\\n11.6.1 Slice ....................................... 2 5 8\\nExample: HyperSlice ............................. 2 5 9\\n11.6.2 Cut ........................................ 2 6 0\\n11.6.3 Project ...................................... 2 6 1\\n11.7 Further Reading .................................... 2 6 1\\n12 Facet into Multiple Views 264\\n12.1 The Big Picture ..................................... 2 6 5\\n12.2 Why Facet? ....................................... 2 6 5\\n12.3 Juxtapose and Coordinate Views .......................... 2 6 7\\n12.3.1 Share Encoding: Same/Different ...................... 2 6 7\\nExample: Exploratory Data Visualizer (EDV) ............... 2 6 8\\n12.3.2 Share Data: All, Subset, None . . ...................... 2 6 9\\nExample: Bird’s-Eye Maps .......................... 2 7 0\\nExample: Multiform Overview–Detail Microarrays ............ 2 7 1\\nExample: Cerebral .............................. 2 7 4\\n12.3.3 Share Navigation: Synchronize . ...................... 2 7 6\\n12.3.4 Combinations ................................. 2 7 6\\nExample: Improvise .............................. 2 7 7\\n12.3.5 Juxtapose Views ................................ 2 7 8\\n12.4 Partition into Views .................................. 2 7 9\\n12.4.1 Regions, Glyphs, and Views . . . ...................... 2 7 9\\n12.4.2 List Alignments ................................ 2 8 1\\n12.4.3 Matrix Alignments ............................... 2 8 2\\nExample: Trellis ................................ 2 8 2\\n12.4.4 Recursive Subdivision ............................. 2 8 5\\n12.5 Superimpose Layers .................................. 2 8 8', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='41c0a9db-7a35-4251-a762-abd393f0d842', embedding=None, metadata={'page_label': 'xii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xii Contents\\n12.5.1 Visually Distinguishable Layers . . . .................... 2 8 9\\n12.5.2 Static Layers .................................. 2 8 9\\nExample: Cartographic Layering ...................... 2 8 9\\nExample: Superimposed Line Charts .................... 2 9 0\\nExample: Hierarchical Edge Bundles .................... 2 9 2\\n12.5.3 Dynamic Layers ................................ 2 9 4\\n12.6 Further Reading .................................... 2 9 5\\n13 Reduce Items and Attributes 298\\n13.1 The Big Picture ..................................... 2 9 9\\n13.2 Why Reduce? ...................................... 2 9 9\\n13.3 Filter ........................................... 3 0 0\\n13.3.1 Item Filtering .................................. 3 0 1\\nExample: FilmFinder ............................. 3 0 1\\n13.3.2 Attribute Filtering ............................... 3 0 3\\nExample: DOSFA ............................... 3 0 4\\n13.4 Aggregate ........................................ 3 0 5\\n13.4.1 Item Aggregation ................................ 3 0 5\\nExample: Histograms ............................. 3 0 6\\nExample: Continuous Scatterplots ..................... 3 0 7\\nExample: Boxplot Charts ........................... 3 0 8\\nExample: SolarPlot .............................. 3 1 0\\nExample: Hierarchical Parallel Coordinates ................ 3 1 1\\n13.4.2 Spatial Aggregation .............................. 3 1 3\\nExample: Geographically Weighted Boxplots ............... 3 1 3\\n13.4.3 Attribute Aggregation: Dimensionality Reduction ............. 3 1 5\\n13.4.3.1 Why and When to Use DR? .................... 3 1 6\\nExample: Dimensionality Reduction for Document Collections ..... 3 1 6\\n13.4.3.2 How to Show DR Data? ...................... 3 1 9\\n13.5 Further Reading .................................... 3 2 0\\n14 Embed: Focus+Context 322\\n14.1 The Big Picture ..................................... 3 2 3\\n14.2 Why Embed? ...................................... 3 2 3\\n14.3 Elide ........................................... 3 2 4\\nExample: DOITrees Revisited ........................ 3 2 5\\n14.4 Superimpose ...................................... 3 2 6\\nExample: Toolglass and Magic Lenses ................... 3 2 6\\n14.5 Distort .......................................... 3 2 7\\nExample: 3D Perspective ........................... 3 2 7\\nExample: Fisheye Lens ............................ 3 2 8\\nExample: Hyperbolic Geometry ....................... 3 2 9', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='327dd7ce-2a23-4b7f-b108-af57a410e382', embedding=None, metadata={'page_label': 'xiii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Contents xiii\\nExample: Stretch and Squish Navigation ................. 3 3 1\\nExample: Nonlinear Magniﬁcation Fields ................. 3 3 3\\n14.6 Costs and Beneﬁts: Distortion ............................ 3 3 4\\n14.7 Further Reading .................................... 3 3 7\\n15 Analysis Case Studies 340\\n15.1 The Big Picture ..................................... 3 4 1\\n15.2 Why Analyze Case Studies? .............................. 3 4 1\\n15.3 Graph-Theoretic Scagnostics ............................. 3 4 2\\n15.4 VisDB .......................................... 3 4 7\\n15.5 Hierarchical Clustering Explorer ........................... 3 5 1\\n15.6 PivotGraph ....................................... 3 5 5\\n15.7 InterRing ........................................ 3 5 8\\n15.8 Constellation ...................................... 3 6 0\\n15.9 Further Reading .................................... 3 6 6\\nFigure Credits 369\\nBibliography 375\\nIdiom and System Examples Index 397\\nConcept Index 399', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='983019ae-f1d8-4d4a-8ec9-b67c3147c056', embedding=None, metadata={'page_label': 'xiv', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='This page intentionally left blankThis page intentionally left blank', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4496d688-d452-4ef6-891f-987d3f4ef6c4', embedding=None, metadata={'page_label': 'xv', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface\\nWhy a New Book?\\nI wrote this book to scratch my own itch: the book I wanted to\\nteach out of for my graduate visualization (vis) course did not exist.\\nThe itch grew through the years of teaching my own course at theUniversity of British Columbia eight times, co-teaching a course\\nat Stanford in 2001, and helping with the design of an early viscourse at Stanford in 1996 as a teaching assistant.\\nI was dissatisﬁed with teaching primarily from original research\\npapers. While it is very useful for graduate students to learn toread papers, what was missing was a synthesis view and a frame-work to guide thinking. The principles and design choices that Iintended a particular paper to illustrate were often only indirectly\\nalluded to in the paper itself. Even after assigning many papersor book chapters as preparatory reading before each lecture, I was\\nfrustrated by the many major gaps in the ideas discussed. More-over, the reading load was so heavy that it was impossible to ﬁt inany design exercises along the way, so the students only gaineddirect experience as designers in a single monolithic ﬁnal project.\\nI was also dissatisﬁed with the lecture structure of my own\\ncourse because of a problem shared by nearly every other course inthe ﬁeld: an incoherent approach to crosscutting the subject mat-\\nter. Courses that lurch from one set of crosscuts to another are\\nintellectually unsatisfying in that they make vis seem like a grab-bag of assorted topics rather than a ﬁeld with a unifying theoreticalframework. There are several major ways to crosscut vis mate-rial. One is by the ﬁeld from which we draw techniques: cognitivescience for perception and color, human–computer interaction for\\nuser studies and user-centered design, computer graphics for ren-\\ndering, and so on. Another is by the problem domain addressed:for example, biology, software engineering, computer networking,medicine, casual use, and so on. Yet another is by the familiesof techniques: focus+context, overview/detail, volume rendering,\\nxv', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7bd2b498-85ea-462d-a193-9ee3aa8ffa31', embedding=None, metadata={'page_label': 'xvi', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xvi Preface\\nand statistical graphics. Finally, evaluation is an important and\\ncentral topic that should be interwoven throughout, but it did notﬁt into the standard pipelines and models. It was typically rele-gated to a single lecture, usually near the end, so that it felt likean afterthought.\\nExisting Books\\nVis is a young ﬁeld, and there are not many books that provide asynthesis view of the ﬁeld. I saw a need for a next step on thisfront.\\nTufte is a curator of glorious examples [Tufte 83, Tufte 91,\\nTufte 97], but he focuses on what can be done on the static printedpage for purposes of exposition. The hallmarks of the last 20 yearsof computer-based vis are interactivity rather than simply static\\npresentation and the use of vis for exploration of the unknown inaddition to exposition of the known. Tufte’s books do not address\\nthese topics, so while I use them as supplementary material, I ﬁndthey cannot serve as the backbone for my own vis course. However,any or all of them would work well as supplementary reading for acourse structured around this book; my own favorite for this role\\nisEnvisioning Information [Tufte 91].\\nSome instructors use Readings in Information Visualization [Card\\net al. 99]. The ﬁrst chapter provides a useful synthesis view of the\\nﬁeld, but it is only one chapter. The rest of the book is a collectionof seminal papers, and thus it shares the same problem as directlyreading original papers. Here I provide a book-length synthesis,and one that is informed by the wealth of progress in our ﬁeld inthe past 15 years.\\nWare’s book Information Visualization: Perception for Design\\n[Ware 13] is a thorough book on vis design as seen through thelens of perception, and I have used it as the backbone for my owncourse for many years. While it discusses many issues on how onecould design a vis, it does not cover what has been done in thisﬁeld for the past 14 years from a synthesis point of view. I wanteda book that allows a beginning student to learn from this collectiveexperience rather than starting from scratch. This book does not\\nattempt to teach the very useful topic of perception per se; it covers\\nonly the aspects directly needed to get started with vis and leavesthe rest as further reading. Ware’s shorter book, Visual Thinking\\nfor Design [Ware 08], would be excellent supplemental reading for\\na course structured around this book.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='218a2fcb-4ba8-4064-9aa1-239dd18b7e64', embedding=None, metadata={'page_label': 'xvii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface xvii\\nThis book offers a considerably more extensive model and\\nframework than Spence’s Information Visualization [Spence 07].\\nWilkinson’s The Grammar of Graphics [Wilkinson 05] is a deep and\\nthoughtful work, but it is dense enough that it is more suitable forvis insiders than for beginners. Conversely, Few’s Show Me The\\nNumbers [Few 12] is extremely approachable and has been used at\\nthe undergraduate level, but the scope is much more limited thanthe coverage of this book.\\nThe recent book Interactive Data Visualization [Ward et al. 10]\\nworks from the bottom up with algorithms as the base, whereas Iwork from the top down and stop one level above algorithmic con-siderations; our approaches are complementary. Like this book, itcovers both nonspatial and spatial data. Similarly, the Data Visu-\\nalization [Telea 07] book focuses on the algorithm level. The book\\nonThe Visualization Toolkit [Schroeder et al. 06] has a scope far be-\\nyond the vtk software, with considerable synthesis coverage of the\\nconcerns of visualizing spatial data. It has been used in many sci-entiﬁc visualization courses, but it does not cover nonspatial data.The voluminous Visualization Handbook [Hansen and Johnson 05]\\nis an edited collection that contains a mix of synthesis material\\nand research speciﬁcs; I refer to some speciﬁc chapters as good re-\\nsources in my Further Reading sections at the end of each chapterin this book.\\nAudience\\nThe primary audience of this book is students in a ﬁrst vis course,particularly at the graduate level but also at the advanced under-\\ngraduate level. While admittedly written from a computer scien-\\ntist’s point of view, the book aims to be accessible to a broad audi-ence including students in geography, library science, and design.It does not assume any experience with programming, mathemat-ics, human–computer interaction, cartography, or graphic design;for those who do have such a background, some of the terms that\\nI deﬁne in this book are connected with the specialized vocabu-\\nlary from these areas through notes in the margins. Other au-diences are people from other ﬁelds with an interest in vis, whowould like to understand the principles and design choices of thisﬁeld, and practitioners in the ﬁeld who might use it as a referencefor a more formal analysis and improvements of production vis\\napplications.\\nI wrote this book for people with an interest in the design and\\nanalysis of vis idioms and systems. That is, this book is aimed', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dae51a7c-2ea8-4d7e-9c03-fab4f7e326f3', embedding=None, metadata={'page_label': 'xviii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xviii Preface\\nat vis designers, both nascent and experienced. This book is not\\ndirectly aimed at vis end users, although they may well ﬁnd someof this material informative.\\nThe book is aimed at both those who take a problem-driven\\napproach and those who take a technique-driven approach. Itsfocus is on broad synthesis of the general underpinnings of vis interms of principles and design choices to provide a framework forthe design and analysis of techniques, rather than the algorithmsto instantiate those techniques.\\nThe book features a uniﬁed approach encompassing informa-\\ntion visualization techniques for abstract data, scientiﬁc visualiza-tion techniques for spatial data, and visual analytics techniquesfor interleaving data transformation and analysis with interactivevisual exploration.\\nWho’s Who\\nI use pronouns in a deliberate way in this book, to indicate roles.Iam the author of this book. I cover many ideas that have a long\\nand rich history in the ﬁeld, but I also advocate opinions that are\\nnot necessarily shared by all visualization researchers and practi-\\ntioners. The pronoun you means the reader of this book; I address\\nyou as if you’re designing or analyzing a visualization system. Thepronoun they refers to the intended users, the target audience for\\nwhom a visualization system is designed. The pronoun we refers\\nto all humans, especially in terms of our shared perceptual andcognitive responses.\\nI’ll also use the abbreviation vis throughout this book, since\\nvisualization is quite a mouthful!\\nStructure: What’s in This Book\\nThe book begins with a deﬁnition of vis and walks through its many\\nimplications in Chapter 1, which ends with a high-level introduc-tion to an analysis framework of breaking down vis design accord-ing what –why –how questions that have data –task –idiom answers.\\nChapter 2 addresses the what question with answers about data\\nabstractions, and Chapter 3 addresses the why question with task\\nabstractions, including an extensive discussion of deriving newdata, a preview of the framework of design choices for how id-\\nioms can be designed, and several examples of analysis throughthis framework.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eb815740-1702-4bb7-88bd-ff2a29433ff4', embedding=None, metadata={'page_label': 'xix', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface xix\\nChapter 4 extends the analysis framework to two additional lev-\\nels: the domain situation level on top and the algorithm level onthe bottom, with the what/why level of data and task abstractionand the how level of visual encoding and interaction idiom designin between the two. This chapter encourages using methods to val-idate your design in a way that matches up with these four levels.\\nChapter 5 covers the principles of marks and channels for en-\\ncoding information. Chapter 6 presents eight rules of thumb fordesign.\\nThe core of the book is the framework for analyzing how vis\\nidioms can be constructed out of design choices. Three chapterscover choices of how to visually encode data by arranging space:Chapter 7 for tables, Chapter 8 for spatial data, and Chapter 9for networks. Chapter 10 continues with the choices for mapping\\ncolor and other channels in visual encoding. Chapter 11 discusses\\nways to manipulate and change a view. Chapter 12 covers ways tofacet data between multiple views. Choices for how to reduce theamount of data shown in each view are covered in Chapter 13, andChapter 14 covers embedding information about a focus set withinthe context of overview data. Chapter 15 wraps up the book withsix case studies that are analyzed in detail with the full framework.\\nEach design choice is illustrated with concrete examples of spe-\\nciﬁc idioms that use it. Each example is analyzed by decompos-ing its design with respect to the design choices that have beenpresented so far, so these analyses become more extensive as thechapters progress; each ends with a table summarizing the analy-\\nsis. The book’s intent is to get you familiar with analyzing existing\\nidioms as a springboard for designing new ones.\\nI chose the particular set of concrete examples in this book as\\nevocative illustrations of the space of vis idioms and my way toapproach vis analysis. Although this set of examples does covermany of the more popular idioms, it is certainly not intended tobe a complete enumeration of all useful idioms; there are manymore that have been proposed that aren’t in here. These examplesalso aren’t intended to be a historical record of who ﬁrst proposedwhich ideas: I often pick more recent examples rather than thevery ﬁrst use of a particular idiom.\\nAll of the chapters start with a short section called The Big Pic-\\nture that summarizes their contents, to help you quickly deter-\\nmine whether a chapter covers material that you care about. Theyall end with a Further Reading section that points you to more in-\\nformation about their topics. Throughout the book are boxes inthe margins: vocabulary notes in purple starting with a star, and', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4cd78eaa-7e32-4579-b5f5-fc8ac85f46d8', embedding=None, metadata={'page_label': 'xx', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xx Preface\\ncross-reference notes in blue starting with a triangle. Terms are\\nhighlighted in purple where they are deﬁned for the ﬁrst time.\\nThe book has an accompanying web page at http:/ /www.cs.ubc.\\nca/∼tmm/vadbook with errata, pointers to courses that use the\\nbook in different ways, example lecture slides covering the mate-rial, and downloadable versions of the diagram ﬁgures.\\nWhat’s Not in This Book\\nThis book focuses on the abstraction and idiom levels of design anddoesn’t cover the domain situation level or the algorithm levels.\\nI have left out algorithms for reasons of space and time, not of\\ninterest. The book would need to be much longer if it covered algo-rithms at any reasonable depth; the middle two levels provide more\\nthan enough material for a single volume of readable size. Also,\\nmany good resources already exist to learn about algorithms, in-cluding original papers and some of the previous books discussedabove. Some points of entry for this level are covered in FurtherReading sections at the end of each chapter. Moreover, this book\\nis intended to be accessible to people without a computer sciencebackground, a decision that precludes algorithmic detail. A ﬁnal\\nconsideration is that the state of the art in algorithms changesquickly; this book aims to provide a framework for thinking aboutdesign that will age more gracefully. The book includes many con-crete examples of previous vis tools to illustrate points in the design\\nspace of possible idioms, not as the ﬁnal answer for the very latest\\nand greatest way to solve a particular design problem.\\nThe domain situation level is not as well studied in the vis lit-\\nerature as the algorithm level, but there are many relevant re-sources from other literatures including human–computer interac-tion. Some points of entry for this level are also covered in Further\\nReading.\\nAcknowledgments\\nMy thoughts on visualization in general have been inﬂuenced bymany people, but especially Pat Hanrahan and the students inthe vis group while I was at Stanford: Robert Bosch, Chris Stolte,\\nDiane Tang, and especially Franc ¸ois Guimbreti ´ere.\\nThis book has beneﬁted from the comments and thoughts of\\nmany readers at different stages.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc935dec-4a75-4594-96af-0349d1c91cf5', embedding=None, metadata={'page_label': 'xxi', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface xxi\\nI thank the recent members of my research group for their\\nincisive comments on chapter drafts and their patience with mysometimes-obsessive focus on this book over the past six years:Matt Brehmer, Jessica Dawson, Joel Ferstay, Stephen Ingram,Miriah Meyer, and especially Michael Sedlmair. I also thank theprevious members of my group for their collaboration and discus-sions that have helped shape my thinking: Daniel Archambault,Aaron Barsky, Adam Bodnar, Kristian Hildebrand, Qiang Kong,Heidi Lam, Peter McLachlan, Dmitry Nekrasovski, James Slack,Melanie Tory, and Matt Williams.\\nI thank several people who gave me useful feedback on my Visu-\\nalization book chapter [Munzner 09b] in the Fundamentals of Com-\\nputer Graphics textbook [Shirley and Marschner 09]: TJ Jankun-\\nKelly, Robert Kincaid, Hanspeter Pﬁster, Chris North, Stephen\\nNorth, John Stasko, Frank van Ham, Jarke van Wijk, and Mar-\\ntin Wattenberg. I used that chapter as a test run of my initialstructure for this book, so their feedback has carried forward intothis book as well.\\nI also thank early readers Jan Hardenburgh, Jon Steinhart, and\\nMaureen Stone. Later reader Michael McGufﬁn contributed manythoughtful comments in addition to several great illustrations.\\nMany thanks to the instructors who have test-taught out of\\ndraft versions of this book, including Enrico Bertini, Remco Chang,Heike J ¨anicke Leitte, Raghu Machiragu, and Melanie Tory. I espe-\\ncially thank Michael Laszlo, Chris North, Hanspeter Pﬁster, MiriahMeyer, and Torsten M ¨oller for detailed and thoughtful feed-\\nback.\\nI also thank all of the students who have used draft versions\\nof this book in a course. Some of these courses were structuredto provide me with a great deal of commentary from the studentson the drafts, and I particularly thank these students for theircontributions.\\nFrom my own 2011 course: Anna Flagg, Niels Hanson, Jingxian\\nLi, Louise Oram, Shama Rashid, Junhao (Ellsworth) Shi, JillianSlind, Mashid ZeinalyBaraghoush, Anton Zoubarev, and ChuanZhu.\\nFrom North’s 2011 course: Ankit Ahuja, S.M. (Arif) Arifuzza-\\nman, Sharon Lynn Chu, Andre Esakia, Anurodh Joshi, Chiran-\\njeeb Kataki, Jacob Moore, Ann Paul, Xiaohui Shu, Ankit Singh,Hamilton Turner, Ji Wang, Sharon Chu Yew Yee, Jessica Zeitz,and especially Lauren Bradel.\\nFrom Pﬁster’s 2012 course: Pankaj Ahire, Rabeea Ahmed, Salen\\nAlmansoori, Ayindri Banerjee, Varun Bansal, Antony Bett, Made-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed751d69-d6ad-40e5-bec6-32976e3a0605', embedding=None, metadata={'page_label': 'xxii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='xxii Preface\\nlaine Boyd, Katryna Cadle, Caitline Carey, Cecelia Wenting Cao,\\nZamyla Chan, Gillian Chang, Tommy Chen, Michael Cherkassky,Kevin Chin, Patrick Coats, Christopher Coey, John Connolly, Dan-iel Crookston Charles Deck, Luis Duarte, Michael Edenﬁeld, Jef-frey Ericson, Eileen Evans, Daniel Feusse, Gabriela Fitz, DaveFobert, James Garﬁeld, Shana Golden, Anna Gommerstadt, BoHan, William Herbert, Robert Hero, Louise Hindal, Kenneth Ho,Ran Hou, Sowmyan Jegatheesan, Todd Kawakita, Rick Lee, Na-talya Levitan, Angela Li, Eric Liao, Oscar Liu, Milady Jiminez Lopez,Valeria Espinosa Mateos, Alex Mazure, Ben Metcalf, Sarah Ngo, PatNjolstad, Dimitris Papnikolaou, Roshni Patel, Sachin Patel, YogeshRana, Anuv Ratan, Pamela Reid, Phoebe Robinson, Joseph Rose,Kishleen Saini, Ed Santora, Konlin Shen, Austin Silva, SamuelQ. Singer, Syed Sobhan, Jonathan Sogg, Paul Stravropoulos, Lila\\nBjorg Strominger, Young Sul, Will Sun, Michael Daniel Tam, Man\\nYee Tang, Mark Theilmann, Gabriel Trevino, Blake Thomas Walsh,Patrick Walsh, Nancy Wei, Karisma Williams, Chelsea Yah, AmyYin, and Chi Zeng.\\nFrom M ¨oller’s 2014 course: Tam ´as Birkner, Nikola Dichev, Eike\\nJens Gnadt, Michael Gruber, Martina Kapf, Manfred Klaffenb ¨ock,\\nS¨umeyye Kocaman, Lea Maria Joseffa Koinig, Jasmin Kuric,\\nMladen Magic, Dana Markovic, Christine Mayer, Anita Moser, Mag-dalena P ¨ohl, Michael Prater, Johannes Preisinger, Stefan Rammer,\\nPhilipp Sturmlechner, Himzo Tahic, Michael T ¨ogel, and Kyriakoula\\nTsafou.\\nI thank all of the people connected wit h A K Peters who con-\\ntributed to this book. Alice Peters and Klaus Peters steadfastedly\\nkept asking me if I was ready to write a book yet for well over adecade and helped me get it off the ground. Sarah Chow, Char-lotte Byrnes, Randi Cohen, and Sunil Nair helped me get it out thedoor with patience and care.\\nI am delighted with and thankful for the graphic design talents\\nof Eamonn Maguire of Antarctic Design, an accomplished vis re-searcher in his own right, who tirelessly worked with me to turnmy hand-drawn Sharpie drafts into polished and expressive dia-grams.\\nI am grateful for the friends who saw me through the days,\\nthrough the nights, and through the years: Jen Archer, Kirsten\\nCameron, Jenny Gregg, Bridget Hardy, Jane Henderson, Yuri Hoff-\\nman, Eric Hughes, Kevin Leyton-Brown, Max Read, Shevek, AnilaSrivastava, Aim ´ee Sturley, Jude Walker, Dave Whalen, and Betsy\\nZeller.\\nI thank my family for their decades of love and support: Naomi\\nMunzner, Sheila Oehrlein, Joan Munzner, and Ari Munzner. I also', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f855a88-a81b-47b6-8ccc-becdfe0e2de3', embedding=None, metadata={'page_label': 'xxiii', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preface xxiii\\nthank Ari for the painting featured on the cover and for the way\\nthat his artwork has shaped me over my lifetime; see http:/ /www.aribertmunzner.com.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29b0c3d5-f1c9-472b-96c6-5b498d050d50', embedding=None, metadata={'page_label': 'xxiv', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='This page intentionally left blankThis page intentionally left blank', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8f5e2ab2-0e2a-4499-90ab-a1c13e097974', embedding=None, metadata={'page_label': '1', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='What’s Vis, and Why Do It?Chapter 1\\n1.1 The Big Picture\\nThis book is built around the following deﬁnition of visualization—\\nvis, for short:\\nComputer-based visualization systems provide visual\\nrepresentations of datasets designed to help people carryout tasks more effectively.\\nVisualization is suitable when there is a need to augment\\nhuman capabilities rather than replace people with com-putational decision-making methods. The design space\\nof possible vis idioms is huge, and includes the consid-\\nerations of both how to create and how to interact withvisual representations. Vis design is full of trade-offs, andmost possibilities in the design space are ineffective for aparticular task, so validating the effectiveness of a design\\nis both necessary and difﬁcult. Vis designers must take\\ninto account three very different kinds of resource limi-tations: those of computers, of humans, and of displays.Vis usage can be analyzed in terms of why the user needsit, what data is shown, and how the idiom is designed.\\nI’ll discuss the rationale behind many aspects of this deﬁnition as\\na way of getting you to think about the scope of this book, and\\nabout visualization itself:\\n•Why have a human in the decision-making loop?\\n•Why have a computer in the loop?\\n•Why use an external representation?\\n•Why depend on vision?\\n1', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3f3be0a2-f0e2-49ae-b438-813c6bfc2153', embedding=None, metadata={'page_label': '2', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2 1. What’s Vis, and Why Do It?\\n•Why show the data in detail?\\n•Why use interactivity?\\n•Why is the vis idiom design space huge?\\n•Why focus on tasks?\\n•Why are most designs ineffective?\\n•Why care about effectiveness?\\n•Why is validation difﬁcult?\\n•Why are there resource limitations?\\n•Why analyze vis?\\n1.2 Why Have a Human in the Loop?\\nVis allows people to analyze data when they don’t know exactly\\nwhat questions they need to ask in advance.\\nThe modern era is characterized by the promise of better deci-\\nsion making through access to more data than ever before. When\\npeople have well-deﬁned questions to ask about data, they can usepurely computational techniques from ﬁelds such as statistics andmachine learning.\\n⋆Some jobs that were once done by humans can ⋆The ﬁeld of machine\\nlearning is a branch of\\nartiﬁcial intelligence where\\ncomputers can handle a\\nwide variety of new situa-tions in response to data-driven training, rather thanby being programmed withexplicit instructions in ad-\\nvance.now be completely automated with a computer-based solution. If\\na fully automatic solution has been deemed to be acceptable, then\\nthere is no need for human judgement, and thus no need for you to\\ndesign a vis tool. For example, consider the domain of stock mar-ket trading. Currently, there are many deployed systems for high-frequency trading that make decisions about buying and sellingstocks when certain market conditions hold, when a speciﬁc price\\nis reached, for example, with no need at all for a time-consuming\\ncheck from a human in the loop. You would not want to designa vis tool to help a person make that check faster, because evenan augmented human will not be able to reason about millions ofstocks every second.\\nHowever, many analysis problems are ill speciﬁed: people don’t\\nknow how to approach the problem. There are many possible ques-\\ntions to ask—anywhere from dozens to thousands or more—andpeople don’t know which of these many questions are the rightones in advance. In such cases, the best path forward is an anal-ysis process with a human in the loop, where you can exploit the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94f5fe0a-6940-46ca-9c10-c89097dae161', embedding=None, metadata={'page_label': '3', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.2. Why Have a Human in the Loop? 3\\npowerful pattern detection properties of the human visual system\\nin your design. Vis systems are appropriate for use when your goalis to augment human capabilities, rather than completely replacethe human in the loop.\\nYou can design vis tools for many kinds of uses. You can make\\na tool intended for transitional use where the goal is to “work itselfout of a job”, by helping the designers of future solutions that arepurely computational. You can also make a tool intended for long-term use, in a situation where there is no intention of replacing the\\nhuman any time soon.\\nFor example, you can create a vis tool that’s a stepping stone\\nto gaining a clearer understanding of analysis requirements beforedeveloping formal mathematical or computational models. Thiskind of tool would be used very early in the transition processin a highly exploratory way, before even starting to develop anykind of automatic solution. The outcome of designing vis toolstargeted at speciﬁc real-world domain problems is often a muchcrisper understanding of the user’s task, in addition to the toolitself.\\nIn the middle stages of a transition, you can build a vis tool\\naimed at the designers of a purely computational solution, to help\\nthem reﬁne, debug, or extend that system’s algorithms or under-stand how the algorithms are affected by changes of parameters.In this case, your tool is aimed at a very different audience thanthe end users of that eventual system; if the end users need vi-sualization at all, it might be with a very different interface. Re-\\nturning to the stock market example, a higher-level system that\\ndetermines which of multiple trading algorithms to use in vary-ing circumstances might require careful tuning. A vis tool to helpthe algorithm developers analyze its performance might be use-ful to these developers, but not to people who eventually buy thesoftware.\\nYou can also design a vis tool for end users in conjunction with\\nother computational decision making to illuminate whether the au-tomatic system is doing the right thing according to human judge-ment. The tool might be intended for interim use when makingdeployment decisions in the late stages of a transition, for exam-\\nple, to see if the result of a machine learning system seems to be\\ntrustworthy before entrusting it to spend millions of dollars tradingstocks. In some cases vis tools are abandoned after that decision ismade; in other cases vis tools continue to be in play with long-termuse to monitor a system, so that people can take action if they spotunreasonable behavior.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b93a97d-8c30-498a-8fd4-ae90999eba51', embedding=None, metadata={'page_label': '4', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4 1. What’s Vis, and Why Do It?\\nFigure 1.1. The Variant View vis tool supports biologists in assessing the impact\\nof genetic variants by speeding up the exploratory analysis process. From [Ferstayet al. 13, Figure 1].\\nIn contrast to these transitional uses, you can also design vis\\ntools for long-term use, where a person will stay in the loop indef-initely. A common case is exploratory analysis for scientiﬁc dis-covery, where the goal is to speed up and improve a user’s abilityto generate and check hypotheses. Figure 1.1 shows a vis tooldesigned to help biologists studying the genetic basis of diseasethrough analyzing DNA sequence variation. Although these scien-tists make heavy use of computation as part of their larger work-ﬂow, there’s no hope of completely automating the process of can-cer research any time soon.\\nYou can also design vis tools for presentation. In this case,\\nyou’re supporting people who want to explain something that theyalready know to others, rather than to explore and analyze theunknown. For example, The New York Times has deployed sophis-\\nticated interactive visualizations in conjunction with news stories.\\n1.3 Why Have a Computer in the Loop?\\nBy enlisting computation, you can build tools that allow people to\\nexplore or present large datasets that would be completely infeasi-ble to draw by hand, thus opening up the possibility of seeing howdatasets change over time.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0a697b20-37af-4a70-a8f0-5521f9367f3e', embedding=None, metadata={'page_label': '5', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.3. Why Have a Computer in the Loop? 5\\n(a)\\n (b)\\nFigure 1.2. The Cerebral vis tool captures the style of hand-drawn diagrams in biology textbooks with vertical layers\\nthat correspond to places within a cell where interactions between genes occur. (a) A small network of 57 nodes\\nand 74 edges might be possible to lay out by hand with enough patience. (b) Automatic layout handles this large\\nnetwork of 760 nodes and 1269 edges and provides a substrate for interactive exploration: the user has moved themouse over the MSK1 gene, so all of its immmediate neighbors in the network are highlighted in red. From [Barsky\\net al. 07, Figures 1 and 2].\\nPeople could create visual representations of datasets manu-\\nally, either completely by hand with pencil and paper, or with com-puterized drawing tools where they individually arrange and coloreach item. The scope of what people are willing and able to domanually is strongly limited by their attention span; they are un-likely to move beyond tiny static datasets. Arranging even smalldatasets of hundreds of items might take hours or days. Mostreal-world datasets are much larger, ranging from thousands tomillions to even more. Moreover, many datasets change dynami-cally over time. Having a computer-based tool generate the visualrepresentation automatically obviously saves human effort com-pared to manual creation.\\nAs a designer, you can think about what aspects of hand-drawn\\ndiagrams are important in order to automatically create drawingsthat retain the hand-drawn spirit. For example, Figure 1.2 shows', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bd651591-35c0-4fa9-9cf3-c01c5bde65f7', embedding=None, metadata={'page_label': '6', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6 1. What’s Vis, and Why Do It?\\nan example of a vis tool designed to show interactions between\\ngenes in a way similar to stylized drawings that appear in biol-ogy textbooks, with vertical layers that correspond to the locationwithin the cell where the interaction occurs [Barsky et al. 07]. Fig-ure 1.2(a) could be done by hand, while Figure 1.2(b) could not.\\n1.4 Why Use an External Representation?\\nExternal representations augment human capacity by allowing us\\nto surpass the limitations of our own internal cognition and mem-ory.\\nVis allows people to ofﬂoad internal cognition and memory us-\\nage to the perceptual system, using carefully designed images asa form of external representations , sometimes also called external\\nmemory . External representations can take many forms, including\\ntouchable physical objects like an abacus or a knotted string, but\\nin this book I focus on what can be shown on the two-dimensionaldisplay surface of a computer screen.\\nDiagrams can be designed to support perceptual inferences,\\nwhich are very easy for humans to make. The advantages of dia-grams as external memory is that information can be organized byspatial location, offering the possibility of accelerating both searchand recognition. Search can be sped up by grouping all the itemsneeded for a speciﬁc problem-solving inference together at the samelocation. Recognition can also be facilitated by grouping all the rel-evant information about one item in the same location, avoidingthe need for matching remembered symbolic labels. However, anonoptimal diagram may group irrelevant information together, orsupport perceptual inferences that aren’t useful for the intendedproblem-solving process.\\n1.5 Why Depend on Vision?\\nVisualization, as the name implies, is based on exploiting the hu-\\nman visual system as a means of communication. I focus exclu-\\nsively on the visual system rather than other sensory modalitiesbecause it is both well characterized and suitable for transmitting\\ninformation.\\nThe visual system provides a very high-bandwidth channel to\\nour brains. A signiﬁcant amount of visual information processingoccurs in parallel at the preconscious level. One example is visual', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='366fc40e-3fd3-4087-955a-66f67c3b2e92', embedding=None, metadata={'page_label': '7', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.6. Why Show the Data in Detail? 7\\npopout, such as when one red item is immediately noticed from a\\nsea of gray ones. The popout occurs whether the ﬁeld of other ob-jects is large or small because of processing done in parallel acrossthe entire ﬁeld of vision. Of course, our visual systems also feedinto higher-level processes that involve the conscious control ofattention.\\nSound is poorly suited for providing overviews of large informa-\\ntion spaces compared with vision. An enormous amount of back-\\nground visual information processing in our brains underlies ourability to think and act as if we see a huge amount of information atonce, even though technically we see only a tiny part of our visual\\nﬁeld in high resolution at any given instant. In contrast, we ex-perience the perceptual channel of sound as a sequential stream,\\nrather than as a simultaneous experience where what we hear over\\na long period of time is automatically merged together. This crucialdifference may explain why soniﬁcation has never taken off despite\\nmany independent attempts at experimentation.\\nThe other senses can be immediately ruled out as communica-\\ntion channels because of technological limitations. The perceptualchannels of taste and smell don’t yet have viable recording and re-production technology at all. Haptic input and feedback devicesexist to exploit the touch and kinesthetic perceptual channels, but\\nthey cover only a very limited part of the dynamic range of what wecan sense. Exploration of their effectiveness for communicating\\nabstract information is still at a very early stage.\\n▶Chapter 5 covers impli-\\ncations of visual perceptionthat are relevant for vis de-sign.\\n1.6 Why Show the Data in Detail?\\nVis tools help people in situations where seeing the dataset struc-\\nture in detail is better than seeing only a brief summary of it. Oneof these situations occurs when exploring the data to ﬁnd patterns,both to conﬁrm expected ones and ﬁnd unexpected ones. Anotheroccurs when assessing the validity of a statistical model, to judgewhether the model in fact ﬁts the data.\\nStatistical characterization of datasets is a very powerful ap-\\nproach, but it has the intrinsic limitation of losing informationthrough summarization. Figure 1.3 shows Anscombe’s Quartet, a\\nsuite of four small datasets designed by a statistician to illustrate\\nhow datasets that have identical descriptive statistics can havevery different structures that are immediately obvious when thedataset is shown graphically [Anscombe 73]. All four have identi-cal mean, variance, correlation, and linear regression lines. If you', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38fd48a5-5a37-479d-ace4-bf6179bc3d75', embedding=None, metadata={'page_label': '8', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='8 1. What’s Vis, and Why Do It?\\n1\\nX          Y2\\nX          Y3\\nX          Y4\\nX          Y\\nMean\\nVariance\\nCorrelationAnscombe’s Quartet: Raw Data\\nFigure 1.3. Anscombe’s Quartet is four datasets with identical simple statisti-\\ncal properties: mean, variance, correlation, and linear regression line. However,visual inspection immediately shows how their structures are quite different. Af-ter [Anscombe 73, Figures 1–4].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='497dff2a-a8c5-4a2f-b0f7-db92caf98962', embedding=None, metadata={'page_label': '9', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.7. Why Use Interactivity? 9\\nare familiar with these statistical measures, then the scatterplot of\\nthe ﬁrst dataset probably isn’t surprising, and matches your intu-ition. The second scatterplot shows a clear nonlinear pattern inthe data, showing that summarizing with linear regression doesn’tadequately capture what’s really happening. The third datasetshows how a single outlier can lead to a regression line that’s mis-leading in a different way because its slope doesn’t quite matchthe line that our eyes pick up clearly from the rest of the data.Finally, the fourth dataset shows a truly pernicious case wherethese measures dramatically mislead, with a regression line that’salmost perpendicular to the true pattern we immediately see inthe data.\\nThe basic principle illustrated by Anscombe’s Quartet, that a\\nsingle summary is often an oversimpliﬁcation that hides the truestructure of the dataset, applies even more to large and complexdatasets.\\n1.7 Why Use Interactivity?\\nInteractivity is crucial for building vis tools that handle complex-\\nity. When datasets are large enough, the limitations of both peopleand displays preclude just showing everything at once; interac-\\ntion where user actions cause the view to change is the way for-\\nward. Moreover, a single static view can show only one aspect ofa dataset. For some combinations of simple datasets and tasks,the user may only need to see a single visual encoding. In con-trast, an interactively changing display supports many possiblequeries.\\nIn all of these cases, interaction is crucial. For example, an in-\\nteractive vis tool can support investigation at multiple levels of de-\\ntail, ranging from a very high-level overview down through multiple\\nlevels of summarization to a fully detailed view of a small part of it.It can also present different ways of representing and summariz-ing the data in a way that supports understanding the connectionsbetween these alternatives.\\nBefore the widespread deployment of fast computer graphics,\\nvisualization was limited to the use of static images on paper. Withcomputer-based vis, interactivity becomes possible, vastly increas-ing the scope and capabilities of vis tools. Although static repre-sentations are indeed within the scope of this book, interaction isan intrinsic part of many idioms.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3939f95c-e113-4775-92e3-fd99cea948d6', embedding=None, metadata={'page_label': '10', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='10 1. What’s Vis, and Why Do It?\\n1.8 Why Is the Vis Idiom Design Space Huge?\\nA vis idiom is a distinct approach to creating and manipulating\\nvisual representations. There are many ways to create a visual en-\\ncoding of data as a single picture. The design space of possibilities\\ngets even bigger when you consider how to manipulate one or moreof these pictures with interaction .\\nMany vis idioms have been proposed. Simple static idioms in-\\nclude many chart types that have deep historical roots, such asscatterplots, bar charts, and line charts. A more complicated id-iom can link together multiple simple charts through interaction.For example, selecting one bar in a bar chart could also result inhighlighting associated items in a scatterplot that shows a differ-ent view of the same data. Figure 1.4 shows an even more com-plex idiom that supports incremental layout of a multilevel networkthrough interactive navigation. Data from Internet Movie Databaseshowing all movies connected to Sharon Stone is shown, where ac-tors are represented as grey square nodes and links between them\\nFigure 1.4. The Grouse vis tool features a complex idiom that combines visual\\nencoding and interaction, supporting incremental layout of a network through in-teractive navigation. From [Archambault et al. 07a, Figure 5].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cc8b415b-e71b-4a5e-aa14-9b47ba404a2d', embedding=None, metadata={'page_label': '11', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.9. Why Focus on T asks? 11\\nmean appearance in the same movie. The user has navigated by\\nopening up several metanodes, shown as discs, to see structure atmany levels of the hierarchy simultaneously; metanode color en-codes the topological structure of the network features it contains,and hexagons indicate metanodes that are still closed. The insetshows the details of the opened-up clique of actors who all appearin the movie Anything but Here , with name labels turned on.\\n▶Compound networks are\\ndiscussed further in Sec-\\ntion 9.5.\\nThis book provides a framework for thinking about the space\\nof vis design idioms systematically by considering a set of designchoices, including how to encode information with spatial position,\\nhow to facet data between multiple views, and how to reduce the\\namount of data shown by ﬁltering and aggregation.\\n1.9 Why Focus on T asks?\\nA tool that serves well for one task can be poorly suited for another,\\nfor exactly the same dataset. The task of the users is an equallyimportant constraint for a vis designer as the kind of data that theusers have.\\nReframing the users’ task from domain-speciﬁc form into ab-\\nstract form allows you to consider the similarities and differences\\nbetween what people need across many real-world usage contexts.\\nFor example, a vis tool can support presentation, or discovery, orenjoyment of information; it can also support producing more in-formation for subsequent use. For discovery, vis can be used togenerate new hypotheses, as when exploring a completely unfamil-iar dataset, or to conﬁrm existing hypotheses about some dataset\\nthat is already partially understood.\\n▶The space of task ab-\\nstractions is discussed indetail in Chapter 3.\\n1.10 Why Focus on Effectiveness?\\nThe focus on effectiveness is a corollary of deﬁning vis to have the\\ngoal of supporting user tasks. This goal leads to concerns aboutcorrectness, accuracy, and truth playing a very central role in vis.The emphasis in vis is different from other ﬁelds that also involvemaking images: for example, art emphasizes conveying emotion,\\nachieving beauty, or provoking thought; movies and comics em-\\nphasize telling a narrative story; advertising emphasizes setting amood or selling. For the goals of emotional engagement, story-telling, or allurement, the deliberate distortion and even fabrica-tion of facts is often entirely appropriate, and of course ﬁction is as', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3327f69a-dc9a-4ded-9926-60ae1f8e6398', embedding=None, metadata={'page_label': '12', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='12 1. What’s Vis, and Why Do It?\\nrespectable as nonﬁction. In contrast, a vis designer does not typi-\\ncally have artistic license. Moreover, the phrase “it’s not just aboutmaking pretty pictures” is a common and vehement assertion invis, meaning that the goals of the designer are not met if the resultis beautiful but not effective.\\nHowever, no picture can communicate the truth, the whole truth,\\nand nothing but the truth. The correctness concerns of a vis de-signer are complicated by the fact that any depiction of data is\\nan abstraction where choices are made about which aspects toemphasize. Cartographers have thousands of years of experience\\n▶Abstraction is discussed\\nin more detail in Chapters 3\\nand 4.with articulating the difference between the abstraction of a map\\nand the terrain that it represents. Even photographing a real-worldscene involves choices of abstraction and emphasis; for example,the photographer chooses what to include in the frame.\\n1.11 Why Are Most Designs Ineffective?\\nThe most fundamental reason that vis design is a difﬁcult enter-\\nprise is that the vast majority of the possibilities in the design space\\nwill be ineffective for any speciﬁc usage context. In some cases, apossible design is a poor match with the properties of the humanperceptual and cognitive systems. In other cases, the design wouldbe comprehensible by a human in some other setting, but it’s a badmatch with the intended task. Only a very small number of pos-sibilities are in the set of reasonable choices, and of those onlyan even smaller fraction are excellent choices. Randomly choosingpossibilities is a bad idea because the odds of ﬁnding a very goodsolution are very low.\\nFigure 1.5 contrasts two ways to think about design in terms of\\ntraversing a search space. In addressing design problems, it’s nota very useful goal to optimize ; that is, to ﬁnd the very best choice. A\\nmore appropriate goal when you design is to satisfy ; that is, to ﬁnd\\none of the many possible good solutions rather than one of the evenlarger number of bad ones. The diagram shows ﬁve spaces, eachof which is progressively smaller than the previous. First, thereis the space of all possible solutions, including potential solutionsthat nobody has ever thought of before. Next, there is the set of\\npossibilities that are known to you, the vis designer. Of course,\\nthis set might be small if you are a novice designer who is notaware of the full array of methods that have been proposed in thepast. If you’re in that situation, one of the goals of this book is toenlarge the set of methods that you know about. The next set is the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f8d625b-0888-4ad8-b707-e60a7b934372', embedding=None, metadata={'page_label': '13', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.11. Why Are Most Designs Ineffective? 13\\nxConsideration \\nspaceProposal \\nspace\\nxBad!\\nxxxx\\nooo\\nx o\\noGood!\\nSpace of possible solutionsKnown \\nspaceSelected\\nsolution \\nx\\nGood solution\\nOK solution\\nPoor Solutionx\\no\\nSpace of possible solutionsox\\noo\\nooo\\noo\\no\\nFigure 1.5. A search space metaphor for vis design.\\nconsideration space, which contains the solutions that you actively\\nconsider. This set is necessarily smaller than the known space,because you can’t consider what you don’t know. An even smallerset is the proposal space of possibilities that you investigate in\\ndetail. Finally, one of these becomes the selected solution.\\nFigure 1.5 contrasts a good strategy on the left, where the known\\nand consideration spaces are large, with a bad strategy on theright, where these spaces are small. The problem of a small con-\\nsideration space is the higher probability of only considering ok\\nor poor solutions and missing a good one. A fundamental princi-ple of design is to consider multiple alternatives and then choosethe best, rather than to immediately ﬁxate on one solution withoutconsidering any alternatives. One way to ensure that more thanone possibility is considered is to explicitly generate multiple ideasin parallel. This book is intended to help you, the designer, en-tertain a broad consideration space by systematically consideringmany alternatives and to help you rule out some parts of the spaceby noting when there are mismatches of possibilities with humancapabilities or the intended task.\\nAs with all design problems, vis design cannot be easily handled\\nas a simple process of optimization because trade-offs abound. Adesign that does well by one measure will rate poorly on another.The characterization of trade-offs in the vis design space is a veryopen problem at the frontier of vis research. This book providesseveral guidelines and suggested processes, based on my synthesisof what is currently known, but it contains few absolute truths.\\n▶Chapter 4 introduces a\\nmodel for thinking aboutthe design process at fourdifferent levels; the modelis intended to guide your\\nthinking through these\\ntrade-offs in a systematicway.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aff0213d-588a-474e-bde6-a6976d3ac133', embedding=None, metadata={'page_label': '14', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='14 1. What’s Vis, and Why Do It?\\n1.12 Why Is Validation Difﬁcult?\\nThe problem of validation for a vis design is difﬁcult because there\\nare so many questions that you could ask when considering whethera vis tool has met your design goals.\\nHow do you know if it works? How do you argue that one de-\\nsign is better or worse than another for the intended users? Forone thing, what does better mean? Do users get something done\\nfaster? Do they have more fun doing it? Can they work more effec-tively? What does effectively mean? How do you measure insight\\norengagement ? What is the design better than? Is it better than\\nanother vis system? Is it better than doing the same things man-ually, without visual support? Is it better than doing the samethings completely automatically? And what sort of thing does itdo better? That is, how do you decide what sort of task the usersshould do when testing the system? And who is this user ? An ex-\\npert who has done this task for decades, or a novice who needs thetask to be explained before they begin? Are they familiar with how\\nthe system works from using it for a long time, or are they seeing\\nit for the ﬁrst time? A concept like faster might seem straightfor-\\nward, but tricky questions still remain. Are the users limited bythe speed of their own thought process, or their ability to movethe mouse, or simply the speed of the computer in drawing eachpicture?\\nHow do you decide what sort of benchmark data you should\\nuse when testing the system? Can you characterize what classesof data the system is suitable for? How might you measure thequality of an image generated by a vis tool? How well do any of\\nthe automatically computed quantitative metrics of quality match\\nup with human judgements? Even once you limit your considera-tions to purely computational issues, questions remain. Does thecomplexity of the algorithm depend on the number of data items toshow or the number of pixels to draw? Is there a trade-off betweencomputer speed and computer memory usage?\\n▶Chapter 4 answers these\\nquestions by providing a\\nframework that addresses\\nwhen to use what methodsfor validating vis designs.\\n1.13 Why Are There Resource Limitations?\\nWhen designing or analyzing a vis system, you must consider at\\nleast three different kinds of limitations: computational capacity,\\nhuman perceptual and cognitive capacity, and display capacity.\\nVis systems are inevitably used for larger datasets than those\\nthey were designed for. Thus, scalability is a central concern: de-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3fb7f7ae-d656-40f3-940e-5e193a5f6c92', embedding=None, metadata={'page_label': '15', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.13. Why Are There Resource Limitations? 15\\nsigning systems to handle large amounts of data gracefully. The\\ncontinuing increase in dataset size is driven by many factors: im-provements in data acquisition and sensor technology, bringingreal-world data into a computational context; improvements incomputer capacity, leading to ever-more generation of data fromwithin computational environments including simulation and log-ging; and the increasing reach of computational infrastructure intoevery aspect of life.\\nAs with any application of computer science, computer time and\\nmemory are limited resources, and there are often soft and hard\\nconstraints on the availability of these resources. For instance, ifyour vis system needs to interactively deliver a response to user in-put, then when drawing each frame you must use algorithms thatcan run in a fraction of a second rather than minutes or hours. In\\nsome scenarios, users are unwilling or unable to wait a long time\\nfor the system to preprocess the data before they can interact withit. A soft constraint is that the vis system should be parsimoniousin its use of computer memory because the user needs to run otherprograms simultaneously. A hard constraint is that even if thevis system can use nearly all available memory in the computer,\\ndataset size can easily outstrip that ﬁnite capacity. Designing sys-\\ntems that gracefully handle larger datasets that do not ﬁt into corememory requires signiﬁcantly more complex algorithms. Thus, thecomputational complexity of algorithms for dataset preprocessing,transformation, layout, and rendering is a major concern. How-ever, computational issues are by no means the only concern!\\nOn the human side, memory and attention are ﬁnite resources.\\nChapter 5 will discuss some of the power and limitations of thelow-level visual preattentive mechanisms that carry out massivelyparallel processing of our current visual ﬁeld. However, humanmemory for things that are not directly visible is notoriously lim-ited. These limits come into play not only for long-term recall but\\nalso for shorter-term working memory, both visual and nonvisual.\\nWe store surprisingly little information internally in visual work-ing memory, leaving us vulnerable to change blindness : the phe-\\nnomenon where even very large changes are not noticed if we areattending to something else in our view [Simons 00].\\n▶More aspects of memory\\nand attention are covered inSection 6.5.\\nDisplay capacity is a third kind of limitation to consider. Vis de-\\nsigners often run out of pixels; that is, the resolution of the screenis not enough to show all desired information simultaneously. Theinformation density of a single image is a measure of the amount\\nof information encoded versus the amount of unused space.\\n⋆Fig-⋆Synonyms for informa-\\ntion density include gra-\\nphic density and data–ink\\nratio . ure 1.6 shows the same tree dataset visually encoded three differ-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='59176850-af39-4bd9-8c62-d65d1fd1a52f', embedding=None, metadata={'page_label': '16', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='16 1. What’s Vis, and Why Do It?\\n(a)\\n(b) (c)\\nFigure 1.6. Low and high information density visual encodings of the same small\\ntree dataset; nodes are the same size in each. (a) Low information density. (b)Higher information density, but depth in tree cannot be read from spatial position.(c) High information density, while maintaining property that depth is encoded with\\nposition. From [McGufﬁn and Robert 10, Figure 3].\\nent ways. The layout in Figure 1.6(a) encodes the depth from root\\nto leaves in the tree with vertical spatial position. However, theinformation density is low. In contrast, the layout in Figure 1.6(b)\\nuses nodes of the same size but is drawn more compactly, so ithas higher information density; that is, the ratio between the sizeof each node and the area required to display the entire tree is\\nlarger. However, the depth cannot be easily read off from spatialposition. Figure 1.6(c) shows a very good alternative that combines\\nthe beneﬁts of both previous approaches, with both high informa-tion density from a compact view and position coding for depth.\\nThere is a trade-off between the beneﬁts of showing as much\\nas possible at once, to minimize the need for navigation and explo-\\nration, and the costs of showing too much at once, where the user\\nis overwhelmed by visual clutter. The goal of idiom design choicesis to ﬁnd an appropriate balance between these two ends of theinformation density continuum.\\n1.14 Why Analyze?\\nThis book is built around the premise that analyzing existing sys-\\ntems is a good stepping stone to designing new ones. When you’reconfronted with a vis problem as a designer, it can be hard to de-cide what to do. Many computer-based vis idioms and tools have', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b16d052-2e1a-4afc-ab31-a088e286d794', embedding=None, metadata={'page_label': '17', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.14. Why Analyze? 17\\nWhy?\\nHow?What?\\nFigure 1.7. Three-part analysis framework for a vis instance: why is the task being\\nperformed, what data is shown in the views, and how is the vis idiom constructed\\nin terms of design choices.\\nbeen created in the past several decades, and considering them\\none by one leaves you faced with a big collection of different pos-sibilities. There are so many possible combinations of data, tasks,and idioms that it’s unlikely that you’ll ﬁnd exactly what you needto know just by reading papers about previous vis tools. More-over, even if you ﬁnd a likely candidate, you might need to digeven deeper into the literature to understand whether there’s anyevidence that the tool was a success.\\nThis book features an analysis framework that imposes a struc-\\nture on this enormous design space, intended as a scaffold to help\\nyou think about design choices systematically. It’s offered as aguide to get you started, not as a straitjacket: there are certainlymany other possible ways to think about these problems!\\nFigure 1.7 shows the high-level framework for analyzing vis use\\naccording to three questions: what data the user sees, why the\\nuser intends to use a vis tool, and how the visual encoding and in-\\nteraction idioms are constructed in terms of design choices. Each\\nthree-fold what–why–how question has a corresponding data–task–\\nidiom answer trio. One of these analysis trios is called an instance .\\n▶Chapter 2 discusses data\\nand the question of what .\\nChapter 3 covers tasks and\\nthe question of why . Chap-\\nters 7 through 14 answerthe question of how idioms\\ncan be designed in detail.Simple vis tools can be fully described as an isolated analy-\\nsis instance, but complex vis tool usage often requires analysisin terms of a sequence of instances that are chained together. Inthese cases, the chained sequences are a way to express dependen-cies. All analysis instances have the input ofwhat data is shown;\\nin some cases, output data is produced as a result of using the\\nvis tool. Figure 1.8 shows an abstract example of a chained se-quence, where the output of a prior instance serves as the input toa subsequent one.\\nThe combination of distinguishing why from how and chained\\nsequences allows you to distinguish between means and ends in', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ddc89926-472b-4600-adb1-b5ec8c632d9d', embedding=None, metadata={'page_label': '18', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='18 1. What’s Vis, and Why Do It?\\nWhy?\\nHow?\\n What?Why?\\nHow?\\n What?Why?\\nHow?\\n What?\\nFigure 1.8. Analyzing vis usage as chained sequences of instances, where the\\noutput of one instance is the input to another.\\nyour analysis. For example, a user could sort the items shown\\nwithin the vis. That operation could be an end in itself, if the user’s\\ngoal is to produce a list of items ranked according to a particularcriterion as a result of an analysis session. Or, the sorting could be\\nthe means to another end, for example, ﬁnding outliers that do notmatch the main trend of the data; in this case, it is simply donealong the way as one of many different operations.\\n1.15 Further Reading\\nEach Further Reading section provides suggestions for further read-\\ning about some of the ideas presented in the chapter and acknowl-edges key sources that inﬂuenced the discussion.\\nWhy Use an External Representation? The role and use of external\\nrepresentations are analyzed in papers on the nature of ex-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='470119a8-5ef4-45e8-af32-7defa9708316', embedding=None, metadata={'page_label': '19', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.15. Further Reading 19\\nternal representations in problem solving [Zhang 97] and a\\nrepresentational analysis of number systems [Zhang and Nor-man 95]. The inﬂuential paper Why A Diagram Is (Sometimes)\\nWorth Ten Thousand Words is the basis for my discussion of\\ndiagrams in this chapter [Larkin and Simon 87].\\nWhy Show the Data in Detail? Anscombe proposed his quartet of illus-\\ntrative examples in a lovely, concise paper [Anscombe 73]. Anearly paper on the many faces of the scatterplot includes a\\ncogent discussion of why to show as much of the data as pos-\\nsible [Cleveland and McGill 84b].\\nWhat Is the Vis Design Space? My discussion of the vis design space\\nis based on our paper on the methodology of design studiesthat covers the question of progressing from a loose to a crispunderstanding of the user’s requirements [Sedlmair et al. 12].\\nWhat Resource Limitations Matter? Ware’s textbook provides a very thor-\\nough discussion of human limitations in terms of perception,memory, and cognition [Ware 13]. A survey paper provides agood overview of the change blindness literature [Simons 00].\\nThe idea of information density dates back to Bertin’s discus-\\nsion of graphic density [Bertin 67], and Tufte has discussed\\nthe data–ink ratio at length [Tufte 83].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2842e9c3-6ff7-4254-97d1-ce7f4837ae48', embedding=None, metadata={'page_label': '20', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Why?\\nHow?What?DatasetsWhat?\\nAttributes\\nDataset TypesData Types\\nData and Dataset Types\\nDataset Availability\\nStatic DynamicTables\\nAttributes (columns)\\nItems \\n(rows)\\nCell containing valueNetworks\\nLink\\nNode \\n(item)\\nTreesFields (Continuous)\\nGeometry (Spatial)Attributes (columns)\\nValue in cellCell\\nMultidimensional Table\\nValue in cellItems Attributes Links Positions GridsAttribute Types\\nOrdering DirectionCategorical\\nOrdered\\nOrdinal\\nQuantitative\\nSequential\\nDiverging\\nCyclicTables Networks & \\nTreesFields Geometry Clusters, \\nSets, Lists\\nItems\\nAttributesItems (nodes)\\nLinks\\nAttributesGrids\\nPositions\\nAttributesItems\\nPositionsItems\\nGrid of positions\\nPosition\\nFigure 2.1. What can be visualized: data, datasets, and attributes.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f007952d-e32a-4ee0-a625-702f6f5c2d08', embedding=None, metadata={'page_label': '21', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='What: Data AbstractionChapter 2\\n2.1 The Big Picture\\nFigure 2.1 shows the abstract types of what can be visualized. The\\nfour basic dataset types are tables, networks, ﬁelds, and geome-try; other possible collections of items include clusters, sets, andlists. These datasets are made up of different combinations of theﬁve data types: items, attributes, links, positions, and grids. Forany of these dataset types, the full dataset could be available im-mediately in the form of a static ﬁle, or it might be dynamic dataprocessed gradually in the form of a stream. The type of an at-tribute can be categorical or ordered, with a further split into or-dinal and quantitative. The ordering direction of attributes can besequential, diverging, or cyclic.\\n2.2 Why Do Data Semantics\\nand T ypes Matter?\\nMany aspects of vis design are driven by the kind of data that you\\nhave at your disposal. What kind of data are you given? Whatinformation can you ﬁgure out from the data, versus the meaningsthat you must be told explicitly? What high-level concepts willallow you to split datasets apart into general and useful pieces?\\nSuppose that you see the following data:\\n14, 2.6, 30, 30, 15, 100001\\nWhat does this sequence of six numbers mean? You can’t pos-\\nsibly know yet, without more information about how to interpreteach number. Is it locations for two points far from each otherin three-dimensional space, 14,2.6,30and 30,15,100001 ? Is it two\\npoints closer to each other in two-dimensional space, 14,2.6and\\n21', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aa233d85-d8f6-4c2f-a918-5a618734367d', embedding=None, metadata={'page_label': '22', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='22 2. What: Data Abstraction\\n30,30, with the ﬁfth number meaning that there are 15 links be-\\ntween these two points, and the sixth number assigning the weightof ‘100001’ to that link?\\nSimilarly, suppose that you see the following data:\\nBasil, 7, S, Pear\\nThese numbers and words could have many possible meanings.\\nMaybe a food shipment of produce has arrived in satisfactory con-dition on the 7th day of the month, containing basil and pears.Maybe the Basil Point neighborhood of the city has had 7 inchesof snow cleared by the Pear Creek Limited snow removal service.Maybe the lab rat named Basil has made seven attempts to ﬁndhis way through the south section of the maze, lured by scent ofthe reward food for this trial, a pear.\\nTo move beyond guesses, you need to know two crosscutting\\npieces of information about these terms: their semantics and theirtypes. The semantics of the data is its real-world meaning. For\\ninstance, does a word represent a human ﬁrst name, or is it the\\nshortened version of a company name where the full name can belooked up in an external list, or is it a city, or is it a fruit? Does anumber represent a day of the month, or an age, or a measurement\\nof height, or a unique code for a speciﬁc person, or a postal codefor a neighborhood, or a position in space?\\nThe type of the data is its structural or mathematical interpre-\\ntation. At the data level, what kind of thing is it: an item, a link, anattribute? At the dataset level, how are these data types combined\\ninto a larger structure: a table, a tree, a ﬁeld of sampled values?\\nAt the attribute level, what kinds of mathematical operations aremeaningful for it? For example, if a number represents a count ofboxes of detergent, then its type is a quantity, and adding two suchnumbers together makes sense. If the number represents a postalcode, then its type is a code rather than a quantity —it is simply\\nthe name for a category that happens to be a number rather than\\na textual name. Adding two of these numbers together does notmake sense.\\nTable 2.1 shows several more lines of the same dataset. This\\nsimple example table is tiny, with only nine rows and four columns.The exact semantics should be provided by the creator of the data-set; I give it with the column titles. In this case, each person has aunique identiﬁer, a name, an age, a shirt size, and a favorite fruit.\\nSometimes types and semantics can be correctly inferred simply\\nby observing the syntax of a data ﬁle or the names of variables', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3aeb61f2-3e59-4274-aa0f-26d99e46f727', embedding=None, metadata={'page_label': '23', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.3. Data T ypes 23\\nID Name Age Shirt Size Favorite Fruit\\n1 Amy 8 S Apple\\n2 Basil 7 S Pear3 Clara 9 M Durian\\n4 Desmond 13 L Elderberry\\n5 Ernest 12 L Peach6 Fanny 10 S Lychee7 George 9 M Orange8 Hector 8 L Loquat9 Ida 10 M Pear10 Amy 12 M Orange\\nTable 2.1. A full table with column titles that provide the intended semantics of the\\nattributes.\\nwithin it, but often they must be provided along with the dataset\\nin order for it to be interpreted correctly. Sometimes this kind ofadditional information is called metadata ; the line between data\\nand metadata is not clear, especially given that the original datais often derived and transformed. In this book, I don’t distinguish\\n▶Deriving data is dis-\\ncussed in Section 3.4.2.3.\\nbetween them, and refer to everything as data .\\nThe classiﬁcation below presents a way to think about dataset\\nand attribute types and semantics in a way that is general enoughto cover the cases interesting in vis, yet speciﬁc enough to be help-ful for guiding design choices at the abstraction and idiom levels.\\n2.3 Data T ypes\\nFigure 2.2 shows the ﬁve basic data types discussed in this book:\\nitems, attributes, links, positions, and grids. An attribute is some\\nspeciﬁc property that can be measured, observed, or logged.⋆For⋆Synonyms for attribute\\nare variable and data di-\\nmension , or just dimen-\\nsion for short. Since dimen-\\nsion has many meanings, in\\nthis book it is reserved for\\nthe visual channels of spa-\\ntial position as discussed inSection 6.3.example, attributes could be salary, price, number of sales, pro-\\ntein expression levels, or temperature. An item is an individual\\nentity that is discrete, such as a row in a simple table or a node\\nData Types\\nItems Attributes Links Positions Grids\\nFigure 2.2. The ﬁve basic data types: items, attributes, links, positions, and grids.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7d20c0db-63f6-481b-9c27-be3730740ffa', embedding=None, metadata={'page_label': '24', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='24 2. What: Data Abstraction\\nin a network. For example, items may be people, stocks, coffee\\nshops, genes, or cities. A link is a relationship between items, typ-\\nically within a network. A grid speciﬁes the strategy for sampling\\ncontinuous data in terms of both geometric and topological rela-\\ntionships between its cells. A position is spatial data, providing a\\nlocation in two-dimensional (2D) or three-dimensional (3D) space.For example, a position might be a latitude–longitude pair describ-ing a location on the Earth’s surface or three numbers specifying alocation within the region of space measured by a medical scanner.\\n2.4 Dataset T ypes\\nAdataset is any collection of information that is the target of anal-\\nysis.⋆The four basic dataset types are tables, networks, ﬁelds, and⋆The word dataset is sin-\\ngular. In vis the word data\\nis commonly used as a sin-\\ngular mass noun as well,in contrast to the traditionalusage in the natural sci-ences where data is plural.geometry. Other ways to group items together include clusters,\\nsets, and lists. In real-world situations, complex combinations of\\nthese basic types are common.\\nFigure 2.3 shows that these basic dataset types arise from com-\\nbinations of the data types of items, attributes, links, positions,and grids.\\nFigure 2.4 shows the internal structure of the four basic dataset\\ntypes in detail. Tables have cells indexed by items and attributes,for either the simple ﬂat case or the more complex multidimen-sional case. In a network, items are usually called nodes, andthey are connected with links; a special case of networks is trees.Continuous ﬁelds have grids based on spatial positions where cellscontain attributes. Spatial geometry has only position information.\\nData and Dataset Types\\nTables Networks & \\nTreesFields Geometry Clusters, \\nSets, Lists\\nItems\\nAttributesItems (nodes)\\nLinks\\nAttributesGrids\\nPositions\\nAttributesItems\\nPositionsItems\\nFigure 2.3. The four basic dataset types are tables, networks, ﬁelds, and geome-\\ntry; other possible collections of items are clusters, sets, and lists. These datasetsare made up of ﬁve core data types: items, attributes, links, positions, and grids.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='73d13ac5-5bd6-4a7e-805a-0517797fefd8', embedding=None, metadata={'page_label': '25', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.4. Dataset T ypes 25\\nTables\\nAttributes (columns)\\nItems \\n(rows)\\nCell containing valueNetworks\\nLink\\nNode \\n(item)\\nTreesFields (Continuous)\\nAttributes (columns)\\nValue in cellCell\\nMultidimensional Table\\nValue in cellGrid of positionsGeometry (Spatial)\\nPositionDataset Types\\nFigure 2.4. The detailed structure of the four basic dataset types.\\n2.4.1 T ables\\nMany datasets come in the form of tables that are made up of\\nrows and columns, a familiar form to anybody who has used aspreadsheet. In this chapter, I focus on the concept of a table assimply a type of dataset that is independent of any particular visualrepresentation; later chapters address the question of what visualrepresentations are appropriate for the different types of datasets.\\n▶Chapter 7 covers how to\\narrange tables spatially.\\nFor a simple ﬂat table , the terms used in this book are that each\\nrow represents an item of data, and each column is an attribute of\\nthe dataset. Each cell in the table is fully speciﬁed by the com-\\nbination of a row and a column—an item and an attribute—andcontains a value for that pair. Figure 2.5 shows an example of\\nthe ﬁrst few dozen items in a table of orders, where the attributesare order ID, order date, order priority, product container, productbase margin, and ship date.\\nAmultidimensional table has a more complex structure for in-\\ndexing into a cell, with multiple keys.▶Keys and values are\\ndiscussed further in Sec-\\ntion 2.6.1.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d3a0b051-a6d6-4121-a980-a0e2500a09a7', embedding=None, metadata={'page_label': '26', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='26 2. What: Data Abstraction\\n20\\nFieldattribute\\nitem cell\\nFigure 2.5. In a simple table of orders, a row represents an item , a column rep-\\nresents an attribute , and their intersection is the cell containing the value for that\\npairwise combination.\\n2.4.2 Networks and T rees\\nThe dataset type of networks is well suited for specifying that there\\nis some kind of relationship between two or more items.⋆An item in⋆A synonym for networks\\nisgraphs . The word graph\\nis also deeply overloaded invis. Sometimes it is usedto mean network as we dis-\\ncuss here, for instance in\\nthe vis subﬁeld called graph\\ndrawing or the mathemat-\\nical subﬁeld called graph\\ntheory . Sometimes it is\\nused in the ﬁeld of statisti-\\ncal graphics to mean chart ,\\nas in bar graphs and linegraphs.a network is often called a node .⋆Alink is a relation between two\\n⋆A synonym for node is\\nvertex .items.⋆For example, in an articulated social network the nodes\\n⋆A synonym for link is\\nedge .are people, and links mean friendship. In a gene interaction net-\\nwork, the nodes are genes, and links between them mean thatthese genes have been observed to interact with each other. In acomputer network, the nodes are computers, and the links repre-sent the ability to send messages directly between two computers\\nusing physical cables or a wireless connection.\\nNetwork nodes can have associated attributes, just like items in\\na table. In addition, the links themselves could also be consideredto have attributes associated with them; these may be partly orwholly disjoint from the node attributes.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0a8b8e5-9ec2-4a69-8fd2-2a54c2cf3210', embedding=None, metadata={'page_label': '27', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.4. Dataset T ypes 27\\nIt is again important to distinguish between the abstract con-\\ncept of a network and any particular visual layout of that networkwhere the nodes and edges have particular spatial positions. Thischapter concentrates on the former.▶The spatial arrangement\\nof networks is covered in\\nChapter 9.\\n2.4.2.1 T rees\\nNetworks with hierarchical structure are more speciﬁcally called\\ntrees . In contrast to a general network, trees do not have cycles:\\neach child node has only one parent node pointing to it. One exam-ple of a tree is the organization chart of a company, showing whoreports to whom; another example is a tree showing the evolu-tionary relationships between species in the biological tree of life,where the child nodes of humans and monkeys both share thesame parent node of primates.\\n2.4.3 Fields\\nThe ﬁeld dataset type also contains attribute values associated\\nwith cells.1Each cell in a ﬁeld contains measurements or calcula-\\ntions from a continuous domain: there are conceptually inﬁnitely\\nmany values that you might measure, so you could always take\\na new measurement between any two existing ones. Continuousphenomena that might be measured in the physical world or simu-lated in software include temperature, pressure, speed, force, anddensity; mathematical functions can also be continuous.\\nFor example, consider a ﬁeld dataset representing a medical\\nscan of a human body containing measurements indicating the\\ndensity of tissue at many sample points, spread regularly through-out a volume of 3D space. A low-resolution scan would have262,144 cells, providing information about a cubical volume ofspace with 64 bins in each direction. Each cell is associated witha speciﬁc region in 3D space. The density measurements couldbe taken closer together with a higher resolution grid of cells, orfurther apart for a coarser grid.\\nContinuous data requires careful treatment that takes into ac-\\ncount the mathematical questions of sampling , how frequently to\\n1My use of the term ﬁeld is related to but not identical to its use in the math-\\nematics literature, where it denotes a mapping from a domain to a range. In this\\ncase, the domain is a Euclidean space of one, two, or three dimensions, and the ad-\\njective modifying ﬁeld is a statement about the range: scalars ,vectors ,o r tensors .\\nAlthough the term ﬁeld by itself is not commonly found in the literature, when I\\nuse it without an adjective I’m emphasizing the continuous nature of the domain,\\nrather than speciﬁcs of the ranges of scalars, vectors, or tensors.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27cef819-7164-4d7b-a969-5cdb6ffe8197', embedding=None, metadata={'page_label': '28', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='28 2. What: Data Abstraction\\ntake the measurements, and interpolation , how to show values in\\nbetween the sampled points in a way that does not mislead. In-terpolating appropriately between the measurements allows youtoreconstruct a new view of the data from an arbitrary viewpoint\\nthat’s faithful to what you measured. These general mathematicalproblems are studied in areas such as signal processing and statis-tics. Visualizing ﬁelds requires grappling extensively with theseconcerns.\\nIn contrast, the table and network datatypes discussed above\\nare an example of discrete data where a ﬁnite number of individ-\\nual items exist, and interpolation between them is not a mean-\\ningful concept. In the cases where a mathematical framework isnecessary, areas such as graph theory and combinatorics providerelevant ideas.\\n2\\n2.4.3.1 Spatial Fields\\nContinuous data is often found in the form of a spatial ﬁeld , where\\nthe cell structure of the ﬁeld is based on sampling at spatial po-sitions. Most datasets that contain inherently spatial data occurin the context of tasks that require understanding aspects of itsspatial structure, especially shape.\\nFor example, with a spatial ﬁeld dataset that is generated with a\\nmedical imaging instrument, the user’s task could be to locate sus-pected tumors that can be recognized through distinctive shapes ordensities. An obvious choice for visual encoding would be to showsomething that spatially looks like an X-ray image of the humanbody and to use color coding to highlight suspected tumors. An-other example is measurements made in a real or simulated windtunnel of the temperature and pressure of air ﬂowing over airplanewings at many points in 3D space, where the task is to comparethe ﬂow patterns in different regions. One possible visual encod-ing would use the geometry of the wing as the spatial substrate,showing the temperature and pressure using size-coded arrows.\\nThe likely tasks faced by users who have spatial ﬁeld data con-\\nstrains many of the choices about the use of space when designingvisual encoding idioms. Many of the choices for nonspatial data ,\\nwhere no information about spatial position is provided with thedataset, are unsuitable in this case.\\n⋆⋆A synonym for nonspatial\\ndata isabstract data .\\n2Technically, all data stored within a computer is discrete rather than continu-\\nous; however, the interesting question is whether the underlying semantics of the\\nbits that are stored represents samples of a continuous phenomenon or intrinsically\\ndiscrete data.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13c2d326-65a3-407b-9e5b-e25ff110bc17', embedding=None, metadata={'page_label': '29', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.4. Dataset T ypes 29\\nThus, the question of whether a dataset has the type of a spa-\\ntial ﬁeld or a nonspatial table has extensive and far-reaching im-plications for idiom design. Historically, vis diverged into areas ofspecialization based on this very differentiation. The subﬁeld ofscientiﬁc visualization ,o r scivis for short, is concerned with situ-\\nations where spatial position is given with the dataset. A central\\nconcern in scivis is handling continuous data appropriately withinthe mathematical framework of signal processing. The subﬁeld ofinformation visualization ,o r infovis for short, is concerned with sit-\\nuations where the use of space in a visual encoding is chosen by\\nthe designer. A central concern in infovis is determining whetherthe chosen idiom is suitable for the combination of data and task,leading to the use of methods from human–computer interactionand design.\\n2.4.3.2 Grid T ypes\\nWhen a ﬁeld contains data created by sampling at completely reg-\\nular intervals, as in the previous example, the cells form a uniform\\ngrid . There is no need to explicitly store the grid geometry in terms\\nof its location in space, or the grid topology in terms of how each\\ncell connects with its neighboring cells. More complicated exam-ples require storing different amounts of geometric and topologicalinformation about the underlying grid. A rectilinear grid supports\\nnonuniform sampling, allowing efﬁcient storage of information that\\nhas high complexity in some areas and low complexity in others, at\\nthe cost of storing some information about the geometric location ofeach each row. A structured grid allows curvilinear shapes, where\\nthe geometric location of each cell needs to be speciﬁed. Finally,unstructured grids provide complete ﬂexibility, but the topological\\ninformation about how the cells connect to each other must be\\nstored explicitly in addition to their spatial positions.\\n2.4.4 Geometry\\nThe geometry dataset type speciﬁes information about the shape\\nof items with explicit spatial positions. The items could be points,or one-dimensional lines or curves, or 2D surfaces or regions, or3D volumes.\\nGeometry datasets are intrinsically spatial, and like spatial ﬁelds\\nthey typically occur in the context of tasks that require shape un-derstanding. Spatial data often includes hierarchical structure atmultiple scales. Sometimes this structure is provided intrinsically', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ea99e91-5c46-47b7-a638-20ec884b5e1c', embedding=None, metadata={'page_label': '30', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='30 2. What: Data Abstraction\\nwith the dataset, or a hierarchy may be derived from the original\\ndata.\\nGeometry datasets do not necessarily have attributes, in con-\\ntrast to the other three basic dataset types. Many of the design\\nissues in vis pertain to questions about how to encode attributes.Purely geometric data is interesting in a vis context only when itis derived or transformed in a way that requires consideration ofdesign choices. One classic example is when contours are derived\\n▶Section 3.4.2.3 covers\\nderiving data.\\nfrom a spatial ﬁeld. Another is when shapes are generated at an\\n▶Section 8.4 covers gen-\\nerating contours from scalar\\nﬁelds.appropriate level of detail for the task at hand from raw geographic\\ndata, such as the boundaries of a forest or a city or a country, orthe curve of a road. The problem of how to create images from a ge-ometric description of a scene falls into another domain: computergraphics. While vis draws on algorithms from computer graphics,it has different concerns from that domain. Simply showing a geo-\\nmetric dataset is not an interesting problem from the point of viewof a vis designer.\\nGeometric data is sometimes shown alone, particularly when\\nshape understanding is the primary task. In other cases, it is thebackdrop against which additional information is overlaid.\\n2.4.5 Other Combinations\\nBeyond tables, there are many ways to group multiple items to-\\ngether, including sets, lists, and clusters. A set is simply an un-\\nordered group of items. A group of items with a speciﬁed orderingcould be called a list.\\n⋆Acluster is a grouping based on attribute ⋆In computer science, ar-\\nray is often used as a syn-\\nonym for list.similarity, where items within a cluster are more similar to each\\nother than to ones in another cluster.\\nThere are also more complex structures built on top of the basic\\nnetwork type. A path through a network is an ordered set of seg-\\nments formed by links connecting nodes. A compound network is\\na network with an associated tree: all of the nodes in the network\\nare the leaves of the tree, and interior nodes in the tree provide ahierarchical structure for the nodes that is different from networklinks between them.\\nMany other kinds of data either ﬁt into one of the previous cat-\\negories or do so after transformations to create derived attributes.\\nComplex and hybrid combinations, where the complete dataset\\ncontains multiple basic types, are common in real-world applica-tions.\\nThe set of basic types presented above is a starting point for\\ndescribing the what part of an analysis instance that pertains to', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='215535e4-5abd-41c8-ba93-2acdd098eec4', embedding=None, metadata={'page_label': '31', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.5. Attribute T ypes 31\\nDataset Availability\\nStatic Dynamic\\nFigure 2.6. Dataset availability can be either static or dynamic, for any dataset\\ntype.\\ndata; that is, the data abstraction . In simple cases, it may be possi-\\nble to describe your data abstraction using only that set of terms.In complex cases, you may need additional description as well.If so, your goal should be to translate domain-speciﬁc terms intowords that are as generic as possible.\\n2.4.6 Dataset Availability\\nFigure 2.6 shows the two kinds of dataset availability: static or\\ndynamic .\\nThe default approach to vis assumes that the entire dataset is\\navailable all at once, as a static ﬁle . However, some datasets are\\ninstead dynamic streams , where the dataset information trickles in\\nover the course of the vis session.⋆One kind of dynamic change is ⋆A synonym for dynamic\\nisonline , and a synonym\\nforstatic isofﬂine .to add new items or delete previous items. Another is to change\\nthe values of existing items.\\nThis distinction in availability crosscuts the basic dataset types:\\nany of them can be static or dynamic. Designing for streaming\\ndata adds complexity to many aspects of the vis process that arestraightforward when there is complete dataset availability up front.\\n2.5 Attribute T ypes\\nFigure 2.7 shows the attribute types. The major disinction is be-\\ntween categorical versus ordered. Within the ordered type is afurther differentiation between ordinal versus quantitative. Or-\\ndered data might range sequentially from a minimum to a maxi-mum value, or it might diverge in both directions from a zero pointin the middle of a range, or the values may wrap around in a cycle.\\nAlso, attributes may have hierarchical structure.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6fea6d4d-faf9-4bd7-a195-00c39b0f1616', embedding=None, metadata={'page_label': '32', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='32 2. What: Data Abstraction\\nAttributes\\nAttribute Types\\nOrdering DirectionCategorical Ordered\\nOrdinal Quantitative\\nSequential Diverging Cyclic\\nFigure 2.7. Attribute types are categorical, ordinal, or quantitative. The direction\\nof attribute ordering can be sequential, diverging, or cyclic.\\n2.5.1 Categorical\\nThe ﬁrst distinction is between categorical and ordered data. The\\ntype of categorical data, such as favorite fruit or names, does not\\nhave an implicit ordering, but it often has hierarchical structure.⋆⋆A synonym for categori-\\ncalisnominal . Categories can only distinguish whether two things are the same\\n(apples) or different (apples versus oranges). Of course, any ar-bitrary external ordering can be imposed upon categorical data.Fruit could be ordered alphabetically according to its name, orby its price—but only if that auxiliary information were available.\\nHowever, these orderings are not implicit in the attribute itself, the\\nway they are with quantitative or ordered data. Other examples ofcategorical attributes are movie genres, ﬁle types, and city names.\\n2.5.2 Ordered: Ordinal and Quantitative\\nAllordered data does have an implicit ordering, as opposed to un-\\nordered categorical data. This type can be further subdivided. With\\nordinal data, such as shirt size, we cannot do full-ﬂedged arith-\\nmetic, but there is a well-deﬁned ordering. For example, largeminus medium is not a meaningful concept, but we know thatmedium falls between small and large. Rankings are another kind', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='764c7b24-4328-4f25-b99d-15fdbc37dfa3', embedding=None, metadata={'page_label': '33', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.5. Attribute T ypes 33\\nof ordinal data; some examples of ordered data are top-ten lists of\\nmovies or initial lineups for sports tournaments depending on pastperformance.\\nA subset of ordered data is quantitative data, namely, a mea-\\nsurement of magnitude that supports arithmetic comparison. Forexample, the quantity of 68 inches minus 42 inches is a mean-ingful concept, and the answer of 26 inches can be calculated.Other examples of quantitative data are height, weight, tempera-ture, stock price, number of calling functions in a program, and\\nnumber of drinks sold at a coffee shop in a day. Both integers and\\nreal numbers are quantitative data.\\n3\\nIn this book, the ordered type is used often; the ordinal type is\\nonly occasionally mentioned, when the distinction between it andthe quantitative type matters.\\n2.5.2.1 Sequential versus Diverging\\nOrdered data can be either sequential , where there is a homoge-\\nneous range from a minimum to a maximum value, or diverging ,\\nwhich can be deconstructed into two sequences pointing in oppo-site directions that meet at a common zero point. For instance,a mountain height dataset is sequential, when measured from a\\nminimum point of sea level to a maximum point of Mount Everest.Abathymetric dataset is also sequential, with sea level on one end\\nand the lowest point on the ocean ﬂoor at the other. A full elevation\\ndataset would be diverging, where the values go up for mountains\\non land and down for undersea valleys, with the zero value of sea\\nlevel being the common point joining the two sequential datasets.\\n2.5.2.2 Cyclic\\nOrdered data may be cyclic , where the values wrap around back\\nto a starting point rather than continuing to increase indeﬁnitely.\\nMany kinds of time measurements are cyclic, including the hourof the day, the day of the week, and the month of the year.\\n2.5.3 Hierarchical Attributes\\nThere may be hierarchical structure within an attribute or between\\nmultiple attributes. The daily stock prices of companies collected\\n3In some domains the quantitative category is further split into interval versus\\nratio data [Stevens 46]; this distinction is typically not useful when designing a\\nvisual encoding, so in this book these types remain collapsed together into this\\nsingle category.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4d020cb4-1881-4f64-8813-c0dfbf3ba7e8', embedding=None, metadata={'page_label': '34', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='34 2. What: Data Abstraction\\nover the course of a decade is an example of a time-series data-\\nset, where one of the attributes is time. In this case, time can beaggregated hierarchically, from individual days up to weeks, up tomonths, up to years. There may be interesting patterns at mul-tiple temporal scales, such as very strong weekly variations forweekday versus weekend, or more subtle yearly patterns show-ing seasonal variations in summer versus winter. Many kinds ofattributes might have this sort of hierarchical structure: for exam-ple, the geographic attribute of a postal code can be aggregated upto the level of cities or states or entire countries.\\n▶Section 13.4 covers hi-\\nerarchical aggregation inmore detail, and Section 7.5\\ncovers the visual encoding\\nof attribute hierarchies.\\n2.6 Semantics\\nKnowing the type of an attribute does not tell us about its seman-\\ntics, because these two questions are crosscutting: one does notdictate the other. Different approaches to considering the seman-tics of attributes that have been proposed across the many ﬁeldswhere these semantics are studied. The classiﬁcation in this bookis heavily focused on the semantics of keys versus values, and therelated questions of spatial and continuous data versus nonspa-tial and discrete data, to match up with the idiom design choiceanalysis framework. One additional consideration is whether anattribute is temporal.\\n2.6.1 Key versus Value Semantics\\nAkey attribute acts as an index that is used to look up value at-\\ntributes.⋆The distinction between key and value attributes is im-⋆A synonym for key at-\\ntribute isindependent at-\\ntribute . A synonym for\\nvalue attribute isdepen-\\ndent attribute . The lan-\\nguage of independent anddependent is common instatistics. In the languageof data warehouses, a syn-onym for independent isdi-\\nmension , and a synonym\\nfordependent ismeasure .portant for the dataset types of tables and ﬁelds, as shown in Fig-\\nure 2.8.\\n2.6.1.1 Flat T ables\\nA simple ﬂat table has only one key, where each item corresponds\\nto a row in the table, and any number of value attributes. In thiscase, the key might be completely implicit, where it’s simply the in-dex of the row. It might be explicit, where it is contained within the\\ntable as an attribute. In this case, there must not be any duplicate\\nvalues within that attribute. In tables, keys may be categorical orordinal attributes, but quantititive attributes are typically unsuit-able as keys because there is nothing to prevent them from havingthe same values for multiple items.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4787bc1e-7f15-48ae-99f1-210b3f806d73', embedding=None, metadata={'page_label': '35', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.6. Semantics 35\\nTables\\nAttributes (columns)\\nItems \\n(rows)\\nCell containing value\\nMultidimensional Table\\nValue in cellFields (Continuous)\\nAttributes (columns)\\nValue in cellCellGrid of positions\\nFigure 2.8. Key and value semantics for tables and ﬁelds.\\nFor example, in Table 2.1, Name is a categorical attribute that\\nmight appear to be a reasonable key at ﬁrst, but the last line shows\\nthat two people have the same name, so it is not a good choice. Fa-\\nvorite Fruit is clearly not a key, despite being categorical, because\\nPear appears in two different rows. The quantitative attribute of\\nAge has many duplicate values, as does the ordinal attribute of\\nShirt Size . The ﬁrst attribute in this ﬂat table has an explicit unique\\nidentiﬁer that acts as the key.4This key attribute could either be\\nordinal, for example if the order that the rows were entered intothe table captures interesting temporal information, or categorical,if it’s simply treated as a unique code.\\nFigure 2.9 shows the order table from Figure 2.5 where each\\nattribute is colored according to its type. There is no explicit key:even the Order ID attribute has duplicates, because orders consist\\nof multiple items with different container sizes, so it does not actas a unique identiﬁer. This table is an example of using an implicitkey that is the row number within the table.\\n4It’s common to store the key attribute in the ﬁrst column, for understandability\\nby people and ease of building data structures by computers.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1ce80293-8c88-4b16-bdd6-45b73c35eff4', embedding=None, metadata={'page_label': '36', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='36 2. What: Data Abstraction\\n22\\n1 = Quantitative\\n2 = Nominal3 = Ordinal\\n1 = Quantitat i\\nv\\ne\\n222 = Nominal\\n333= O\\nr\\ndinal quantitative\\n ordinal categorical\\nFigure 2.9. The order table with the attribute columns colored by their type; none\\nof them is a key.\\n2.6.1.2 Multidimensional T ables\\nThe more complex case is a multidimensional table , where multi-\\nple keys are required to look up an item. The combination of allkeys must be unique for each item, even though an individual keyattribute may contain duplicates. For example, a common multidi-mensional table from the biology domain has a gene as one key and\\ntime as another key, so that the value in each cell is the activity\\nlevel of a gene at a particular time.\\nThe information about which attributes are keys and which are\\nvalues may not be available; in many instances determining which\\nattributes are independent keys versus dependent values is the\\ngoal of the vis process, rather than its starting point. In this case,the successful outcome of analysis using vis might be to recast aﬂat table into a more semantically meaningful multidimensionaltable.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='06d229c3-6cdc-4f36-9bfa-56787b122f2f', embedding=None, metadata={'page_label': '37', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.6. Semantics 37\\n2.6.1.3 Fields\\nAlthough ﬁelds differ from tables a fundamental way because they\\nrepresent continuous rather than discrete data, keys and valuesare still central concerns. (Different vocabulary for the same basicidea is more common with spatial ﬁeld data, where the term in-\\ndependent variable is used instead of key , and dependent variable\\ninstead of value .)\\nFields are structured by sampling in a systematic way so that\\neach grid cell is spanned by a unique range from a continuousdomain. In spatial ﬁelds, spatial position acts as a quantitativekey, in contrast to a nonspatial attribute in the case of a table thatis categorical or ordinal. The crucial difference between ﬁelds andtables is that useful answers for attribute values are returned forlocations throughout the sampled range, not just the exact pointswhere data was recorded.\\nFields are typically characterized in terms of the number of keys\\nversus values. Their multivariate structure depends on the number\\nof value attributes, and their multidimensional structure depends\\non the number of keys. The standard multidimensional cases are2D and 3D ﬁelds for static measurements taken in two or threespatial dimensions,\\n5and ﬁelds with three or four keys, in the case\\nwhere these measurements are time-varying. A ﬁeld can be bothmultidimensional and multivariate if it has multiple keys and mul-tiple values. The standard classiﬁcation according to multivariatestructure is that a scalar ﬁeld has one attribute per cell, a vector\\nﬁeld has two or more attributes per cell, and a tensor ﬁeld has\\nmany attributes per cell.\\n⋆⋆ These deﬁnitions of\\nscalar ,vector , and ten-\\nsor follow the common\\nusage in vis. In a strictmathematical sense, thesedistinctions are not techni-cally correct, since scalarsand vectors are included\\nas a degenerate case\\nof tensors. Mapping themathematical usage to thevis usage, scalars mean\\nmathematical tensors oforder 0, vectors mean\\nmathematical tensors of\\norder 1, and tensors mean\\nmathematical tensors oforder 2 or more.2.6.1.4 Scalar Fields\\nAscalar ﬁeld is univariate, with a single value attribute at each\\npoint in space. One example of a 3D scalar ﬁeld is the time-varyingmedical scan above; another is the temperature in a room at eachpoint in 3D space. The geometric intuition is that each point ina scalar ﬁeld has a single value. A point in space can have sev-eral different numbers associated with it; if there is no underlyingconnection between them then they are simply multiple separatescalar ﬁelds.\\n2.6.1.5 Vector Fields\\nAvector ﬁeld is multivariate, with a list of multiple attribute values\\nat each point. The geometric intuition is that each point in a vector\\n5It’s also possible for a spatial ﬁeld to have just one key.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4bc84cd3-f3ef-48bd-9ab7-e7d3b474b712', embedding=None, metadata={'page_label': '38', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='38 2. What: Data Abstraction\\nﬁeld has a direction and magnitude, like an arrow that can point in\\nany direction and that can be any length. The length might meanthe speed of a motion or the strength of a force. A concrete exampleof a 3D vector ﬁeld is the velocity of air in the room at a speciﬁc timepoint, where there is a direction and speed for each item. The di-mensionality of the ﬁeld determines the number of components inthe direction vector; its length can be computed directly from thesecomponents, using the standard Euclidean distance formula. Thestandard cases are two, three, or four components, as above.\\n2.6.1.6 T ensor Fields\\nAtensor ﬁeld has an array of attributes at each point, representing\\na more complex multivariate mathematical structure than the listof numbers in a vector. A physical example is stress, which in thecase of a 3D ﬁeld can be deﬁned by nine numbers that representforces acting in three orthogonal directions. The geometric intution\\nis that the full information at each point in a tensor ﬁeld cannot be\\nrepresented by just an arrow and would require a more complexshape such as an ellipsoid.\\n2.6.1.7 Field Semantics\\nThis categorization of spatial ﬁelds requires knowledge of the at-\\ntribute semantics and cannot be determined from type informa-\\ntion alone. If you are given a ﬁeld with multiple measured values\\nat each point and no further information, there is no sure way toknow its structure. For example, nine values could represent manythings: nine separate scalar ﬁelds, or a mix of multiple vector ﬁeldsand scalar ﬁelds, or a single tensor ﬁeld.\\n2.6.2 T emporal Semantics\\nAtemporal attribute is simply any kind of information that re-\\nlates to time. Data about time is complicated to handle because\\nof the rich hierarchical structure that we use to reason about time,and the potential for periodic structure. The time hierarchy isdeeply multiscale: the scale of interest could range anywhere fromnanoseconds to hours to decades to millennia. Even the commonwords time and date are a way to partially specify the scale of tem-\\nporal interest. Temporal analysis tasks often involve ﬁnding or ver-ifying periodicity either at a predetermined scale or at some scalenot known in advance. Moreover, the temporal scales of interest\\ndo not all ﬁt into a strict hierarchy; for instance, weeks do not ﬁt', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='653b0bab-b956-433b-b978-8f2fe06edd5a', embedding=None, metadata={'page_label': '39', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2.6. Semantics 39\\ncleanly into months. Thus, the generic vis problems of transforma-\\ntion and aggregation are often particularly complex when dealingwith temporal data. One important idea is that even though the▶Section 3.4.2.3 intro-\\nduces the problem ofdata transformation. Sec-tion 13.4 discusses the\\nquestion of aggregation in\\ndetail. dataset semantics involves change over time, there are many ap-\\nproaches to visually encoding that data—and only one of them isto show it changing over time in the form of an animation.\\n▶Vision versus memory is\\ndiscussed further in Sec-\\ntion 6.5.Temporal attributes can have either value or key semantics. Ex-\\namples of temporal attributes with dependent value semantics area duration of elapsed time or the date on which a transaction oc-curred. In both spatial ﬁelds and abstract tables, time can be anindependent key. For example, a time-varying medical scan canhave the independent keys of x, y, z, t to cover spatial position and\\ntime, with the dependent value attribute of density for each com-bination of four indices to look up position and time. A temporalkey attribute is usually considered to have a quantitative type, al-though it’s possible to consider it as ordinal data if the duration\\nbetween events is not interesting.\\n2.6.2.1 Time-Varying Data\\nA dataset has time-varying semantics when time is one of the key\\nattributes, as opposed to when the temporal attribute is a valuerather than a key. As with other decisions about semantics, thequestion of whether time has key or value semantics requires ex-ternal knowledge about the nature of the dataset and cannot bemade purely from type information. An example of a dataset withtime-varying semantics is one created with a sensor network thattracks the location of each animal within a herd by taking newmeasurements every second. Each animal will have new locationdata at every time point, so the temporal attribute is an indepen-dent key and is likely to be a central aspect of understanding thedataset. In contrast, a horse-racing dataset covering a year’s worthof races could have temporal value attributes such as the race starttime and the duration of each horse’s run. These attributes do in-deed deal with temporal information, but the dataset is not time-varying.\\nA common case of temporal data occurs in a time-series dataset,\\nnamely, an ordered sequence of time–value pairs. These datasets\\nare a special case of tables, where time is the key. These time-\\nvalue pairs are often but not always spaced at uniform temporalintervals. Typical time-series analysis tasks involve ﬁnding trends,correlations, and variations at multiple time scales such as hourly,daily, weekly, and seasonal.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0ff9f722-6694-4b5b-aeb3-9249c7a752ed', embedding=None, metadata={'page_label': '40', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='40 2. What: Data Abstraction\\nThe word dynamic is often used ambiguously to mean one of\\ntwo very different things. Some use it to mean a dataset has time-\\nvarying semantics, in contrast to a dataset where time is not a key\\nattribute, as discussed here. Others use it to mean a dataset has\\nstream type, in contrast to an unchanging ﬁle that can be loaded\\nall at once. In this latter sense, items and attributes can be added▶The dataset types of dy-\\nnamic streams versus staticﬁles are discussed in Sec-tion 2.4.6.\\nor deleted and their values may change during a running session\\nof a vis tool. I carefully distinguish between these two meaningshere.\\n2.7 Further Reading\\nThe Big Picture The framework presented here was inspired in part\\nby the many taxonomies of data that have been previouslyproposed, including the synthesis chapter at the beginning of\\nan early collection of infovis readings [Card et al. 99], a tax-onomy that emphasizes the division between continuous anddiscrete data [Tory and M ¨oller 04a], and one that emphasizes\\nboth data and tasks [Shneiderman 96].\\nField Datasets Several books discuss the spatial ﬁeld dataset type\\nin far more detail, including two textbooks [Telea 07, Wardet al. 10], a voluminous handbook [Hansen and Johnson 05],and the vtk book [Schroeder et al. 06].\\nAttribute T ypes The attribute types of categorical, ordered, and quan-\\ntitative were proposed in the seminal work on scales of mea-surement from the psychophysics literature [Stevens 46].Scales of measurement are also discussed extensively in thebook The Grammar of Graphics [Wilkinson 05] and are used\\nas the foundational axes of an inﬂuential vis design space\\ntaxonomy [Card and Mackinlay 97].\\nKey and Value Semantics The Polaris vis system, which has been com-\\nmercialized as Tableau, is built around the distinction be-tween key attributes (independent dimensions) and value at-tributes (dependent measures) [Stolte et al. 02].\\nT emporal Semantics A good resource for time-oriented data vis\\nis a recent book, Visualization of Time-Oriented Data [Aigner\\net al. 11].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eff98820-7df0-4e39-a9d1-54665193598c', embedding=None, metadata={'page_label': '41', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='This page intentionally left blankThis page intentionally left blank', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d0555fba-18db-4feb-a31f-16e80cee7bc8', embedding=None, metadata={'page_label': '42', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='TrendsActions\\nAnalyze\\nSearch\\nQueryWhy?\\nAll Data\\nOutliers Features\\nAttributes\\nOne Many\\nDistribution Dependency Correlation Similarity\\nNetwork Data\\nSpatial Data\\nShapeTopology\\nPathsExtremesConsume\\nPresent Enjoy Discover\\nProduce\\nAnnotate Record Derive\\nIdentify Compare Summarizetag\\nTarget known Target unknown\\nLocation \\nknown\\nLocation \\nunknownLookup\\nLocateBrowse\\nExploreTargets\\nWhy?\\nHow?What?\\nFigure 3.1. Why people are using vis in terms of actions and targets.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8fe6481b-ed52-4edd-96dc-ebd41fe54e3a', embedding=None, metadata={'page_label': '43', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Why: T ask AbstractionChapter 3\\n3.1 The Big Picture\\nFigure 3.1 breaks down into actions and targets the reasons why\\na vis tool is being used. The highest-level actions are to use visto consume or produce information. The cases for consuming areto present, to discover, and to enjoy; discovery may involve gen-\\nerating or verifying a hypothesis. At the middle level, search can\\nbe classiﬁed according to whether the identity and location of tar-gets are known or not: both are known with lookup, the target isknown but its location is not for locate, the location is known butthe target is not for browse, and neither the target nor the location\\nare known for explore. At the low level, queries can have three\\nscopes: identify one target, compare some targets, and summarizeall targets. Targets for all kinds of data are ﬁnding trends and out-liers. For one attribute, the target can be one value, the extremesof minimum and maximum values, or the distribution of all valuesacross the entire attribute. For multiple attributes, the target can\\nbe dependencies, correlations, or similarities between them. The\\ntarget with network data can be topology in general or paths inparticular, and with spatial data the target can be shape.\\n3.2 Why Analyze T asks Abstractly?\\nThis framework encourages you to consider tasks in abstract form,\\nrather than the domain-speciﬁc way that users typically thinkabout them.\\nTransforming task descriptions from domain-speciﬁc language\\ninto abstract form allows you to reason about similarities and dif-ferences between them. Otherwise, it’s hard to make useful com-parisons between domain situations, because if you don’t do thiskind of translation then everything just appears to be different.That apparent difference is misleading: there are a lot of similar-\\n43', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='419887ca-8633-438d-a12f-cd3036e2e944', embedding=None, metadata={'page_label': '44', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='44 3. Why: T ask Abstraction\\nities in what people want to do once you strip away the surface\\nlanguage differences.\\nFor example, an epidimiologist studying the spread of a new\\nstrain of inﬂuenza might initially describe her task as “contrastthe prognosis of patients who were intubated in the ICU morethan one month after exposure to patients hospitalized within theﬁrst week”, while a biologist studying immune system responsemight use language such as “see if the results for the tissue sam-ples treated with LL-37 match up with the ones without the pep-tide”. Even if you know what all the specialized vocabulary means,it’s still hard to think about what these two descriptions have incommon because they’re using different words: “contrast” versus“match up”. If you transform these into descriptions using a con-sistent set of generic terms, then you can spot that these two tasksare just two instances of the same thing: “compare values betweentwo groups”.\\nThe analysis framework has a small set of carefully chosen\\nwords to describe why people are using vis, designed to help you\\ncrisply and concisely distinguish between different goals. This sethas verbs describing actions , and nouns describing targets . It’s\\npossible that you might decide to use additional terms to com-pletely and precisely describe the user’s goals; if so, strive to trans-late domain-speciﬁc terms into words that are as generic as possi-ble.\\nThe same vis tool might be usable for many different goals. It is\\noften useful to consider only one of the user’s goals at a time, in or-der to more easily consider the question of how a particular idiom\\nsupports that goal. To describe complex activities, you can specifya chained sequence of tasks, where the output of one becomes theinput to the next.\\nAnother important reason to analyze the task is to understand\\nwhether and how to transform the user’s original data into differentforms by deriving new data. That is, the task abstraction can andshould guide the data abstraction.\\n3.3 Who: Designer or User\\nIt’s sometimes useful to augment an analysis instance speciﬁca-\\ntion by indicating who has a goal or makes a design choice: the\\ndesigner of the vis or the end user of the vis. Both cases are com-mon.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='96f09fd0-b4e1-4a61-ae79-0ffdd8d50520', embedding=None, metadata={'page_label': '45', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.4. Actions 45\\nVis tools fall somewhere along a continuum from speciﬁc to gen-\\neral. On the speciﬁc side, tools are narrow: the designer has builtmany choices into the design of the tool itself in a way that the usercannot override. These tools are limited in the kinds of data andtasks that they can address, but their strength is that users are notfaced with an overwhelming array of design choices. On the gen-eral side, tools are ﬂexible and users have many choices to make.The breadth of choices is both a strength and a limitation: usershave a lot of power, but they also may make ineffective choices ifthey do not have a deep understanding of many vis design issues.\\nSpecialized vis tools are designed for speciﬁc contexts with a\\nnarrow range of data conﬁgurations, especially those createdthrough a problem-driven process. These specialized datasets areoften an interesting mix of complex combinations of and specialcases of the basic data types. They also are a mix of original andderived data. In contrast, general vis tools are designed to handle awide range of data in a ﬂexible way, for example, by accepting anydataset of a particular type as input: tables, or ﬁelds, or networks.\\n▶Dataset types are cov-\\nered in Section 2.4.\\nSome particularly broad tools handle multiple dataset types, for in-\\nstance, supporting transformations between tables and networks.\\n3.4 Actions\\nFigure 3.2 shows three levels of actions that deﬁne user goals. The\\nhigh-level choices describe how the vis is being used to analyze ,\\neither to consume existing data or to also produce additional data.\\nThe mid-level choices cover what kind of search is involved, in\\nterms of whether the target and location are known or not. Thelow-level choices pertain to the kind of query : does the user need\\nto identify one target, compare some targets, or summarize all ofthe targets? The choices at each of these three levels are indepen-dent from each other, and it’s usually useful to describe actions atall three of them.\\n3.4.1 Analyze\\nAt the highest level, the framework distinguishes between two pos-\\nsible goals of people who want to analyze data using a vis tool:\\nusers might want only to consume existing information or also to\\nactively produce new information.\\nThe most common use case for vis is for the user to consume\\ninformation that has already been generated as data stored in a', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='41351b8e-c04b-41d3-93b1-7d28b9d05aa5', embedding=None, metadata={'page_label': '46', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='46 3. Why: T ask Abstraction\\nAnalyze\\nSearch\\nQueryConsume\\nPresent Enjoy Discover\\nProduce\\nAnnotate Record Derive\\nIdentify Compare Summarizetag\\nTarget known Target unknown\\nLocation \\nknown\\nLocation \\nunknownLookup\\nLocateBrowse\\nExploreActions\\nFigure 3.2. Three levels of actions: analyze, search, and query.\\nformat amenable to computation. The framework has three fur-\\nther distinctions within that case: whether the goal is to presentsomething that the user already understands to a third party, orfor the user to discover something new or analyze information that', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f2043462-b241-4f58-9516-fbea8b537512', embedding=None, metadata={'page_label': '47', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.4. Actions 47\\nis not already completely understood, or for users to enjoy a vis to\\nindulge their casual interests in a topic.\\n3.4.1.1 Discover\\nThe discover goal refers to using vis to ﬁnd new knowledge that was\\nnot previously known. Discovery may arise from the serendipitousobservation of unexpected phenomena, but investigation may be\\nmotivated by existing theories, models, hypotheses, or hunches.\\nThis usage includes the goal of ﬁnding completely new things; thatis, the outcome is to generate a new hypothesis. It also includes\\nthe goal of ﬁguring out whether a conjecture is true or false; thatis, to verify —or disconﬁrm—an existing hypothesis.\\nWhile vis for discovery is often associated with modes of sci-\\nentiﬁc inquiry, it is not restricted to domain situations that are\\nformally considered branches of science. The discover goal is oftendiscussed as the classic motivation for sophisticated interactive id-ioms, because the vis designer doesn’t know in advance what the\\nuser will need to see.\\n⋆The fundamental motivation of this analysis⋆This distinction between\\nthe goals of presentation ofthe known and discovery of\\nthe unknown is very com-\\nmon in the vis literature, butother sources may use dif-ferent terms, such as ex-\\nplain versus explore .\\nframework is to help you separate out the questions of why the vis\\nis being used from how the vis idiom is designed to achieve those\\ngoals, so I will repeatedly emphasize that why doesn’t dictate how .\\n3.4.1.2 Present\\nThe present goal refers to the use of vis for the succinct commu-\\nnication of information, for telling a story with data, or guiding\\nan audience through a series of cognitive operations. Presenta-tion using vis may take place within the context of decision mak-ing, planning, forecasting, and instructional processes. The crucialpoint about the present goal is that vis is being used by somebody\\nto communicate something speciﬁc and already understood to an\\naudience.\\nPresentation may involve collaborative or pedagogical contexts,\\nand the means by which a presentation is given may vary accord-ing to the size of the audience, whether the presentation is live orprerecorded, and whether the audience is in the same place as thepresenter. One classic example of a present vis is static informa-\\ntion graphics, such as a diagram in a newspaper or an image in\\na blog. However, the present goal is not intrinsically limited to a\\nstatic visual encoding idiom; it’s very possible to pursue this goalwith dynamic vis idioms that include interaction and animation.Once again, the decision about why is separable from how the id-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6a1a6c00-79d8-427f-907d-16d36241df10', embedding=None, metadata={'page_label': '48', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='48 3. Why: T ask Abstraction\\niom is designed: presentation can be supported through a wide\\nvariety of idiom design choices.\\nA crucial aspect of presentation is that the knowledge commu-\\nnicated is already known to the presenter in advance. Sometimesthe presenter knows it before using vis at all and uses the vis onlyfor communication. In other cases, the knowledge arose from thepresenter’s previous use of vis with the goal of discovery, and it’s\\nuseful to think about a chained sequence of tasks where the outputof a discover session becomes the input to a present session.\\n3.4.1.3 Enjoy\\nThe enjoy goal refers to casual encounters with vis. In these con-\\ntexts, the user is not driven by a previously pressing need to verifyor generate a hypothesis but by curiosity that might be both stim-ulated and satisﬁed by the vis. Casual encounters with vis forenjoyment can be ﬂeeting, such as when looking at an infographicwhile reading a blog post. However, users can become sufﬁcientlyengaged with an enjoyable vis tool that they use it intensively for amore extended period of time.\\nOne aspect of this classiﬁcation that’s tricky is that the goals\\nof the eventual vis user might not be a match with the user goalsconjectured by the vis designer. For example, a vis tool may havebeen intended by the designer for the goal of discovery with a par-ticular audience, but it might be used for pure enjoyment by adifferent group of people. In the analyses presented in this bookI’ll assume that these goals are aligned, but in your own experienceas a designer you might need to consider how they might diverge.\\nFigure 3.3 shows the Name Voyager, which was created for ex-\\npectant parents deciding what to name their new baby. When the\\nuser types characters of a name, the vis shows data for the popu-larity of names in the United States since 1900 that start with thatsequence of characters. The tool uses the visual encoding idiomwhere each name has a stripe whose height corresponds to popu-\\nlarity at a given time. Currently popular names are brighter, andgender is encoded by color. The Name Voyager appealed to many\\npeople with no interest in having children, who analyzed many dif-ferent historical trends and posted extensively about their ﬁndingsin their personal blogs, motivated by their own enjoyment ratherthan a pressing need [Wattenberg 05].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='91244af3-12f9-4926-b23f-d2661b2708d7', embedding=None, metadata={'page_label': '49', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.4. Actions 49\\nFigure 3.3. Name Voyager, a vis tool originally intended for parents focused deciding on what to name their expected\\nbaby, ended up being used by many nonparents to analyze historical trends for their own enjoyment. Left: Namesstarting with ‘O’ had a notable dip in popularity in the middle of the century. Right: Names starting with ‘LA T’ showa trend of the 1970s. After [Wattenberg 05, Figures 2 and 3], using http:/ /www.babynamewizard.com.\\n3.4.2 Produce\\nIn contrast to using vis only for consuming existing information, in\\nthe produce case the intent of the user is to generate new material.\\nOften the goal with produce is to produce output that is used im-\\nmediately, as input to a next instance. Sometimes the user intendsto use this new material for some other vis-related task later on,\\nsuch as discovery or presentation. Sometimes the intended use of\\nthe new material is for some other purpose that does not requirevis, such as downstream analysis using nonvisual tools. There arethree kinds of produce goals: annotate ,record , and derive .\\n3.4.2.1 Annotate\\nThe annotate goal refers to the addition of graphical or textual an-\\nnotations associated with one or more preexisting visualization el-ements, typically as a manual action by the user. When an annota-tion is associated with data items, the annotation could be thoughtof as a new attribute for them. For example, the user could anno-\\n▶Attributes are covered in\\nChapter 2.\\ntate all of the points within a cluster with a text label.\\n3.4.2.2 Record\\nThe record goal saves or captures visualization elements as persis-\\ntent artifacts. These artifacts include screen shots, lists of book-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dfb7f8dd-1ac9-435f-9219-c5f0d43eefb6', embedding=None, metadata={'page_label': '50', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='50 3. Why: T ask Abstraction\\nFigure 3.4. Graphical history recorded during an analysis session with T ableau. From [Heer et al. 08, Figure 1].\\nmarked elements or locations, parameter settings, interaction logs,\\nor annotations. The record choice saves a persistent artifact, in\\ncontrast to the annotate , which attaches information temporarily\\nto existing elements; an annotation made by a user can subse-\\nquently be recorded. One interesting example of a record goal is\\nto assemble a graphical history , in which the output of each task\\nincludes a static snapshot of the view showing its current state,and these snapshots accumulate in a branching meta-visualizationshowing what occurred during the user’s entire session of usingthe vis tool. Figure 3.4 shows an example from the Tableau vistool [Heer et al. 08]. Recording and retaining artifacts such as theseare often desirable for maintaining a sense of analytical prove-nance, allowing users to revisit earlier states or parameter settings.\\n3.4.2.3 Derive\\nThe derive goal is to produce new data elements based on existing\\ndata elements. New attributes can be derived from information\\ncontained within existing ones, or data can be transformed fromone type into another. Deriving new data is a critical part of the visdesign process. The common case is that deriving new data is achoice made by vis designers, but this choice could also be drivenby a user of a vis tool.\\nWhen you are faced with a dataset, you should always consider\\nwhether to simply use it as is, or to transform it to another form:you could create newly derived attributes from the original ones, oreven transform the dataset from the original type to another one.\\nThere is a strong relationship between the form of the data—\\nthe attribute and dataset types—and what kinds of vis idioms are', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='410b74d7-b019-449e-af82-b8ee24dd0c59', embedding=None, metadata={'page_label': '51', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.4. Actions 51\\neffective at displaying it. The good news is that your hands are\\nnot tied as a designer because you can transform the data into aform more useful for the task at hand. Don’t just draw what you’regiven; decide what the right thing to show is, create it with a seriesof transformations from the original dataset, and draw that!\\nThe ability to derive new data is why the data abstraction used\\nin a vis tool is an active choice on the part of the designer, ratherthan simply being dictated by what the user provides. Changingthe dataset to another form by deriving new attributes and typesgreatly expands the design space of possible vis idioms that youcan use to display it. The ﬁnal data abstraction that you choosemight simply be the dataset in its original form, but more complexdata abstractions based on deriving new attributes and types arefrequently necessary if you’re designing a vis tool for a complex,real-world use case. Similarly, when you consider the design ofan existing vis system, understanding how the original designerchose to transform the given dataset should be a cornerstone ofyour analysis.\\nA dataset often needs to be transformed beyond its original state\\nin order to create a visual encoding that can solve the desired prob-lem. To do so, we can create derived attributes that extend the\\ndataset beyond the original set of attributes that it contains.\\n⋆⋆A synonym for derive is\\ntransform . In some cases, the derived attribute encodes the same data as\\nthe original, but with a change of type. For example, a datasetmight have an original attribute that is quantitative data: for in-stance, ﬂoating point numbers that represent temperature. Forsome tasks, like ﬁnding anomalies in local weather patterns, that\\nraw data might be used directly. For another task, like deciding\\nwhether water is an appropriate temperature for a shower, thatquantitative attribute might be transformed into a new derived at-tribute that is ordered: hot, warm, or cold. In this transformation,most of the detail is aggregated away. In a third example, when\\nmaking toast, an even more lossy transformation into a binary cat-\\negorical attribute might sufﬁce: burned or not burned.\\nIn other cases, creating the derived attribute requires access\\nto additional information. For a geographic example, a categoricalattribute of city name could be transformed into two derived quan-titative attributes containing the latitude and longitude of the city.\\nThis transformation could be accomplished through a lookup to a\\nseparate, external database.\\nA new derived attribute may be created using arithmetic, log-\\nical, or statistical operations ranging from simple to complex. Acommon simple operation is subtracting two quantitative attributes', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2824decf-3af9-48ad-861d-ebe076e53780', embedding=None, metadata={'page_label': '52', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='52 3. Why: T ask Abstraction\\nOriginal Dataexports\\nimports\\n(a)Derived Datatrade balance = exports −importstrade \\nbalance\\n(b)\\nFigure 3.5. Derived attributes can be directly visually encoded. (a) T wo original\\ndata attributes are plotted, imports and exports. (b) The quantitative derived at-tribute of trade balance, the difference between the two originals, can be plotteddirectly.\\nto create a new quantitative difference attribute, which can then be\\ndirectly visually encoded. Figure 3.5 shows an example of encod-ing two attributes directly, versus encoding the derived variable ofthe difference between them. For tasks that require understandingthis difference, Figure 3.5(b) is preferable because it encodes thedifference directly. The user can interpret the information by judg-ing position along a common frame. In contrast, in Figure 3.5(a)the user must judge the difference in heights between the two orig-inal curves at each step, a perceptual operation that is more difﬁ-cult and demanding. This operation is simple because it is local-ized to a pair of attribute values; a more complex operation wouldrequire global computations across all values for an attribute, suchas averaging for a single attribute or the correlation between two ofthem.\\nDatasets can be transformed into new ones of a different type,\\njust as new attributes can be derived from existing ones. Thefull process of creating derived data may involve multiple stagesof transformation.\\nFor example, the VxInsight system transforms a table of ge-\\nnomics data into a network through a multistage derivation pro-cess by ﬁrst creating a quantitative derived attribute of similarity,\\nand then creating a derived network with links only between the\\nmost similar items [Davidson et al. 01]. The table had 6000 rowsof yeast genes, and 18 columns containing measurements of thegene activity level in a speciﬁc experimental condition. The valuesin the columns were used to derive a new attribute, the similar-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c5cc6fdf-0f77-462f-8172-58634220fa86', embedding=None, metadata={'page_label': '53', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.4. Actions 53\\nity score, deﬁned between each pair of genes. The similarity score\\nwas computed using sophisticated statistical processing to be ro-bust in the presence of nonlinear and noisy data, as occurs in thissort of biological application. This derived attribute was then usedto create a derived network, where the nodes in the network weregenes. A link was established between two genes when the simi-larity score was high; speciﬁcally, links were created only for thetop 20 similarity scores.\\n3.4.3 Search\\nAll of the high-level analyze cases require the user to search for\\nelements of interest within the vis as a mid-level goal.⋆The classi- ⋆The verb ﬁnd is often\\nused as a synonym in de-scriptions of search tasks,\\nimplying a successful out-come.ﬁcation of search into four alternatives is broken down according\\nto whether the identity and location of the search target is alreadyknown or not.\\n3.4.3.1 Lookup\\nIf users already know both what they’re looking for and where it\\nis, then the search type is simply lookup . For example, a user\\nof a tree vis showing the ancestral relationships between mammalspecies might want to look up humans, and can get to the rightspot quickly by remembering how humans are classiﬁed: they’rein the group that has live young rather than laying eggs like aplatypus or having a pouch like kangaroos, and within that grouphumans fall into the category of primates.\\n3.4.3.2 Locate\\nTo ﬁnd a known target at an unknown location, the search type is\\nlocate : that is, ﬁnd out where the speciﬁc object is. In a similar\\nexample, the same user might not know where to ﬁnd rabbits, andwould have to look around in a number of places before locatingthem as lagomorphs (not rodents)!\\n3.4.3.3 Browse\\nIn contrast, the exact identity of a search target might not be\\nknown in advance; rather, it might be speciﬁed based on char-acteristics. In this case, users are searching for one or more itemsthat ﬁt some kind of speciﬁcation, such as matching up with aparticular range of attribute values. When users don’t know ex-actly what they’re looking for, but they do have a location in mind', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cdbb4c81-d080-4285-9e53-a06f2e8dc0ad', embedding=None, metadata={'page_label': '54', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='54 3. Why: T ask Abstraction\\nof where to look for it, the search type is browse . For instance,\\nif a user of a tree vis is searching within a particular subtree forleaf nodes having few siblings, it would be an instance of browse\\nbecause the location is known in advance, even though the exact\\nidentity of the search target isn’t. Another example of browsing is auser of a vis tool with the visual encoding idiom of a line graph dis-playing the share price of multiple companies over the past month,who examines the share price of each line on June 15.\\n3.4.3.4 Explore\\nWhen users are not even sure of the location, the search type is\\nexplore . It entails searching for characteristics without regard to\\ntheir location, often beginning from an overview of everything. Ex-amples include searching for outliers in a scatterplot, for anoma-\\nlous spikes or periodic patterns in a line graph of time-series data,or for unanticipated spatially dependent patterns in a choropleth\\nmap.\\n3.4.4 Query\\nOnce a target or set of targets for a search has been found, a low-\\nlevel user goal is to query these targets at one of three scopes:\\nidentify ,compare ,o r summarize . The progression of these three\\ncorresponds to an increase in the amount of search targets under\\nconsideration: one, some, or all. That is, identify refers to a single\\ntarget, compare refers to multiple targets, and summarize refers to\\nthe full set of possible targets.\\nFor a concrete example, consider different uses of a choropleth\\nmap of US election results, where each state is color-coded by theparty that won. A user can identify the election results for one\\nstate, compare the election results of one state to another, or sum-\\nmarize the election results across all states to determine how many\\nfavored one candidate or the other or to determine the overall dis-\\ntribution of margin of victory values.\\n3.4.4.1 Identify\\nThe scope of identify is a single target. If a search returns known\\ntargets, either by lookup orlocate , then identify returns their char-\\nacteristics. For example, a user of a static map that representsUS election results by color coding each state red or blue, with thesaturation level of either hue showing the proportion, can identify', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4486c7d3-7881-4c69-be5e-30fde3e69839', embedding=None, metadata={'page_label': '55', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.5. T argets 55\\nthe winning party and margin of victory for the state of California.\\nConversely, if a search returns targets matching particular charac-teristics, either by browse orexplore , then identify returns speciﬁc\\nreferences. For instance, the election map user can identify the\\nstate having the highest margin of victory.\\n3.4.4.2 Compare\\nThe scope of compare is multiple targets. Comparison tasks are\\ntypically more difﬁcult than identify tasks and require more so-phisticated idioms to support the user. For example, the capabilityof inspecting a single target in detail is often necessary, but notsufﬁcient, for comparison.\\n3.4.4.3 Summarize\\nThe scope of summarize task is all possible targets. A synonym for\\nsummarize isoverview , a term is frequently used in the vis liter-\\nature both as a verb, where it means to provide a comprehensiveview of everything, and as a noun, where it means a summary dis-play of everything. The goal of providing an overview is extremelycommon in visualization.▶Section 6.7 discusses the\\nquestion of how and when\\nto provide overviews.\\n3.5 T argets\\nFigure 3.6 shows four kinds of abstract targets. The actions dis-\\ncussed above refer to a target , meaning some aspect of the data\\nthat is of interest to the user. Targets are nouns, whereas actionsare verbs. The idea of a target is explicit with search and queryactions. It is more implicit with the use actions, but still relevant:for example, the thing that the user presents or discovers.\\nThree high-level targets are very broadly relevant, for all kinds\\nof data: trends ,outliers , and features .A trend is a high-level char-\\nacterization of a pattern in the data.\\n⋆Simple examples of trends in-⋆Indeed, a synonym for\\ntrend is simply pattern .\\nclude increases, decreases, peaks, troughs, and plateaus. Almost\\ninevitably, some data doesn’t ﬁt well with that backdrop; those el-ements are the outliers .\\n⋆The exact deﬁnition of features is task⋆There are many other\\nsynonyms for outliers , in-\\ncluding anomalies ,novel-\\nties,deviants , and sur-\\nprises .dependent, meaning any particular structures of interest.\\nAttributes are speciﬁc properties that are visually encoded. The\\n▶Attributes are discussed\\nin detail in Chapter 2.lowest-level target for an attribute is to ﬁnd an individual value.\\nAnother frequent target of interest is to ﬁnd the extremes: theminimum or maximum value across the range. A very common', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd0292ff-086c-49d3-8e4f-09325ca0eec9', embedding=None, metadata={'page_label': '56', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='56 3. Why: T ask Abstraction\\nTrendsAll Data\\nOutliers Features\\nAttributes\\nOne Many\\nDistribution Dependency Correlation Similarity\\nNetwork Data\\nSpatial Data\\nShapeTopology\\nPathsExtremesTargets\\nFigure 3.6. The goals of the user might be to ﬁnd or understand speciﬁc aspects\\nof the data: trends and outliers for all kinds of data; individual values, the minimumor maximum extremes of the range, or the entire distribution of a single attribute; orthe dependencies, correlations, or similarities between multiple attributes; topologyor paths for network data, and shape for spatial data.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='71bfaede-10ff-4fbd-85be-65d742f25fc8', embedding=None, metadata={'page_label': '57', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.6. How: A Preview 57\\ntarget that has high-level scope is the distribution of all values for\\nan attribute.\\nSome targets encompass the scope of multiple attributes: de-\\npendencies ,correlations , and similarities between attributes. A ﬁrst\\nattribute can have a dependency on a second, where the values for\\nthe ﬁrst directly depend on those of the second. There is a correla-\\ntion between one attribute and another if there is a tendency for the\\nvalues of second to be tied to those of the ﬁrst. The similarity be-\\ntween two attributes can be deﬁned as a quantitative measurementcalculated on all of their values, allowing attributes to be rankedwith respect to how similar, or different, they are from each other.\\nThe abstract tasks of understanding trends, outliers, distribu-\\ntions, and correlations are extremely common reasons to use vis.Each of them can be expressed in very diverse terms using domain-speciﬁc language, but you should be on the lookout to recognizethese abstractions.\\nSome targets pertain to speciﬁc types of datasets. Network data\\nspeciﬁes relationships between nodes as links. The fundamentaltarget with network data is to understand the structure of theseinterconnections; that is, the network’s topology . A more speciﬁc\\ntopological target is a path of one or more links that connects two\\nnodes. For spatial data, understanding and comparing the geo-\\n▶The network datatype is\\ncovered in Section 2.4.2,and choices for how ar-range networks are coveredin Chapter 9.\\nmetric shape is the common target of user actions.\\n▶Section 2.4.3.1 covers\\nthe dataset type of spa-tial ﬁelds, and Section 2.4.4covers geometry. Choicesfor arranging spatial dataare covered in Chapter 8.3.6 How: A Preview\\nThe third part of an analysis instance trio is how a vis idiom can\\nbe constructed out of a set of design choices. Figure 3.7 providesa preview of these choices, with a high-level breakdown into fourmajor classes.\\nThe family of how to encode data within a view has ﬁve choices\\nfor how to arrange data spatially: express values; separate, order,\\nand align regions; and use given spatial data. This family also in-\\ncludes how to map data with all of the nonspatial visual channelsincluding color, size, angle, shape, and many more. The manipu-late family has the choices of change any aspect of the view, selectelements from within the view, and navigate to change the view-\\npoint within the view—an aspect of change with a rich enough set\\nof choices to merit its own category. The family of how to facetdata between views has choices for how to juxtapose and coordi-nate multiple views, how to partition data between views, and howto superimpose layers on top of each other. The family of how to', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ae05863d-99e3-4d0b-abac-57b6021c2414', embedding=None, metadata={'page_label': '58', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='58 3. Why: T ask Abstraction\\nHow?\\nEncode Manipulate Facet Reduce\\nArrange\\nMapChange\\nSelect\\nNavigateExpress Separate\\nOrder Align\\nUseJuxtapose\\nPartition\\nSuperimposeFilter\\nAggregate\\nEmbed\\nColor\\nMotionSize, Angle, Curvature, ...Hue Saturation Luminance\\nShape\\nDirection, Rate, Frequency, ...from categorical and ordered \\nattributes\\nWhy?\\nHow?\\n What?\\nFigure 3.7. How to design vis idioms: encode, manipulate, facet, and reduce.\\nreduce the data shown has the options of ﬁlter data away, aggre-\\ngate many data elements together, and embed focus and contextinformation together within a single view.\\nThe rest of this book deﬁnes, describes, and discusses these\\nchoices in depth.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1239b436-0de4-4700-be0b-fcc5c6f84d55', embedding=None, metadata={'page_label': '59', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.7. Analyzing and Deriving: Examples 59\\n3.7 Analyzing and Deriving: Examples\\nThe three analysis and derivation examples below give a taste of\\nhow this what–why–how framework can be used right away. Theﬁrst example covers comparative analysis between two vis tools.The second example discusses deriving a single attribute, an im-portance measure for trees to decide which branches to show tosummarize its topological structure. The third example covers de-riving many new attributes and augmenting a spatial ﬂuid dynam-ics dataset by creating derived spaces in which features of interestare easy to ﬁnd.\\n3.7.1 Comparing T wo Idioms\\nThe what–why–how analysis framework is useful for comparative\\nanalysis, for example, to examine two different vis tools that havedifferent answers for the question of how the idiom is designed\\nwhen used for exactly the same context of why and what at the\\nabstraction level.\\nSpaceTree [Plaisant et al. 02], shown in Figure 3.8(a), and Tree-\\nJuxtaposer [Munzner et al. 03], shown in Figure 3.8(b), are tree vis\\n(a)\\n (b)\\nFigure 3.8. Comparing two idioms. (a) SpaceT ree [Plaisant et al. 02]. (b) T reeJuxtaposer. From http:/ /www.cs.umd.\\nedu/hcil/spacetree and [Munzner et al. 03, Figure 1].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5527faf9-6135-43e7-ab99-3b70869600cd', embedding=None, metadata={'page_label': '60', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='60 3. Why: T ask Abstraction\\nPresent Locate Identify\\nPath between two nodesActions\\nTargetsSpaceTree\\nTreeJuxtaposerEncode Navigate Select Filter AggregateTree\\nArrangeWhy? What? How?\\nEncode Navigate Select\\nFigure 3.9. Analyzing what–why–how comparatively for the SpaceT ree and T reeJuxtaposer idioms.\\ntools that use somewhat different idioms. What these tools take as\\ninput data is the same: a large tree composed of nodes and links.Why these tools are being used is for the same goal in this sce-nario: to present a path traced between two nodes of interest to acolleague. In more detail, both tools can be used to locate pathsbetween nodes and identify them.\\nSome aspects of idioms are the same: both systems allow the\\nuser to navigate and to select a path, with the result that it’s en-\\ncoded differently from the nonselected paths through highlighting.The systems differ in how elements of the visualization are ma-nipulated and arranged. SpaceTree ties the act of selection to achange of what is shown by automatically aggregating and ﬁlteringthe unselected items. In contrast, TreeJuxtaposer allows the user\\nto arrange areas of the tree to ensure visibility for areas of interest.\\nFigure 3.9 summarizes this what–why–how analyis.\\n3.7.2 Deriving One Attribute\\nIn a vis showing a complex network or tree, it is useful to be able to\\nﬁlter out most of the complexity by drawing a simpler picture thatcommunicates the key aspects of its topological structure. Oneway to support this kind of summarization is to calculate a new\\nderived attribute that measures the importance of each node in\\nthe graph and ﬁlter based on that attribute. Many different ap-proaches to calculating importance have been proposed; centrality\\nmetrics do so in a way that takes into account network topology.\\nThe Strahler number is a measure of node importance originally', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='de4d4243-7fed-48c7-b367-0f29ecb8b744', embedding=None, metadata={'page_label': '61', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.7. Analyzing and Deriving: Examples 61\\n(a)\\n (b)\\nFigure 3.10. The derived quantitative attribute of Strahler numbers is used to ﬁlter\\nthe tree in order to create a recognizable summary. (a) The important skeleton ofa large tree is visible when only 5000 of the highest-ranked nodes are drawn. (b)The full tree has over a half million nodes. From [Auber 02, Figures 10 and 13].\\ndeveloped in hydrogeology to characterize the branching structure\\nof rivers that has been adapted and extended for use visualizingtrees and networks [Auber 02]. Very central nodes have large\\nStrahler numbers, whereas peripheral nodes have low values. The\\nStrahler number is an example of a derived attribute for networkdata that is the result of a complex and global computation, ratherthan simply a local calculation on a small neighborhood around anode.\\nFigure 3.10 shows an example of ﬁltering according to the Strah-\\nler derived attribute to summarize a tree effectively. The result ofdrawing only the top-ranked 5000 nodes and the links that con-nect them is a recognizable skeleton of the full tree, shown inFigure 3.10(a), while over a half million nodes are shown in Fig-\\nure 3.10(b). In contrast, if the 5000 nodes to draw were picked ran-domly, the structure would not be understandable. Both versions\\nof the network are also colored according to the Strahler number,to show how the centrality measure varies within the network.\\nTo summarize this example concisely in terms of a what–why–\\nhow analysis, as shown in Figure 3.11, a new quantitative attribute\\nis derived and used to ﬁlter away the peripheral parts of a tree, insupport of the task of summarizing the tree’s overall topology. As inthe previous example, the tree is encoded as a node–link diagram,the most common choice for tree and network arrangment.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='17562a62-f50a-4441-ac52-2d124ff2674a', embedding=None, metadata={'page_label': '62', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='62 3. Why: T ask Abstraction\\nTask 1\\n.58\\n.54\\n.64.84\\n.24.74\\n.64\\n.84\\n.84\\n.94.74\\nOut\\nQuantitative \\nattribute on nodes.58\\n.54\\n.64.84\\n.24.74\\n.64\\n.84\\n.84\\n.94.74\\nIn\\nQuantitative \\nattribute on nodesTask 2\\nDeriveWhy? What?\\nIn Tree Reduce SummarizeHow? Why? What?\\nIn Quantitative attribute on nodes TopologyIn Tree\\nFilterIn\\nTreeOut\\nFiltered tree\\nRemoved \\nunimportant partsIn\\nTree +\\nOut  Quantitative \\nattribute on nodes Out  Filtered tree\\nFigure 3.11. Analyzing a chained sequence of two instances where an attribute is derived in order to summarize a\\ntree by ﬁltering away the unimportant parts.\\n3.7.3 Deriving Many New Attributes\\nData transformations can shed light into spatial data as well. In an\\nexample from computational ﬂuid dynamics, linked derived spacesare used for feature detection [Henze 98]. The vis system shownin Figure 3.12 allows the user to quickly create plots of any twooriginal or derived variables from the palette of variables shownin the upper left derived ﬁelds pane. The views are linked together\\nwith color highlighting. The power of this idiom lies in seeing whereregions that are contiguous in one view fall in the other views.\\n▶Multiple views are dis-\\ncussed further in Chap-ter 12.\\nThe original dataset is a time-varying spatial ﬁeld with measure-\\nments along a curvilinear mesh ﬁtted to an airfoil. The plot in thephysical space pane on the upper right of Figure 3.12 shows the\\ndata in this physical space, using the two spatial ﬁeld variables.\\nUndisturbed airﬂow enters the physical space from the left, and\\nthe back tip of the airfoil is on the right. Two important regionsin back of the airfoil are distinguished with color: a red recircula-tion region and a yellow wake region. While these regions are noteasy to distinguish in this physical view, they can be understood\\nand selected more easily by interaction with the four other derived\\nviews. For example, in the derived space of vorticity vs enthalpy in\\nthe upper middle of Figure 3.12, the recirculation zone is distin-guishable as a coherent spatial structure at the top, with the yellowwake also distinguishable beneath it. As the white box shows, the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b6416938-806f-4401-a122-4460d14c13d8', embedding=None, metadata={'page_label': '63', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.7. Analyzing and Deriving: Examples 63\\nFigure 3.12. Computational ﬂuid dynamics vis showing the list of many derived attributes (top left), one view of\\nthe original spatial ﬁeld (top right), and four other views showing pairs of selected derived attributes. The multiplejuxtaposed views are coordinated with shared colored highlights. From [Henze 98, Figure 5].\\nrecirculation zone can easily be selected in this view. The pressure\\nvs temperature pane in the bottom middle of Figure 3.12 shows an-\\nother derived space made by plotting the pressure versus the tem-perature. In this view, the red recirculation zone and the yellowwake appear where both the pressure and temperature variables\\nare high, in the upper right. Without getting into the exact tech-\\nnical meaning of the derived variables as used in ﬂuid dynamics(vorticity, entropy, enthalpy, and so on), the point of this exampleis that many structures of interest in ﬂuid dynamics can be seenmore easily from layouts in the derived spaces.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3241bdac-088e-4ac6-b1fc-ebc319fbd69c', embedding=None, metadata={'page_label': '64', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='64 3. Why: T ask Abstraction\\nTask 1\\nOut\\nMany quantitative \\nattributesIn\\nMany quantitative \\nattributesTask 2\\nDeriveWhy? What?\\nIn Spatial fieldHow? Why? What?\\nIn Many quantitative \\nattributes\\nFeaturesIn Spatial fieldIn\\nSpatial fieldOut\\nJuxtaposed attribute plots with \\nlinked coloringIn\\nSpatial field\\nActions\\nTargetsDiscover\\nExplore\\nBrowse\\nIdentify\\nCompareFacet ManipulateMap Arrange\\nExpress Hue\\nJuxtapose\\nPartitionSelect\\nNavigateOut Many \\nquantitative \\nattributesOut  Juxtaposed \\nattribute plots with linked coloring+\\nFigure 3.13. Analyzing a chained sequence, where many attributes are derived and visually encoded.\\nTo summarize this example in terms of a what–why–how analy-\\nsis, as shown in Figure 3.13, many new quantitative attributes arederived from an original spatial ﬁeld dataset. Each pair of them\\nis visually encoded into a view, as is the original spatial data, and\\nthe multiple juxtaposed views are coordinated with shared colorcoding and highlighting.\\n3.8 Further Reading\\nThe Big Picture An earlier version of the what–why–how framework\\nwas ﬁrst presented as a paper [Brehmer and Munzner 13],\\nwhich includes a very detailed discussion of its relationshipto the extensive previous work in classiﬁcations of tasks andinteraction idioms. That discussion covers 30 previous clas-siﬁcations and 20 relevant references, ranging from a charac-\\nterization of the scientiﬁc data analysis process [Springmeyer\\net al. 92], to an inﬂuential low-level task classiﬁcation [Amaret al. 05], to a taxonomy of tasks for network datasets [Leeet al. 06], to a recent taxonomy of interaction dynamics [Heerand Shneiderman 12].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='30b1f44e-f7ef-4574-b2aa-344b282467f2', embedding=None, metadata={'page_label': '65', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.8. Further Reading 65\\nWho: Designers versus Users Some of the challenges inherent in bridg-\\ning the gaps between vis designers and users are discussedin an inﬂuential paper [van Wijk 06].\\nDerive Many vis pipeline models discuss the idea of data trans-\\nformation as a critical early step [Card et al. 99, Chi andRiedl 98], and others also point out the need to transform be-tween different attribute types [Velleman and Wilkinson 93].A later taxonomy of vis explicitly discusses the idea that data\\ntypes can change as the result of the transformation [Tory\\nand M ¨oller 04b].\\nExamples The analysis examples are SpaceTree [Plaisant et al. 02],\\nTreeJuxtaposer [Munzner et al. 03], Strahler numbers for treesimpliﬁcation [Auber 02], and linked derived spaces for fea-ture detection [Henze 98].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7587794d-5fad-4aa7-a514-9f1ff15f8ff4', embedding=None, metadata={'page_label': '66', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Domain situation\\nObserve target users using existing tools\\nVisual encoding/interaction idiom\\nJustify design with respect to alternatives\\nAlgorithm\\nMeasure system time/memoryAnalyze computational complexity\\nObserve target users after deployment ( )\\nMeasure adoptionAnalyze results qualitatively\\nMeasure human time with lab experiment ( lab study )Data/task abstraction\\nFigure 4.1. The four nested levels of vis design have different threats to validity at each level, and validation\\napproaches should be chosen accordingly.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2beb5394-7972-469e-af47-c99c66ba27fb', embedding=None, metadata={'page_label': '67', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Analysis: Four Levels for ValidationChapter 4\\n4.1 The Big Picture\\nFigure 4.1 shows four nested levels of design: domain situation,\\ntask and data abstraction, visual encoding and interaction idiom,and algorithm. The task and data abstraction level addresses thewhy and what questions, and the idiom level addresses the ques-\\ntion of how . Each of these levels has different threats to validity, so\\nit’s a good idea to choose your validation method with these levelsin mind.\\n4.2 Why Validate?\\nValidation is important for the reasons discussed in Chapter 1: the\\nvis design space is huge, and most designs are ineffective. In that\\nchapter, I also discuss the many reasons that validation is a trickyproblem that is difﬁcult to get right. It’s valuable to think abouthow you might validate your choices from the very beginning ofthe design process, rather than leaving these considerations for\\nthe end as an afterthought.\\nThis chapter introduces two more levels of design to consider,\\none above the why–what abstraction level and one below the how\\nidiom level. While this book focuses on the two middle levels, con-sidering all four is helpful when thinking about how to validate\\nwhether a given design has succeeded.\\n4.3 Four Levels of Design\\nSplitting the complex problem of vis design into four cascading lev-\\nels provides an analysis framework that lets you address differentconcerns separately. Figure 4.2 shows these four levels.\\n67', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84a55fd6-c395-4c9c-8360-2db3a1974387', embedding=None, metadata={'page_label': '68', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='68 4. Analysis: Four Levels for Validation\\nData/task abstraction\\nVisual encoding/interaction idiom\\nAlgorithmDomain situation\\nFigure 4.2. The four nested levels of vis design.\\nAt the top is the situation level, where you consider the details\\nof a particular application domain for vis. Next is the what–why\\nabstraction level, where you map those domain-speciﬁc problemsand data into forms that are independent of the domain. The fol-lowing how level is the design of idioms that specify the approach\\nto visual encoding and interaction. Finally, the last level is thedesign of algorithms to instantiate those idioms computationally.\\nThese levels are nested; the output from an upstream level above\\nis input to the downstream level below. A block is the outcome of\\nthe design process at that level. The challenge of this nesting is\\nthat choosing the wrong block at an upstream level inevitably cas-cades to all downstream levels. If you make a poor choice in theabstraction stage, then even perfect choices at the idiom and algo-rithm levels will not result in a vis system that solves the intendedproblem.\\nThe value of separating these concerns into four levels is that\\nyou can separately analyze the question of whether each level hasbeen addressed correctly, independently of whatever order design\\ndecisions were made in the process of building the vis tool. Al-\\nthough I encourage you to consider these four levels separately foranalysis, in practice you wouldn’t ﬁnalize design decisions at onelevel before moving on to the next. Vis design is usually a highlyiterative reﬁnement process, where a better understanding of the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0759305e-4794-4e16-bee5-4148b2568351', embedding=None, metadata={'page_label': '69', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.3. Four Levels of Design 69\\nblocks at one level will feed back and forward into reﬁning the\\nblocks at the other levels. Thus, it is one of many examples of theprinciple of design as redesign [Green 89].\\n4.3.1 Domain Situation\\nBlocks at this top level describe a speciﬁc domain situation , which\\nencompasses a group of target users, their domain of interest, theirquestions, and their data. The term domain is frequently used in\\nthe vis literature to mean a particular ﬁeld of interest of the target\\nusers of a vis tool, for example microbiology or high-energy physicsor e-commerce. Each domain usually has its own vocabulary fordescribing its data and problems, and there is usually some exist-ing workﬂow of how the data is used to solve their problems. Thegroup of target users might be as narrowly deﬁned as a handful\\nof people working at a speciﬁc company, or as broadly deﬁned asanybody who does scientiﬁc research.\\nOne example of a situation block is a computational biologist\\nworking in the ﬁeld of comparative genomics, using genomic se-quence data to ask questions about the genetic source of adaptiv-\\nity in a species [Meyer et al. 09]. While one kind of situation is a\\nspeciﬁc set of users whose questions about their data arise fromtheir work, situations arise in other contexts. For example, an-other situation is members of the general public making medicaldecisions about their healthcare in the presence of uncertainty [Mi-callef et al. 12].\\nAt this level, situation blocks are identiﬁed : the outcome of\\nthe design process is an understanding that the designer reachesabout the needs of the user. The methods typically used by de-signers to identify domain situation blocks include interviews, ob-servations, or careful research about target users within a speciﬁcdomain.\\nDeveloping a clear understanding of the requirements of a par-\\nticular target audience is a tricky problem for a designer.\\n⋆While ⋆Working closely with a\\nspeciﬁc target audience toiteratively reﬁne a designis called user-centered de-\\nsign orhuman-centered\\ndesign in the human–com-\\nputer interaction literature.it might seem obvious to you that it would be a good idea to un-\\nderstand requirements, it’s a common pitfall for designers to cutcorners by making assumptions rather than actually engaging withany target users.\\nIn most cases users know they need to somehow view their data,\\nbut they typically cannot directly articulate their analysis needs ina clear-cut way. Eliciting system requirements is not easy, evenwhen you have unfettered access to target users ﬂuent in the vo-cabulary of the domain and immersed in its workﬂow. Asking', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3ea5fbc1-0944-49bb-a907-09a44100fb8f', embedding=None, metadata={'page_label': '70', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='70 4. Analysis: Four Levels for Validation\\nusers to simply introspect about their actions and needs is no-\\ntoriously insufﬁcient: what users say they do when reﬂecting ontheir past behavior gives you an incomplete picture compared withwhat they actually do if you observe them.\\nThe outcome of identifying a situation block is a detailed set of\\nquestions asked about or actions carried out by the target users,about a possibly heterogeneous collection of data that’s also un-derstood in detail. Two of the questions that may have been askedby the computational biologist working in comparative genomics\\nworking above were “What are the differences between individual\\nnucleotides of feature pairs?” and “What is the density of coverageand where are the gaps across a chromosome?” [Meyer et al. 09].In contrast, a very general question such as “What is the geneticbasis of disease?” is not speciﬁc enough to be useful as input to\\nthe next design level.\\n4.3.2 T ask and Data Abstraction\\nDesign at the next level requires abstracting the speciﬁc domain\\nquestions and data from the domain-speciﬁc form that they haveat the top level into a generic representation. Abstracting into thedomain-independent vocabulary allows you to realize how domainsituation blocks that are described using very different languagemight have similar reasons why the user needs the vis tool andwhat data it shows.\\nQuestions from very different domain situations can map to the\\nsame abstract vis tasks. Examples of abstract tasks include brows-\\ning, comparing, and summarizing. Task blocks are identiﬁed bythe designer as being suitable for a particular domain situationblock, just as the situation blocks themselves are identiﬁed at thelevel above.\\n▶Chapter 3 covers abstract\\ntasks in detail.\\nAbstract data blocks, however, are designed . Selecting a data\\nblock is a creative design step rather than simply an act of identiﬁ-\\ncation. While in some cases you may decide to use the data in ex-\\nactly the way that it was identiﬁed in the domain situation, you willoften choose to transform the original data from its upstream formto something quite different. The data abstraction level requiresyou to consider whether and how the same dataset provided by a\\nuser should be transformed into another form. Many vis idioms\\nare speciﬁc to a particular data type, such as a table of numberswhere the columns contain quantitative, ordered, or categoricaldata; a node–link graph or tree; or a ﬁeld of values at every pointin space. Your goal is to determine which data type would support', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='be501da3-f679-4991-b68d-e7d9ce134335', embedding=None, metadata={'page_label': '71', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.3. Four Levels of Design 71\\na visual representation of it that addresses the user’s problem. Al-\\nthough sometimes the original form of the dataset is a good matchfor a visual encoding that solves the problem, often a transforma-tion to another data type provides a better solution.▶Chapter 2 covers ab-\\nstract data types, and Sec-tion 3.4.2.3 discusses trans-forming and deriving data.\\nExplicitly considering the choices made in abstracting from\\ndomain-speciﬁc to generic tasks and data can be very useful in thevis design process. The unfortunate alternative is to do this ab-straction implicitly and without justiﬁcation. For example, manyearly web vis papers implicitly posited that solving the “lost in hy-\\nperspace” problem should be done by showing the searcher a vi-\\nsual representation of the topological structure of the web’s hyper-link connectivity graph. In fact, people do not need an internalmental representation of this extremely complex structure to ﬁnda page of interest. Thus, no matter how cleverly the information\\nwas visually encoded at the idiom design level, the resulting vis\\ntools all incurred additional cognitive load for the user rather thanreducing it.\\n4.3.3 Visual Encoding and Interaction Idiom\\nAt the third level, you decide on the speciﬁc way to create and\\nmanipulate the visual representation of the abstract data block\\nthat you chose at the previous level, guided by the abstract tasksthat you also identiﬁed at that level. I call each distinct possibleapproach an idiom . There are two major concerns at play with\\nidiom design. One set of design choices covers how to create a sin-gle picture of the data: the visual encoding idiom controls exactly\\nwhat users see. Another set of questions involves how to manip-\\nulate that representation dynamically: the interaction idiom con-\\ntrols how users change what they see. For example, the Word Treesystem [Wattenberg and Viegas 08] shown in Figure 4.3 combinesthe visual encoding idiom of a hierarchical tree representation ofkeywords laid out horizontally, preserving information about thecontext of their use within the original text, and the interactionidiom of navigation based on keyword selection. While it’s oftenpossible to analyze encoding and interaction idioms as separabledecisions, in some cases these decisions are so intertwined thatit’s best to consider the outcome of these choices to be a singlecombined idiom.\\nIdiom blocks are designed: they are the outcome of decisions\\nthat you make. The design space of static visual encoding idiomsis already enormous, and when you consider how to manipulatethem dynamically that space of possibilities is even bigger. The\\n▶Chapters 7 through 14\\nfeature a thorough look at\\nthe design space of vis id-ioms.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='56bd1d3d-024f-49e9-98f5-1756ba6d3811', embedding=None, metadata={'page_label': '72', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='72 4. Analysis: Four Levels for Validation\\nFigure 4.3. Word T ree combines the visual encoding idiom of a hierarchical tree of keywords laid out horizontally\\nand the interaction idiom of navigation based on keyword selection. From [Wattenberg and Viegas 08, Figure 3].\\nnested model emphasizes identifying task abstractions and decid-\\ning on data abstractions in the previous level exactly so that youcan use them to rule out many of the options as being a bad matchfor the goals of the users. You should make decisions about goodand bad matches based on understanding human abilities, espe-cially in terms of visual perception and memory.▶Chapters 5 and 6 cover\\nprinciples of human percep-tion and memory that arerelevant for making idiom\\ndesign choices.\\nWhile it’s common for vis tools to provide multiple idioms that\\nusers might choose between, some vis tools are designed to be verynarrow in scope, supporting only a few or even just a single idiom.\\n4.3.4 Algorithm\\nThe innermost level involves all of the design choices involved in\\ncreating an algorithm : a detailed procedure that allows a computer\\nto automatically carry out a desired goal. In this case, the goalis to efﬁciently handle the visual encoding and interaction idioms\\nthat you chose in the previous level. Algorithm blocks are alsodesigned, rather than just identiﬁed.\\nYou could design many different algorithms to instantiate the\\nsame idiom. For example, one visual encoding idiom for creatingimages from a three-dimensional ﬁeld of measurements, such asscans created for medical purposes with magnetic resonance imag-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3f72cc3-d6e5-48a6-8080-1b307c0b00b9', embedding=None, metadata={'page_label': '73', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.4. Angles of Attack 73\\ning, is direct volume rendering. Many different algorithms have\\nbeen proposed as ways to achieve the requirements of this idiom,including ray casting, splatting, and texture mapping. You mightdetermine that some of these are better than others according tomeasures such as the speed of the computation, how much com-puter memory is required, and whether the resulting image is anexact match with the speciﬁed visual encoding idiom or just anapproximation.\\nThe nested model emphasizes separating algorithm design,\\nwhere your primary concerns are about computational issues, fromidiom design, where your primary concerns are about human per-ceptual issues.\\nOf course, there is an interplay between these levels. For ex-\\nample, a design that requires something to change dynamically\\nwhen the user moves the mouse may not be feasible if computingthat would take minutes or hours instead of a fraction of a second.However, clever algorithm design could save the day if you comeup with a way to precompute data that supports a fast enoughresponse.\\n4.4 Angles of Attack\\nThere are two common angles of attack for vis design: top down or\\nbottom up. With problem-driven work, you start at the top domain\\nsituation level and work your way down through abstraction, id-iom, and algorithm decisions. In technique-driven work, you work\\nat one of the bottom two levels, idiom or algorithm design, whereyour goal is to invent new idioms that better support existing ab-stractions, or new algorithms that better support existing idioms.\\nIn problem-driven vis, you begin by grappling with the problems\\nof some real-world user and attempt to design a solution that helpsthem work more effectively. In this vis literature, this kind of workis often called a design study . Often the problem can be solved\\nusing existing visual encoding and interaction idioms rather thandesigning new ones, and much of the challenge lies at the abstrac-tion level. However, sometimes the problem motivates the designof new idioms, if you decide that no existing ones will adequatelysolve the abstracted design problem.\\nConsidering the four levels of nested model explicitly can help\\nyou avoid the pitfall of skipping important steps in problem-drivenwork. Some designers skip over the domain situation level com-pletely, short-circuit the abstraction level by assuming that the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='733a3ecc-d33e-410b-aeed-078bacd3b454', embedding=None, metadata={'page_label': '74', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='74 4. Analysis: Four Levels for Validation\\nﬁrst abstraction that comes to mind is the correct one, and jump\\nimmediately into the third level of visual encoding and interactionidiom design. I argue against this approach; the abstraction stageis often the hardest to get right. A designer struggling to ﬁnd theright abstraction may end up realizing that the domain situationhas not yet been adequately characterized and jump back up towork at that level before returning to this one. As mentioned above,the design process for problem-driven work is almost never strictlylinear; it involves iterative reﬁnement at all of the levels.\\nIn technique-driven work, your starting point is an idea for a\\nnew visual encoding or interaction idiom, or a new algorithm. Inthis style of work, you start directly at one of the two lower levels\\nand immediately focus design at that level. Considering the nestedmodel can help you articulate your assumptions at the level justabove your primary focus: either to articulate the abstraction re-quirements for your new idiom, or to articulate the idiom require-\\nments for your algorithm.\\nThe analysis framework of this book is focused on the what–\\nwhy abstraction and how idiom levels and is intended to help you\\nwork in either direction. For problem-driven work, it allows you towork downward when searching for existing idioms by analyzingwhat design choices are appropriate for task abstraction that youhave identiﬁed and data abstraction that you have chosen. Fortechnique-driven work, it allows you to work upward by classifyingyour proposed idiom within the framework of design choices, giv-ing you a clear framework in which to discuss its relationship withpreviously proposed idioms. Similarly, it is helpful to explicitly an-alyze a new algorithm with respect to the idioms that it supports.Although in some cases this analysis is very straightforward, itcan sometimes be tricky to untangle connections between algo-rithms and idioms. Can your new algorithm simply be switchedfor a previous one, providing a faster way to compute the samevisual encoding? Or does your new algorithm result in a visualencoding different enough to constitutes a new idiom that requiresjustiﬁcation to show it’s a good match for human capabilities andthe intended task?\\n4.5 Threats to Validity\\nValidating the effectiveness of a vis design is difﬁcult because there\\nare so many possible questions on the table. Considering the va-▶Section 1.12 presented\\nmany questions to considerwhen validating a vis design.\\nlidity of your decisions at each level of the nested model separately', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68bf893a-2d77-45db-9678-311ca586a4c3', embedding=None, metadata={'page_label': '75', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.6. Validation Approaches 75\\nDomain situation\\nYou misunderstood their needs\\nYou’re showing them the wrong thing\\nVisual encoding/interaction idiom\\nThe way you show it doesn’t work\\nAlgorithm\\nYour code is too slowData/task abstraction\\nFigure 4.4. The four nested levels of vis design have different threats to validity at\\neach level.\\ncan help you ﬁnd your way through this thicket of questions about\\nvalidating your decisions, in the same way that the levels also con-\\nstrain the decision-making process itself.\\nEach of the four levels has a different set of threats to valid-\\nity: that is, different fundamental reasons why you might have\\nmade the wrong choices.⋆Figure 4.4 summarizes the four classes⋆ I have borrowed the\\nevocative phrase threats to\\nvalidity from the computer\\nsecurity domain, by way ofthe software engineering lit-\\nerature. I use the word\\nvalidation rather than eval-\\nuation to underscore the\\nidea that validation is re-quired for every level andextends beyond user stud-\\nies and ethnographic obser-\\nvation to include complex-ity analysis and benchmarktimings. In software engi-neering, validation is about\\nwhether you have built the\\nright product, and veriﬁca-\\ntion is about whether you\\nhave built the product right.Similarly, in the simulationcommunity, validation of\\nthe scientiﬁc model with re-\\nspect to real-world obser-vations is similarly consid-ered separately from veri-\\nﬁcation of the implementa-\\ntion, and connotes a level\\nof rigor beyond the methods\\ndiscussed here. My use ofvalidation includes both of\\nthese questions.of threats, where they means the target users and you means the\\nvis designer:\\n•Wrong problem: You misunderstood their needs.\\n•Wrong abstraction: You’re showing them the wrong thing.\\n•Wrong idiom: The way you show it doesn’t work.\\n•Wrong algorithm: Your code is too slow.\\n4.6 Validation Approaches\\nDifferent threats require very different approaches to validation.\\nFigure 4.5 shows a summary of the threats and validation ap-proaches possible at each level. The rest of this section explains', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6abb0c1a-807d-48cf-9251-b0a648317f52', embedding=None, metadata={'page_label': '76', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='76 4. Analysis: Four Levels for Validation\\nThreat       Wrong problem\\nThreat   Wrong task/data abstraction\\nThreat       Ineffective encoding/interaction idiom\\nThreat       Slow algorithmValidate   Observe and interview target users\\nValidate   Analyze computational complexity\\nValidate   Measure system time/memory\\nValidate   Observe adoption ratesValidate   Test on target users, collect anecdotal evidence of utility\\nValidate   Field study, document human usage of deployed systemValidate   Qualitative/quantitative result image analysis\\nValidate   Lab study, measure human time/errors for taskValidate   Justify encoding/interaction design\\nImplement system\\n Test on any users, informal usability study\\nFigure 4.5. Threats and validation at each of the four levels. Many threats at the\\nouter levels require downstream validation, which cannot be carried out until theinner levels within them are addressed, as shown by the red lines. Any singleproject would only address a subset of these levels, not all of them at once.\\nthese ideas in more detail. I give only a brief outline of each vali-\\ndation method here; the Further Reading section at the end of thischapter has pointers to more thorough discussions of their use.\\nThe analysis below distinguishes between immediate and down-\\nstream validation approaches. An important corollary of the model\\nhaving nested levels is that most kinds of validation for the outerlevels are not immediate because they require results from thedownstream levels nested within them. These downstream de-pendencies add to the difﬁculty of validation: a poor showing of\\na test may misdirect attention upstream, when in fact the prob-\\nlem results from a poor choice at the current level. For example, apoor visual encoding choice may cast doubt when testing a legiti-mate abstraction choice, or poor algorithm design may cast doubtwhen testing an interaction technique. Despite their difﬁculties,', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8a788ba4-66f6-4f46-8932-858f57015588', embedding=None, metadata={'page_label': '77', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.6. Validation Approaches 77\\nthe downstream validations are necessary. The immediate vali-\\ndations only offer partial evidence of success; none of them aresufﬁcient to demonstrate that the threat to validity at that levelhas been addressed.\\nThis model uses the language of immediate and downstream\\nin order to make the discussion of the issues at each level eas-ier to understand—but it is not always necessary to carry out thefull process of design and implementation at each level before do-ing any downstream validation. There are many rapid prototyp-\\ning methodologies for accelerating this process by creating low-\\nﬁdelity stand-ins exactly so that downstream validation can oc-cur sooner. For example, paper prototypes and Wizard of Oz test-ing [Dow et al. 05] can be used to get feedback from target usersabout abstraction and encoding designs before diving into design-\\ning or implementing any algorithms.\\n4.6.1 Domain Validation\\nAt the top level, when characterizing the domain situation, a vis\\ndesigner is asserting that particular problems of the target audi-ence would beneﬁt from vis tool support. The primary threat isthat the problem is mischaracterized: the target users do not infact have these problems. An immediate form of validation is tointerview and observe the target audience to verify the character-ization, as opposed to relying on assumptions or conjectures. Acommon approach for this case is a ﬁeld study , where the investi-\\ngator observes how people act in real-world settings, rather than\\nby bringing them into a laboratory setting. Field studies for do-main situation assessment often involve gathering qualitative datathrough semi-structured interviews. The method of contextual in-quiry [Holtzblatt and Jones 93], where the researcher observesusers working in their real-world context and interrupts to ask\\nquestions when clariﬁcation is needed, is typically better suited\\nfor vis designers than silent observation because of the complexcognitive tasks that are targeted.\\nOne downstream form of validation is to report the rate at which\\nthe tool has been adopted by the target audience. Of course, adop-tion rates do not tell the whole story: many well-designed tools fail\\nto be adopted, and some poorly designed tools win in the market-\\nplace. Nevertheless, the important aspect of this signal is that itreports what the target users do of their own accord, as opposed tothe approaches below where target users are implicitly or explicitlyasked to use a tool. In particular, a tool that is actually used by its', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e3608bc5-a2b0-4145-8710-3ec8ed7aa3e8', embedding=None, metadata={'page_label': '78', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='78 4. Analysis: Four Levels for Validation\\nintended users has reached a different level of success than one\\nthat has only been used by its designers.\\n4.6.2 Abstraction Validation\\nAt the abstraction level, the threat is that the identiﬁed task ab-\\nstraction blocks and designed data abstraction blocks do not solvethe characterized problems of the target audience. The key aspectof validation against this threat is that the system must be testedby target users doing their own work, rather than doing an abstracttask speciﬁed by the designers of the vis system.\\nA common downstream form of validation is to have a member\\nof the target user community try the tool, in hopes of collectinganecdotal evidence that the tool is in fact useful. These anecdotesmay have the form of insights found or hypotheses conﬁrmed. Ofcourse, this observation cannot be made until after all three ofthe other levels have been fully addressed, after the algorithm de-signed at the innermost level is implemented. Although this formof validation is usually qualitative, some inﬂuential work towardquantifying insight has been done [Saraiya et al. 05]. As with thelevel above, it’s important to distinguish between a discovery madeby a target user and one that you’ve make yourself; the former is amore compelling argument for the utility of the vis tool.\\nA more rigorous validation approach for this level is to conduct\\na ﬁeld study to observe and document how the target audienceuses the deployed system, again as part of their real-world work-ﬂow. The key difference between ﬁeld studies at this level andthose just described for assessing domain situations is that you’reobserving how their behavior changes after intervening with thedeployment of a vis tool, as opposed to documenting their existingwork practices.\\n4.6.3 Idiom Validation\\nAt the visual encoding and interaction idiom level, the threat is that\\nthe chosen idioms are not effective at communicating the desiredabstraction to the person using the system. One immediate vali-dation approach is to carefully justify the design of the idiom withrespect to known perceptual and cognitive principles. Evaluation\\n▶Perceptual and cognitive\\nprinciples will be covered inChapters 5 and 6.\\nmethods such as heuristic evaluation [Zuk et al. 08] and expert\\nreview [Tory and M ¨oller 05] are a way to systematically ensure that\\nno known guidelines are being violated by the design.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4f59dd99-9e95-4e19-ae54-8d1fd98f7784', embedding=None, metadata={'page_label': '79', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.6. Validation Approaches 79\\nA downstream approach to validate against this threat is to\\ncarry out a lab study : a controlled experiment in a laboratory set-\\nting.⋆This method is appropriate for teasing out the impact of spe- ⋆The term user study is\\ncommon in the vis litera-ture, but it’s used ambigu-ously: sometimes it’s nar-rowly used to mean only alab study , whereas other\\ntimes it might also be ap-\\nplied to a ﬁeld study . I use\\nit broadly, to mean both ofthese.ciﬁc idiom design choices by measuring human performance on\\nabstract tasks that were chosen by the study designers. Many ex-perimental designs include both quantitative and qualitative mea-surements. It’s extremely common to collect the objective mea-surements of the time spent and errors made by the study par-ticipants; subjective measurements such as their preferences are\\nalso popular. Other kinds of quantitative data that are sometimes\\ngathered include logging actions such as mouse moves and clicksby instrumenting the vis tool, or tracking the eye movements of theparticipants with external gear. Qualitative data gathering often in-cludes asking participants to reﬂect about their strategies through\\nquestionnaires. In this context, the expected variation in human\\nbehavior is small enough that it is feasible to design experimentswhere the number of participants is sufﬁcient to allow testing forstatistical signiﬁcance during the analysis process.\\nAnother downstream validation approach is the presentation of\\nand qualitative discussion of results in the form of still images orvideo. This approach is downstream because it requires an im-plemented system to carry out the visual encoding and interactionspeciﬁcations designed at this level. This validation approach isstrongest when there is an explicit discussion pointing out the de-sirable properties in the results, rather than assuming that everyreader will make the desired inferences by unassisted inspectionof the images or video footage. These qualitative discussions of im-ages sometimes occur as usage scenarios, supporting an argumentthat the tool is useful for a particular task–dataset combination.\\nA third appropriate form of downstream validation is the quan-\\ntitative measurement of result images created by the implementedsystem; these are often called quality metrics . For example, many\\nmeasurable layout metrics such as number of edge crossings and\\nedge bends have been proposed to assess drawings of node–linknetworks. Some of these metrics have been empirically testedagainst human judgement, while others remains unproved con-jectures.\\nInformal usability studies do appear in Figure 4.5, but I specif-\\nically refrain from calling them a validation method. As Andrewseloquently states: “Formative methods [including usability studies]lead to better and more usable systems, but neither offer valida-tion of an approach nor provide evidence of the superiority of anapproach for a particular context” [Andrews 08]. They are listed', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='95ebaa20-1f71-493c-8add-9ec91e5a5d2c', embedding=None, metadata={'page_label': '80', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='80 4. Analysis: Four Levels for Validation\\nat this level because it is a very good idea to do them upstream\\nof attempting a validating laboratory or ﬁeld study. If the systemis unusable, no useful conclusions about its utility can be drawnfrom a user study. I distinguish usability studies from informaltesting with users in the target domain, as described for the levelabove. Although the informal testing with target users describedat the level above may uncover usability problems, the goal is tocollect anecdotal evidence that the system meets its design goals.Such anecdotes are much less convincing when they come from arandom person rather than a member of the target audience. Incontrast, in an informal usability study, the person using the sys-tem does not need to be in the target audience; the only constraintis that the user is not the system designer.\\n4.6.4 Algorithm Validation\\nAt the algorithm level, the primary threat is that the algorithm is\\nsuboptimal in terms of time or memory performance, either to atheoretical minimum or in comparison with previously proposedalgorithms. Obviously, poor time performance is a problem if theuser expects the system to respond in milliseconds but instead theoperation takes hours or days.▶The issue of matching\\nsystem latency to user ex-pectations is discussed inmore detail in Section 6.8.\\nAn immediate form of validation is to analyze the computational\\ncomplexity of the algorithm, using the standard approaches from\\nthe computer science literature. While many designers analyze al-\\ngorithm complexity in terms of the number of items in the dataset,in some cases it will be more appropriate to consider the numberof pixels in the display.\\nThe downstream form of validation is to measure the wall-clock\\ntime and memory performance of the implemented algorithm. Thistype of measurement is so common that it’s nearly mandatory forpapers claiming a contribution at the algorithm level. The primaryconsideration is typically scalability in terms of how dataset size af-fects algorithm speed. One of the trickier questions is to determinewhat data you should use to test the algorithm. Considerations in-clude matching up with standard benchmarks , which are used in\\nprevious papers, and incorporating a sufﬁciently broad set of data.\\nAnother threat is incorrectness at the algorithm level, where\\nthe implementation does not meet the speciﬁcation from the idiomlevel above. The problem could come from poor algorithm design,or the implementation of the algorithm could have bugs like any\\ncomputer program. Establishing the correctness of a computer\\nprogram is a notoriously difﬁcult problem, whether through carefultesting or formal methods.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4055b4b-745b-4fd5-851a-80230783cd0f', embedding=None, metadata={'page_label': '81', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.7. Validation Examples 81\\nThe threat of algorithm incorrectness is often addressed implic-\\nitly rather than explicitly within the vis literature. Presenting stillimages or videos created by the implemented algorithm is one formof implicit validation against this threat, where the reader of a pa-per can directly see that the algorithm correctness objectives havebeen met. Explicit qualitative discussion of why these images showthat the algorithm is in fact correct is not as common.\\n4.6.5 Mismatches\\nA common problem in weak vis projects is a mismatch between the\\nlevel at which the beneﬁt is claimed and the validation methodolo-gies chosen. For example, the beneﬁt of a new visual encodingidiom cannot be validated by wall-clock timings of the algorithm,which addresses a level downstream of the claim. Similarly, thethreat of a mischaracterized task cannot be addressed through aformal laboratory study, where the task carried out by the partic-ipants is dictated by the study designers, so again the validationmethod is at a different level than the threat against the claim. Thenested model explicitly separates the vis design problem into levelsin order to guide validation according to the unique threats at eachlevel.\\nHowever, it would be impossible for any single research paper to\\naddress all four levels in detail, because of limitations on space andtime—such a paper would require hundreds of pages and might\\ntake a decade to ﬁnish! Instead, any individual research paper\\nwould use only a small subset of these validation methods, wherecareful consideration is made of which methods match the levelsof design where research contributions are being claimed.\\n4.7 Validation Examples\\nThis section presents examples of several vis research papers, an-\\nalyzed according to the levels of vis design that they target andthe methods used to validate their beneﬁts. These projects alsoprovide a preview of many approaches to vis that are discussed inmore detail later in the book.\\n4.7.1 Genealogical Graphs\\nMcGufﬁn and Balakrishnan present a system for the visualization\\nof genealogical graphs [McGufﬁn and Balakrishnan 05]. They pro-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9414d031-ed44-4b24-a777-1cb7856057a5', embedding=None, metadata={'page_label': '82', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='82 4. Analysis: Four Levels for Validation\\n(a)\\n (b)\\nFigure 4.6. Genealogical graphs. (a) Three layouts for the dual-tree: classical node–link top-to-bottom at the top,\\nclassical left-to-right on the left, and the new indented outline algorithm on the right. (b) Widget for subtree collapsingand expanding with ballistic drags. From [McGufﬁn and Balakrishnan 05, Figures 13 and 14].\\npose multiple new visual encoding idioms, including one based on\\nthe dual-tree , a subgraph formed by the union of two trees, as\\nshown in Figure 4.6(a). Their prototype features sophisticated in-teraction idioms, including automatic camera framing, animatedtransitions, and a new widget for ballistically dragging out sub-\\ntrees to arbitrary depths as shown in Figure 4.6(b).\\nThis exemplary paper explicitly covers all four levels. The ﬁrst\\ndomain situation level is handled concisely but clearly: their do-\\nmain is genealogy, and they brieﬂy discuss the needs of and cur-rent tools available for genealogical hobbyists. The paper particu-larly shines in the analysis at the second abstraction level. Theypoint out that the very term family tree is highly misleading, be-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fa1be7b4-ea74-4f56-afd3-b584191d2891', embedding=None, metadata={'page_label': '83', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.7. Validation Examples 83\\nJustify encoding/interaction design\\nQualitative result image analysis\\nTest on target users, collect anecdotal evidence of utility\\nFigure 4.7. Genealogical graphs [McGufﬁn and Balakrishnan 05] validation levels.\\ncause the data type in fact is a more general graph with specialized\\nconstraints on its structure. They discuss conditions for which thedata type is a true tree, a multitree, or a directed acyclic graph.They map the domain problem of recognizing nuclear family struc-ture into an abstract task of determining subgraph structure. Atthe third level of the model, they discuss the strengths and weak-nesses of several visual encoding idiom design choices, includingusing connection, containment, adjacency and alignment, and in-dentation. They present in passing two more specialized encoding\\n▶Design choices for visual\\nencoding idioms for networkdata are discussed in Chap-\\nter 9. idioms, fractal node–link and containment for free trees, before\\npresenting in detail their main proposal for visual encoding. Theyalso carefully address interaction idiom design, which also falls\\ninto the third level of the model. At the fourth level of algorithm\\ndesign, they concisely cover the algorithmic details of dual-tree lay-out.\\nThree validation methods are used in this paper, shown in Fig-\\nure 4.7. There is the immediate justiﬁcation of encoding and in-teraction idiom design decisions in terms of established principles,and the downstream method of a qualitative discussion of resultimages and videos. At the abstraction level, there is the down-stream informal testing of a system prototype with a target user tocollect anecdotal evidence.\\n4.7.2 MatrixExplorer\\nHenry and Fekete present the MatrixExplorer system for social net-\\nwork analysis [Henry and Fekete 06], shown in Figure 4.8. Its de-sign comes from requirements formalized by interviews and partic-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='97ce57d4-664e-4c00-932c-77ad2f7bae43', embedding=None, metadata={'page_label': '84', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='84 4. Analysis: Four Levels for Validation\\nFigure 4.8. MatrixExplorer features both node–link and matrix representations in an interface designed for sociolo-\\ngists and historians to explore social networks. From [Henry and Fekete 06, Figure 1].\\nipatory design sessions with social science researchers. They use\\nboth matrix representations to minimize clutter for large and dense\\ngraphs and the more intuitive node–link representations of graphs\\nfor smaller networks.▶The strengths and weak-\\nnesses of matrix and node–link representations of net-works are discussed in Sec-\\ntion 9.4.\\nAll four levels of the model are addressed, with validation at\\nthree of the levels, shown in Figure 4.9. At the domain situa-tion level, there is explicit characterization of the social network\\nanalysis domain, which is validated with the qualitative techniques\\nof interviews and an exploratory study using participatory designmethods with social scientists and other researchers who use so-cial network data. At the abstraction level, the paper includes adetailed list of requirements of the target user needs discussed in\\nterms of abstract tasks and data. There is a thorough discussion of\\nthe primary encoding idiom design decision to use both node–linkand matrix views to show the data, and also of many secondaryencoding issues. There is also a discussion of both basic interac-tion idioms and more complex interaction via interactive reorderingand clustering. In both cases the authors use the immediate val-\\nidation method of justifying these design decisions. There is also\\nan extensive downstream validation of this level using qualitativediscussion of result images. At the algorithm level, the focus ison the reordering algorithm. Downstream benchmark timings arementioned very brieﬂy.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0706967-5f15-4d01-bff8-3b89219e34e3', embedding=None, metadata={'page_label': '85', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.7. Validation Examples 85\\nJustify encoding/interaction design\\nMeasure system time/memory\\nQualitative result image analysisObserve and interview target users\\nFigure 4.9. MatrixExplorer [Henry and Fekete 06] validation methods.\\n4.7.3 Flow Maps\\nPhan et al. propose a system for creating ﬂow maps that show the\\nmovement of objects from one location to another, and demon-strate it on network trafﬁc, census data, and trade data [Phanet al. 05]. Flow maps reduce visual clutter by merging edges, butmost previous instances were hand drawn. They present auto-matic techniques inspired by graph layout algorithms to minimizeedge crossings and distort node positions while maintaining rela-tive positions, as shown in Figure 4.10. Figure 4.10(a) shows mi-\\n▶The visual encoding of\\ngeographic data is dis-\\ncussed in Section 8.3.1. gration to California, while Figure 4.10(b) shows the top ten states\\nsending migrants to California and New York.\\nIn their paper, Phan et al. focus on the innermost algorithm\\ndesign level, but the idiom and abstraction levels are also cov-ered. Their analysis of the useful characteristics of hand-drawnﬂow maps falls into the abstraction level. At the idiom level, theyhave a brief but explicit description of the goals of their layout al-gorithm, namely, intelligent distortion of positions to ensure thatthe separation distance between nodes is greater than the maxi-mum thickness of the ﬂow lines while maintaining left–right and\\nup–down ordering relationships. The domain situation level is ad-\\ndressed more implicitly than explicitly: there is no actual discus-sion of who uses ﬂow maps and why. However, the analysis ofhand-drawn ﬂow maps could be construed as an implicit claim oflongstanding usage needs.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='25e22209-8bdf-4bf3-9042-1953485e8cc9', embedding=None, metadata={'page_label': '86', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='86 4. Analysis: Four Levels for Validation\\n(a)\\n (b)\\nFigure 4.10. Flow maps showing migration patterns from 1995 to 2000 US Census data. (a) Migration from Cali-\\nfornia. (b) The top ten states that sent migrants to California shown in green, and to New Y ork in blue. From [Phanet al. 05, Figures 1c and 10].\\nFour validation methods were used in this paper, shown in Fig-\\nure 4.11. At the algorithm level, there is an immediate complexityanalysis. There is also a brief downstream report of system timing,\\nsaying that all images were computed in a few seconds. There isalso a more involved downstream validation through the qualita-\\nJustify encoding/interaction design\\nComputation complexity analysis\\nMeasure system time/memory\\nQualitative result image analysis\\nFigure 4.11. Flow map [Phan et al. 05] validation methods.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd809467-74be-4246-8bc3-b158d0c4e699', embedding=None, metadata={'page_label': '87', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.7. Validation Examples 87\\n(a)\\n (b)\\nFigure 4.12. LiveRAC supports exploration of system management time-series data with a reorderable matrix and\\nsemantic zooming. (a) The ﬁrst several dozen rows have been stretched out to show sparklines for the devices. (b)The top three rows have been enlarged more, so the charts appear in full detail. From [McLachlan et al. 08, Figure 3].\\ntive discussion of result images generated by their system. In this\\ncase, the intent was mainly to discuss algorithm correctness issuesat the innermost algorithm level, as opposed to addressing the vi-\\nsual encoding idiom level. At the idiom level, the authors justifytheir three fundamental requirements as the outcome of analyzinghand-drawn diagrams: intelligent distortion of positions, merging\\nof edges that share destinations, and intelligent edge routing.\\n4.7.4 LiveRAC\\nMcLachlan et al. present the LiveRAC system for exploring sys-\\ntem management time-series data [McLachlan et al. 08]. LiveRAC\\nuses a reorderable matrix of charts with stretch and squish nav-igation combined with semantic zooming, so that the chart’s vi-sual representation adapts to the available space. Figure 4.12(a)\\n▶Reorderable matrix align-\\nments are covered in Sec-tion 7.5.2, semantic zoom-ing is covered in Sec-tion 11.5.2, and stretch andsquish navigation is cov-\\nered in Section 14.5.shows a mix of small boxes showing only a single attribute encoded\\nwith color and somewhat larger boxes showing concise line charts.The top three rows have been enlarged in Figure 4.12(b), providingenough room that the representation switches to detailed chartswith axes and labels. The paper reports on an informal longitudi-nal ﬁeld study of its deployment to operators of a large corporate', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e876113-b9a8-4a87-b7d6-edd5a68b37a9', embedding=None, metadata={'page_label': '88', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='88 4. Analysis: Four Levels for Validation\\nJustify encoding/interaction design\\nQualitative result image analysisObserve and interview target users\\nField study, document usage of deployed \\nsystem\\nFigure 4.13. LiveRAC [McLachlan et al. 08] validation methods.\\nweb hosting service. Four validation methods were used in this\\npaper, shown in Figure 4.13.\\nAt the domain situation level, the paper explains the roles and\\nactivities of system management professionals and their existingworkﬂow and tools. The validation approach was interviews withthe target audience. The phased design methodology, where man-agement approval was necessary for access to the true target users,led to a mix of immediate and downstream timing for this valida-tion: many of these interviews occurred after a working prototypewas developed. This project is a good example of the iterative pro-cess alluded to in Section 4.3.\\nAt the abstraction level, the choice of a collection of time-series\\ndata for data type is discussed early in the paper. The rationaleis presented in the opposite manner from the discussion above:rather than justifying that time-series data is the correct choice for\\nthe system management domain, the authors justify that this do-\\nmain is an appropriate one for studying this data type. The paperalso contains a set of explicit design requirements, which includesabstract tasks like search, sort, and ﬁlter. The downstream vali-dation for the abstraction level is a longitudinal ﬁeld study of thesystem deployed to the target users, life cycle engineers for man-\\naged hosting services inside a large corporation.\\nAt the visual encoding and interaction level, there is an exten-\\nsive discussion of design choices, with immediate validation by jus-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='257c66b2-9063-49cd-b555-ac035f88edc1', embedding=None, metadata={'page_label': '89', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.7. Validation Examples 89\\ntiﬁcation in terms of design principles and downstream validation\\nthrough a qualitative discussion of the results. Algorithms are notdiscussed.\\n4.7.5 LinLog\\nNoack’s LinLog paper introduces an energy model for graph draw-\\ning designed to reveal clusters in the data, where clusters are de-ﬁned as a set of nodes with many internal edges and few edges to\\nnodes outside the set [Noack 03]. Energy-based and force-directedmethods are related approaches to network layout and have beenheavily used in information visualization. Previous models strove\\n▶Force-directed placement\\nis discussed in Section 9.2.\\nto enforce a layout metric of uniform edge lengths, but Noack\\npoints out that creating visually distinguishable clusters requires\\nlong edges between them. Figure 4.14(a) shows the success of thisapproach, in contrast to the indifferentiated blob created by a pre-viously proposed method shown in Figure 4.14(b).\\nAlthough a quick glance might lead to an assumption that this\\ngraph drawing paper has a focus on algorithms, the primary con-tribution is in fact at the visual encoding idiom level. The two vali-dation methods used in the paper are qualitative and quantitativeresult image analysis, shown in Figure 4.15.\\nNoack clearly distinguishes between the two aspects of energy-\\nbased methods for force-directed graph layout: the energy modelitself versus the algorithm that searches for a state with minimum\\ntotal energy. In the vocabulary of my model, his LinLog energy\\nmodel is a visual encoding idiom. Requiring that the edges betweenclusters are longer than those within clusters is a visual encoding\\n(a)\\n (b)\\nFigure 4.14. The LinLog energy model reveals clusters in node–link graphs. (a)\\nLinLog clearly shows clusters with spatial separation. (b) The popular Fructerman-Reingold model for force-directed placement does not separate the clusters.From [Noack 03, Figure 1].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='316d1dad-cfd4-487a-aafa-51a59fe074ff', embedding=None, metadata={'page_label': '90', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='90 4. Analysis: Four Levels for Validation\\nQualitative/quantitative result image analysis\\nFigure 4.15. LinLog [Noack 03] validation methods.\\nusing the visual channel of spatial position. One downstream val-\\nidation approach in this paper is a qualitative discussion of resultimages, which is appropriate for a contribution at the encodinglevel. This paper also contains a validation method not listed inthe model, because it is relatively rare in vis: mathematical proof.These proofs are about the optimality of the model results when\\nmeasured by quantitative metrics involving edge lengths and node\\ndistances. Thus, this model classiﬁes it in the quantitative imageanalysis category, another appropriate method to validate at theidiom level.\\nThis paper does not in fact address the innermost algorithm\\nlevel. Noack explicitly leaves the problem of designing better energy-minimization algorithms as future work, using previously proposedalgorithms to showcase the results of his model. The domain situ-ation level is handled concisely but adequately by referencing pre-vious work about application domains with graph data where thereis a need to see clusters. For the abstraction level, although thepaper does not directly use the vocabulary of task and data ab-\\nstraction , it clearly states that the abstract task is ﬁnding clusters\\nand that the data abstraction is a network.\\n4.7.6 Sizing the Horizon\\nHeer et al. compare line charts to the more space-efﬁcient horizon\\ngraphs [Heer et al. 09], as Figure 4.16 shows. They identify tran- ▶Line charts are discussed\\nin Section 9.2. sition points at which reducing the chart height results in signiﬁ-\\ncantly differing drops in estimation accuracy across the comparedchart types, and they ﬁnd optimal positions in the speed–accuracytrade-off curve at which viewers performed quickly without atten-dant drops in accuracy. This paper features lab studies that aredesigned to validate (or invalidate) speciﬁc design choices at the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76d0e811-6ed1-403e-81b3-513ef825097b', embedding=None, metadata={'page_label': '91', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.8. Further Reading 91\\nFigure 4.16. Experiment 2 of Sizing the Horizon compared ﬁlled line charts, one-band horizon graphs, and two-\\nband horizon graphs of different sizes to ﬁnd transition points where reducing chart height results in major drops in\\nestimation accuracy across chart types. From [Heer et al. 09, Figure 7].\\nLab study, measure human time/errors for task\\nFigure 4.17. Lab studies as a validation method.\\nvisual encoding and interaction idiom level by measuring time and\\nerror rates of people carrying out abstracted tasks, as shown inFigure 4.17.\\n4.8 Further Reading\\nThe Big Picture I ﬁrst presented the four-level nested model of vis\\ndesign as a paper [Munzner 09a], with a discussion of blocksand guidelines between them in a follow-up paper [Meyer\\net al. 13]; both of these contain many more references to pre-\\nvious and related work. McGrath’s analysis of the strengthsand limitations of different experimental methods is well worthreading [McGrath 94], and it inﬂuenced my partition of vali-dation techniques according to levels.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='83e29aa9-3650-48e5-85ea-a0077c3b0e34', embedding=None, metadata={'page_label': '92', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='92 4. Analysis: Four Levels for Validation\\nProblem-Driven Work A good entry point for problem-driven vis work\\nis a detailed discussion of design study methodology, with anine-stage framework for conducting them and suggestionsfor how to avoid 32 pitfalls [Sedlmair et al. 12]. Anotherframework for problem-driven work is the MultidimensionalIn-depth Long-term Case studies (MILC) approach, which alsoadvocates working closely with domain users [Shneidermanand Plaisant 06].\\nAbstraction Level A recent paper argues that both data and task ab-\\nstractions are important points of departure for vis design-ers [Pretorius and van Wijk 09]. The problems at the abstrac-tion level fall into the realm of requirements elicitation andanalysis in software engineering; a good starting point for thatliterature is a recent book chapter [Maalej and Thurimella 13].\\nAlgorithm Level There are several existing books with a heavy focus\\non the algorithm level, including two textbooks [Telea 07,Ward et al. 10] and a large handbook [Hansen and John-son 05]. Other options are recent survey papers on a particu-lar topic, or speciﬁc research papers for very detailed discus-sion about a given algorithm. The larger issues of algorithmdesign are certainly not unique to vis; an excellent general ref-erence for algorithms is a popular textbook that also coverscomplexity analysis [Cormen et al. 90].\\nHuman–Computer Interaction A comprehensive textbook is a good\\nstarting point for the academic human–computer interaction\\nliterature [Sharp et al. 07]. A very accessible book is a goodstarting point for the large literature aimed at practitioners[Kuniavsky 03].\\nEvaluation Methods A book chapter provides an excellent survey and\\noverview of evaluation and validation methods for vis, includ-\\ning an extensive discussion of qualitative methods [Carpen-dale 08]. Another discussion of evaluation challenges in-cludes a call for more repositories of data and tasks [Plais-ant 04]. A viewpoint article contains the thoughts of sev-\\neral researchers on why, how, and when to do user stud-ies [Kosara et al. 03].\\nField Studies For ﬁeld studies, contextual inquiry is a particularly\\nimportant method and is covered well in a book by one of itspioneers [Holtzblatt and Jones 93].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c15289e-eeb0-46b7-8aaf-fe1e92fb9a24', embedding=None, metadata={'page_label': '93', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4.8. Further Reading 93\\nExperiment Design For lab studies, my current favorite references\\nfor experiment design and analysis are a cogent and acces-sible recent monograph [Hornbaek 13], a remarkably wittybook [Field and Hole 03], and a new textbook with many ex-amples featuring visualization [Purchase 12].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b2cf8efd-966e-4458-9070-6982a93b283d', embedding=None, metadata={'page_label': '94', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Magnitude Channels: Ordered Attributes Identity Channels: Categorical Attributes\\nSpatial region\\nColor hueMotion\\nShapePosition on common scalePosition on unaligned scale\\nLength (1D size)Tilt/angleArea (2D size)Depth (3D position)Color luminanceColor saturationCurvatureVolume (3D size)Channels: Expressiveness Types and Effectiveness Ranks\\nFigure 5.1. The effectiveness of channels that modify the appearance of marks depends on matching the expres-\\nsiveness of channels with the attributes being encoded.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a8a2eaec-f881-4d2e-9b6b-6afbdc97b63b', embedding=None, metadata={'page_label': '95', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Marks and ChannelsChapter 5\\n5.1 The Big Picture\\nMarks are basic geometric elements that depict items or links, and\\nchannels control their appearance. The effectiveness of a channelfor encoding data depends on its type: the channels that percep-tually convey magnitude information are a good match for ordereddata, and those that convey identity information with categoricaldata. Figure 5.1 summarizes the channel rankings.\\n5.2 Why Marks and Channels?\\nLearning to reason about marks and channels gives you the build-\\ning blocks for analyzing visual encodings. The core of the design\\nspace of visual encodings can be described as an orthogonal combi-\\nnation of two aspects: graphical elements called marks, and visualchannels to control their appearance. Even complex visual encod-ings can be broken down into components that can be analyzed interms of their marks and channel structure.\\n5.3 Deﬁning Marks and Channels\\nAmark is a basic graphical element in an image. Marks are geo-\\nmetric primitive objects classiﬁed according to the number of spa-tial dimensions they require. Figure 5.2 shows examples: a zero-\\ndimensional ( 0D) mark is a point, a one-dimensional ( 1D) mark\\nis a line, and a two-dimensional ( 2D) mark is an area. A three-\\ndimensional ( 3D) volume mark is possible, but they are not fre-\\nquently used.\\n95', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e8dfa6b3-68c2-4a4c-8fa5-df37c8fa50fd', embedding=None, metadata={'page_label': '96', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='96 5. Marks and Channels\\nPoints Lines Areas\\nFigure 5.2. Marks are geometric primitives.\\nA visual channel is a way to control the appearance of marks,\\nindependent of the dimensionality of the geometric primitive.⋆Fig- ⋆ The term channel is\\npopular in the vis litera-ture and is not meant toimply any particular theoryabout the underlying mech-\\nanisms of human visual per-\\nception. There are many,many synonyms for visual\\nchannel : nearly any com-\\nbination of visual ,graphical ,\\nperceptual ,retinal for the\\nﬁrst word, and channel ,at-\\ntribute ,dimension ,variable ,\\nfeature , and carrier for the\\nsecond word.ure 5.3 shows a few of the many visual channels that can encode\\ninformation as properties of a mark. Some pertain to spatial po-sition, including aligned planar position, unaligned planar posi-tion, depth (3D position), and spatial region. Others pertain tocolor, which has three distinct aspects: hue, saturation, and lu-minance. There are three size channels, one for each added di-mension: length is 1D size, area is 2D size, and volume is 3D size.The motion-oriented channels include the motion pattern, for in-stance, oscillating circles versus straight jumps, the direction ofmotion, and the velocity. Angle is also a channel, sometimes called\\ntilt. Curvature is also a visual channel. Shape is a complex phe-\\nnomenon, but it is treated as a channel in this framework.\\nHorizontalPosition\\nVertical BothColor\\nShape Tilt\\nSize\\nLength Area Volume\\nFigure 5.3. Visual channels control the appearance of marks.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='094a403a-2415-44e5-8546-d44fe760f125', embedding=None, metadata={'page_label': '97', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.3. Deﬁning Marks and Channels 97\\n(a) (b) (c) (d)\\nFigure 5.4. Using marks and channels. (a) Bar charts encode two attributes using\\na line mark with the vertical spatial position channel for the quantitative attribute,and the horizontal spatial position channel for the categorical attribute. (b) Scat-terplots encode two quantitative attributes using point marks and both vertical andhorizontal spatial position. (c) A third categorical attribute is encoded by addingcolor to the scatterplot. (d) Adding the visual channel of size encodes a fourthquantitative attribute as well.\\nFigure 5.4 shows a progression of chart types, with each show-\\ning one more quantitative data attribute by using one more visualchannel. A single quantitative attribute can be encoded with ver-tical spatial position. Bar charts are a common example of thisencoding: the height of the bar conveys a quantitative value forthat attribute, as in Figure 5.4(a). Bar charts show two attributes,but only one is quantitative: the other is the categorical attributeused to spread out the bars along the axis (in this case, the hor-izontal axis). A second, independent quantitative attribute can beencoded by using the visual channel of horizontal spatial positionto directly encode information. It doesn’t make sense any more touse a line for the mark in this case, so the mark type needs to bea point. This visual encoding, shown in Figure 5.4(b), is a scatter-plot. You cannot continue to add more spatial position channelswhen creating drawings in two-dimensional space, but many visualchannels are nonspatial. An additional categorical data attributecan be encoded in a scatterplot format using the visual channel ofhue (one aspect of color), as in Figure 5.4(c). Figure 5.4(d) showsthe addition of a fourth quantitative attribute encoded with the vi-sual channel of size.\\nIn these examples, each attribute is encoded with a single chan-\\nnel. Multiple channels can be combined to redundantly encode the\\nsame attribute. The limitation of this approach is that more chan-\\nnels are “used up” so that not as many attributes can be encodedin total, but the beneﬁt is that the attributes that are shown willbe very easily perceived.\\nThe size and shape channels cannot be used on all types of\\nmarks: the higher-dimensional mark types usually have built-in', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='762b4b2f-a07c-4267-860e-4fd28fa4e9ab', embedding=None, metadata={'page_label': '98', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='98 5. Marks and Channels\\nconstraints that arise from the way that they are deﬁned. An\\narea mark has both dimensions of its size constrained intrinsi-cally as part of its shape, so area marks typically are not sizecoded or shape coded. For example, an area mark denoting a stateor province within a country on a geographic map already has acertain size, and thus attempting to size code the mark with anadditional attribute usually doesn’t make sense.\\n1Similarly, the\\ntreemap visual encoding idiom shows the hierarchical structureof a tree using nested area marks; Figure 9.8 shows an example.The size of these marks is determined by an existing attribute thatwas used in construction of the treemap, as is their shape andposition. Changing the size of a mark according to an additionalattribute would destroy the meaning of the visual encoding.\\nA line mark that encodes a quantitative attribute using length in\\none direction can be size coded in the other dimension by changingthe width of the line to make it fatter. However, it can’t be sizecoded in the ﬁrst direction to make it longer because its length isalready “taken” with the length coding and can’t be co-opted by asecond attribute. For example, the bars in Figure 5.4(a) can’t besize coded vertically. Thus, even though lines are often consideredto be inﬁnitely thin objects in mathematical contexts, line marksused in visual encoding do take up a nonzero amount of area. Theycan be made wider on an individual basis to encode an additionalattribute, or an entire set of bars can simply be made wider in auniform way to be more visible.\\nPoint marks can indeed be size coded and shape coded because\\ntheir area is completely unconstrained. For instance, the circles ofvarying size in the Figure 5.4(d) scatterplot are point marks thathave been size coded, encoding information in terms of their area.An additional categorical attribute could be encoded by changingthe shape of the point as well, for example, to a cross or a triangleinstead of a circle. This meaning of the term point is different\\nthan the mathematical context where it implies something that isinﬁnitely small in area and cannot have a shape. In the context ofvisual encoding, point marks intrinsically convey information onlyabout position and are exactly the vehicle for conveying additional\\ninformation through area and shape.\\n1The cartogram visual encoding idiom, where exactly this kind of size coding of\\nan additional attribute on a set of geographic regions is carried out, is an exception.\\nThis idiom carefully alters the boundaries with a uniﬁed calculation that guarantees\\nthat the borders remain contiguous while attempting to preserve each area’s shape\\nas much as possible.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f8925ffa-fe32-44e9-b0ba-b5f4c13497bc', embedding=None, metadata={'page_label': '99', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.4. Using Marks and Channels 99\\n5.3.1 Channel T ypes\\nThe human perceptual system has two fundamentally different\\nkinds of sensory modalities. The identity channels tell us infor-\\nmation about what something is or where it is. In contrast, the\\nmagnitude channels tell us how much of something there is.⋆⋆ In the psychophysics\\nliterature, the identity chan-\\nnels are called metathetic\\norwhat–where , and the\\nmagnitude channels are\\ncalled prothetic or how\\nmuch .For instance, we can tell what shape we see: a circle, a trian-\\ngle, or a cross. It does not make much sense to ask magnitudequestions for shape. Other what visual channels are shape, the\\ncolor channel of hue, and motion pattern. We can tell what spatial\\nregion marks are within, and where the region is.\\nIn contrast, we can ask about magnitudes with line length: how\\nmuch longer is this line than that line? And identity is not a pro-ductive question, since both objects are lines. Similarly, we canask luminance questions about how much darker one mark is thananother, or angle questions about how much space is between apair of lines, or size questions about how much bigger one markis than another. Many channels give us magnitude information,including the size channels of length, area, and volume; two of thethree color channels, namely, luminance and saturation; and tilt.\\n5.3.2 Mark T ypes\\nThe discussion so far has been focused on table datasets, where\\na mark always represents an item. For network datasets, a markmight represent either an item—also known as a node—or a link.Link marks represent a relationship between items. The two linkmark types are connection and containment. A connection mark\\nshows a pairwise relationship between two items, using a line. A\\ncontainment mark shows hierarchical relationships using areas,\\nand to do so connection marks can be nested within each other atmultiple levels.\\n⋆While the visual representation of the area mark ⋆Synonyms for contain-\\nment are enclosure and\\nnesting .might be with a line that depicts its boundary, containment is fun-\\ndamentally about the use of area. Links cannot be represented by\\npoints, even though individual items can be. Figure 5.5 summa-rizes the possibilities.\\n5.4 Using Marks and Channels\\nAll channels are not equal: the same data attribute encoded with\\ntwo different visual channels will result in different information', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0b7a3563-d8fc-402c-887b-2e83f60fc165', embedding=None, metadata={'page_label': '100', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='100 5. Marks and Channels\\nMarks as Items/Nodes\\nMarks as LinksPoints Lines Areas\\nContainment Connection\\nFigure 5.5. Marks can represent individual items, or links between them.\\ncontent in our heads after it has passed through the perceptual\\nand cognitive processing pathways of the human visual system.\\nThe use of marks and channels in vis idiom design should be\\nguided by the principles of expressiveness and effectiveness. Theseideas can be combined to create a ranking of channels accordingto the type of data that is being visually encoded. If you haveidentiﬁed the most important attributes as part of developing yourtask and data abstraction, you can ensure that they are encodedwith the highest ranked channels.\\n5.4.1 Expressiveness and Effectiveness\\nTwo principles guide the use of visual channels in visual encoding:\\nexpressiveness and effectiveness.\\nThe expressiveness principle dictates that the visual encoding\\nshould express all of, and only, the information in the dataset at-tributes. The most fundamental expression of this principle is thatordered data should be shown in a way that our perceptual systemintrinsically senses as ordered. Conversely, unordered data shouldnot be shown in a way that perceptually implies an ordering thatdoes not exist. Violating this principle is a common beginner’smistake in vis.\\nIt’s no coincidence that the classiﬁcation of data attributes in\\nChapter 2 has a central split along this very same line. This splitof channel types into two major categories is so fundamental tovisual encoding design that this distinction is built into the classi-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='20697e4c-94fc-4dab-a963-61848f7fd350', embedding=None, metadata={'page_label': '101', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.4. Using Marks and Channels 101\\nﬁcation at the ground level. The identity channels are the correct\\nmatch for the categorical attributes that have no intrinsic order.The magnitude channels are the correct match for the ordered at-tributes, both ordinal and quantitative.\\nThe effectiveness principle dictates that the importance of the\\nattribute should match the salience of the channel; that is, its no-\\nticeability. In other words, the most important attributes shouldbe encoded with the most effective channels in order to be most no-ticeable, and then decreasingly important attributes can be matchedwith less effective channels.\\nThe rest of this chapter is devoted to the question of what the\\nword effectiveness means in the context of visual encoding.\\n5.4.2 Channel Rankings\\nFigure 5.6 presents effectiveness rankings for the visual channels\\nbroken down according to the two expressiveness types of orderedand categorical data. The rankings range from the most effectivechannels at the top to the least effective at the bottom.\\nOrdered attributes should be shown with the magnitude chan-\\nnels. The most effective is aligned spatial position , followed by un-\\naligned spatial position . Next is length , which is one-dimensional\\nsize, and then angle , and then area , which is two-dimensional size.\\nPosition in 3D, namely, depth , is next. The next two channels are\\nroughly equally effective: luminance and saturation . The ﬁnal two▶Luminance and satura-\\ntion are aspects of color dis-\\ncussed in Chapter 10.\\nchannels, curvature and volume (3D size), are also roughly equiva-\\nlent in terms of accuracy.\\nCategorical attributes should be shown with the identity chan-\\nnels. The most effective channel for categorical data is spatial re-\\ngion , with color hue as the next best one. The motion channel is ▶Hue is an aspect of color\\ndiscussed in Chapter 10. also effective, particularly for a single set of moving items against\\na sea of static ones. The ﬁnal identity channel appropriate for cat-egorical attributes is shape .\\nWhile it is possible in theory to use a magnitude channel for\\ncategorical data or a identity channel for ordered data, that choicewould be a poor one because the expressiveness principle wouldbe violated.\\nThe two ranked lists of channels in Figure 5.6 both have chan-\\nnels related to spatial position at the top in the most effective spot.Aligned and unaligned spatial position are at the top of the list forordered data, and spatial region is at the top of the list for cate-gorical data. Moreover, the spatial channels are the only ones thatappear on both lists; none of the others are effective for both data', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='40f4bf4b-6e17-4586-a010-e60f1890eb55', embedding=None, metadata={'page_label': '102', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='102 5. Marks and Channels\\nMagnitude Channels: Ordered Attributes Identity Channels: Categorical Attributes\\nSpatial region\\nColor hueMotionShapePosition on common scale\\nPosition on unaligned scale\\nLength (1D size)Tilt/angleArea (2D size)Depth (3D position)Color luminanceColor saturationCurvatureVolume (3D size)Channels: Expressiveness Types and Effectiveness Ranks\\nFigure 5.6. Channels ranked by effectiveness according to data and channel type. Ordered data should be shown\\nwith the magnitude channels, and categorical data with the identity channels.\\ntypes. This primacy of spatial position applies only to 2D positions\\nin the plane; 3D depth is a much lower-ranked channel. These▶The limitations and ben-\\neﬁts of 3D are covered inSection 6.3.fundamental observations have motivated many of the vis idioms\\nillustrated in this book, and underlie the framework of idiom designchoices. The choice of which attributes to encode with position isthe most central choice in visual encoding. The attributes encodedwith position will dominate the user’s mental model —their internal\\nmental representation used for thinking and reasoning—comparedwith those encoded with any other visual channel.\\nThese rankings are my own synthesis of information drawn\\nfrom many sources, including several previous frameworks, exper-imental evidence from a large body of empirical studies, and my', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e52ebcf1-ecc4-43a9-a318-ee3a2d107c7b', embedding=None, metadata={'page_label': '103', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.5. Channel Effectiveness 103\\nown analysis. The further reading section at the end of this chap-\\nter contains pointers to the previous work. The following sectionsof this chapter discuss the reasons for these rankings at length.\\n5.5 Channel Effectiveness\\nTo analyze the space of visual encoding possibilities you need to\\nunderstand the characteristics of these visual channels, becausemany questions remain unanswered: How are these rankings jus-tiﬁed? Why did the designer decide to use those particular visual\\nchannels? How many more visual channels are there? What kindsof information and how much information can each channel en-code? Why are some channels better than others? Can all ofthe channels be used independently or do they interfere with each\\nother?\\nThis section addresses these questions by introducing the anal-\\nysis of channels according to the criteria of accuracy, discrim-\\ninability, separability, the ability to provide visual popout, and theability to provide perceptual groupings.\\n5.5.1 Accuracy\\nThe obvious way to quantify effectiveness is accuracy : how close\\nis human perceptual judgement to some objective measurement ofthe stimulus? Some answers come to us from psychophysics , the\\nsubﬁeld of psychology devoted to the systematic measurement ofgeneral human perception. We perceive different visual channelswith different levels of accuracy; they are not all equally distin-guishable. Our responses to the sensory experience of magnitudeare characterizable by power laws, where the exponent depends onthe exact sensory modality: most stimuli are magniﬁed or com-pressed, with few remaining unchanged.\\nFigure 5.7 shows the psychophysical power law of Stevens\\n[Stevens 75]. The apparent magnitude of all sensory channels fol-lows a power function based on the stimulus intensity:\\nS=I\\nn, (5.1)\\nwhere Sis the perceived sensation and Iis the physical inten-\\nsity. The power law exponent nranges from the sublinear 0.5 for\\nbrightness to the superlinear 3.5 for electric current. That is, thesublinear phenomena are compressed, so doubling the physical', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fbf34531-315f-49e0-86ae-1431c3007635', embedding=None, metadata={'page_label': '104', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='104 5. Marks and Channels\\nFigure 5.7. Stevens showed that the apparent magnitude of all sensory channels\\nfollows a power law S=In, where some sensations are perceptually magniﬁed\\ncompared with their objective intensity (when n> 1) and some compressed (when\\nn< 1). Length perception is completely accurate, whereas area is compressed\\nand saturation is magniﬁed. Data from Stevens [Stevens 75, p. 15].\\nbrightness results in a perception that is considerably less than\\ntwice as bright. The superlinear phenomena are magniﬁed: dou-bling the amount of electric current applied to the ﬁngertips resultsis a sensation that is much more than twice as great. Figure 5.7shows that length has an exponent of n=1.0, so our perception of\\nlength is a very close match to the true value. Here length means\\nthe length of a line segment on a 2D plane perpendicular to the ob-server. The other visual channels are not perceived as accurately:area and brightness are compressed, while red–gray saturation ismagniﬁed.\\nAnother set of answers to the question of accuracy comes from\\ncontrolled experiments that directly map human response to vi-sually encoded abstract information, giving us explicit rankings ofperceptual accuracy for each channel type. For example, Clevelandand McGill’s experiments on the magnitude channels [Clevelandand McGill 84a] showed that aligned position against a common\\nscale is most accurately perceived, followed by unaligned position\\nagainst an identical scale, followed by length, followed by angle.Area judgements are notably less accurate than all of these. Theyalso propose rankings for channels that they did not directly test:after area is an equivalence class of volume, curvature, and lumi-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84ba0ebd-36a4-4111-a8c0-0521c8776639', embedding=None, metadata={'page_label': '105', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.5. Channel Effectiveness 105\\nPositions\\nRectangular \\nareas \\n(aligned or in a \\ntreemap)Angles\\nCircular \\nareasCleveland & McGill’s  Results\\nCrowdsourced Results1.0 3.0 1.5 2.5 2.0\\nLog Error\\n1.0 3.0 1.5 2.5 2.0\\nLog Error\\nFigure 5.8. Error rates across visual channels, with recent crowdsourced results replicating and extending seminal\\nwork from Cleveland and McGill [Cleveland and McGill 84a]. After [Heer and Bostock 10, Figure 4].\\nnance; that class is followed by hue in last place. (This last place\\nranking is for hue as a magnitude channel, a very different matterthan its second-place rank as a identity channel.) These accuracyresults for visual encodings dovetail nicely with the psychophysicalchannel measurements in Figure 5.7. Heer and Bostock conﬁrmedand extended this work using crowdsourcing, summarized in Fig-ure 5.8 [Heer and Bostock 10]. The only discrepancy is that thelater work found length and angle judgements roughly equivalent.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a82f4139-8683-4924-96c5-6540f9bba44a', embedding=None, metadata={'page_label': '106', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='106 5. Marks and Channels\\nThe rankings in Figure 5.6 are primarily based on accuracy,\\nwhich differs according to the type of the attribute that is beingencoded, but also take into account the other four considerations.\\n5.5.2 Discriminability\\nThe question of discriminability is: if you encode data using a par-\\nticular visual channel, are the differences between items percepti-ble to the human as intended? The characterization of visual chan-nel thus should quantify the number of bins that are available for\\nuse within a visual channel, where each bin is a distinguishablestep or level from the other.\\nFor instance, some channels have a very limited number of\\nbins. Consider line width: changing the line size only works fora fairly small number of steps. Increasing the width past that limitwill result in a mark that is perceived as a polygon area rather thana line mark. A small number of bins is not a problem if the numberof values to encode is also small. For example, Figure 5.9 shows anexample of effective linewidth use. Linewidth can work very well toshow three or four different values for a data attribute, but it wouldbe a poor choice for dozens or hundreds of values. The key factoris matching the ranges: the number of different values that needto be shown for the attribute being encoded must not be greaterthan the number of bins available for the visual channel used toencode it. If these do not match, then the vis designer should ei-ther explicitly aggregate the attribute into meaningful bins or usea different visual channel.\\n5.5.3 Separability\\nYou cannot treat all visual channels as completely independent\\nfrom each other, because some have dependencies and interactionswith others. You must consider a continuum of potential interac-tions between channels for each pair, ranging from the orthogonaland independent separable channels to the inextricably combined\\nintegral channels. Visual encoding is straightforward with sepa-\\nrable channels, but attempts to encode different information inintegral channels will fail. People will not be able to access the de-\\nsired information about each attribute; instead, an unanticipatedcombination will be perceived.\\nClearly, you cannot separately encode two attributes of informa-\\ntion using vertical and horizontal spatial position and then expectto encode a third attribute using planar proximity. In this case it', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='59074d65-b5ec-44af-bbf7-504a65f0a110', embedding=None, metadata={'page_label': '107', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.5. Channel Effectiveness 107\\nFigure 5.9. Linewidth has a limited number of discriminable bins.\\nis obvious that the third channel precludes the use of the ﬁrst two.\\nHowever, some of the interchannel interference is less obvious.\\nFigure 5.10 shows pairs of visual channels at four points along\\nthis continuum. On the left is a pair of channels that are com-pletely separable: position and hue. We can easily see that the\\npoints fall into two categories for spatial position, left and right.We can also separately attend to their hue and distinguish the redfrom the blue. It is easy to see that roughly half the points fall into\\neach of these categories for each of the two channels.\\nNext is an example of interference between channels, showing\\nthat size is not fully separable from color hue. We can easily distin-guish the large half from the small half, but within the small halfdiscriminating between the two colors is much more difﬁcult. Sizeinteracts with many visual channels, including shape.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5da1bd6-c04f-4d88-94c0-0916a333ed17', embedding=None, metadata={'page_label': '108', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='108 5. Marks and Channels\\nPosition\\n    Hue (Color)Size\\n    Hue (Color)Width\\n    HeightRed\\n    Green\\nFully separable Some interference Some/significant \\ninterferenceMajor interference\\nFigure 5.10. Pairs of visual channels fall along a continuum from fully separable\\nto intrinsically integral. Color and location are separable channels well suited toencode different data attributes for two different groupings that can be selectivelyattended to. However, size interacts with hue, which is harder to perceive for smallobjects. The horizontal size and and vertical size channels are automatically fused\\ninto an integrated perception of area, yielding three groups. Attempts to code\\nseparate information along the red and green axes of the RGB color space fail,because we simply perceive four different hues. After [Ware 13, Figure 5.23].\\nThe third example shows an integral pair. Encoding one vari-\\nable with horizontal size and another with vertical size is ineffectivebecause what we directly perceive is the planar size of the circles,namely, their area. We cannot easily distinguish groupings of widefrom narrow, and short from tall. Rather, the most obvious per-ceptual grouping is into three sets: small, medium, and large. Themedium category includes the horizontally ﬂattened as well as thevertically ﬂattened.\\nThe far right on Figure 5.10 shows the most inseparable chan-\\nnel pair, where the red and green channels of the RGB color space\\nare used. These channels are not perceived separately, but inte-\\ngrated into a combined perception of color. While we can tell thatthere are four colors, even with intensive cognitive effort it is verydifﬁcult to try to recover the original information about high andlow values for each axis. The RGB color system used to specifyinformation to computers is a very different model than the color\\nprocessing systems of our perceptual system, so the three chan-\\nnels are not perceptually separable.\\n▶Color is discussed in de-\\ntail in Section 10.2.\\nIntegrality versus separability is not good or bad; the important\\nidea is to match the characteristics of the channels to the informa-tion that is encoded. If the goal is to show the user two differentdata attributes, either of which can be attended to selectively, thena separable channel pair of position and color hue is a good choice.If the goal is to show a single data attribute with three categories,', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6d10bba1-365a-47c9-89ba-7969a832d772', embedding=None, metadata={'page_label': '109', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.5. Channel Effectiveness 109\\nthen the integral channel pair of horizontal and vertical size is a\\nreasonable choice because it yields the three groups of small, ﬂat-tened, and large.\\nFinally, integrality and separability are two endpoints of a con-\\ntinuum, not strictly binary categories. As with all of the otherperceptual issues discussed in this chapter, many open questions\\nremain. I do not present a deﬁnitive list with a categorization foreach channel pair, but it’s wise to keep this consideration in mindas you design with channels.\\n5.5.4 Popout\\nMany visual channels provide visual popout , where a distinct item\\nstands out from many others immediately.⋆Figure 5.11 shows two ⋆ Visual popout is of-\\nten called preattentive pro-\\ncessing ortunable detec-\\ntion .examples of popout: spotting a red object from a sea of blue ones,\\nor spotting one circle from a sea of squares. The great value ofpopout is that the time it takes us to spot the different object doesnot depend on the number of distractor objects. Our low-levelvisual system does massively parallel processing on these visualchannels, without the need for the viewer to consciously directlyattention to items one by one. The time it takes for the red circleto pop out of the sea of blue ones is roughly equal when there are15 blue ones as in Figure 5.11(a) or 50 as in Figure 5.11(b).\\nPopout is not an all-or-nothing phenomenon. It depends on\\nboth the channel itself and how different the target item is fromits surroundings. While the red circle pops out from the seas of15 and 50 red squares in Figures 5.11(c) and 5.11(d) at roughly\\n(a) (b) (c) (d) (e) (f)\\nFigure 5.11. Visual popout. (a) The red circle pops out from a small set of blue circles. (b) The red circle pops out\\nfrom a large set of blue circles just as quickly. (c) The red circle also pops out from a small set of square shapes,although a bit slower than with color. (d) The red circle also pops out of a large set of red squares. (e) The red circledoes not take long to ﬁnd from a small set of mixed shapes and colors. (f) The red circle does not pop out from alarge set of red squares and blue circles, and it can only be found by searching one by one through all the objects.\\nAfter http:/ /www.csc.ncsu.edu/faculty/healey/PP by Christopher G. Healey.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6171234-31ee-4315-bc70-f676cce45f2b', embedding=None, metadata={'page_label': '110', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='110 5. Marks and Channels\\n(a) (b) (c)\\n(d)\\n (e) (f)\\nFigure 5.12. Many channels support visual popout, including (a) tilt, (b) size,\\n(c) shape, (d) proximity, and (e) shadow direction. (f) However, parallel line pairs\\ndo not pop out from a sea of slightly tilted distractor object pairs and can only be\\ndetected through serial search. After http:/ /www.csc.ncsu.edu/faculty/healey/PP byChristopher G. Healey.\\nthe same time, this popout effect is slower than with the color\\ndifference versions in Figures 5.11(a) and 5.11(b). The differencebetween red and blue on the color hue channel is larger than thedifference in shape between ﬁlled-in circles and ﬁlled-in squares.\\nAlthough many different visual channels provide popout on their\\nown, they cannot simply be combined. A red circle does not pop out\\nautomatically from a sea of objects that can be red or blue and cir-cles or squares: the speed of ﬁnding the red circle is much faster in\\nFigures 5.11(e) with few distracting objects than in Figure 5.11(f)with many distractors. The red circle can only be detected withserial search : checking each item, one by one. The amount of time\\nit takes to ﬁnd the target depends linearly on the number of dis-tractor objects.\\nMost pairs of channels do not support popout, but a few pairs\\ndo: one example is space and color, and another is motion andshape. Popout is deﬁnitely not possible with three or more chan-nels. As a general rule, vis designers should only count on usingpopout for a single channel at a time.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='56cecbd4-0380-472c-b233-93fab2002f41', embedding=None, metadata={'page_label': '111', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.5. Channel Effectiveness 111\\nPopout occurs for many channels, not just color hue and shape.\\nFigures 5.12(a) through 5.12(e) show several examples: tilt, size,shape, proximity, and even shadow direction. Many other chan-nels support popout, including several different kinds of motionsuch as ﬂicker, motion direction, and motion velocity. All of themajor channels commonly used in visual encoding that are shownin Figure 5.6 do support popout individually, although not in com-bination with each other. However, a small number of potentialchannels do not support popout. Figure 5.12(f) shows that par-allelism is not preattentively detected; the exactly parallel pair oflines does not pop out from the slightly angled pairs but requiresserial search to detect.\\n5.5.5 Grouping\\nThe effect of perceptual grouping can arises from either the use\\nof link marks, as shown in Figure 5.5, or from the use of iden-\\ntity channels to encode categorical attributes, as shown in Fig-ure 5.6.\\nEncoding link marks using areas of containment or lines of\\nconnection conveys the information that the linked objects forma group with a very strong perceptual cue. Containment is thestrongest cue for grouping, with connection coming in second.\\nAnother way to convey that items form a group is to encode cat-\\negorical data appropriately with the identity channels. All of theitems that share the same level of the categorical attribute can beperceived as a group by simply directing attention to that level se-lectively. The perceptual grouping cue of the identity channels isnot as strong as the use of connection or containment marks, buta beneﬁt of this lightweight approach is that it does not add addi-tional clutter in the form of extra link marks. The third strongestgrouping approach is proximity ; that is, placing items within the\\nsame spatial region. This perceptual grouping phenomenon is thereason that the top-ranked channel for encoding categorical datais spatial region. The ﬁnal grouping channel is similarity with the\\nother categorical channels of hue and motion, and also shape ifchosen carefully. Logically, proximity is like similarity for spatialposition; however, from a perceptual point of view the effect of thespatial channels is so much stronger than the effect of the othersthat it is is useful to consider them separately.\\nFor example, the categorical attribute of animal type with the\\nthree levels of cat,dog , and wombat can be encoded with the three\\nhue bins of red,green , and blue respectively. A user who chooses', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e074a68d-cd3b-43d9-904d-49d307feb7f9', embedding=None, metadata={'page_label': '112', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='112 5. Marks and Channels\\nto attend to the blue hue will automatically see all of the wombats\\nas a perceptual group globally, across the entire scene.\\nThe shape channel needs to be used with care: it is possible to\\nencode categorical data with shape in a way that does not auto-matically create perceptual groupings. For example, the shapes ofa forward ‘C’ and a backward ‘C’ do not automatically form globallyselectable groups, whereas the shapes of a circle versus a star do.Similarly, motion also needs to be used with care. Although a setof objects moving together against a background of static objects isa very salient cue, multiple levels of motion all happening at oncemay overwhelm the user’s capacity for selective attention.\\n5.6 Relative versus Absolute Judgements\\nThe human perceptual system is fundamentally based on relative\\njudgements, not absolute ones; this principle is known as Weber’s\\nLaw .⋆For instance, the amount of length difference we can detect ⋆More formally, Weber’s\\nLaw is typically stated asthe detectable difference in\\nstimulus intensity Ias a\\nﬁxed percentage Kof the\\nobject magnitude: δI/I =\\nK.is a percentage of the object’s length.\\nThis principle holds true for all sensory modalities. The fact that\\nour senses work through relative rather than absolute judgementshas far-ranging implications. When considering questions such\\nas the accuracy and discriminability of our perceptions, we mustdistinguish between relative and absolute judgements. For exam-ple, when two objects are directly next to each other and aligned,we can make much more precise judgements than when they are\\nnot aligned and when they are separated with many other objectsbetween them.\\nAn example based on Weber’s Law illuminates why position\\nalong a scale can be more accurately perceived than a pure lengthjudgement of position without a scale. The length judgement inFigure 5.13(a) is difﬁcult to make with unaligned and unframedbars. It is easier with framing, as in Figure 5.13(b), or alignment,as in Figure 5.13(c), so that the bars can be judged against a com-mon scale. When making a judgement without a common scale,the only information is the length of the bars themselves. Placinga common frame around the bars provides another way to estimatemagnitude: we can check the length of the unﬁlled bar. Bar B isonly about 15% longer than Bar A, approaching the range wherelength differences are difﬁcult to judge. But the unﬁlled part ofthe frame for Bar B is about 50% smaller than the one for Bar A,an easily discriminable difference. Aligning the bars achieves thesame effect without the use of a frame.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5bd3d81-94cc-4aeb-8e5e-6872a1593948', embedding=None, metadata={'page_label': '113', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.6. Relative versus Absolute Judgements 113\\nAB\\nUnframed \\nUnaligned\\n(a)Framed \\nUnalignedAB\\n(b)AB\\nUnframed \\nAligned\\n(c)\\nFigure 5.13. Weber’s Law states that we judge based on relative, not absolute\\ndifferences. (a) The lengths of unframed, unaligned rectangles of slightly different\\nsizes are hard to compare. (b) Adding a frame allows us to compare the very dif-ferent sizes of the unﬁlled rectangles between the bar and frame tops. (c) Aligningthe bars also makes the judgement easy. Redrawn and extended after [Clevelandand McGill 84a, Figure 12].\\nAnother example shows that our perception of color and lumi-\\nnance is completely contextual, based on the contrast with sur-rounding colors. In Figure 5.14(a), the two labeled squares in acheckerboard appear to be quite different shades of gray. In Fig-ure 5.14(b), superimposing a solid gray mask that touches bothsquares shows that they are identical. Conversely, Figure 5.15\\n(a)\\n (b)\\nFigure 5.14. Luminance perception is based on relative, not absolute, judgements.\\n(a) The two squares A and B appear quite different. (b) Superimposing a gray\\nmask on the image shows that they are in fact identical.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1676a75f-612b-428d-bcbf-71644767531b', embedding=None, metadata={'page_label': '114', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='114 5. Marks and Channels\\n(a)\\n (b)\\nFigure 5.15. Color perception is also relative to surrounding colors and depends on context. (a) Both cubes have\\ntiles that appear to be red. (b) Masking the intervening context shows that the colors are very different: with yellowapparent lighting, they are orange; with blue apparent lighting, they are purple.\\nshows two colorful cubes. In Figure 5.15(a) corresponding squares\\nboth appear to be red. In Figure 5.15(b), masks show that thetile color in the image apparently illuminated by a yellowish lightsource is actually orange, and for the bluish light the tiles are actu-ally purple. Our visual system evolved to provide color constancy\\nso that the same surface is identiﬁable across a broad set of illumi-nation conditions, even though a physical light meter would yieldvery different readings. While the visual system works very well\\nin natural environments, many of its mechanisms work againstsimple approaches to visually encoding information with color.\\n5.7 Further Reading\\nThe Big Picture The highly inﬂuential theory of visual marks and\\nchannels was proposed by Bertin in the 1960s [Bertin 67].The ranking of channel effectiveness proposed in this chap-ter is my synthesis across the ideas of many previous authorsand does not come directly from any speciﬁc source. It was in-ﬂuenced by the foundational work on ranking of visual chan-nels through measured-response experiments [Cleveland andMcGill 84a], models [Cleveland 93a], design guidelines for', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5538c41d-8450-49f0-b2d7-347dee4e762b', embedding=None, metadata={'page_label': '115', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5.7. Further Reading 115\\nmatching visual channels to data type [Mackinlay 86], and\\nbooks on visualization [Ware 13] and cartography [MacEach-ren 95]. It was also affected by the more recent work oncrowdsourced judgements [Heer and Bostock 10], taxonomy-based glyph design [Maguire et al. 12], and glyph design ingeneral [Borgo et al. 13].\\nPsychophysical Measurement The foundational work on the variable\\ndistinguishability of different visual channels, the categoriza-\\ntion of channels as metathetic identity and prothetic magni-\\ntude, and scales of measurement was done by a pioneer inpsychophysics [Stevens 57, Stevens 75].\\nEffectiveness and Expressiveness Principles The principles of expres-\\nsiveness for matching channel to data type and effectivenessfor choosing the channels by importance ordering appearedin a foundational paper [Mackinlay 86].\\nPerception This chapter touches on many perceptual and cognitive\\nphenomena, but I make no attempt to explain the mecha-nisms that underlie them. I have distilled an enormous liter-\\nature down to the bare minimum of what a beginning vis de-\\nsigner needs to get started. The rich literature on perceptionand cognitive phenomena is absolutely worth a closer look,because this chapter only scratches the surface; for example,the Gestalt principles are not covered.\\nWare offers a broad, thorough, and highly recommended in-\\ntroduction to perception for vis in his two books [Ware 08,\\nWare 13]. His discussion includes more details from nearlyall of the topics in this chapter, including separability andpopout. An overview of the literature on popout and otherperceptual phenomena appears on a very useful page that in-cludes interactive demos http:/ /www.csc.ncsu.edu/faculty/\\nhealey/PP [Healey 07]; one of the core papers in this litera-ture begins to untangle what low-level features are detected\\nin early visual processing [Treisman and Gormican 88].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c253770-3e70-48bf-aef9-110ee901fb81', embedding=None, metadata={'page_label': '116', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='•No Unjustiﬁed 3D\\n–The Power of the Plane\\n–The Disparity of Depth\\n–Occlusion Hides Information\\n–Perspective Distortion Dangers\\n–Tilted T ext Isn’t Legible\\n•No Unjustiﬁed 2D\\n•Eyes Beat Memory\\n•Resolution over Immersion\\n•Overview First, Zoom and Filter, Detail on Demand\\n•Responsiveness Is Required\\n•Get It Right in Black and White\\n•Function First, Form Next\\nFigure 6.1. Eight rules of thumb.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9a8f37d-89a6-4e51-8f61-2f772db3a825', embedding=None, metadata={'page_label': '117', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Rules of ThumbChapter 6\\n6.1 The Big Picture\\nThis chapter contains rules of thumb : advice and guidelines. Each\\nof them has a catchy title in hopes that you’ll remember it as aslogan. Figure 6.1 lists these eight rules of thumb.\\n6.2 Why and When to Follow Rules of Thumb?\\nThese rules of thumb are my current attempt to synthesize the cur-\\nrent state of knowledge into a more uniﬁed whole. In some cases Irefer to empirical studies, in others I make arguments based on my\\nown experience, and some have been proposed in previous work.\\nThey are not set in stone; indeed, they are deeply incomplete. Thecharacterization of what idioms are appropriate for which task anddata abstractions is still an ongoing research frontier, and thereare many open questions.\\n6.3 No Unjustiﬁed 3D\\nMany people have the intuition that if two dimensions are good,\\nthree dimensions must be better—after all, we live in a three-dimensional world. However, there are many difﬁculties in visu-ally encoding information with the third spatial dimension, depth,which has important differences from the two planar dimensions.\\nIn brief, 3D vis is easy to justify when the user’s task involves\\nshape understanding of inherently three-dimensional structures.In this case, which frequently occurs with inherently spatial data,the beneﬁts of 3D absolutely outweigh the costs, and designers canuse the many interaction idioms designed to mitigate those costs.\\nIn all other contexts, the use of 3D needs to be carefully justi-\\nﬁed. In most cases, rather than choosing a visual encoding using\\n117', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='67e008cf-1020-4e46-804d-84dbffcda89a', embedding=None, metadata={'page_label': '118', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='118 6. Rules of Thumb\\nthree dimensions of spatial position, a better answer is to visually\\nencode using only two dimensions of spatial position. Often anappropriate 2D encoding follows from a different choice of data ab-straction, where the original dataset is transformed by computingderived data.\\nThe cues that convey depth information to our visual system\\ninclude occlusion, perspective distortion, shadows and lighting,familiar size, stereoscopic disparity, and others. This section dis-cusses the costs of these depth cues in a visual encoding context\\nand the challenges of text legibility given current display technol-\\nogy. It then discusses situations where the beneﬁts of showingdepth information could outweigh these costs and the need for jus-tiﬁcation that the situation has been correctly analyzed.\\n6.3.1 The Power of the Plane\\nA crucial point when interpreting the channel rankings in Fig-\\nure 5.6 is that the spatial position channels apply only to planarspatial position, not arbitrary 3D position.\\nVertical and horizontal position are combined into the shared\\ncategory of planar because the differences between the up–down\\nand side-to-side axes are relatively subtle. We do perceive height\\ndifferences along the up–down axis as more important than hor-izontal position differences, no doubt due to the physical effectsof gravity in real life. While the vertical spatial channel thus hasa slight priority over the horizontal one, the aspect ratio of stan-\\ndard displays gives more horizontal pixels than vertical ones, so\\ninformation density considerations sometimes override this con-cern. For the perceived importance of items ordered within theaxes, reading conventions probably dominate. Most Western lan-guages go from left to right and from top to bottom, but Arabic andHebrew are read from right to left, and some Asian languages are\\nread vertically.\\n6.3.2 The Disparity of Depth\\nThe psychophysical power law exponents for accuracy shown in\\nFigure 5.7 are different for depth position judgements in 3D thanfor planar position judgements in 2D. Our highly accurate length\\nperception capability, with the linear nvalue of 1.0, only holds for\\nplanar spatial position. For depth judgements of visual distance,nwas measured as 0.67 [Stevens 57]; that exponent is even worse\\nthan the value of 0.7 for area judgements. This phenomenon is', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3e482fc3-0bab-4266-8937-f43a13517dc5', embedding=None, metadata={'page_label': '119', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 119\\nToward AwayUp\\nDownRight\\nLeft\\n(a)Thousands of points up/down and left/right\\nWe can only see the outside shell of the world\\n(b)\\nFigure 6.2. Seeing planar position versus depth. (a) The sideways and up–down\\naxes are fundamentally different from the toward–away depth axis. (b) Along thedepth axis we can see only one point for each ray, as opposed to millions of raysfor the other two axes. After [Ware 08, page 44].\\nnot surprising when considered mathematically, because as shown\\nin Figure 6.2 the length of a line that extends into the scene isscaled nonlinearly in depth, whereas a line that traverses the pic-ture plane horizontally or vertically is scaled linearly, so distancesand angles are distorted [St. John et al. 01].\\nConsidered perceptually, the inaccuracy of depth judgements is\\nalso not surprising; the common intuition that we experience the\\nworld in 3D is misleading. We do not really live in 3D, or even 2.5D:\\nto quote Colin Ware, we see in 2.05D [Ware 08]. That is, most of\\nthe visual information that we have is about a two-dimensional im-\\nage plane , as deﬁned below, whereas the information that we have\\nabout a third depth dimension is only a tiny additional fractionbeyond it. The number of 0.05is chosen somewhat arbitrarily to\\nrepresent this tiny fraction.\\nConsider what we see when we look out at the world along\\na ray from some ﬁxed viewpoint, as in Figure 6.2(a). There is\\na major difference between the toward–away depth axis and theother two axes, sideways and up–down. There are millions of raysthat we can see along these two axes by simply moving our eyes,to get information about the nearest opaque object. This infor-mation is like a two-dimensional picture, often called the image\\nplane . In contrast, we can only get information at one point along\\nthe depth axis for each ray away from us toward the world, asin Figure 6.2(b). This phenomenon is called line-of-sight ambigu-\\nity[St. John et al. 01]. In order to get more information about what\\nis hidden behind the closest objects shown in the image plane, we', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='978a00bb-a959-493a-ac2d-9e2c5654fc78', embedding=None, metadata={'page_label': '120', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='120 6. Rules of Thumb\\nwould need to move our viewpoint or the objects. At best we could\\nchange the viewpoint by simply moving our head, but in manycases we would need to move our body to a very different position.\\n6.3.3 Occlusion Hides Information\\nThe most powerful depth cue is occlusion , where some objects can-\\nnot be seen because they are hidden behind others. The visibleobjects are interpreted as being closer than the occluded ones.The occlusion relationships between objects change as we movearound; this motion parallax allows us to build up an understand-\\ning of the relative distances between objects in the world.\\nWhen people look at realistic scenes made from familiar objects,\\nthe use of motion parallax typically does not impose cognitive loador require conscious attention. In synthetic scenes, navigationcontrols that allow the user to change the 3D viewpoint interac-tively invoke the same perceptual mechanisms to provide motionparallax. In sufﬁciently complex scenes where a single ﬁxed view-point does not provide enough information about scene structure,interactive navigation capability is critical for understanding 3Dstructure. In this case, the cost is time: interactive navigationtakes longer than inspecting a single image.\\nThe overarching problem with occlusion in the context of visual\\nencoding is that presumably important information is hidden, anddiscovering it via navigation has a time cost. In realistic environ-ments, there is rarely a need to inspect all hidden surfaces. How-\\never, in a vis context, the occluded detail might be critical. It is\\nespecially likely to be important when using spatial position as avisual channel for abstract, nonspatial data.\\nMoreover, if the objects have unpredictable and unfamiliar\\nshapes, understanding the three-dimensional structure of the scenecan be very challenging. In this case there can be appreciable cog-\\nnitive load because people must use internal memory to remember\\nthe shape from previous viewpoints, and internally synthesize anunderstanding of the structure. This case is common when usingthe spatial position channels for visual encoding. Figure 6.3 illus-trates the challenges of understanding the topological structure ofa node–link graph laid out in 3D, as an example of the unfamiliar\\nstructure that arises from visually encoding an abstract dataset.\\nSynthesizing an understanding of the structure of the linkages hid-den from the starting viewpoint shown here is likely to take a con-siderable amount of time. While sophisticated interaction idiomshave been proposed to help users do this synthesis more quickly', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c794ed81-cba3-4cf0-af26-0dfed97420f4', embedding=None, metadata={'page_label': '121', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 121\\nFigure 6.3. Resolving the 3D structure of the occluded parts of the scene is possi-\\nble with interactive navigation, but that takes time and imposes cognitive load, even\\nwhen sophisticated interaction idioms are used, as in this example of a node–link\\ngraph laid out in 3D space. From [Carpendale et al. 96, Figure 21].\\nthan with simple realistic navigation, thus lowering the time cost,\\nvis designers should always consider whether the beneﬁts of 3Dare worth the costs.\\n6.3.4 Perspective Distortion Dangers\\nThe phenomenon of perspective distortion is that distant objects\\nappear smaller and change their planar position on the imageplane. Imagine a photograph looking along railroad tracks: al-▶The disparity in our per-\\nception of depth from ourperception of planar spa-\\ntial position is discussed in\\nSection 6.3.2.though they are of course parallel, they appear to draw together as\\nthey recede into the distance. Although the tracks have the samewidth in reality, measuring with a ruler on the photograph itselfwould show that in the picture the width of the nearby track ismuch greater than that of the distant track.\\n⋆⋆The phenomenon of per-\\nspective distortion is also\\nknown as foreshortening .One of the major breakthroughs of Western art was the Renais-\\nsance understanding of the mathematics of perspective to createvery realistic images, so many people think of perspective as a good', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='089a0518-a96f-460d-a509-ba9c818ba82e', embedding=None, metadata={'page_label': '122', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='122 6. Rules of Thumb\\nFigure 6.4. 3D bar charts are more difﬁcult than 2D bar charts because of both\\nperspective distortion and occlusion. From [Few 07, Question 7].\\nthing. However, in the context of visually encoding abstract data,\\nperspective is a very bad thing! Perspective distortion is one ofthe main dangers of depth because the power of the plane is lost;it completely interferes with visual encodings that use the planarspatial position channels and the size channel. For example, it ismore difﬁcult to judge bar heights in a 3D bar chart than in mul-tiple horizontally aligned 2D bar charts, as shown in Figure 6.4.Foreshortening makes direct comparison of bar heights difﬁcult.\\nFigure 6.5 shows another example where size coding in multiple\\ndimensions is used for bars that recede into the distance in 3D ona ground plane. The result of the perspective distortion is thatthe bar sizes cannot be directly compared as a simple perceptualoperation.\\nFigure 6.5. With perspective distortion, the power of the planar spatial position\\nchannel is lost, as is the size channel. From [Mukherjea et al. 96, Figure 1].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4f91d81b-20ac-49a4-ac9f-996660cfd7e7', embedding=None, metadata={'page_label': '123', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 123\\n6.3.5 Other Depth Cues\\nIn realistic scenes, one of the depth cues is the size of familiar\\nobjects. We roughly know the size of a car, so when we see one ata distance we can estimate the size of a nearby unfamiliar object.If all objects in the scene are visually encoded representations of\\nabstract information, we do not have access to this strong depthcue.\\nThe depth cues of shadows and surface shading also commu-\\nnicate depth and three-dimensional structure information. Castshadows are useful for resolving depth ambiguity because they al-low us to infer the height of an object with respect to a groundplane. Shading and self-shadowing show the three-dimensionalshape of an object. One problem with using these lighting-basedcues when visualizing abstract data is that they create visual clut-ter that distracts the viewer’s attention from the meaningful partsof the scene that represent information. Another problem is thatcast shadows, regions of self-shadowing, or highlights could bemistaken by the viewer for true marks that are the substrate forthe visual channels showing attribute information. Cast shad-ows could also cause problems by occluding true marks. The ﬁ-nal problem is that surface shading effects interfere with the colorchannels: highlights can change the hue or saturation, and shad-ows change the luminance.\\nStereoscopic depth is a cue that comes from the disparities be-\\ntween two images made from two camera viewpoints slightly sepa-rated in space, just like our two eyes are. In contrast, all of the pre-vious discussion pertained to pictoral cues from a single camera.Although many people assume that stereo vision is the strongestdepth cue, it is in fact a relatively weak one compared with theothers listed above and contributes little for distant objects. Stereodepth cues are most useful for nearby objects that are at roughlythe same depth, providing guidance for manipulating things withinarm’s reach.\\nStereo displays, which deliver a slightly different image for each\\nof our two eyes, do help people better resolve depth. Conveniently,they do not directly interfere with any of the main visual channels.Stereo displays do indeed improve the accuracy of depth perceptioncompared with single-view displays—but even still depth cannot beperceived with the accuracy of planar position. Of course, stereo\\ncannot solve any of the problems associated with perspective dis-\\ntortion.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7a24ba35-f22a-414f-930b-0e97732bda89', embedding=None, metadata={'page_label': '124', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='124 6. Rules of Thumb\\nThe relatively subtle depth cue of atmospheric perspective,\\nwhere the color of distant objects is shifted toward blue, wouldconﬂict with color encoding.\\n6.3.6 Tilted T ext Isn’t Legibile\\nAnother problem with the use of 3D is dramatically impaired text\\nlegibility with most standard graphics packages that use currentdisplay technology [Grossman et al. 07]. Text fonts have beenvery carefully designed for maximum legibility when rendered onthe grid of pixels that makes up a 2D display, so that charactersas little as nine pixels high are easily readable. Although hard-ware graphics acceleration is now nearly pervasive, so that textpositioned at arbitrary orientations in 3D space can be renderedquickly , this text is usually not rendered well . As soon as a text\\nlabel is tilted in any way off of the image plane, it typically becomesblocky and jaggy. The combination of more careful rendering andvery high-resolution displays of many hundred of dots per inchmay solve this problem in the future, but legibility is a major prob-lem today.\\n6.3.7 Beneﬁts of 3D: Shape Perception\\nThe great beneﬁt of using 3D comes when the viewer’s task fun-\\ndamentally requires understanding the three-dimensional geomet-ric structure of objects or scenes. In almost all of these cases,\\na 3D view with interactive navigation controls to set the 3D view-\\npoint will allow users to construct a useful mental model of datasetstructure more quickly than simply using several 2D axis-alignedviews. For these tasks, all of the costs of using 3D discussed aboveare outweighed by the beneﬁt of helping the viewer build a mentalmodel of the 3D geometry.\\nFor example, although people can be trained to comprehend\\nblueprints with a top view and two side views, synthesizing theinformation contained within these views to understand what acomplex object looks like from some arbitrary 3D viewpoint is a dif-ﬁcult problem that incurs signiﬁcant cognitive and memory load.\\nThe 2D blueprint views are better for the task of accurately dis-\\ncriminating the sizes of building elements, which is why they arestill heavily used in construction. However, there is considerableexperimental evidence that 3D outperforms 2D for shape under-standing tasks [St. John et al. 01].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0586aaf-87a4-424c-8c0e-4085d62d0e62', embedding=None, metadata={'page_label': '125', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 125\\nFigure 6.6. The use of 3D is well justiﬁed when the central task is shape under-\\nstanding, as in this example of 3D streamline showing the patterns of ﬂuid ﬂowthrough a volume. From [Li and Shen 07, Figure 9].\\nMost tasks that have inherently 3D spatial data after the ab-\\nstraction stage fall into this category. Some classical examples areﬂuid ﬂow over an airplane wing, a medical imaging tomographydataset of the human body, or molecular interaction within a liv-ing cell. Figure 6.6 shows an example of streamlines in 3D ﬂuid▶Streamlines are discus-\\nsed further in Section 8.5,and geometric navigation in\\nSection 11.5.\\nﬂow [Li and Shen 07], where geometric navigation based on 3D\\nrotation is a good strategy to help users understand the complexshapes quickly.\\n6.3.8 Justiﬁcation and Alternatives\\nThe question of whether to use two or three channels for spatial\\nposition has now been extensively studied. When computer-based\\nvis began in the late 1980s, there was a lot of enthusiasm for 3Drepresentations. As the ﬁeld matured, researchers began to bet-ter appreciate the costs of 3D approaches when used for abstractdatasets [Ware 01]. By now, the use of 3D for abstract data re-quires careful justiﬁcation. In many cases, a different choice atthe abstraction or visual encoding levels would be more appropri-ate.\\nExample: Cluster–Calendar Time-Series Vis\\nA good example is a system from van Wijk and van Selow designed to\\nbrowse time-series data [van Wijk and van Selow 99]. The dataset has two', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1483663a-accb-48fa-9f59-4ad2d317e188', embedding=None, metadata={'page_label': '126', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='126 6. Rules of Thumb\\nKW\\n0:006:0012:0018:0024:00\\nhours\\n1 jan.5 feb.daysKW\\n12 mar.16 apr.21 may25 jun.30 jul.3 sep.8 oct.12 nov.17 dec.Total KW consumption ECN\\n0400800120016002000\\n(a)\\n(b)\\nFigure 6.7. 3D versus 2D. (a) A 3D representation of this time-series dataset introduces the problems of occlusion\\nand perspective distortion. (b) The linked 2D views of derived aggregate curves and the calendar allow direct\\ncomparison and show more ﬁne-grained patterns. From [van Wijk and van Selow 99, Figures 1 and 4].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c3d5c83e-bfef-4d39-a3b1-8710fbe31f34', embedding=None, metadata={'page_label': '127', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 127\\nrelated sets of measurements: the number of people inside and amount\\nof power used in an ofﬁce building, with measurements over the courseof each day for one full year. The authors compare a straightforward 3Drepresentation with a carefully designed approach using linked 2D views,which avoids the problems of occlusion and perspective distortion. Fig-ure 6.7(a) shows the straightforward 3D representation created directlyfrom the original time-series data, where each cross-section is a 2D time\\nseries curve showing power consumption for one day, with one curve for\\neach day of the year along the extruded third axis. Only very large-scalepatterns such as the higher consumption during working hours and theseasonal variation between winter and summer are visible.\\nThe ﬁnal vis designed by the authors uses multiple linked 2D views\\nand a different data abstraction. They created the derived data of a hier-\\n▶Linked views are dis-\\ncussed in Chapter 12. archical clustering of the time-series curves through an iterative process\\nwhere the most similar curves are merged together into a cluster that can\\nbe represented by the average of the curves within it.\\nFigure 6.7(b) shows a single aggregate curve for each of the highest-\\nlevel groups in the clustering in the window on the right of the display.There are few enough of these aggregate curves that they can all be su-perimposed in the same 2D image without excessive visual clutter. Di-rect comparison between the curve heights at all times of the day is easybecause there is no perspective distortion or occlusion. (The cluster–\\ncalendar vis shows the number of people in the building, rather than the\\npower consumption of the 3D extruded vis.)\\nOn the left side of Figure 6.7(b) is a calendar view. Calendars are a\\nvery traditional and successful way to show temporal patterns. The viewsare linked with shared color coding. The same large-scale patterns ofseasonal variation between summer and winter that can be seen in 3D arestill very visible, but smaller-scale patterns that are difﬁcult or impossibleto spot in the 3D view are also revealed. In this Dutch calendar, weeks are\\nvertical strips with the weekend at the bottom. We can identify weekends\\nand holidays as the nearly ﬂat teal curve where nobody is in the building,and normal weekdays as the topmost tan curve with a full house. Summerand Fridays during the winter are the brown curve with one hundred fewerpeople, and Fridays in the summer are the green curve with nearly halfof the employees gone. The blue and magenta curves show days betweenholiday times where most people also take vacation. The red curve showsthe unique Dutch holiday of Santa Claus day, where everybody gets toleave work an hour early.\\nWhile unbridled enthusiasm for 3D is no longer common, there\\nare indeed situations where its use is justiﬁable even for abstractdata.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='09682abe-82ac-4c3f-a24c-3fda606e18bf', embedding=None, metadata={'page_label': '128', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='128 6. Rules of Thumb\\nExample: Layer-Oriented Time-Series Vis\\nFigure 6.8 shows an example that is similar on the surface to the pre-\\nvious one, but in this case 3D is used with care and the design is welljustiﬁed [Lopez-Hernandez et al. 10]. In this system for visualizing os-cilloscope time-series data, the user starts by viewing the data using the\\ntraditional eye diagram where the signal is wrapped around in time and\\nshown as many overlapping traces. Users can spread the traces apartusing the metaphor of opening a drawer, as shown in Figure 6.8(a). Thisdrawer interface does use 3D, but with many constraints. Layers are or-thographically projected and always face the viewer. Navigation complexityis controlled by automatically zooming and framing as the user adjusts thedrawer’s orientation, as shown in Figure 6.8(b).\\n(a)\\n(b)\\nFigure 6.8. Careful use of 3D. (a) The user can evolve the view from the traditional\\noverlapping eye diagram with the metaphor of opening a drawer. (b) The interac-tion is carefully designed to avoid the difﬁculties of unconstrained 3D navigation.From [Lopez-Hernandez et al. 10, Figures 3 and 7].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='75aa541a-86ea-4530-9412-51b31a428ddf', embedding=None, metadata={'page_label': '129', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.3. No Unjustiﬁed 3D 129\\n6.3.9 Empirical Evidence\\nEmpirical experiments are critical in understanding user perfor-\\nmance, especially because of the well-documented dissociation be-\\ntween stated preference for 3D and actual task performance [An-dre and Wickens 95]. Experimental evidence suggests that 3D in-terfaces are better for shape understanding, whereas 2D are bestfor relative position tasks: those that require judging the precise\\ndistances and angles between objects [St. John et al. 01]. Mosttasks involving abstract data do not beneﬁt from 3D; for exam-\\nple, an experiment comparing 3D cone trees to an equivalent 2D\\ntree browser found that the 3D interaction had a signiﬁcant timecost [Cockburn and McKenzie 00].\\nDesigning controlled experiments that untangle the efﬁcacy of\\nspeciﬁc interfaces that use 3D can be tricky. Sometimes the goal\\nof the experimenter is simply to compare two alternative interfacesthat differ in many ways; in such cases it is dangerous to concludethat if an interface that happens to be 3D outperforms anotherthat happens to be 2D, it is the use of 3D that made the differ-\\nence. In several cases, earlier study results that were interpretedas showing beneﬁts for 3D were superseded by more careful exper-\\nimental design that eliminated uncontrolled factors. For example,the 3D Data Mountain interface for organizing web page thumbnail\\nimages was designed to exploit human spatial cognition and wasshown to outperform the standard 2D Favorites display in InternetExplorer [Robertson et al. 98]. However, this study left open thequestion of whether the beneﬁt was from the use of 3D or the use\\nof the data mountain visual encoding, namely, a spatial layout al-lowing immediate access to every item in each pile of information.A later study compared two versions of Data Mountain, one with3D perspective and one in 2D, and no performance beneﬁt for 3Dwas found [Cockburn and McKenzie 01].\\nAnother empirical study found no beneﬁts for 3D landscapes\\ncreated to reﬂect the density of a 2D point cloud, compared withsimply showing the point cloud in 2D [Tory et al. 07]. In the 3Dinformation landscape idiom, the density of the points on the plane\\nis computed as a derived attribute and used to construct a surfacewhose height varies according to this attribute in order to show\\nits value in a form similar to geographic terrain.\\n⋆A third alterna-⋆Other names for a 3D\\nlandscape are height ﬁeld\\nand terrain . tive to landscapes or points is a contour plot , where colored bands\\nshow the outlines of speciﬁc heights. A contour plot can be used\\n▶Contour plots are dis-\\ncussed in Section 8.4.1.alone as a 2D landscape or can be combined with 3D for a colored\\nlandscape. Proponents of this idiom have argued that landscapes', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c69798a7-936f-4160-9a1d-79a11faff263', embedding=None, metadata={'page_label': '130', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='130 6. Rules of Thumb\\n(a)\\n (b)\\n (c)\\n (d)\\n(e)\\n (f)\\n (g)\\nFigure 6.9. Point-based displays were found to outperform information landscapes in an empirical study of visual\\nencodings for dimensionally reduced data. (a) Colored points. (b) Grayscale points. (c) Colored 2D landscape.(d) Grayscale 2D landscape. (e) Colored 3D landscape. (f) Grayscale 3D landscape. (g) Height only. From [T oryet al. 07, Figure 1].\\nare familiar and engaging, and they have been used in several sys-\\ntems for displaying high-dimensional data after dimensionality re-\\nduction was used to reduce to two synthetic dimensions [Davidson\\net al. 01, Wise et al. 95].▶Dimensionality reduction\\nis discussed in Section13.4.3.\\nFigure 6.9 shows the seven possibilities tested in the empirical\\nstudy comparing points to colored and uncolored landscapes. Theﬁndings were that points were far superior to landscapes for search\\nand point estimation tasks and in the landscape case 2D land-scapes were superior to 3D landscapes [Tory et al. 07]. A follow-up study for a visual memory task yielded similar results [Toryet al. 09].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f595052-a305-4ffb-b8ea-dbf013700b67', embedding=None, metadata={'page_label': '131', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.4. No Unjustiﬁed 2D 131\\n6.4 No Unjustiﬁed 2D\\nLaying out data in 2D space should also be explicitly justiﬁed, com-\\npared with the alternative of simply showing the data with a 1Dlist.\\nLists have several strengths. First, they can show the maximal\\namount of information, such as text labels, in minimal space. Incontrast, 2D layouts such as node–link representations of networkdata require considerably more space to show the same number oflabels, so they have notably lower information density.\\nSecond, lists are excellent for lookup tasks when they are or-\\ndered appropriately, for example in alphabetical order when the\\ngoal is to ﬁnd a known label. In contrast, ﬁnding a speciﬁc labelin a 2D node–link representation might require the user to hunt\\naround the entire layout, unless a speciﬁc search capability is builtinto the vis tool.\\nWhen the task truly requires understanding the topological\\nstructure of the network, then the beneﬁts of showing those rela-tionships explicitly outweigh the cost of the space required. How-ever, some tasks are handled well by linear lists, even if the originaldata has network structure.\\n6.5 Eyes Beat Memory\\nUsing our eyes to switch between different views that are visible\\nsimultaneously has much lower cognitive load than consulting our\\nmemory to compare a current view with what was seen before.Many interaction idioms implicitly rely on the internal use of mem-ory and thus impose cognitive load on the viewer. Consider navi-gation within a single view, where the display changes to show thescene from a different viewpoint. Maintaining a sense of orienta-\\ntion implicitly relies on using internal resources, either by keeping\\ntrack of past navigation choices (for example, I zoomed into the\\nnucleus ) or by remembering past views (for example, earlier all the\\nstock options in the tech sector were in the top corner of the view ). In\\ncontrast, having a small overview window with a rectangle within\\nit showing the position and size of the current camera viewport for\\nthe main view is a way to show that information through an exter-nal representation easily consulted by looking at that region of thescreen, so that it can be read off by the perceptual system insteadof remembered.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3f1b91e-b93c-4f0a-b82f-a94948c88952', embedding=None, metadata={'page_label': '132', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='132 6. Rules of Thumb\\n6.5.1 Memory and Attention\\nBroadly speaking, people have two different categories of mem-\\nory: long-term memory that can last a lifetime, versus short-termmemory that lasts several seconds, also known as working mem-\\nory. While the capacity of long-term memory doesn’t have a strict\\nupper limit, human working memory is a very limited resource.When these limits are reached, people experience cognitive load\\nand will fail to absorb all of the information that is presented.\\nHuman attention also has severe limits. Conscious search for\\nitems is an operation that grows more difﬁcult with the numberof items there are to be checked. Vigilance is also a highly lim-ited resource: our ability to perform visual search tasks degradesquickly, with far worse results after several hours than in the ﬁrstfew minutes.\\n6.5.2 Animation versus Side-by-Side Views\\nSome animation-based idioms also impose signiﬁcant cognitive load\\non the viewer because of implicit memory demands. Animation isan overloaded word that can mean many different things consid-ered through the lens of vis encoding and interaction. I distinguishbetween these three deﬁnitions:\\n•narrative storytelling, as in popular movies;\\n•transitions from just one state to another;\\n•video-style playback of a multiframe sequence: play, pause,\\nstop, rewind, and step forward/back.\\nSome people have the intuition that because animation is a\\npowerful storytelling medium for popular movies, it should also besuitable in a vis context. However, the situation is quite different.Successful storytelling requires careful and deliberate choreogra-phy to ensure that action is only occurring in one place at a timeand the viewer’s eyes have been guided to ensure that they are\\nlooking in the right place. In contrast, a dataset animation might\\nhave simultaneous changes in many parts of the view.\\nAnimation is extremely powerful when used for transitions be-\\ntween two dataset conﬁgurations because it helps the user main-tain context. There is considerable evidence that animated transi-tions can be more effective than jump cuts, because they help peo-ple track changes in object positions or camera viewpoints. These', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c9c7d40f-c6c1-43bb-9226-14f7787f13fe', embedding=None, metadata={'page_label': '133', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.5. Eyes Beat Memory 133\\ntransitions are most useful when only a few things change; if the\\nnumber of objects that change between frames is large, people willhave a hard time tracking everything that occurs. We are blindto changes in regions of the image that are not the focus of ourattention.\\n▶Change blindness is cov-\\nered in Section 6.5.3.\\nAlthough jump cuts are hard to follow when only seen once,\\ngiving the user control of jumping back and forth between just twoframes can be effective for detecting whether there is a localizedchange between two scenes. This blink comparator idiom was used\\nby the astronomer who found Pluto.\\nFinally, I consider animations as sequences of many frames,\\nwhere the viewer can control the playback using video-style con-trols of play, pause, stop, rewind, and sometimes single-step for-ward or backward frame by frame. I distinguish animation fromtrue interactive control, for example, navigation by ﬂying througha scene. With animation the user does not directly control whatoccurs, only the speed at which the animation is played.\\nThe difﬁculty of multiframe animations is that making compar-\\nisons between frames that do not adjoin relies on internal memoryof what previous frames looked like. If changes only occur in one\\nplace at a time, the demands on attention and internal memory are\\nsmall. However, when many things change all over the frame andthere are many frames, we have a very difﬁcult time in trackingwhat happens. Giving people the ability to pause and replay theanimation is much better than only seeing it a single time straightthrough, but that control does not fully solve the problem.\\nFor tasks requiring detailed comparison across many frames,\\nseeing all the frames at once side by side can be more effectivethan animation. The number of frames must be small enoughthat the details within each can be discerned, so this approachis typically suitable for dozens but not hundreds of frames withcurrent display resolutions. The action also should be segmented\\ninto meaningful chunks, rather than keyframes that are randomly\\nchosen. Many vis idioms that use multiple views exploit this ob-servation, especially small multiples.\\n▶Small multiples are cov-\\nered in Section 12.3.2.\\n6.5.3 Change Blindness\\nThe human visual system works by querying the world around us\\nusing our eyes. Our visual system works so well that most peoplehave the intuition that we have detailed internal memory of thevisual ﬁeld that surrounds us. However, we do not. Our eyes dart\\naround, gathering information just in time for our need to use it, so', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='997d7b75-efa3-4a7f-ad9d-8d6c2247e89a', embedding=None, metadata={'page_label': '134', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='134 6. Rules of Thumb\\nquickly that we do not typically notice this motion at a conscious\\nlevel.\\nThe phenomenon of change blindness is that we fail to notice\\neven quite drastic changes if our attention is directed elsewhere.For example, experimenters set up a real-world interaction wheresomebody was engaged by a stranger who asked directions, onlyto be interrupted by people carrying a door who barged in betweenthem. The experimenters orchestrated a switch during this visualinterruption, replacing the questioner with another person. Re-markably, most people did not notice, even when the new ques-tioner was dressed completely differently—or was a different gen-der than the old one!\\nAlthough we are very sensitive to changes at the focus of our\\nattention, we are surprisingly blind to changes when our attention\\nis not engaged. The difﬁculty of tracking complex and widespreadchanges across multiframe animations is one of the implications ofchange blindness for vis.\\n6.6 Resolution over Immersion\\nPixels are precious: if you are faced with a trade-off between reso-\\nlution and immersion, resolution usually is far more important.\\nImmersive environments emphasize simulating realistic inter-\\naction and perception as closely as possible through technologysuch as stereo imagery delivered separately to each eye to en-hance depth perception, and full six-degree-of-freedom head andposition tracking so that the displays respond immediately to theuser’s physical motion of walking and moving the head around.The most common display technology is head-mounted displays,or small rooms with rear-projection displays on walls, ﬂoor, andceilings. Immersion is most useful when a sense of presence isan important aspect of the intended task. With current displayhardware, there is a trade-off between resolution , the number of\\navailable pixels divided by the display area, and immersion , the\\nfeeling of presence in virtual reality. The price of immersion isresolution; these displays cannot show as many pixels as state-of-the-art desktop displays of the equivalent area. The number ofpixels available on a computer display is a limited resource thatis usually the most critical constraint in vis design. Thus, it is\\n▶Display resolution con-\\nstraints are discussed inSection 1.13.\\nextremely rare that immersion is worth the cost in resolution.\\nAnother price of immersion is the integration of vis with the\\nrest of a user’s typical computer-based workﬂow. Immersive dis-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='81de6dfc-cff7-4564-a9e0-058e50355268', embedding=None, metadata={'page_label': '135', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.7. Overview First, Zoom and Filter, Details on Demand 135\\nplay environments are almost always special-purpose settings that\\nare a different physical location than the user’s workspace, requir-ing them to leave their usual ofﬁce and go to some other location,whether down the hall or in another building. In most cases usersstand rather than sit, so working for extended periods of time isphysically taxing compared with sitting at a desk. The most criticalproblem is that they do not have access to their standard workingenvironment of their own computer system. Without access to theusual input devices of mouse and keyboard, standard applicationssuch as web browsing, email reading, text and spreadsheet editing,and other data analysis packages are completely unusable in mostcases, and very awkward at best. In contrast, a vis system thatﬁts into a standard desktop environment allows integration withthe usual workﬂow and fast task switching between vis and otherapplications.\\nA compelling example of immersion is the use of virtual reality\\nfor phobia desensitization; somebody with a fear of heights wouldneed a sense of presence in the synthetic environment in order tomake progress. However, this example is not an application of vis,since the goal is to simulate reality rather than to visually encodeinformation. The most likely case where immersion would be help-ful for vis is when the chosen abstraction includes 3D spatial data.Even in this case, the designer should consider whether a sense ofpresence is worth the penalties of lower resolution and no workﬂowintegration. It is very rare that immersion would be necessary fornonspatial, abstract data. Using 3D for visual encoding of abstractdata is the uncommon case that needs careful justiﬁcation. The\\n▶The need for justifying 3D\\nfor abstract data is coveredin Section 6.3.\\nuse of an immersive display in this case would require even more\\ncareful justiﬁcation.\\n6.7 Overview First, Zoom and Filter, Details\\non Demand\\nBen Shneiderman’s inﬂuential mantra of Overview First, Zoom and\\nFilter, Details on Demand [Shneiderman 96] is a heavily cited de-\\nsign guideline that emphasizes the interplay between the need foroverview and the need to see details, and the role of data reductionin general and navigation in particular in supporting both.\\nA vis idiom that provides an overview is intended to give the\\nuser a broad awareness of the entire information space. Using thelanguage of the what–why–how analysis framework, it’s an idiom', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ffa702a0-eb3f-4b16-883e-9fdbc3353ad0', embedding=None, metadata={'page_label': '136', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='136 6. Rules of Thumb\\nwith the goal of summarize . A common goal in overview design\\nis to show all items in the dataset simultaneously, without anyneed for navigation to pan or scroll. Overviews help the user ﬁndregions where further investigation in more detail might be produc-tive. Overviews are often shown at the beginning of the explorationprocess, to guide users in choosing where to drill down to inspectin more detail. However, overview usage is not limited to initialreconnaissance; it’s very common for users to interleave the useof overviews and detail views by switching back and forth betweenthem many times.\\nWhen the dataset is sufﬁciently large, some form of reduce ac-\\ntion must be used in order to show everything at once. Overviewcreation can be understood in terms of both ﬁltering and aggre-gation. A simple way to create overviews is by zooming out ge-ometrically, so that the entire dataset is visible within the frame.Each object is drawn smaller, with less room to show detail. In thissense, overviews are created by removing all ﬁltering: an overviewis created by changing from a zoomed-in view where some itemsare ﬁltered out, to a zoomed-out view where all items are shown.When the number of items in a dataset is large enough, showingan overview of the entire dataset in a single screen using one markper item is impossible, even if the mark size is decreased to a sin-gle pixel. When the number of items to draw outstrips the numberof available pixels, the number of marks to show must be reducedwith aggregation. Moreover, even for datasets of medium size, ex-\\n▶Aggregation is discussed\\nin Section 13.4. plicitly designing an overview display using a more sophisticated\\napproach than simple geometric zooming can be fruitful. These\\ncustom overviews are similar in spirit to semantic zooming, in that\\nthe representation of the items is qualitatively different rather thansimply being drawn smaller than the full-detail versions. These▶Geometric and semantic\\nzooming are discussed inSection 11.5.\\nkinds of overviews often use dynamic aggregation that is implicitly\\ndriven by navigation, rather than being explicitly chosen by theuser.\\nThere is no crisp line dividing an “overview” from an “ordinary”\\nvis idiom, because many idioms provide some form of overview orsummary. However, it’s often useful to make a relative distinctionbetween a less detailed view that summarizes a lot of data and amore detailed view that shows a smaller number of data items with\\nmore information about each one. The former one is clearly the\\noverview , the latter one is the detail view . It’s particularly obvious\\nhow to distinguish between these when the idiom design choice ofmultiple views is being used; the mantra is particularly applicablewhen the detail view pops up in response to a select action by the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2bebaaf5-ac72-4c3f-ad16-0f08127ae349', embedding=None, metadata={'page_label': '137', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.8. Responsiveness Is Required 137\\nuser, but it’s also common for the detail view to be permanently\\nvisible side by side with the overview. There two other major fam-▶Chapter 12 covers multi-\\nple views.ilies of idioms that support overviewing. One is to use a single\\nview that dynamically changes over time by providing support for\\nreduce actions such as zooming and ﬁltering; then that single view\\nsometimes acts as an overview and sometimes as a detail view. The▶Chapter 13 covers ap-\\nproaches to data reduction.\\nthird choice is to embed both detailed focus and overview context\\ninformation together within a single view.▶Chapter 14 covers fo-\\ncus+context idioms.This mantra is most helpful when dealing with datasets of mod-\\nerate size. When dealing with enormous datasets, creating a usefuloverview for top-down exploration may not be feasible. In sloganform, an alternative approach is Search, Show Context, Expand on\\nDemand [van Ham and Perer 09], where search results provide the\\nstarting point for browsing of local neighborhoods.\\n6.8 Responsiveness Is Required\\nThe latency of interaction, namely, how much time it takes for the\\nsystem to respond to the user action, matters immensely for inter-action design. Our reaction to latency does not simply occur on acontinuum, where our irritation level gradually rises as things takelonger and longer. Human reaction to phenomena is best modeledin terms of a series of discrete categories, with a different timeconstant associated with each one. A system will feel responsive ifthese latency classes are taken into account by providing feedbackto the user within the relevant time scale. The three categoriesmost relevant for vis designers are shown in Table 6.1.\\nThe perceptual processing time constant of one-tenth of a sec-\\nond is relevant for operations such as screen updates. The immedi-ate response time constant of one second is relevant for operationssuch as visual feedback showing what item that user has selectedwith a mouse click, or the length of time for an animated transi-tion from one layout to another. The brief task time constant of ten\\nTime Constant\\nValue (in seconds)\\nperceptual processing 0.1\\nimmediate response 1\\nbrief tasks 10\\nTable 6.1. Human response to interaction latency changes dramatically at these\\ntime thresholds. After [Card et al. 91, T able 3].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fa3b5f1d-8243-41b1-b5c0-fbc7b9689fec', embedding=None, metadata={'page_label': '138', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='138 6. Rules of Thumb\\nseconds is relevant for breaking down complex tasks into simpler\\npieces; a good granularity for the smallest pieces is this brief tasktime.\\n6.8.1 Visual Feedback\\nFrom the user’s point of view, the latency of an interaction is\\nthe time between their action and some feedback from the sys-tem indicating that the operation has completed. In a vis system,that feedback would most naturally be some visual indication ofstate change within the system itself, rather than cumbersome ap-proaches such as printing out status indications at the console ora popup dialog box conﬁrmation that would interfere with the ﬂowof exploration.\\nThe most obvious principle is that the user should indeed have\\nsome sort of conﬁrmation that the action has completed, ratherthan being left dangling wondering whether the action is still inprogress, or whether the action never started in the ﬁrst place (forexample, because they missed the target and clicked on the back-ground rather than the intended object). Thus, feedback such ashighlighting a selected item is a good way to conﬁrm that the de-sired operation has completed successfully. In navigation, feed-back would naturally come when the user sees the new frameis drawn from the changed viewpoint. Visual feedback shouldtypically take place within the immediate response latency class:around one second.\\nAnother principle is that if an action could take signiﬁcantly\\nlonger than a user would naturally expect, some kind of progressindicator should be shown to the user. A good rule of thumb forsigniﬁcantly longer is crossing from one latency class into another,as shown in Table 6.1.\\n6.8.2 Latency and Interaction Design\\nSuccessful interaction design for a vis system depends on hav-\\ning a good match between the latencies of the low-level interaction\\nmechanism, the visual feedback mechanism, the system update\\ntime, and the cognitive load of operation itself.\\nFor example, consider the operation of seeing more details for\\nan item and the latency difference between three different low-levelinteraction mechanisms for doing so. Clicking on the item is slow-est, because the user must move the mouse toward the target lo-cation, stop the motion in the right place, and press down on the', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ecf5489f-dcd8-442a-b2a9-6a1517df4d1f', embedding=None, metadata={'page_label': '139', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.8. Responsiveness Is Required 139\\nmouse. Mouseover hover, where the cursor is placed over the ob-\\nject for some short period of dwell time but no click is required,may or may not be faster depending on the dwell time. Mouseoveractions with no dwell time requirement, where the action is trig-gered by the cursor simply crossing the object, are of course thefastest because the second step is also eliminated and only the ﬁrststep needs to take place.\\nFor visual feedback, consider three different mechanisms for\\nshowing the information. One is showing the information on aﬁxed detail pane at the side of the screen. In order to see the in-formation, the user’s eyes need to move from the current cursorlocation to the side of the screen, so this operation has relativelyhigh latency for making use of the visual feedback. On the otherhand, from a visual encoding point of view, an advantage is thata lot of detail information can be shown without occluding any-thing else in the main display. A second feedback mechanism isa popup window at the current cursor location, which is faster touse since there is no need to move the eyes away from trackingthe cursor. Since placing information directly in the view might oc-clude other objects, there is a visual encoding cost to this choice. Athird mechanism is a visual highlight change directly in the view,for instance by highlighting all neighbors within the graph that areone hop from the graph node under the cursor through a colorchange.\\nSystem update time is another latency to consider. With tiny\\ndatasets stored completely locally, update time will be negligible\\nfor any of these options. With larger datasets, the time to redraw\\nthe entire view could be considerable unless the rendering\\n⋆frame- ⋆The term rendering is\\nused in computer graphicsfor drawing an image. work has been designed to deliver frames at a guaranteed rate.\\nSimilarly, scalable rendering frameworks can support fast updatefor changing a few items or a small part of the display without re-drawing the entire screen, but most graphics systems do not offerthis functionality by default. Thus, designing systems to guar-antee immediate response to user actions can require signiﬁcantalgorithmic attention. With distributed datasets, obtaining detailsmay require a round trip from the client to the server, possiblytaking several seconds on a congested network.\\nWhen systems are designed so that all of these latencies are\\nwell matched, the user interacts ﬂuidly and can stay focused on\\nhigh-level goals such as building an internal mental model of thedataset. When there is a mismatch, the user is jarred out of astate of ﬂow [Csikszentmihalyi 91] by being forced to wait for thesystem.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5340e260-d1e8-4b88-bc1f-3c77e2241b88', embedding=None, metadata={'page_label': '140', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='140 6. Rules of Thumb\\n6.8.3 Interactivity Costs\\nInteractivity has both power and cost. The beneﬁt of interaction\\nis that people can explore a larger information space than can beunderstood in a single static image. However, a cost to interaction\\nis that it requires human time and attention. If the user must\\nexhaustively check every possibility, use of the vis system maydegenerate into human-powered search. Automatically detectingfeatures of interest to explicitly bring to the user’s attention via thevisual encoding is a useful goal for the vis designer. However, if thetask at hand could be completely solved by automatic means, there\\nwould be no need for a vis in the ﬁrst place. Thus, there is always\\na trade-off between ﬁnding automatable aspects and relying on thehuman in the loop to detect patterns.\\n6.9 Get It Right in Black and White\\nMaureen Stone has advocated the slogan Get It Right in Black and\\nWhite as a design guideline for effective use of color [Stone 10].\\nThat is, ensure that the most crucial aspects of visual represen-tation are legible even if the image is transformed from full colorto black and white. Do so by literally checking your work in blackand white, either with image processing or by simply printing out ascreenshot on a black and white printer. This slogan suggests en-coding the most important attribute with the luminance channel toensure adequate luminance contrast and considering the hue andsaturation channels as secondary sources of information.▶The principles of us-\\ning color to visually encode\\ndata are discussed in Sec-tion 10.2. Figure 12.13shows an example of ex-plicitly checking luminancecontrast between elements\\non different layers.\\n6.10 Function First, Form Next\\nThe best vis designs should shine in terms of both form and func-\\ntion; that is, they should be both beautiful and effective. Neverthe-less, in this book, I focus on function.\\nMy rationale is that given an effective but ugly design, it’s possi-\\nble to reﬁne the form to make it more beautiful while maintainingthe base of effectiveness. Even if the original designer of the vis hasno training in graphic design, collaboration is possible with peoplewho do have that background.\\nIn contrast, given a beautiful and ineffective design, you will\\nprobably need to toss it out and start from scratch. Thus, I don’tadvocate a “form ﬁrst” approach, because progressive reﬁnement', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9f8b076d-8395-470b-857e-b409d641ef52', embedding=None, metadata={'page_label': '141', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6.11. Further Reading 141\\nis usually not possible. My argument mirrors the claims I made in\\nthe ﬁrst chapter about the size of the vis design space and the factthat most designs are ineffective.\\nEqually important is the point that I don’t advocate “form never”:\\nvisual beauty does indeed matter, given that vis makes use of hu-man visual perception. Given the choice of two equally effectivesystems, where one is beautiful and one is ugly, people will preferthe better form. Moreover, good visual form enhances the effective-ness of visual representations.\\nI don’t focus on teaching the principles and practice of graphic\\ndesign in this book because they are covered well by many othersources. I focus on the principles of vis effectiveness because ofthe lack of other resources.\\n6.11 Further Reading\\nNo Unjustiﬁed 3D The differences between planar and depth spatial\\nperception and the characteristics of 3D depth cues are dis-cussed at length in both of Ware’s books [Ware 08, Ware 13].An in-depth discussion of the issues of 2D versus 3D [St. Johnet al. 01] includes references to many previous studies inthe human factors and air trafﬁc control literature includingthe extensive work of Wickens. Several careful experimentsoverturned previous claims of 3D beneﬁts over 2D [Cockburnand McKenzie 00, Cockburn and McKenzie 01, Cockburn andMcKenzie 04].\\nMemory Ware’s textbook is an excellent resource for memory and at-\\ntention as they relate to vis [Ware 13], with much more detailthan I provide here. A recent monograph contains an inter-\\nesting and thorough discussion of supporting and exploitingspatial memory in user interfaces [Scarr et al. 13].\\nAnimation An inﬂuential paper on incorporating the principles of\\nhand-drawn animation into computer graphics discusses theimportance of choreography to guide the viewer’s eyes duringnarrative storytelling [Lasseter 87]. A meta-review of anima-tion argues that many seemingly promising study results are\\nconfounded by attempts to compare incommensurate situa-\\ntions; the authors ﬁnd that small multiples are better thananimation if equivalent information is shown [Tversky et al. 02]and the segmentation is carefully chosen [Zacks and Tver-sky 03]. An empirical study found that while trend anima-', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fbbfb378-29ca-400a-991a-8898c9682a72', embedding=None, metadata={'page_label': '142', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='142 6. Rules of Thumb\\ntion was fast and enjoyable when used for presentation it did\\nlead to errors, and it was signiﬁcantly slower than both smallmultiples and trace lines for exploratory analysis [Robertsonet al. 08].\\nChange Blindness A survey paper is a good starting point for the\\nchange blindness literature [Simons 00].\\nOverview, Zoom and Filter, Details on Demand This early and inﬂuen-\\ntial mantra about overviews is presented in a very readablepaper [Shneiderman 96]. More recently, a synthesis reviewanalyzes the many ways that overviews are used in infovis[Hornbæk and Hertzum 11].\\nResponsiveness Is Required Card pioneered the discussion of latency\\nclasses for vis and human–computer interaction [Card et al. 91];\\nan excellent book chapter covering these ideas appears in avery accessible book on interface design [Johnson 10, Chap-ter 12]. The costs of interaction are discussed in a synthesis\\nreview [Lam 08] and a proposed framework for interaction [Yiet al. 07].\\nGet It Right in Black and White A blog post on Get It Right in Black\\nand White is a clear and concise starting point for the topic[Stone 10].\\nFunction First, Form Next A very accessible place to start for basic\\ngraphic design guidelines is The Non-Designer’s Design Book\\n[Williams 08].', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e85e1b8d-22a2-4b12-9afc-492d5b1f2c29', embedding=None, metadata={'page_label': '143', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='This page intentionally left blankThis page intentionally left blank', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='386ce652-255e-4b94-8c50-f012860804a5', embedding=None, metadata={'page_label': '144', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Arrange Tables\\nExpress Values\\nSeparate, Order, Align Regions\\nAxis Orientation\\nLayout Density\\nDense Space-FillingSeparate Order Align\\n1 Key 2  Keys 3 Keys Many Keys\\nList Recursive Subdivision Volume Matrix\\nRectilinear Parallel Radial\\nFigure 7.1. Design choices for arranging tables.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04a7d7e4-eb9e-493b-ac16-59d6433fbb03', embedding=None, metadata={'page_label': '145', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Arrange T ablesChapter 7\\n7.1 The Big Picture\\nFigure 7.1 shows the four visual encoding design choices for how\\nto arrange tabular data spatially. One is to express values. Theother three are to separate, order, and align regions. The spatialorientation of axes can be rectilinear, parallel, or radial. Spatiallayouts may be dense, and they may be space-ﬁlling.▶ A ﬁfth arrangement\\nchoice, to use a given spa-tial layout, is not an option\\nfor nonspatial information; it\\nis covered in Chapter 8.\\n7.2 Why Arrange?\\nThe arrange design choice covers all aspects of the use of spatial\\nchannels for visual encoding. It is the most crucial visual encod-\\ning choice because the use of space dominates the user’s mental\\nmodel of the dataset. The three highest ranked effectiveness chan-nels for quantitative and ordered attributes are all related to spatialposition: planar position against a common scale, planar positionalong an unaligned scale, and length. The highest ranked effectiv-ness channel for categorical attributes, grouping items within the\\nsame region, is also about the use of space. Moreover, there are\\nno nonspatial channels that are highly effective for all attributetypes: the others are split into being suitable for either orderedor categorical attributes, but not both, because of the principle ofexpressiveness.\\n▶The primacy of the spa-\\ntial position channels is dis-cussed at length in Chap-ter 5, as are the principles\\nof effectiveness and expres-\\nsiveness.\\n7.3 Arrange by Keys and Values\\nThe distinction between key and value attributes is very relevant to\\nvisually encoding table data. A key is an independent attribute that\\ncan be used as a unique index to look up items in a table, while avalue is a dependent attribute: the value of a cell in a table. Key▶See Section 2.6.1 for\\nmore on keys and values.\\nattributes can be categorical or ordinal, whereas values can be all\\n145', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3e75506c-440c-47ca-86e7-e8880fcc84c5', embedding=None, metadata={'page_label': '146', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='146 7. Arrange T ables\\nthree of the types: categorical, ordinal, or quantitative. The unique\\nvalues for a categorical or ordered attribute are called levels ,t o\\navoid the confusion of overloading the term value .\\nThe core design choices for visually encoding tables directly re-\\nlate to the semantics of the table’s attributes: how many keys andhow many values does it have? An idiom could only show val-ues, with no keys; scatterplots are the canonical example of show-ing two value attributes. An idiom could show one key and one\\nvalue attribute; bar charts are the best-known example. An idiomcould show two keys and one value; for example, heatmaps. Idiomsthat show many keys and many values often recursively subdivide\\nspace into many regions, as with scatterplot matrices.\\nWhile datasets do only have attributes with value semantics,\\nit would be rare to visually encode a dataset that has only keyattributes. Keys are typically used to deﬁne a region of space foreach item in which one or more value attributes are shown.\\n7.4 Express: Quantitative Values\\nUsing space to express quantitative attributes is a straightforward\\nuse of the spatial position channel to visually encode data. Theattribute is mapped to spatial position along an axis.\\nIn the simple case of encoding a single value attribute, each item\\nis encoded with a mark at some position along the axis. Additionalattributes might also be encoded on the same mark with othernonspatial channels such as color and size. In the more complexcase, a composite glyph object is drawn, with internal structure\\nthat arises from multiple marks. Each mark lies within a subregion\\nin the glyph that is visually encoded differently, so the glyph can\\nshow multiple attributes at once.\\n▶Glyphs and views are\\ndiscussed further in Sec-tion 12.4.\\nExample: Scatterplots\\nThe idiom of scatterplots encodes two quantitative value variables using\\nboth the vertical and horizontal spatial position channels, and the marktype is necessarily a point.\\nScatterplots are effective for the abstract tasks of providing overviews\\nand characterizing distributions, and speciﬁcally for ﬁnding outliers and\\nextreme values. Scatterplots are also highly effective for the abstract taskof judging the correlation between two attributes. With this visual en-coding, that task corresponds the easy perceptual judgement of noticing', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a4ef878e-6573-4339-bb60-135eb90904ae', embedding=None, metadata={'page_label': '147', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7.4. Express: Quantitative Values 147\\nFigure 7.2. Scatterplot. Each point mark represents a country, with horizontal\\nand vertical spatial position encoding the primary quantitative attributes of life ex-pectancy and infant mortality. The color channel is used for the categorical countryattribute and the size channel for quantitative population attribute. From [Robert-son et al. 08, Figure 1c].\\nwhether the points form a line along the diagonal. The stronger the cor-\\nrelation, the closer the points fall along a perfect diagonal line; positivecorrelation is an upward slope, and negative is downward. Figure 7.2shows a highly negatively correlated dataset.\\nAdditional transformations can also be used to shed more light on the\\ndata. Figure 7.3(a) shows the relationship between diamond price and\\nweight. Figure 7.3(b) shows a scatterplot of derived attributes createdby logarithmically scaling the originals; the transformed attributes arestrongly positively correlated.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='39ac699d-9d45-4b84-ab08-1fccd55dfce9', embedding=None, metadata={'page_label': '148', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='148 7. Arrange T ables\\n(a)\\n (b)\\nFigure 7.3. Scatterplots. (a) Original diamond price/carat data. (b) Derived log-scale attributes are highly positively\\ncorrelated. From [Wickham 10, Figure 10].\\nWhen judging correlation is the primary intended task, the derived\\ndata of a calculated regression line is often superimposed on the raw scat-terplot of points, as in Figures 7.3(b) and 1.3.\\nScatterplots are often augmented with color coding to show an addi-\\ntional attribute. Size coding can also portray yet another attribute; size-coded scatterplots are sometimes called bubble plots . Figure 7.2 shows an\\nexample of demographic data, plotting infant mortality on the vertical axisagainst life expectancy on the horizontal axis.\\nThe scalability of a scatterplot is limited by the need to distinguish\\npoints from each other, so it is well suited for dozens or hundreds of items.\\nThe table below summarizes this discussion in terms of a what–why–\\nhow analysis instance. All of the subsequent examples will end with asimilar summary table.\\nIdiom\\nScatterplots\\nWhat: Data T able: two quantitative value attributes.\\nHow: Encode Express values with horizontal and vertical spatial\\nposition and point marks.\\nWhy: T ask Find trends, outliers, distribution, correlation; locateclusters.\\nScale Items: hundreds.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e2e53dfe-34e6-4c74-bdd4-6fe5699cf1f9', embedding=None, metadata={'page_label': '149', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7.5. Separate, Order, and Align: Categorical Regions 149\\n7.5 Separate, Order, and Align:\\nCategorical Regions\\nThe use of space to encode categorical attributes is more complex\\nthan the simple case of quantitative attributes where the valuecan be expressed with spatial position. Spatial position is an or-dered magnitude visual channel, but categorical attributes haveunordered identity semantics. The principle of expressiveness\\nwould be violated if they are encoded with spatial position.\\nThe semantics of categorical attributes does match up well with\\nthe idea of a spatial region : regions are contiguous bounded areas\\nthat are distinct from each other. Drawing all of the items with thesame values for a categorical attribute within the same region usesspatial proximity to encode the information about their similarity,in a way that adheres nicely to the expressiveness principle. Thechoice to separate into regions still leaves enormous ﬂexibility inhow to encode the data within each region: that’s a different designchoice. However, these regions themselves must be given spatialpositions on the plane in order to draw any speciﬁc picture.\\nThe problem becomes easier to understand by breaking down\\nthe distribution of regions into three operations: separating intoregions, aligning the regions, and ordering the regions. The sepa-ration and the ordering always need to happen, but the alignmentis optional. The separation should be done according to an at-tribute that is categorical, whereas alignment and ordering shouldbe done by some other attribute that is ordered. The attributeused to order the regions must have ordered semantics, and thusit cannot be the categorical one that was used to do the separa-tion. If alignment is done, the ordered attribute used to control thealignment between regions is sometimes the same one that is used\\nto encode the spatial position of items within the region. It’s also\\npossible to use a different one.\\n7.5.1 List Alignment: One Key\\nWith a single key, separating into regions using that key yields\\none region per item. The regions are frequently arranged in aone-dimensional list alignment , either horizontal or vertical. The\\nview itself covers a two-dimensional area: the aligned list of itemsstretches across one of the spatial dimensions, and the region inwhich the values are shown stretches across the other.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9930eaf7-8b93-4410-a495-463b2d638c80', embedding=None, metadata={'page_label': '150', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='150 7. Arrange T ables\\nExample: Bar Charts\\nThe well-known bar chart idiom is a simple initial example. Figure 7.4\\nshows a bar chart of approximate weights on the vertical axis for each\\nof three animal species on the horizontal axis. Analyzing the visual en-coding, bar charts use a line mark and encode a quantitative value at-\\ntribute with one spatial position channel. The other attribute shown inthe chart, animal species, is a categorical key attribute. Each line markis indeed in a separate region of space, and there is one for each level ofthe categorical attribute. These line marks are all aligned within a com-mon frame, so that the highest-accuracy aligned position channel is usedrather than the lower-accuracy unaligned channel. In Figure 7.4(a) theregions are ordered alphabetically by species name. Formally, the alpha-\\nbetical ordering of the names should be considered a derived attribute.\\nThis frequent default choice does have the beneﬁt of making lookup byname easy, but it often hides what could be meaningful patterns in thedataset. Figure 7.4(b) shows this dataset with the regions ordered by thevalues of the same value attribute that is encoded by the bar heights,animal weight. This kind of data-driven ordering makes it easier to seedataset trends. Bar charts are also well suited for the abstract task oflooking up individual values.\\nThe scalability issues with bar charts are that there must be enough\\nroom on the screen to have white space interleaved between the bar linemarks so that they are distinguishable. A bar corresponds to a level of thecategorical key attribute, and it’s common to show between several anddozens of bars. In the limit, a full-screen chart with 1000 pixels couldhandle up to hundreds of bars, but not thousands.\\n100\\n75\\n50\\n25\\n0     \\nAnimal Type\\n(a)100\\n75\\n50\\n25\\n0     \\nAnimal Type\\n(b)\\nFigure 7.4. Bar chart. The key attribute, species , separates the marks along\\nthe horizontal spatial axis. The value attribute, weight , expresses the value with\\naligned vertical spatial position and line marks. (a) Marks ordered alphabeticallyaccording to species name. (b) Marks ordered by the weight attribute used for barheights.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='345c57ef-636b-4715-9a75-4ed31cc03255', embedding=None, metadata={'page_label': '151', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7.5. Separate, Order, and Align: Categorical Regions 151\\nIdiom Bar Charts\\nWhat: Data T able: one quantitative value attribute, one categori-\\ncal key attribute.\\nHow: Encode Line marks, express value attribute with aligned ver-tical position, separate key attribute with horizontalposition.\\nWhy: T ask Lookup and compare values.\\nScale Key attribute: dozens to hundreds of levels.\\nExample: Stacked Bar Charts\\nAstacked bar chart uses a more complex glyph for each bar, where multiple\\nsub-bars are stacked vertically. The length of the composite glyph stillencodes a value, as in a standard bar chart, but each subcomponent also\\nencodes a length-encoded value. Stacked bar charts show information\\nabout multidimensional tables, speciﬁcally a two-dimensional table withtwo keys. The composite glyphs are arranged as a list according to aprimary key. The other secondary key is used in constructing the verticalstructure of the glyph itself. Stacked bar charts are an example of a listalignment used with more than one key attribute. They support the taskof lookup according to either of the two keys.\\nStacked bar charts typically use color as well as length coding. Each\\nsubcomponent is colored according to the same key that is used to deter-\\nmine the vertical ordering; since the subcomponents are all abutted endto end without a break and are the same width, they would not be dis-tiguishable without different coloring. While it would be possible to useonly black outlines with white ﬁll as the rectangles within a bar, com-paring subcomponents across different bars would be considerably moredifﬁcult.\\nFigure 7.5 shows an example of a stacked bar chart used to inspect\\ninformation from a computer memory proﬁler. The key used to distributecomposite bars along the axis is the combination of a processor and aprocedure. The key used to stack and color the glyph subcomponents isthe type of cache miss; the height of each full bar encodes all cache missesfor each processor–procedure combination.\\nEach component of the bar is separately stacked, so that the full bar\\nheight shows the value for the combination of all items in the stack. The\\nheights of the lowest bar component and the full combined bar are botheasy to compare against other bars because they can be read off againstthe ﬂat baseline; that is, the judgement is position against a commonscale. The other components in the stack are more difﬁcult to compare', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='65cf93a4-c704-43ad-90ff-5b886d5a85fb', embedding=None, metadata={'page_label': '152', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='152 7. Arrange T ables\\nFigure 7.5. Stacked bar chart. The Thor memory proﬁler shows cache misses\\nstacked and colored by miss type. From [Bosch 01, Figure 4.1].\\nacross bars because their starting points are not aligned to a common\\nscale. Thus, the order of stacking is signiﬁcant for the kinds of patternsthat are most easily visible, in addition to the ordering of bars across themain axis, as with standard bar charts.▶Stacked bars are typi-\\ncally used for absolute data;relative proportions of partsto a whole can be shown\\nwith a normalized stacked\\nbar chart, where each barshows the same informationas in an entire pie chart, asdiscussed in Section 7.6.3.The scalability of stacked bar charts is similar to standard bar charts\\nin terms of the number of categories in the key attribute distributed acrossthe main axis, but it is more limited for the key used to stack the subcom-ponents within the glyph. This idiom works well with several categories,with an upper limit of around one dozen.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c2774817-79cd-4834-a373-010f0fb8591b', embedding=None, metadata={'page_label': '153', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7.5. Separate, Order, and Align: Categorical Regions 153\\nIdiom Stacked Bar Charts\\nWhat: Data Multidimensional table: one quantitative value at-\\ntribute, two categorical key attributes.\\nHow: Encode Bar glyph with length-coded subcomponents ofvalue attribute for each category of secondary keyattribute. Separate bars by category of primary keyattribute.\\nWhy: T ask Part-to-whole relationship, lookup values, ﬁndtrends.\\nScale Key attribute (main axis): dozens to hundreds of lev-els. Key attribute (stacked glyph axis): several to onedozen\\nExample: Streamgraphs\\nFigure 7.6 shows a more complex generalized stacked graph display idiom\\nwith a dataset of music listening history, with one time series per artist\\ncounting the number of times their music was listened to each week [By-ron and Wattenberg 08]. The streamgraph idiom shows derived geometry\\nthat emphasizes the continuity of the horizontal layers that represent theartists, rather than showing individual vertical glyphs that would empha-size listening behavior at a speciﬁc point in time.\\n1The derived geome-\\ntry is the result of a global computation, whereas individual glyphs canbe constructed using only calculations about their own local region. Thestreamgraph idiom emphasizes the legibility of the individual streams witha deliberately organic silhouette, rather than using the horizontal axis as\\nFigure 7.6. Streamgraph of music listening history. From [Byron and Wattenberg 08, Figure 0].\\n1In this case, the main axis showing the quantitative time attribute is horizon-\\ntal; both streamgraphs and stacked bar charts can be oriented either vertically or\\nhorizontally.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29946af9-1a84-4b72-8262-0e54de3fdccc', embedding=None, metadata={'page_label': '154', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='154 7. Arrange T ables\\n(a)\\n(b)\\nFigure 7.7. Streamgraphs with layers ordered by different derived attributes. (a)\\nVolatility of artist’s popularity. (b) Onset time when artist’s music of ﬁrst gainedattention. From [Byron and Wattenberg 08, Figure 15].\\nthe baseline. The shape of the layout is optimized as a trade-off between\\nmultiple factors, including the external silhouette of the entire shape, thedeviation of each layer from the baseline, and the amount of wiggle inthe baseline. The order of the layers is computed with an algorithm that\\nemphasizes a derived value; Figure 7.7 shows the difference between sort-\\ning by the volatility of the artist’s popularity, as shown in Figure 7.7(a),and the onset time when they begin to gain attention, as shown in Fig-ure 7.7(b).\\nStreamgraphs scale to a larger number of categories than stacked bar\\ncharts, because most layers do not extend across the entire length of thetimeline.\\nIdiom\\nStreamgraphs\\nWhat: Data Multidimensional table:\\none quantitative value attribute (counts), one or-dered key attribute (time), one categorical key at-tribute (artist).\\nWhat: Derived One quantitative attribute (for layer ordering).\\nHow: Encode Use derived geometry showing artist layers acrosstime, layer height encodes counts.\\nScale Key attributes (time, main axis): hundreds of timepoints. Key attributes (artists, short axis): dozens tohundreds', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='32f386c4-9bed-471a-a7dd-c21a4e86e2f4', embedding=None, metadata={'page_label': '155', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7.5. Separate, Order, and Align: Categorical Regions 155\\nExample: Dot and Line Charts\\nThe dot chart idiom is a visual encoding of one quantitative attribute using\\nspatial position against one categorical attribute using point marks, ratherthan the line marks of a bar chart.\\n⋆Figure 7.8(a) shows a dot chart of cat ⋆ The terms dot chart\\nand dot plot are some-\\ntimes used as synonymsand have been overloaded.I use dot chart here for\\nthe idiom popularized byCleveland [Becker et al. 96,\\nCleveland and McGill 84a],\\nwhereas Wilkinson [Wilkin-son 99] uses dot plot for\\nan idiom that shows distri-butions in a way similar to\\nthe histograms discussed in\\nSection 13.4.1.weight over time with the ordered variable of year on the horizontal axis\\nand the quantitative weight of a speciﬁc cat on the vertical axis.\\nOne way to think about a dot chart is like a scatterplot where one\\nof the axes shows a categorical attribute, rather than both axes showingquantitative attributes. Another way to think about a dot chart is like a\\nbar chart where the quantitative attribute is encoded with point marks\\nrather than line marks; this way matches more closely with its standarduse.\\nThe idiom of line charts augments dot charts with line connection\\nmarks running between the points. Figure 7.8(b) shows a line chart forthe same dataset side by side with the dot chart, plotting the weight of acat over several years. The trend of constantly increasing weight, followed\\nby loss after a veterinarian-imposed diet regime in 2010, is emphasized by\\nthe connecting lines.\\nIdiom\\nDot Charts\\nWhat: Data T able: one quantitative value attribute, one ordered\\nkey attribute.\\nHow: Encode Express value attribute with aligned vertical positionand point marks. Separate/order into horizontal re-gions by key attribute.\\n20\\n1510\\n50     \\nYear\\n(a)201510\\n50     \\nYear\\n(b)\\nFigure 7.8. Line charts versus dot charts. (a) Dot charts use a point mark to\\nshow the value for each item. (b) Line charts use point marks connected by linesbetween them.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0921f1d5-3693-46a3-ab2d-7f3e7ddd1093', embedding=None, metadata={'page_label': '156', 'file_name': 'Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_path': 'D:\\\\pythonProjects\\\\LammaIndex\\\\data\\\\Visualization analysis and design by Tamara Munzner (z-lib.org).pdf', 'file_type': 'application/pdf', 'file_size': 72905249, 'creation_date': '2024-09-21', 'last_modified_date': '2024-09-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='156 7. Arrange T ables\\nIdiom Line Charts\\nWhat: Data T able: one quantitative value attribute, one ordered\\nkey attribute.\\nHow: Encode Dot chart with connection marks between dots.\\nWhy Show trend.\\nScale Key attribute: hundreds of levels.\\nLine charts, dot charts, and bar charts all show one value at-\\ntribute and one key attribute with a rectilinear spatial layout. All ofthese chart types are often augmented to show a second categori-cal attribute using color or shape channels. They use one spatialposition channel to express a quantitative attribute, and use the\\nother direction for a second key attribute. The difference is that\\nline charts also use connection marks to emphasize the orderingof the items along the key axis by explicitly showing the relation-ship between one item and the next. Thus, they have a strongerimplication of trend relationships, making them more suitable for\\nthe abstract task of spotting trends.\\nLine charts should be used for ordered keys but not categor-\\nical keys. A line chart used for categorical data violates the ex-pressiveness principle, since it visually implies a trend where onecannot exist. This implication is so strong that it can overridecommon knowledge. Zacks and Tversky studied how people an-\\nswered questions about the categorical data type of gender versus\\nthe quantitative data type of age, as shown in Figure 7.9 [Zacks andTversky 99]. Line charts for quantitative data elicited appropriatetrend-related answers, such as “Height increases with age”. Barcharts for quantitative data elicited equally appropriate discrete-comparison answers such as “Twelve year olds are taller than ten\\nyear olds”. However, line charts for categorical data elicited inap-propriate trend answers such as “The more male a person is, thetaller he/she is”.\\nWhen designing a line chart, an important question to consider\\nis its aspect ratio : the ratio of width to height of the entire plot.\\nWhile many standard charting packages simply use a square or\\nsome other ﬁxed size, in many cases this default choice hides data-\\nset structure. The relevant perceptual principle is that our abilityto judge angles is more accurate at exact diagonals than at arbi-trary directions. We can easily tell that an angle like 43\\n◦is off from\\nthe exact 45◦diagonal, whereas we cannot tell 20◦from 22◦. The', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=SimpleDirectoryReader('data/').load_data()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e52c365-3b87-43d6-b898-ca5515701e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "you are a Q&A assistant. Your goal is to answer questions as accurately as possible \n",
    "based on the instructions and context provided.\n",
    "\"\"\"\n",
    "## Default format which is supportable by LLama2\n",
    "query_wrapper_prompt=SimpleInputPrompt('<|USER|>{query_str}<|ASSISTANT|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78b83b3-28c1-4397-8e53-e6bc4178b2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\26amr\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"insert the token here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16217473-9866-4c52-83c2-9dc2fdd97a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.62s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "llm=HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={'temperature':0.0,'do_sample':False},\n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name='meta-llama/Llama-2-7b-chat-hf',\n",
    "    model_name='meta-llama/Llama-2-7b-chat-hf',\n",
    "    device_map='auto',\n",
    "    # uncomment this if using CUDA to reduce memmory usage\n",
    "    model_kwargs={'torch_dtype':torch.float16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dcae41e-d2ab-4853-b86e-8e7b740f4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6fc3e1-b0ac-4a59-be0a-e75ea50001a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_11480\\440833903.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\26amr\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_model=LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c96a18-1e88-4bec-9a42-f9bc8251eb1d",
   "metadata": {},
   "source": [
    "## service context \n",
    "- combine all of these \n",
    "- llama 2 service context\n",
    "- bundle of commanly used resouces during the indexing and querying stage in a LlamaIndex pipeline\n",
    "- in short bundle the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51b94472-0e38-4c0b-a9e8-54ca18be4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_context=ServiceContext.from_defaults(\n",
    "#     chunk_size=1024,\n",
    "#     llm=llm,\n",
    "#     embed_model=embed_model\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ecd465d-9463-4ae8-a808-2917b6cb0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "\n",
    "Settings.chunk_size=1024\n",
    "Settings.llm=llm\n",
    "Settings.embed_model=embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0f4b0dc-5c88-4358-9b43-9e7d8a43824c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.service_context.ServiceContext"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02d861d5-a667-4c88-a069-e54af00f1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93a7dca5-0834-448e-8415-960bf313bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2a358db-5cdc-4e1e-8ed3-94b487d3f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Triggers in MySQL are a mechanism that allows you to automate specific actions in response to certain events, such as inserting, updating, or deleting data in a database table. Triggers are defined using a specific syntax and can be used to enforce business rules, validate data, or perform other actions based on the data changes in a table.\n",
      "\n",
      "In MySQL, a trigger can be defined using the following syntax:\n",
      "```sql\n",
      "CREATE TRIGGER trigger_name\n",
      "BEFORE/AFTER INSERT/UPDATE/DELETE ON table_name\n",
      "FOR EACH ROW\n",
      "BEGIN\n",
      "  -- PL/SQL code here\n",
      "END;\n",
      "```\n",
      "The trigger syntax defines the following parts:\n",
      "\n",
      "* `CREATE TRIGGER`: This keyword is used to create a new trigger.\n",
      "* `trigger_name`: This is the name of the trigger.\n",
      "* `BEFORE/AFTER`: This specifies the event that triggers the action, such as `BEFORE INSERT` or `AFTER UPDATE`.\n",
      "* `INSERT/UPDATE/DELETE`: This specifies the type of event that the trigger is associated with.\n",
      "* `ON table_name`: This specifies the table that the trigger is\n"
     ]
    }
   ],
   "source": [
    "response=query_engine.query('what are triggers in MySQL?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "204dccb7-f0ea-41e6-9e16-7240e71dbfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak entities are entities that have a relationship with another entity, but the primary key of the related entity does not contain a primary key component of the parent entity. In other words, a weak entity is an entity that is existence-dependent on another entity, but does not inherit a primary key component from the parent entity.\n",
      "\n",
      "Explanation:\n",
      "A weak entity is an entity that is existence-dependent on another entity, meaning that it cannot exist without the related entity. However, the primary key of the related entity does not contain a primary key component of the parent entity. This means that the related entity does not inherit a primary key component from the parent entity, and therefore, the relationship between the two entities is considered weak.\n",
      "\n",
      "For example, in the given context, the DEPENDENT entity is a weak entity because it is existence-dependent on the EMPLOYEE entity. The primary key of the DEPENDENT entity (DEP_NUM) does not contain a primary key component of the EMPLOYEE entity (EMP_NUM), so the relationship between the two entities is considered weak.\n",
      "\n",
      "Note that weak entities are also known as non-identifying relationships, and they are typically represented using a dashed\n"
     ]
    }
   ],
   "source": [
    "response=query_engine.query('what are weak entities?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0185cf-5095-4519-83b1-ead10f3362e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
